
from rest_framework.response import Response
from rest_framework import generics
from .models import appinfo,test_reports,job_offers,training_schedule,training_schedule_temp,company_login,course_schedule,course_trainer_feedback,comman_announcement,eligible_student_list,student_request, course_content_feedback, job_offers,company_master, skill_type,login,tests_candidates_answers,tests_candidates_map,test_master,question_master,candidate_master,content_master,skills_master,topic_master,test_type,question_type,college_master,department_master,trainer_master, rules, question_paper_master, job_offers, company_master,  student_request, course_trainer_feedback
from .serializers import testcandidatemapSerializersupdateNew,contentSerializers_NEW,folderSerializer,trainer_ReportSerializerstrain,CollegeSimpleSerializer,skilltypeSerializertrainer,StudentRequestSerializer,questionsSerializerImportPhysico,candidateSerializerImport,jobOffersSerializer,loginSerializerUpdatefunction,InvoiceDateUpdateSerializer,jobOfferSerializer,testReportsSerializer_testname,questionsPaperSerializer_Place,testReportsSerializer,courseStudentfeedbackSerializer,loginSerializerupdatepass,trainerSerializerSkills,eligible_studentSerializer,UserSerializer,studentRequestSerializer,trainerfeedbackSerializer,loginSerializer,companySerializer,jobSerializer,tests_candidates_answerSerializer,courseScheduleSerializer, courseContentFeedbackSerializer, testcandidatemapSerializers,testsSerializers,questionsSerializer,skilltypeSerializer,contentSerializers,collegeSerializers,departmentSerializers,questiontypeSerializers,testtypeSerializers,topicSerializers,skillSerializer,candidatesSerializer,trainerSerializer, testsSerializersImport, questionsSerializerImport, ruleSerializers, testsSerializersAddUpdate, questionsSerializerMasterData, loginSerializerStu, questionsSerializerCodeImport, candidatesoneSerializer, questionsPaperSerializer, questionsSerializer_IO, candidateuserSerializerImport, loginSerializerStuser, questionsSerializer_code, NonDbTestAssignSerializer, jobSerializer, companySerializer, studentRequestSerializer, trainerfeedbackSerializer
from rest_framework.decorators import api_view
from .forms import QuestionForm,QuestionFormMCQ,EligibleStudentListForm,ScreenshotsForm,AnnouncementUpdateForm,TrainerMasterForm,DocumentForm, QuestionCodeForm, CollegeForm, QuestionFormMCQ,CollegeFormUpdate
from django.http import HttpResponse 
from django.utils.timezone import localtime
from django.shortcuts import render, redirect
from .forms import QuestionImportForm,CCAnnouncementForm,TrainingScheduleFormUpdate,PlacementAnnouncementForm,CandidateUpdateForm,CompanyForm
from .models import question_master_temp
import docx
from django.views import View
from django.utils.timezone import now,localtime
from django.db import connection  # For debugging
import hashlib
import traceback
from django.db.models import Count, Q,Min, Case, When, Value,CharField, F,DateTimeField
from django.db.models.fields import DateTimeField
from django.db.models.functions import Concat,ExtractMonth,Length, TruncDate, TruncTime


from django.utils.dateformat import format as django_format_date

from rest_framework.decorators import api_view
from rest_framework.response import Response
from .models import tests_candidates_map
from django.utils.dateformat import format as django_format_date
from collections import defaultdict
from django.core.mail import EmailMessage
from django.conf import settings
from .models import test_master
from .serializers import TestMasterEmailUpdateSerializer

from rest_framework.views import APIView
from rest_framework.response import Response

from django.core.mail import EmailMessage
from django.db.models import IntegerField, CharField
from django.db.models.functions import Cast

from .serializers import TestroundUpdateSerializer

import json

from django.shortcuts import get_object_or_404
from django.db import transaction
from django.utils import timezone
import pandas as pd

from .models import invoice_form
from .serializers import invoice_formserializer
from django.utils.dateparse import parse_date
from twilio.rest import Client
import re

from rest_framework.generics import UpdateAPIView

from .models import question_paper_master
from .serializers import QuestionPaperSerializers
import base64
from django.shortcuts import get_object_or_404
from django.http import JsonResponse
from django.http.response import JsonResponse

from rest_framework import status
import pandas as pd
from django.views.decorators.csrf import csrf_exempt
from django.db.models import Avg, Sum, Subquery, OuterRef, Func
from docx.oxml.ns import qn
from .models import question_master, question_paper_master

import requests
import io

import json
from collections import OrderedDict
from itertools import chain
import time

from django.core.files.uploadedfile import InMemoryUploadedFile

from thefuzz import fuzz
import urllib.parse
import math
import random

from django.db.models import Avg, Sum, Subquery, OuterRef, Max, Q, Exists,F,Prefetch

import io,math,random,datetime,json,string,collections,itertools,functools
import sys
import builtins
from django.core.exceptions import ObjectDoesNotExist
from datetime import date
from io import StringIO
import datetime
import logging
import subprocess
import os,re,shutil
import uuid
import io,math,random,datetime,json,string,collections,itertools,functools
import sys
from django.conf import settings
from datetime import datetime
from io import BytesIO
from .serializers import  TestCandidateMapSerializerNeedInfo, testsSerializersAdd, testcandidatemapSerializersupdate

from django.utils.dateformat import format as django_format_date

import calendar

logger = logging.getLogger('app')
from django.db import transaction
from django.db import connection
from django.core.cache import cache
from django.core.files.base import ContentFile 
import threading
from django.core.mail import send_mass_mail

from .models import Screenshots


from django.contrib.postgres.aggregates import StringAgg
from collections import defaultdict

from random import shuffle
from .models import trainer_master, course_schedule
from django.core.mail import send_mail
from rest_framework.pagination import PageNumberPagination
from django.views.decorators.cache import cache_page



class CustomPagination(PageNumberPagination):
    page_size = 10  # Default number of items per page
    page_size_query_param = 'page_size'
    max_page_size = 100

#_____________________________Master Tables_____________________________________________#

class skilltypegetAPIView(generics.ListAPIView):
    queryset = skill_type.objects.filter(deleted=0).order_by('-id')
    serializer_class = skilltypeSerializer

    def get(self, request, *args, **kwargs):
       
        return super().get(request, *args, **kwargs)


class skilltypecreateAPIView(generics.CreateAPIView):
    queryset = skill_type.objects.all()
    serializer_class = skilltypeSerializer

    def create(self, request, *args, **kwargs):
       
        return super().create(request, *args, **kwargs)


class skilltypeRetrieveUpdateDestroyAPIView(generics.RetrieveUpdateAPIView):
    queryset = skill_type.objects.all()
    serializer_class = skilltypeSerializer

    def update(self, request, *args, **kwargs):
       # ##logger.debug('Updating skill type with id: %s', kwargs.get('pk'))
        return super().update(request, *args, **kwargs)

    def retrieve(self, request, *args, **kwargs):
       # ##logger.debug('Retrieving skill type with id: %s', kwargs.get('pk'))
        return super().retrieve(request, *args, **kwargs)


@api_view(['PUT', 'PATCH'])
def delete_skill_type(request, pk):
   # ##logger.debug('Entering delete_skill_type function with id: %s', pk)
    try:
        skilltype = skill_type.objects.get(id=pk)
      #  ##logger.debug('Skill type found: %s', skilltype)
    except skill_type.DoesNotExist:
        logger.error('Skill type with id %s not found', pk)
        return JsonResponse("Skill type not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    skilltype.deleted = 1
    skilltype.save()
   # ##logger.debug('Skill type marked as deleted: %s', skilltype)

    return JsonResponse("Skill 'deleted' field updated successfully", safe=False)


#------------------------------Test-type-------------------------------------------------------------#


class test_type_listView(generics.ListAPIView):
    queryset = test_type.objects.filter(deleted=0).order_by('-id')
    serializer_class = testtypeSerializers

    def get(self, request, *args, **kwargs):
       # #logger.info("Fetching test types where deleted=0")
        return super().get(request, *args, **kwargs)

class test_type_create(generics.CreateAPIView):
    queryset = test_type.objects.all()
    serializer_class = testtypeSerializers

    def post(self, request, *args, **kwargs):
      #  #logger.info("Creating a new test type")
        return super().post(request, *args, **kwargs)

class test_type_Update(generics.RetrieveUpdateAPIView):
    queryset = test_type.objects.all()
    serializer_class = testtypeSerializers

    def put(self, request, *args, **kwargs):
      #  #logger.info(f"Updating test type with id {kwargs.get('pk')}")
        return super().put(request, *args, **kwargs)

    def patch(self, request, *args, **kwargs):
       # #logger.info(f"Partially updating test type with id {kwargs.get('pk')}")
        return super().patch(request, *args, **kwargs)

@api_view(['PUT', 'PATCH'])
def delete_test_type(request, pk):
    try:
       # #logger.info(f"Attempting to mark test type with id {pk} as deleted")
        test_typevar = test_type.objects.get(id=pk)
    except test_type.DoesNotExist:
        logger.error(f"Test type with id {pk} not found")
        return JsonResponse("test_type not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    test_typevar.deleted = 1
    test_typevar.save()

   # #logger.info(f"Marked test type with id {pk} as deleted")
    return JsonResponse("test_type 'deleted' field updated successfully", safe=False)

#------------------------------------Question_type--------------------------------------#

class question_type_listView(generics.ListAPIView):
    serializer_class = questiontypeSerializers

    def get_queryset(self):
       # #logger.info("Fetching question types where deleted=0")
        queryset = question_type.objects.filter(deleted=0).order_by('-id')
        ##logger.info("Fetched question types successfully")
        return queryset

class question_type_create(generics.CreateAPIView):
    queryset = question_type.objects.all()
    serializer_class = questiontypeSerializers

    def post(self, request, *args, **kwargs):
        ##logger.info("Creating a new question type")
        response = super().post(request, *args, **kwargs)
        ##logger.info("Created a new question type successfully")
        return response

class question_type_Update(generics.RetrieveUpdateAPIView):
    queryset = question_type.objects.all()
    serializer_class = questiontypeSerializers

    def put(self, request, *args, **kwargs):
       # #logger.info(f"Updating question type with id {kwargs.get('pk')}")
        response = super().put(request, *args, **kwargs)
      #  #logger.info(f"Updated question type with id {kwargs.get('pk')} successfully")
        return response

    def patch(self, request, *args, **kwargs):
       # #logger.info(f"Partially updating question type with id {kwargs.get('pk')}")
        response = super().patch(request, *args, **kwargs)
       # #logger.info(f"Partially updated question type with id {kwargs.get('pk')} successfully")
        return response

@api_view(['PUT', 'PATCH'])
def delete_question_type(request, pk):
   # #logger.info(f"Attempting to mark question type with id {pk} as deleted")
    try:
        question_typevar = question_type.objects.get(id=pk)
    except question_type.DoesNotExist:
        logger.error(f"Question type with id {pk} not found")
        return JsonResponse("question_type not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    question_typevar.deleted = 1
    question_typevar.save()

   # #logger.info(f"Marked question type with id {pk} as deleted successfully")
    return JsonResponse("question_type 'deleted' field updated successfully", safe=False)


#------------------------------college----------------------------------------#
@api_view(['GET'])
def CollegeListView(request):
    """
    API view to fetch the list of colleges filtered by `deleted=0` 
    and ordered by `id` in descending order, using `.values()`.
    """
    try:
        # Fetch data using ORM with `.values()`
        queryset = college_master.objects.filter(deleted=0).order_by('-id').values(
            'id', 'college',  'college_group', 'college_code'
        )

        # Return the response
        return Response(list(queryset), status=status.HTTP_200_OK)

    except Exception as e:
        # Handle errors gracefully
        return Response(
            {'error': f'An error occurred: {str(e)}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )


@api_view(['PUT', 'PATCH'])
def delete_college(request, pk):
   
    try:
        college = college_master.objects.get(id=pk)
    except college_master.DoesNotExist:
        logger.error(f"College with id {pk} not found")
        return Response("college not found", status=404)

    college.deleted = 1
    college.save()

    return Response("college 'deleted' field updated successfully")


#----------------------------------------department---------------------------------------------#
@api_view(['GET'])
def DepartmentListView(request):
    """
    API view to fetch the list of colleges filtered by `deleted=0` 
    and ordered by `id` in descending order, using `.values()`.
    """
    try:
        # Fetch data using ORM with `.values()`
        queryset = department_master.objects.filter(deleted=0).order_by('-id').values(
            'id', 'department'
        )

        # Return the response
        return Response(list(queryset), status=status.HTTP_200_OK)

    except Exception as e:
        # Handle errors gracefully
        return Response(
            {'error': f'An error occurred: {str(e)}'},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

class departmentCreateView(generics.CreateAPIView):
    queryset = department_master.objects.all()
    serializer_class = departmentSerializers

    def post(self, request, *args, **kwargs):
       
        response = super().post(request, *args, **kwargs)
      
        return response

class departmentUpdateView(generics.RetrieveUpdateAPIView):
    queryset = department_master.objects.all()
    serializer_class = departmentSerializers

    def put(self, request, *args, **kwargs):
       
        response = super().put(request, *args, **kwargs)
       
        return response

    def patch(self, request, *args, **kwargs):
        
        response = super().patch(request, *args, **kwargs)
       
        return response

@api_view(['PUT', 'PATCH'])
def delete_department(request, pk):
   
    try:
        department = department_master.objects.get(id=pk)
    except department_master.DoesNotExist:
        logger.error(f"department with id {pk} not found")
        return Response("department not found", status=404)

    department.deleted = 1
    department.save()
    return Response("department 'deleted' field updated successfully")

#___________________________SKILL_master_________________________________________

class skillsAPIView(generics.ListAPIView):
    queryset = skills_master.objects.filter(deleted=0).order_by('-id')
    serializer_class = skillSerializer


class skillscreateAPIView(generics.CreateAPIView):
    queryset = skills_master.objects.all()
    serializer_class = skillSerializer

    def post(self, request, *args, **kwargs):
        
        response = super().post(request, *args, **kwargs)
        
        return response


class skillsRetrieveUpdateAPIView(generics.RetrieveUpdateAPIView):
    queryset = skills_master.objects.all()
    serializer_class = skillSerializer

    def put(self, request, *args, **kwargs):
        try:
            response = super().put(request, *args, **kwargs)
            return response
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

    def patch(self, request, *args, **kwargs):
        try:
            response = super().patch(request, *args, **kwargs)
            return response
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)


@api_view(['PUT', 'PATCH'])
def delete_skills(request, pk):
   
    try:
        print("Entering Function..")
        skills = skills_master.objects.get(id=pk)

        print("skill: ", skills)
    except skills_master.DoesNotExist:
        return JsonResponse("tests not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    skills.deleted = 1
    skills.save()
    print("skill: ", skills)

    return JsonResponse("skill 'deleted' field updated successfully", safe=False)


#___________________________________candidate_master________________________________________

@api_view(['GET'])
def get_candidate(request):
    try:
        # Create a cache key that uniquely identifies this query
        cache_key = 'candidate_master_data'
        
        # Try to get the data from the cache
        candidate_list = cache.get(cache_key)
        
        # If the data is not in the cache, fetch it from the database
        if not candidate_list:
            # Fetch all candidates with related data in one query
            candidate_data = candidate_master.objects.filter(deleted=0).select_related(
                'college_id', 'department_id'
            ).values(
                'id',
                'students_name',
                'user_name',
                'registration_number',
                'gender',
                'email_id',
                'mobile_number',
                'year',
                'cgpa',
                'marks_10th',
                'marks_12th',
                'marks_semester_wise',
                'history_of_arrears',
                'standing_arrears',
                'number_of_offers',
                'text',
                'it_of_offers',
                'core_of_offers',
                'college_id__college',   # Direct field access
                'college_id__id',        # Direct field access
                'department_id__department',  # Direct field access
                'department_id__id'      # Direct field access
            ).order_by('-id')

            # Convert the queryset into a list of dictionaries
            candidate_list = list(candidate_data)
            
            # Store the fetched data in the cache with a timeout
            cache.set(cache_key, candidate_list, timeout=300)  # Timeout is set to 1 hour (3600 seconds)
        
        # Return the cached or freshly fetched data
        return Response(candidate_list)
    except Exception as e:
        return Response({'error': str(e)}, status=500)



@api_view(['GET'])
def get_candidate_all(request):
    try:
        # Fetch candidates with related college, department, and prefetched skills
        candidatelist = candidate_master.objects.filter(deleted=0)\
            .select_related('college_id', 'department_id')\
            .prefetch_related('skill_id')\
            .values(
                'id', 
                'college_id', 
                'college_id__college',  # Get college name
                'students_name', 
                'user_name', 
                'registration_number', 
                'gender',
                'email_id', 
                'mobile_number', 
                'year', 
                'cgpa', 
                'department_id__department',  # Get department name
                'marks_10th',
                'marks_12th', 
                'marks_semester_wise', 
                'history_of_arrears', 
                'standing_arrears',
                'number_of_offers', 
                'text', 
                'it_of_offers', 
                'core_of_offers',
            )
        
        # Fetch skills for all candidates in a single query
        skill_mapping = {}
        skill_queryset = candidate_master.objects.filter(deleted=0)\
            .prefetch_related('skill_id')  # Prefetch skills

        for candidate in skill_queryset:
            skill_mapping[candidate.id] = [skill.id for skill in candidate.skill_id.all()]

        # Attach skills to candidates
        candidate_data = []
        for candidate in candidatelist:
            candidate['skill_id'] = skill_mapping.get(candidate['id'], [])
            candidate_data.append(candidate)

        return Response(candidate_data)
    except Exception as e:
        return Response({'error': str(e)}, status=500)
from django.db import IntegrityError

class candidatescreateAPIView(generics.CreateAPIView):
    queryset = candidate_master.objects.filter(deleted=0)
    serializer_class = candidatesSerializer

    def post(self, request, *args, **kwargs):        
        try:
            return super().post(request, *args, **kwargs)
        except IntegrityError as e:
            if 'user_name' in str(e):
                return Response({'error': 'Username already exists'}, status=status.HTTP_400_BAD_REQUEST)
            elif 'email_id' in str(e):
                return Response({'error': 'Email already exists'}, status=status.HTTP_400_BAD_REQUEST)
            else:
                return Response({'error': 'Something went wrong'}, status=status.HTTP_400_BAD_REQUEST)


class candidates_Select_Update(generics.RetrieveUpdateAPIView):
    queryset = candidate_master.objects.all()
    serializer_class = candidatesSerializer

    def update(self, request, *args, **kwargs):
        instance = self.get_object()
        serializer = self.get_serializer(instance, data=request.data, partial=True)
        serializer.is_valid(raise_exception=True)
        serializer.save()
        return Response(serializer.data)




@api_view(['PATCH'])
def delete_candidates(request):
    try:
        print("üöÄ Entering delete_candidates function...")

        data = request.data  # Get request body
        print(f"üì• Received data: {data}")

        candidate_ids = data.get("ids", [])  # Expecting list of IDs
        print(f"üÜî Extracted candidate IDs: {candidate_ids}")

        if not candidate_ids:
            print("‚ö†Ô∏è No candidate IDs provided!")
            return JsonResponse({"error": "No candidate IDs provided"}, status=400)

        # Update 'deleted' field for multiple records
        updated_count = candidate_master.objects.filter(id__in=candidate_ids).update(deleted=1)
        print(f"üîÑ Updated {updated_count} candidates' deleted field.")

        if updated_count == 0:
            print("‚ùå No matching candidates found!")
            return JsonResponse({"error": "No candidates found with given IDs"}, status=404)

        print(f"‚úÖ Successfully marked {updated_count} candidates as deleted.")
        return JsonResponse({"message": f"{updated_count} candidates marked as deleted"}, safe=False)

    except Exception as e:
        print(f"üî• Exception occurred: {e}")
        return JsonResponse({"error": str(e)}, status=500)

#____________________________________content_master________________________________________

@api_view(['GET'])
def get_content(request):
    try:
        search = request.query_params.get('search', '') 

        # Base query with static filters
        base_query = content_master.objects.filter(deleted=0)

        # Apply search filtering
        if search:
            base_query = base_query.filter(
                Q(topic__icontains=search)
            )

        # Annotate related fields and fetch required values
        content_data = base_query.values(
            'id',
            'topic',
            'question_type_id__question_type',  # Fetch the related question_type field
            'skill_type_id__skill_type',        # Fetch the related skill_type field
            'content_url',
            'actual_content',
            'worksheet_link',
        ).order_by('-id')

        # Initialize pagination
        paginator = CustomPagination()
        paginated_data = paginator.paginate_queryset(content_data, request)

        # Return the paginated response
        return paginator.get_paginated_response(paginated_data)

    except Exception as e:
        return Response(
            {"error": str(e), "message": "Failed to fetch content data."},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )


class contentcreateAPIView(generics.CreateAPIView):
    queryset = content_master.objects.all()
    serializer_class =contentSerializers_NEW

    def post(self, request, *args, **kwargs):
       
        response = super().post(request, *args, **kwargs)
       
        return response
class contentUpdateAPIView(generics.RetrieveUpdateDestroyAPIView):
    queryset = content_master.objects.all()
    serializer_class =contentSerializers

    def put(self, request, *args, **kwargs):
        
        response = super().put(request, *args, **kwargs)
       
        return response

    def patch(self, request, *args, **kwargs):
        ##logger.info(f"Partially updating Content with id {kwargs.get('pk')}")
        response = super().patch(request, *args, **kwargs)
        ##logger.info(f"Partially updated Content with id {kwargs.get('pk')} successfully")
        return response

@api_view(['PUT', 'PATCH'])
def delete_content(request, pk):
    ##logger.info(f"Attempting to mark Content with id {pk} as deleted")
    try:
        print("Entering Function..")
        content=content_master.objects.get(id=pk)

        print("content: ",content)
    except content_master.DoesNotExist:
        return JsonResponse("tests not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    content.deleted = 1
    content.save()

    ##logger.info(f"Marked Content with id {pk} as deleted successfully")

    print("content:content status changed deleted=0")

    return JsonResponse("content 'deleted' field updated successfully", safe=False)


#_______________________________________trainer_master__________________________________________________________

@api_view(['GET'])
def get_trainer_all(request):
    try:
        # Fetch trainers with related skills
        trainers = trainer_master.objects.filter(deleted=0).prefetch_related('skill_id').order_by('-id')

        # Serialize the data
        serializer = trainerSerializer(trainers, many=True, context={'request': request})

        return Response(serializer.data)
    except Exception as e:
        return Response({'error': str(e)}, status=500)

class TrainerCreateAPIView(generics.CreateAPIView):
    queryset = trainer_master.objects.all()
    serializer_class = trainerSerializer

    def post(self, request, *args, **kwargs):
        # Extract and decode the Base64 encoded resume
        resume_data = request.data.get('resume')
        if resume_data:
            # Remove the data URL scheme part
            resume_data = resume_data.split(',')[1]
            resume_content = base64.b64decode(resume_data)
            # Use the trainer_name to name the file
            fileName = str(uuid.uuid4())  #unique file name
            resume_file = ContentFile(resume_content, name=f'{fileName}.pdf')

            # Create a new instance of the serializer with the modified data
            data = request.data.copy()  # Create a mutable copy of request.data
            data['resume'] = resume_file  # Replace the 'resume' field with the new file
            
            # Instantiate the serializer with the modified data
            serializer = self.get_serializer(data=data)
            if serializer.is_valid():
                # Save the object if the data is valid
                self.perform_create(serializer)
                headers = self.get_success_headers(serializer.data)
                return Response(serializer.data, status=status.HTTP_201_CREATED, headers=headers)
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        else:
            return Response({"error": "No resume data provided"}, status=status.HTTP_400_BAD_REQUEST)


class TrainerRetrieveUpdateAPIView(generics.RetrieveUpdateAPIView):
    queryset = trainer_master.objects.all()
    serializer_class = trainerSerializer

    def put(self, request, *args, **kwargs):
        ##logger.info(f"Updating Trainer with id {kwargs.get('pk')}")
        response = super().put(request, *args, **kwargs)
        ##logger.info(f"Updated Trainer with id {kwargs.get('pk')} successfully")
        return response

    def patch(self, request, *args, **kwargs):
        ##logger.info(f"Partially updating Trainer with id {kwargs.get('pk')}")
        response = super().patch(request, *args, **kwargs)
        ##logger.info(f"Partially updated Trainer with id {kwargs.get('pk')} successfully")
        return response

@api_view(['PUT', 'PATCH'])
def delete_trainer(request, pk):
    ##logger.info(f"Attempting to mark Trainer with id {pk} as deleted")
    try:
        print("Entering Function..")
        trainer=trainer_master.objects.get(id=pk)

        print("trainer: ",trainer)
    except trainer_master.DoesNotExist:
        return JsonResponse("tests not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    trainer.deleted = 1
    trainer.save()

    ##logger.info(f"Marked Trainer with id {pk} as deleted successfully")

    print("content: ",trainer)

    return JsonResponse("trainer 'deleted' field updated successfully", safe=False)

#_____________________________________Test_________________________________________________________#


@api_view(['GET'])
def get_test(request):
    # Create a cache key that uniquely identifies this query
    cache_key = 'test_master_data'
    
    # Try to get the data from the cache
    test_data = cache.get(cache_key)
    
    # If the data is not in the cache, fetch it from the database
    if not test_data:
        test_data = list(test_master.objects.filter(deleted=0)
                        .select_related('test_type_id', 'question_type_id', 'skill_type_id')
                        .values(
                            'id',
                            'test_name',
                            'test_type_id__test_type',               # Fetch the related test_type field
                            'test_type_id__test_type_categories',    # Fetch the related test_type_categories field
                            'question_type_id__question_type',       # Fetch the related question_type field
                            'skill_type_id__skill_type'              # Fetch the related skill_type field
                        ))

        # Store the fetched data in the cache with a timeout
        cache.set(cache_key, test_data, timeout=3600)  # Timeout is set to 1 hour (3600 seconds)
    
    # Return the cached or freshly fetched data
    return Response(test_data)

class testcreateAPIView(generics.CreateAPIView):
    queryset = test_master.objects.all()
    serializer_class = testsSerializersAdd

    def post(self, request, *args, **kwargs):
        ##logger.info("Creating a new Test")
        response = super().post(request, *args, **kwargs)
        ##logger.info("Created a new Test successfully")
        return response

class testsRetrieveUpdateAPIView(generics.RetrieveUpdateAPIView):
    queryset = test_master.objects.all()
    serializer_class = testsSerializersAddUpdate

    def put(self, request, *args, **kwargs):
        ##logger.info(f"Updating Test with id {kwargs.get('pk')}")
        response = super().put(request, *args, **kwargs)
        ##logger.info(f"Updated Test with id {kwargs.get('pk')} successfully")
        return response

    def patch(self, request, *args, **kwargs):
        ##logger.info(f"Partially updating Test with id {kwargs.get('pk')}")
        response = super().patch(request, *args, **kwargs)
        ##logger.info(f"Partially updated Test with id {kwargs.get('pk')} successfully")
        return response

@api_view(['PUT', 'PATCH'])
def delete_tests(request, pk):
    ##logger.info(f"Attempting to mark Test with id {pk} as deleted")
    try:
        print("Entering Function..")
        test = test_master.objects.get(id=pk)

      
    except test_master.DoesNotExist:
        return JsonResponse("tests not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    test.deleted = 1
    test.save()

    ##logger.info(f"Marked Test with id {pk} as deleted successfully")

    print("skill1: ",test)

    return JsonResponse("skill 'deleted' field updated successfully", safe=False)


#____________________________test_candidate-map________________________________#


@api_view(['GET'])
@cache_page(60)  # Cache for 60 seconds
def get_tests_candidates_map(request):
    try:
        username = request.query_params.get('username')

        filters = {'deleted': 0}
        if username:
            filters['student_id__user_name'] = username

        # Efficient query: only join required fields
        query = tests_candidates_map.objects.filter(**filters).select_related(
            'college_id', 'department_id', 'student_id'
        ).only(
            'id', 'test_name',
            'college_id__college',
            'department_id__department',
            'student_id__students_name', 'student_id__user_name',
            'dtm_start', 'dtm_end', 'total_score', 'status'
        ).values(
            'id', 'test_name',
            'college_id__college',
            'department_id__department',
            'student_id__students_name', 'student_id__user_name',
            'dtm_start', 'dtm_end', 'total_score', 'status'
        )

        return Response(list(query))

    except Exception as e:
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)




@api_view(['GET'])
def get_tests_candidates_map_Update_ID(request): 
    # Get the test_name from request parameters
    testName = request.GET.get('test_name')
    
    if not testName:
        return Response({'error': 'test_name parameter is required'}, status=400)
    
    tests_candidates = tests_candidates_map.objects.filter(
        deleted=0, 
        test_name=testName
    ).select_related( 
        'rules_id', 'department_id', 'question_id', 'student_id', 'college_id'
    ).annotate(
        rules_id_value=F('rules_id__id'),
        question_id_value=F('question_id__id'),
    ).values(
        'id', 'test_name', 'question_id_value', 
        'dtm_start', 'dtm_end', 'duration', 'duration_type',
        'rules_id_value'
    )

    # Check if there are any candidates
    if tests_candidates.exists():
        # Get the first entry
        first_id = tests_candidates.first()['id']
        # Filter by the first ID
        tests_candidates = tests_candidates.filter(id=first_id)

        testing = tests_candidates.first()

        # Format the datetime fields
        dtm_start_formatted = django_format_date(localtime(testing['dtm_start']), 'd-m-Y h:i A')
        dtm_end_formatted = django_format_date(localtime(testing['dtm_end']), 'd-m-Y h:i A')

        # Prepare response data
        test_candidate_map_data = {
            'id': testing['id'],
            'test_name': testing['test_name'],
            'question_id': testing['question_id_value'], 
            'dtm_start': dtm_start_formatted,
            'dtm_end': dtm_end_formatted,
            'duration': testing['duration'],
            'duration_type': testing['duration_type'],
            'rules_id': testing['rules_id_value'],
        }
        
        return Response([test_candidate_map_data])  # Return as a list
    
    # If no candidates found
    return Response({'error': 'Test candidate map not found'}, status=404)



@api_view(['GET'])
def get_tests_Reports(request):
    try:
        # Fetch test candidates with necessary related fields
        tests_candidates = tests_candidates_map.objects.filter(deleted=0).select_related(
            'department_id', 'question_id', 'student_id', 'college_id'
        ).only(
            'id', 'test_name', 'college_id__college', 'department_id__department',
            'question_id__question_paper_name', 'dtm_start', 'dtm_end', 'is_camera_on',
            'is_active', 'year', 'need_candidate_info', 'total_score', 'avg_mark',
            'student_id__id', 'student_id__students_name', 'student_id__user_name',
            'student_id__email_id', 'student_id__mobile_number', 'student_id__gender',
            'student_id__registration_number'
        )

        # Fetch related test_master records in bulk and use a dictionary for quick lookup
        test_master_data = test_master.objects.select_related('question_type_id').only(
            'test_name', 'question_type_id__question_type'
        )
        test_master_dict = {
            test.test_name: test.question_type_id.question_type if test.question_type_id else None
            for test in test_master_data
        }

        # Prepare the response data
        def format_test_data(test):
            return {
                'id': test.id,
                'test_name': test.test_name,
                'college_id': test.college_id.college if test.college_id else None,
                'department_id': test.department_id.department if test.department_id else None,
                'question_id': test.question_id.question_paper_name if test.question_id else None,
                'dtm_start': django_format_date(localtime(test.dtm_start), 'd-m-Y h:i A') if test.dtm_start else None,
                'dtm_end': django_format_date(localtime(test.dtm_end), 'd-m-Y h:i A') if test.dtm_end else None,
                'is_camera_on': test.is_camera_on,
                'is_active': test.is_active,
                'year': test.year,
                'need_candidate_info': test.need_candidate_info,
                'total_score': test.total_score if test.total_score is not None else 'AA',
                'avg_mark': test.avg_mark,
                'student_id': test.student_id.id if test.student_id else None,
                'student_name': test.student_id.students_name if test.student_id else None,
                'user_name': test.student_id.user_name if test.student_id else None,
                'email_id': test.student_id.email_id if test.student_id else None,
                'mobile_number': test.student_id.mobile_number if test.student_id else None,
                'gender': test.student_id.gender if test.student_id else None,
                'registration_number': test.student_id.registration_number if test.student_id else None,
                'question_type': test_master_dict.get(test.test_name)  # Lookup question_type from pre-fetched data
            }

        test_candidate_map_data = [format_test_data(test) for test in tests_candidates]

        return Response(test_candidate_map_data)

    except Exception as e:
        return Response({'error': str(e)}, status=500)



class testcandidatemapUpdateAPIView(APIView):
    serializer_class = testcandidatemapSerializersupdateNew

    def get_queryset(self, request):
        test_name = request.data.get("test_name") or request.query_params.get("test_name")
        print(f"Querying for test_name: {test_name}")
        return tests_candidates_map.objects.filter(test_name=test_name)

    def _parse_datetime(self, value):
        """Parse DD-MM-YYYY hh:mm AM/PM ‚Üí datetime"""
        if not value:
            return None
        try:
            return datetime.strptime(value, "%d-%m-%Y %I:%M %p")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to parse datetime '{value}': {e}")
            return None

    def put(self, request, *args, **kwargs):
        print("‚úèÔ∏è PUT request received")
        print("Request data:", request.data)

        data = request.data.copy()
        queryset = self.get_queryset(request)

        if not queryset.exists():
            print("‚ùå Test not found")
            return Response({"detail": "Not found."}, status=status.HTTP_404_NOT_FOUND)

        # Convert frontend strings ‚Üí datetime
        if "dtm_start" in data:
            data["dtm_start"] = self._parse_datetime(data["dtm_start"])
        if "dtm_end" in data:
            data["dtm_end"] = self._parse_datetime(data["dtm_end"])

        # ORM bulk update
        # Prepare update fields
        update_fields = {
            "dtm_start": data.get("dtm_start"),
            "dtm_end": data.get("dtm_end"),
            "dtm_start1": data.get("dtm_start"),
            "dtm_end1": data.get("dtm_end"),
            "duration_type": data.get("duration_type"),
            "rules_id": data.get("rules_id"),
            "question_id": data.get("question_id"),
            "dtm_created": timezone.now(),
        }

        # Conditionally update 'duration'
        if data.get("duration_type") == "Start&EndTime":
            dtm_start = data.get("dtm_start")
            dtm_end = data.get("dtm_end")
            if dtm_start and dtm_end:
                calculated_duration = int((dtm_end - dtm_start).total_seconds() / 60)
                update_fields["duration"] = calculated_duration
        elif data.get("duration_type") == "QuestionTime":
            print("‚è±Ô∏è Skipping duration update for QuestionTime")

        # (Optional) Debug
        print("üõ†Ô∏è Final update fields:", update_fields)

        # ORM update
        queryset.update(**update_fields)

        
        print("‚úÖ Update successful")
        return Response({"detail": f"{queryset.count()} record(s) updated"}, status=status.HTTP_200_OK)

    def patch(self, request, *args, **kwargs):
        print("‚úèÔ∏è PATCH request received")
        return self.put(request, *args, **kwargs)  # Reuse logic


from rest_framework.decorators import api_view
from rest_framework.response import Response
from .models import tests_candidates_map, college_master

@api_view(['PUT', 'PATCH'])
def delete_testcandidatemap(request, test_name):
    """
    Mark tests_candidates_map.deleted = 1 for all records matching test_name and college_id
    """
    college_id = request.data.get('college_id')
    if not college_id:
        return Response({"error": "college_id is required in request body."}, status=400)

    try:
        # Ensure college_id is integer
        college_id = int(college_id)

        # Filter by test_name AND college_id
        queryset = tests_candidates_map.objects.filter(
            test_name=test_name,
            college_id=college_id
        )

        print(f"Found {queryset.count()} record(s) matching test_name='{test_name}' and college_id={college_id}")

        if not queryset.exists():
            return Response({"error": "No matching tests found"}, status=404)

        # Bulk update deleted field
        updated_count = queryset.update(deleted=1)
        print(f"Updated 'deleted' field for {updated_count} record(s)")

        return Response({"message": f"'deleted' field updated for {updated_count} record(s)."}, status=200)

    except Exception as e:
        print("Error:", str(e))
        return Response({"error": str(e)}, status=500)


@api_view(['PUT', 'PATCH'])
def update_testcandidatemap_is_active(request, pk):
    """
    Mark the candidate record as active and reset scores.
    """
    # Fetch the instance or return 404
    tests_candidate = get_object_or_404(tests_candidates_map, pk=pk)

    # Set the fields
    tests_candidate.is_active = True
    tests_candidate.total_score = 0
    tests_candidate.avg_mark   = 0

    # Save only the three changed fields for efficiency
    tests_candidate.save(update_fields=['is_active', 'total_score', 'avg_mark'])

    return Response(
        {
            "message": "Candidate activated and scores reset.",
            "id": pk,
            "is_active": tests_candidate.is_active,
            "total_score": tests_candidate.total_score,
            "avg_mark": tests_candidate.avg_mark
        },
        status=status.HTTP_200_OK
    )


@api_view(['PUT', 'PATCH'])
def update_testcandidatemap_status_login(request, student_id_value):
    try:
        current_date = now()
        # Update only needed fields without loading full objects
        updated_count = tests_candidates_map.objects.filter(
            student_id=student_id_value
        ).update(
            dtm_login=current_date,
            status="Database Updated"
        )

        if updated_count == 0:
            return JsonResponse({"message": "Tests not found"}, status=404)

        return JsonResponse({
            "message": f"{updated_count} entries updated successfully"
        })

    except Exception as e:
        return JsonResponse({
            "error": str(e)
        }, status=500)




@api_view(['PUT', 'PATCH'])
def update_testcandidatemap_status_submit(request, pk):
    try:
        print("Entering Function..")
        tests_candidates = tests_candidates_map.objects.get(id=pk)
        print("tests_candidates: ", tests_candidates)
    except tests_candidates_map.DoesNotExist:
        return JsonResponse("Tests not found", status=404)

    # Update fields
    currentDate = datetime.now()  # Assuming 'curr' is the current datetime
    tests_candidates.dtm_submit = currentDate 
    tests_candidates.status = "Submitted"  # Assuming you want to set status to this string
    
    tests_candidates.save()
    print("tests_candidates updated: ", tests_candidates)

    return JsonResponse("tests_candidates_map 'deleted' field updated successfully", safe=False)


@api_view(['PUT', 'PATCH'])
def update_testcandidatemap_status_start_test(request, pk):
    try:
        print("Entering Function..")
        tests_candidates = tests_candidates_map.objects.get(id=pk)
        print("tests_candidates: ", tests_candidates)
    except tests_candidates_map.DoesNotExist:
        return JsonResponse("Tests not found", status=404)

    # Update fields
    currentDate = datetime.now()  # Assuming 'curr' is the current datetime
    tests_candidates.dtm_start_test = currentDate 
    tests_candidates.status = "Test Started"
    tests_candidates.total_score = 0
    tests_candidates.avg_mark   = 0  # Assuming you want to set status to this string
    print("tests_candidates updated: ", tests_candidates)
    tests_candidates.save()
    print("tests_candidates updated: ", tests_candidates)

    return JsonResponse("tests_candidates_map 'deleted' field updated successfully", safe=False)

#__________________________test_candidate_answer____________________________

@api_view(['GET'])
@cache_page(60)  # Disable caching while debugging
def get_tests_candidates_answer(request):
    # Step 1: Get query params
    username = request.query_params.get('username')
    testName = request.query_params.get('testName')
    logger.info(f"[STEP 1] Received params - username: {username}, testName: {testName}")

    if not username or not testName:
        logger.warning("[STEP 1] Missing username or testName")
        return Response({"error": "username and testName are required"}, status=400)

    # Step 2: Find student_id from tests_candidates_map
    test_candidate_map = tests_candidates_map.objects.filter(
        deleted=0,
        student_id__user_name__iexact=username,
        test_name__iexact=testName
    ).values('student_id__id').first()

    if not test_candidate_map:
        logger.info("[STEP 2] No test candidate mapping found")
        return Response([])  # No mapping found

    student_id = test_candidate_map['student_id__id']
    logger.info(f"[STEP 2] Found student_id: {student_id}")

    # Step 2b: Print all answers for debugging
    all_answers_for_user_test = tests_candidates_answers.objects.filter(
        student_id__user_name__iexact=username,
        test_name__iexact=testName
    ).values('id', 'student_id__user_name', 'test_name', 'question_id__id', 'answer')
    print("[DEBUG] All answers for this username and testName:")
    print(list(all_answers_for_user_test))

    
    # Step 4: Fetch candidate answers for this student
    test_candidate_answer_data = tests_candidates_answers.objects.filter(
        deleted=0,
        student_id__id=student_id,
        test_name__iexact=testName
    ).select_related('student_id', 'question_id').order_by('-id').values(
        'id',
        'student_id__id',
        'question_id__id',
        'test_name',
        'answer',
        'result',
        'submission_compile_code',
    )
    logger.info(f"[STEP 4] Fetched {test_candidate_answer_data.count()} candidate answers")

    # Step 5: Return the response
    return Response(list(test_candidate_answer_data))


@csrf_exempt
@api_view(['POST'])
def test_candidates_answer_view(request, format=None):
    ques_id =  request.data.get('question_id')
    ans =  request.data.get('ans')
    code =  request.data.get('code')

    # code = urllib.parse.unquote(code)
    print("Parameters: ", ques_id, ans, code)
    
    try:
        question = question_master.objects.get(id=ques_id, deleted=0)
    except question_master.DoesNotExist:
        return JsonResponse({'error': 'Question not found'}, status=404)

    if question.answer == ans:
        result = question.mark
    else:
        # Handling multi-line strings
        similarity_score = fuzz.ratio(question.explain_answer.strip(), code.strip())
        result = round((similarity_score / 100) * question.mark)


    # Round the result to the nearest integer
    result = round(result)
    print("Result: ", result)
    
    test_candidate_answer_data = {
        'test_name': request.data.get('test_name'),
        'question_id': ques_id,
        'student_id': request.data.get('student_id'),
        'submission_compile_code': ans,
        'compile_code_editor': code,
        'result': result,
        'dtm_start': request.data.get('dtm_start'),
        'dtm_end': request.data.get('dtm_end'),
    }

    serializer = tests_candidates_answerSerializer(data=test_candidate_answer_data)
    print("Serializer: ", serializer)
    
    if serializer.is_valid():
        serializer.save()
        print('Test Answer is added Successfully')
        return JsonResponse(serializer.data, status=201)
    else:
        print(serializer.errors)
        return JsonResponse(serializer.errors, status=400)

@csrf_exempt
@api_view(['POST'])
def test_candidates_answer_view_Submit(request, format=None):
    ques_id =  request.data.get('question_id')
    ans =  request.data.get('ans')
    code =  request.data.get('code')

    # code = urllib.parse.unquote(code)
    print("Parameters: ", ques_id, ans, code)
    
    try:
        question = question_master.objects.get(id=ques_id, deleted=0)
    except question_master.DoesNotExist:
        return JsonResponse({'error': 'Question not found'}, status=404)

    if question.answer == ans:
        result = question.mark
    else:
        # Handling multi-line strings
        similarity_score = fuzz.ratio(question.explain_answer.strip(), code.strip())
        result = round((similarity_score / 100) * question.mark)


    # Round the result to the nearest integer
    result = round(result)
    print("Result: ", result)
    
    test_candidate_answer_data = {
        'test_name': request.data.get('test_name'),
        'question_id': ques_id,
        'student_id': request.data.get('student_id'),
        'answer': ans,
        'compile_code_editor': code,
        'result': result,
        'dtm_start': request.data.get('dtm_start'),
        'dtm_end': request.data.get('dtm_end'),
    }

    serializer = tests_candidates_answerSerializer(data=test_candidate_answer_data)
    print("Serializer: ", serializer)
    
    if serializer.is_valid():
        serializer.save()
        print('Test Answer is added Successfully')
        return JsonResponse(serializer.data, status=201)
    else:
        print(serializer.errors)
        return JsonResponse(serializer.errors, status=400)


class testcandidateanscreateAPIView(APIView):
    def post(self, request, *args, **kwargs):
        data = request.data
        student_id = data.get("student_id")
        test_name = data.get("test_name")
        question_id = data.get("question_id")

        if not (student_id and test_name and question_id):
            return Response({"status": "fail", "message": "Missing student_id, test_name or question_id"},
                            status=status.HTTP_400_BAD_REQUEST)

        defaults = {
            "answer": data.get("answer"),
            "result": data.get("result"),
            "dtm_start": data.get("dtm_start"),
            "dtm_end": data.get("dtm_end"),
            "submission_compile_code": data.get("submission_compile_code"),
            "compile_code_editor": data.get("compile_code_editor"),
            "test_case1": data.get("test_case1"),
            "test_case2": data.get("test_case2"),
            "test_case3": data.get("test_case3"),
            "modified_by": data.get("modified_by"),
            "dtm_modified": timezone.now(),
        }

        obj, created = tests_candidates_answers.objects.update_or_create(
            student_id_id=student_id,
            test_name=test_name,
            question_id_id=question_id,
            defaults=defaults
        )

        serializer = tests_candidates_answerSerializer(obj)
        return Response({
            "status": "success",
            "message": "Created" if created else "Updated",
            "data": serializer.data
        }, status=status.HTTP_200_OK)

class testcandidateansUpdateAPIView(generics.RetrieveUpdateDestroyAPIView):
    queryset = tests_candidates_answers.objects.all()
    serializer_class =tests_candidates_answerSerializer

    def put(self, request, *args, **kwargs):
        ##logger.info(f"Updating test-candidate-answer with id {kwargs.get('pk')}")
        response = super().put(request, *args, **kwargs)
        ##logger.info(f"Updated test-candidate-answer with id {kwargs.get('pk')} successfully")
        return response

    def patch(self, request, *args, **kwargs):
        ##logger.info(f"Partially updating test-candidate-answer with id {kwargs.get('pk')}")
        response = super().patch(request, *args, **kwargs)
        ##logger.info(f"Partially updated test-candidate-answer with id {kwargs.get('pk')} successfully")
        return response



@api_view(['PUT', 'PATCH'])
def delete_testcandidateanswer(request, pk):
    ##logger.info(f"Attempting to mark test-candidate-answer with id {pk} as deleted")

    try:
        print("Entering Function..")
        tests_candidates_ans=tests_candidates_answers.objects.get(id=pk)

        print("tests_candidates_ans: ",tests_candidates_ans)
    except tests_candidates_answers.DoesNotExist:
        return JsonResponse("tests not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    tests_candidates_ans.deleted = 1
    tests_candidates_ans.save()

    ##logger.info(f"Marked test-candidate-answer with id {pk} as deleted successfully")

    print("tests_candidates: ",tests_candidates_ans)

    return JsonResponse("tests_candidates_ans 'deleted' field updated successfully", safe=False)



#-----------------------------Login-----------------------------------------#
from django.db import IntegrityError


class login_create(generics.CreateAPIView):
    queryset = login.objects.all()
    serializer_class = loginSerializer

    def create(self, request, *args, **kwargs):
        try:
            response = super().create(request, *args, **kwargs)
            return response

        except IntegrityError as e:
            logger.error(f'IntegrityError in login_create: {e}')
            if 'user_name' in str(e):
                return Response({'error': 'Username already exists'}, status=status.HTTP_400_BAD_REQUEST)
            elif 'email_id' in str(e):
                return Response({'error': 'Email already exists'}, status=status.HTTP_400_BAD_REQUEST)
            return Response({'error': 'A database error occurred'}, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            logger.error(f'Unexpected error in login_create: {e}')
            return Response({'error': 'An error occurred while creating login'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

@api_view(['GET'])
def get_login(request):
    try:
        # Fetch login records with related college data using ORM
        login_data = login.objects.select_related('college_id').filter(deleted=0).values(
            'id',
            'email_id',
            'user_name',
            'password',
            'role',
            'college_id__id',      # related college ID
            'college_id__college', # related college name
            'remarks',             # üëà include remarks
            'mobile_number'        # üëà include mobile number
        )

        # Rename fields to match the desired output
        formatted_login_data = [
            {
                'id': entry['id'],
                'email_id': entry['email_id'],
                'user_name': entry['user_name'],
                'password': entry['password'],
                'role': entry['role'],
                'college_id': entry['college_id__id'],
                'college_name': entry['college_id__college'],
                'remarks': entry['remarks'],                 # üëà added
                'mobile_number': entry['mobile_number'],     # üëà added
            }
            for entry in login_data
        ]

        return Response(formatted_login_data)
    except Exception as e:
        logger.error(f'Error occurred in get_login function: {e}')
        return Response({'error': 'An error occurred'}, status=500)


class update_login_password(generics.RetrieveUpdateAPIView):
    queryset = login.objects.all()
    serializer_class = loginSerializerupdatepass
    lookup_field = 'user_name' 


@api_view(['PUT', 'PATCH'])
def delete_login(request, pk):
    try:
        print("Entering Function..")
        # Fetch the login entry
        logins = login.objects.get(id=pk)
        print("Login entry: ", logins)
    except login.DoesNotExist:
        return JsonResponse("Login not found", status=404)

    # Soft delete the login by setting 'deleted' to 1
    logins.deleted = 1
    logins.save()
    print("Login after update: ", logins)

    # If the role is 'Trainer', look for a matching trainer_master entry
    if logins.role == 'Trainer':  # Assuming you have a role field in your login model
        try:
            # Compare the user_name from login with trainer_master user_name
            trainer = trainer_master.objects.get(user_name=logins.user_name)
            # Soft delete the trainer by setting 'deleted' to 1
            trainer.deleted = 1
            trainer.save()
            print("Trainer after update: ", trainer)
        except trainer_master.DoesNotExist:
            return JsonResponse("Trainer not found in trainer_master", status=404)

    # If the role is 'Student', look for a matching candidate_master entry
    elif logins.role == 'Student':  # Assuming you have a role field in your login model
        try:
            # Compare the user_name from login with candidate_master user_name
            candidate = candidate_master.objects.get(user_name=logins.user_name)
            # Soft delete the candidate by setting 'deleted' to 1
            candidate.deleted = 1
            candidate.save()
            print("Candidate after update: ", candidate)
        except candidate_master.DoesNotExist:
            return JsonResponse("Candidate not found in candidate_master", status=404)

    return JsonResponse("Login, Trainer/Student 'deleted' field updated successfully", safe=False)


#-----------------------------Course Schedule-----------------------------------------#
class add_course_schedule(generics.CreateAPIView):
    queryset = course_schedule.objects.all()
    serializer_class = courseScheduleSerializer

@api_view(['GET'])
def get_student_schedule(request):
    try:
        search = request.query_params.get('search', '')
        topic = request.query_params.get('topic')
        college = request.query_params.get('college')
        training_date = request.query_params.get('training_date')
        source = request.query_params.get('source')  # ‚úÖ this decides which table to use

        if not source or source not in ['course', 'training']:
            return Response({"error": "Missing or invalid 'source' parameter"}, status=status.HTTP_400_BAD_REQUEST)

        if source == 'course':
            queryset = course_schedule.objects.filter(deleted=0).select_related(
                'college_id', 'student_id', 'department_id', 'topic_id'
            )
            if topic:
                queryset = queryset.filter(topic_id__topic=topic)
            if college:
                queryset = queryset.filter(college_id__college=college)
            if training_date:
                queryset = queryset.filter(dtm_of_training=training_date)
            if search:
                queryset = queryset.filter(
                    Q(topic_id__topic__icontains=search) |
                    Q(college_id__college__icontains=search) |
                    Q(student_id__students_name__icontains=search)
                )

            data = queryset.values(
                'id',
                'college_id__college',
                'college_id__id',
                'student_id__students_name',
                'year',
                'department_id__department',
                'department_id__id',
                'topic_id__topic',
                'topic_id__sub_topic',
                'trainer_ids',
                'dtm_start_student',
                'dtm_end_student',
                'dtm_start_trainer',
                'dtm_end_trainer',
                'dtm_of_training',
            )

            # Process trainer names
            result = []
            for item in data:
                trainer_ids = item.get('trainer_ids', [])
                trainer_names = []
                if trainer_ids:
                    trainers = trainer_master.objects.filter(id__in=trainer_ids, deleted=0)
                    trainer_names = [t.trainer_name for t in trainers]

                result.append({
                    'id': item['id'],
                    'college_name': item['college_id__college'],
                    'college_id': item['college_id__id'],
                    'student_name': item['student_id__students_name'],
                    'year': item['year'],
                    'department_name': item['department_id__department'],
                    'department_id': item['department_id__id'],
                    'topic_name': item['topic_id__topic'],
                    'sub_topic': item['topic_id__sub_topic'],
                    'trainer_ids': trainer_ids,
                    'trainer_names': trainer_names,
                    'dtm_start_student': item['dtm_start_student'],
                    'dtm_end_student': item['dtm_end_student'],
                    'dtm_start_trainer': item['dtm_start_trainer'],
                    'dtm_end_trainer': item['dtm_end_trainer'],
                    'dtm_of_training': item['dtm_of_training'],
                })

        elif source == 'training':
            queryset = training_schedule.objects.filter(deleted=0).select_related(
                'college_id', 'topic_id', 'trainer_id'
            )

            if topic:
                queryset = queryset.filter(topic_id__topic=topic)
            if college:
                queryset = queryset.filter(college_id__college=college)
            if training_date:
                queryset = queryset.filter(dtm_of_training=training_date)
            if search:
                queryset = queryset.filter(
                    Q(topic_id__topic__icontains=search) |
                    Q(college_id__college__icontains=search) |
                    Q(trainer_id__trainer_name__icontains=search)
                )

            result = []
            for schedule in queryset:
                student_ids = schedule.student_ids or []

                students = candidate_master.objects.filter(id__in=student_ids, deleted=0).values('id', 'students_name')

                for student in students:
                    result.append({
                        'id': schedule.id,
                        'college_name': schedule.college_id.college if schedule.college_id else None,
                        'college_id': schedule.college_id.id if schedule.college_id else None,
                        'student_id': student['id'],
                        'student_name': student['students_name'],
                        'year': None,
                        'department_name': None,
                        'department_id': None,
                        'topic_name': schedule.topic_id.topic if schedule.topic_id else None,
                        'sub_topic': schedule.topic_id.sub_topic if schedule.topic_id else None,
                        'trainer_ids': [schedule.trainer_id.id] if schedule.trainer_id else [],
                        'trainer_names': [schedule.trainer_id.trainer_name] if schedule.trainer_id else [],
                        'dtm_start_student': schedule.dtm_start_student,
                        'dtm_end_student': schedule.dtm_end_student,
                        'dtm_start_trainer': schedule.dtm_start_trainer,
                        'dtm_end_trainer': schedule.dtm_end_trainer,
                        'dtm_of_training': schedule.dtm_of_training,
                    })

        paginator = CustomPagination()
        paginated_data = paginator.paginate_queryset(result, request)
        return paginator.get_paginated_response(paginated_data)

    except Exception as e:
        print(f"‚ùå Error in get_course_schedule: {str(e)}")
        return Response(
            {"error": "An error occurred while fetching schedule data."},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

class update_course_schedule(generics.UpdateAPIView):
    queryset = course_schedule.objects.all()
    serializer_class = courseScheduleSerializer



@api_view(['PUT', 'PATCH'])
def delete_course_schedule(request, pk):
    try:
        print("Entering Function..")
        course = course_schedule.objects.get(id=pk)

        print("course: ", course)
    except course_schedule.DoesNotExist:
        return JsonResponse("course not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    course.deleted = 1
    course.save()
    print("logins: ", course)

    return JsonResponse("course 'deleted' field updated successfully", safe=False)



#-----------------------------Course Content Feedback-----------------------------------------#

class add_course_content_feedback(generics.CreateAPIView):
    queryset = course_content_feedback.objects.all()
    serializer_class = courseContentFeedbackSerializer

    def post(self, request, *args, **kwargs):
        ##logger.info("Creating a new Course content feedback")
        response = super().post(request, *args, **kwargs)
        ##logger.info("Created a new Course content feedback successfully")
        return response



@api_view(['GET'])
def get_course_content_feedback(request):
    try:
        # Fetch data with related fields using select_related and values
        course_content_feedback_data = course_content_feedback.objects.filter(deleted=0).select_related(
            'student_id__college_id', 'student_id__department_id', 'topic_id', 'trainer_id'
        ).values(
            'id',
            'student_id__students_name', 
            'student_id__college_id__college',
            'student_id__department_id__department',
            'topic_id__topic',
            'topic_id__sub_topic',
            'trainer_id__trainer_name',
            'dtm_session',
            'feedback',
            'remarks'
        )

        # Rename the fields as per the desired output format
        formatted_course_content_feedback_data = [
            {
                'id': content['id'],
                'student_name': content['student_id__students_name'],
                'college_name': content['student_id__college_id__college'],
                'department_name': content['student_id__department_id__department'],
                'topic': content['topic_id__topic'],
                'sub_topic': content['topic_id__sub_topic'],
                'trainer_name': content['trainer_id__trainer_name'],
                'dtm_session': content['dtm_session'],
                'feedback': content['feedback'],
                'remarks': content['remarks']
            }
            for content in course_content_feedback_data
        ]

        return Response(formatted_course_content_feedback_data)
    except Exception as e:
        logger.error(f'Error occurred in get_course_content_feedback function: {e}')
        return Response({'error': 'An error occurred'}, status=500)


class update_course_content_feedback(generics.UpdateAPIView):
    queryset = course_content_feedback.objects.all()
    serializer_class = courseContentFeedbackSerializer

    def put(self, request, *args, **kwargs):
        ##logger.info(f"Updating course content feedback with id {kwargs.get('pk')}")
        response = super().put(request, *args, **kwargs)
        ##logger.info(f"Updated course content feedback with id {kwargs.get('pk')} successfully")
        return response

    def patch(self, request, *args, **kwargs):
        ##logger.info(f"Partially updating course content feedback with id {kwargs.get('pk')}")
        response = super().patch(request, *args, **kwargs)
        ##logger.info(f"Partially updated course content feedback with id {kwargs.get('pk')} successfully")
        return response



@api_view(['PUT', 'PATCH'])
def delete_course_content_feedback(request, pk):
    ##logger.info(f"Attempting to mark course content feedback with id {pk} as deleted")

    try:
        print("Entering Function..")
        course = course_content_feedback.objects.get(id=pk)

        print("course: ", course)
    except course_content_feedback.DoesNotExist:
        return JsonResponse("course not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    course.deleted = 1
    course.save()

    ##logger.info(f"Marked course content feedback with id {pk} as deleted successfully")

    print("course: ", course)

    return JsonResponse("course 'deleted' field updated successfully", safe=False)

#--------------------------------------Import Database-----------------------------------#

def get_college_id(college_name):
    college_instance = college_master.objects.filter(college=college_name,deleted=0).first()
    if not college_instance:
        raise ValueError(f"College '{college_name}' not found")
    return college_instance.id

def get_college_id_and_group(college_name, college_group=None):
    """
    Retrieve the ID of a college based on the college name and optional college group.
    
    Parameters:
    - college_name (str): Name of the college.
    - college_group (str, optional): Branch or group of the college.

    Returns:
    - int: ID of the matching college.

    Raises:
    - ValueError: If the college does not exist, or if multiple entries exist and `college_group` is not provided.
    """
    try:
        # Fetch all colleges matching the provided name
        college_queryset = college_master.objects.filter(college=college_name,deleted=0)

        # Check if the college exists
        if not college_queryset.exists():
            raise ValueError(f"College '{college_name}' not found.")

        # Handle cases with multiple entries
        if college_queryset.count() > 1:
            # If `college_group` is not provided, raise an error
            if college_group is None:
                raise ValueError(f"College branch (college_group) is required for '{college_name}' due to multiple entries.")
            
            # Find the specific college entry with the provided `college_group`
            college_with_group = college_queryset.filter(college_group=college_group).first()
            if not college_with_group:
                raise ValueError(f"College '{college_name}' with branch '{college_group}' not found.")
            return college_with_group.id

        # If there's only one entry, return its ID
        return college_queryset.first().id

    except college_master.DoesNotExist:
        raise ValueError(f"College '{college_name}' not found.")

def get_department_id(department_name):
    department_instance = department_master.objects.filter(department=department_name,deleted=0).first()
    if not department_instance:
        raise ValueError(f"Department '{department_name}' not found")
    return department_instance.id

# Function to handle conversion of float values to clean strings (removes .0, handles NaN)
def clean_char_field(value):
    if pd.isna(value):
        return ''
    if isinstance(value, float) and value.is_integer():
        return str(int(value))
    return str(value).strip()


class ExcelImportView_CandidateLAST(APIView):
    def post(self, request, format=None):
        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)
        
        file = request.FILES['file']
        print('file: ', file)
        
        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            df = pd.read_excel(file)
            print('df: ', df)
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)
        print("Step 3: Renaming columns using header_mapping")
        header_mapping = {
            'College Name**': 'college_id',
            'College Branch': 'college_group',
            'Batch': 'batch_no',
            'Student Name': 'students_name',
            'User Name**': 'user_name',
            'Reg No': 'registration_number',
            'Gender': 'gender',
            'Email ID': 'email_id',
            'Mobile Number': 'mobile_number',
            'Year**': 'year',
            'CGPA': 'cgpa',
            'Department**': 'department_id',
            '10th Mark': 'marks_10th',
            '12th Mark': 'marks_12th',
           
            'History Of Arrears': 'history_of_arrears',
            'Standing Arrears': 'standing_arrears',
            'No.Of.IT Offers': 'it_of_offers',
            'No.Of.Core Offers': 'core_of_offers',
            'No.Of.Offers': 'number_of_offers',
            'Password**': 'password'
        }
        
        df.rename(columns=header_mapping, inplace=True)

        char_fields = ['college_id', 'user_name', 'year', 'password']  # Add any other char fields as needed

        # Combine clean_char_field and strip operations in one loop
        for column in df.columns:
            if column in char_fields:
                df[column] = df[column].apply(clean_char_field)
            if df[column].dtype == 'object':
                df[column] = df[column].str.strip()

        # Validate and map IDs
        try:
            #df['college_id'] = df.apply(lambda row: get_college_id_and_group(row['college_id'], row['college_group'] if pd.notna(row['college_group']) else None), axis=1)
           # df['college_id'] = df['college_id'].apply(lambda col: get_college_id_and_group(col))
            def debug_get_college_id_and_group(row):
                college_name = row['college_id']
                college_group = row['college_group']
                print(f"Mapping college_id: name={college_name}, group={college_group}")
                return get_college_id_and_group(college_name, college_group)

            df['college_id'] = df.apply(debug_get_college_id_and_group, axis=1)

            for index, row in df.iterrows():
                if not row['college_id']:
                    return Response({'error': f"College '{row['college_id']}' is required in row {index + 2}"}, status=status.HTTP_400_BAD_REQUEST)

                college_obj = college_master.objects.filter(college=row['college_id'],deleted=0).first()
                print("Unique college names:", df['college_id'].unique())
                print("Unique college groups:", df['college_group'].unique())

               # if college_obj and college_master.objects.filter(college=row['college_id'], college_group__isnull=False).exists():
                   # if row['college_group'] is None:
                       # return Response({'error': f"College Branch (college_group) is required for '{row['college_id']}' in row {index + 2}"}, status=status.HTTP_400_BAD_REQUEST)
                if college_obj and college_master.objects.filter(college=row['college_id'], college_group__isnull=False).exists():
                   if row['college_group'] is None:
                       return Response({'error': f"College Branch (college_group) is required for '{row['college_id']}' in row {index + 2}"}, status=status.HTTP_400_BAD_REQUEST)

            df['department_id'] = df['department_id'].apply(get_department_id)
            if not row['department_id']:
                return Response({'error': f'Department not found in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)


        except ValueError as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)



        mandatory_columns = ['college_id', 'user_name', 'department_id', 'year', 'password']
        for column in mandatory_columns:
            if column not in df.columns:
                return Response({'error': f'Mandatory column {column} is missing'}, status=status.HTTP_400_BAD_REQUEST)
        
        for index, row in df.iterrows():
            for col in mandatory_columns:
                if pd.isna(row[col]) or str(row[col]).strip() == '':
                    return Response(
                        {'error': f"Mandatory field '{col}' is missing in row {index + 2}"},
                        status=status.HTTP_400_BAD_REQUEST
                    )

        email_regex = re.compile(r'^\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b$')

        user_names = df['user_name']
        existing_users = set(login.objects.filter(user_name__in=user_names).values_list('user_name', flat=True))
        duplicate_in_excel = user_names[user_names.duplicated()].unique()
        duplicate_total = list(set(existing_users).union(set(duplicate_in_excel)))

        if duplicate_total:
            if len(duplicate_total) <= 5:
                return Response(
                    {'error': f"user_name(s) already exist: {', '.join(duplicate_total)}"},
                    status=status.HTTP_400_BAD_REQUEST
                )
            else:
                return Response(
                    {'error': f"{len(duplicate_total)} user_name(s) already exist or are duplicated in the file."},
                    status=status.HTTP_400_BAD_REQUEST
                )
        
        skipped_usernames = []
        added_usernames = []
        processed_usernames = set()
        valid_rows = []
        
        for index, row in df.iterrows():
            username = row['user_name']

            if username in existing_users or username in processed_usernames:
                skipped_usernames.append(username)
                continue  # Skip this row if username already exists or is a duplicate within the file
            if skipped_usernames:
                return Response(
                    {'error': f"user_name(s) already exist: {', '.join(skipped_usernames)}"},
                    status=status.HTTP_400_BAD_REQUEST
                )


            processed_usernames.add(username)
            
            if not row['college_id']:
                return Response({'error': f'College not found in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)
            elif not row['department_id']:
                return Response({'error': f'Department not found in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)

            year_value = str(row['year'])
            print('year value: ', year_value)
            if year_value not in ['1', '2', '3', '4']:
                return Response({'error': f'Year is mismatch in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)

            if pd.notna(row['email_id']):
                if not isinstance(row['email_id'], str) or not email_regex.match(row['email_id']):
                    return Response({'error': f'Email ID is not in correct format in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)
        
            if pd.notna(row['mobile_number']):
                if len(str(int(row['mobile_number']))) != 10:
                    return Response({'error': f'Mobile number is not 10 digits in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)

            integer_fields = ['history_of_arrears', 'standing_arrears', 'core_of_offers', 'it_of_offers', 'number_of_offers']
            for field in integer_fields:
                if pd.notna(row[field]):
                    try:
                        value = float(row[field])
                        if value.is_integer() and 0 <= value <= 100:
                            row[field] = int(value)
                        else:
                            return Response({'error': f'{field.replace("_", " ").title()} must be an integer between 0 and 100 in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)
                    except ValueError:
                        return Response({'error': f'{field.replace("_", " ").title()} must be an integer between 0 and 100 in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)

            float_fields = ['cgpa', 'marks_10th', 'marks_12th']
            for field in float_fields:
                if pd.notna(row[field]):
                    try:
                        row[field] = float(row[field])
                    except ValueError:
                        return Response({'error': f'{field.replace("_", " ").title()} must be a number in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)
    
            df.at[index, 'user_name'] = username

            valid_rows.append(row)
        
        df_valid = pd.DataFrame(valid_rows)
        df_valid['role'] = 'Student'
        df_valid['is_database'] = True

        print('*********df_valid**********: ', df_valid)
        
        optional_columns = ['batch_no', 'students_name', 'registration_number', 'gender', 'email_id', 'mobile_number',
                            'cgpa', 'marks_10th', 'marks_12th', 'marks_semester_wise',
                            'history_of_arrears', 'standing_arrears', 'number_of_offers', 'it_of_offers', 'core_of_offers', 'text']
        
        for column in optional_columns:
            if column in df_valid.columns:
                if df_valid[column].dtype == 'float64':  # For float columns
                    df_valid[column] = df_valid[column].fillna(0.0)
                elif df_valid[column].dtype == 'int64':  # For integer columns
                    df_valid[column] = df_valid[column].fillna(0)
                else:  # For other columns
                    df_valid[column] = df_valid[column].fillna(pd.NA)
            else:
                if column in ['cgpa', 'marks_10th', 'marks_12th']:
                    df_valid[column] = 0.0
                elif column in ['history_of_arrears', 'standing_arrears', 'number_of_offers', 'it_of_offers', 'core_of_offers']:
                    df_valid[column] = 0
                else:
                    df_valid[column] = pd.NA
        
        df_valid['email_id'] = df_valid['email_id'].apply(lambda x: x if pd.notna(x) and '@' in str(x) else 'placeholder@example.com')
        
        df_valid = df_valid.where(pd.notnull(df_valid), None)

        
        
        login_data = df_valid[['email_id','mobile_number', 'user_name', 'password', 'college_id', 'role']]
        print('login_data: ', login_data)

        login_records = login_data.to_dict(orient='records')
        print('login_records: ', login_records)

        login_serializer = loginSerializerStu(data=login_records, many=True)
        print('login_serializers: ', login_serializer)
        
        if not login_serializer.is_valid():
            print('login_serializer.errors: ', login_serializer.errors)
            return Response(login_serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        candidate_data = df_valid[['college_id', 'batch_no', 'students_name', 'registration_number', 'gender', 'email_id', 'mobile_number',
                             'department_id', 'year', 'cgpa', 'marks_10th', 'marks_12th', 'marks_semester_wise',
                             'history_of_arrears', 'standing_arrears', 'number_of_offers', 'it_of_offers', 'core_of_offers', 'user_name', 'text', 'is_database']]
        
        print('candidate data: ', candidate_data)
        
        candidate_records = candidate_data.to_dict(orient='records')
        
        candidate_serializer = candidateSerializerImport(data=candidate_records, many=True)
        print('candidate_seriaizer: ', candidate_serializer)
        
        if not candidate_serializer.is_valid():
            print('candidate_serializer.errors: ', candidate_serializer.errors)
            return Response(candidate_serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        with transaction.atomic():
            login_serializer.save()
            candidate_serializer.save()

        # Return a summary message
        summary_message = f"Excel file imported successfully. Skipped {len(skipped_usernames)} existing users, added {len(valid_rows)} new users."
        return Response({'message': summary_message}, status=status.HTTP_201_CREATED)


class ExcelImportView_Candidateuser(APIView):
    def post(self, request, format=None):
        current_date_time = timezone.now()

        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded.'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']
        if not file.name.endswith('.xlsx'):
            return Response({'error': 'Only .xlsx files are accepted.'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
        except Exception as e:
            return Response({'error': f'Error reading Excel file: {str(e)}'}, status=status.HTTP_400_BAD_REQUEST)

        # Rename and validate required columns
        header_mapping = {
            'User Name**': 'user_name',
            'Password**': 'password',
            'College Name**': 'college_id',
            'College Branch': 'college_group',
            'Batch': 'batch_no',
        }
        df.rename(columns=header_mapping, inplace=True)

        # Check if required columns exist
        for field in ['user_name', 'password', 'college_id']:
            if field not in df.columns:
                return Response({'error': f'{field.replace("_", " ").title()} column is missing.'}, status=status.HTTP_400_BAD_REQUEST)

        # Check for blank or missing required values
        required_fields = ['user_name', 'password', 'college_id']
       
        missing_columns = [field for field in required_fields if field not in df.columns]
        if missing_columns:
            return Response({'error': f"{', '.join([col.replace('_', ' ').title() for col in missing_columns])}  column(s) missing or blank values.. "}, status=status.HTTP_400_BAD_REQUEST)

        # Check for missing or blank values in the required fields
        blank_fields = []
        for field in required_fields:
            if df[field].isnull().any() or df[field].astype(str).str.strip().eq('').any():
                blank_fields.append(field.replace('_', ' ').title())

        if blank_fields:
            return Response({'error': f"{', '.join(blank_fields)} column(s) missing or blank values.. "}, status=status.HTTP_400_BAD_REQUEST)
        # Check duplicate user names in Excel
        duplicate_usernames = df[df.duplicated(subset=['user_name'], keep='first')]['user_name'].unique()
        if duplicate_usernames.size > 0:
            return Response({'error': f'Duplicate user names in file: {", ".join(duplicate_usernames)}'}, status=status.HTTP_400_BAD_REQUEST)

        df = df.drop_duplicates(subset=['user_name'], keep='first')

        try:
            df['college_id'] = df.apply(
                lambda row: get_college_id_and_group(row['college_id'], row['college_group'] if pd.notna(row['college_group']) else None),
                axis=1
            )
            for index, row in df.iterrows():
                if not row['college_id']:
                    return Response({'error': f"College not found in row {index + 2}"}, status=status.HTTP_400_BAD_REQUEST)

                college_obj = college_master.objects.filter(college=row['college_id'],deleted=0).first()
                if college_obj and college_master.objects.filter(college=row['college_id'], college_group__isnull=False).exists():
                    if pd.isna(row['college_group']) or str(row['college_group']).strip() == '':
                        return Response({'error': f"College Branch is required for '{row['college_id']}' in row {index + 2}"}, status=status.HTTP_400_BAD_REQUEST)

        except ValueError as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Prepare login and candidate data
        login_data = df[['user_name', 'password', 'college_id']]
        login_data['role'] = 'Student'
        login_data.fillna('', inplace=True)

        candidate_data = df[['user_name', 'college_id', 'batch_no']]
        candidate_data['is_database'] = False
        candidate_data['dtm_upload'] = current_date_time
        candidate_data.fillna('', inplace=True)

        # Check existing users
        existing_login_users = set(login.objects.filter(user_name__in=login_data['user_name'], deleted=0).values_list('user_name', flat=True))
        existing_candidate_users = set(candidate_master.objects.filter(user_name__in=candidate_data['user_name'], deleted=0 ).values_list('user_name', flat=True))

        already_existing_users = list(existing_login_users.union(existing_candidate_users))
        if already_existing_users:
            return Response({'error': f"The following user_name(s) already exist: {', '.join(already_existing_users)}"}, status=status.HTTP_400_BAD_REQUEST)

        new_login_records = login_data.to_dict(orient='records')
        new_candidate_records = candidate_data.to_dict(orient='records')

        try:
            with transaction.atomic():
                login_serializer = loginSerializerStuser(data=new_login_records, many=True)
                if not login_serializer.is_valid():
                    return Response({'error': 'Login data validation failed', 'details': login_serializer.errors}, status=status.HTTP_400_BAD_REQUEST)
                login_serializer.save()

                candidate_serializer = candidateuserSerializerImport(data=new_candidate_records, many=True)
                if not candidate_serializer.is_valid():
                    return Response({'error': 'Candidate data validation failed', 'details': candidate_serializer.errors}, status=status.HTTP_400_BAD_REQUEST)
                candidate_serializer.save()

        except Exception as e:
            return Response({'error': f'Unexpected error during save: {str(e)}'}, status=status.HTTP_400_BAD_REQUEST)

        return Response({
            'message': 'Data uploaded successfully.',
            'new_login_data': new_login_records,
            'new_candidate_data': new_candidate_records
        }, status=status.HTTP_201_CREATED)

class ExcelImportView_CandidateuserCollege(APIView):
    def post(self, request, format=None):
        print("Starting Excel Import Process...")

        # Expected column order
        expected_columns = ['user_name', 'password', 'batch_no']

        # Fetch college_id from query parameters
        college_id = request.query_params.get('college_id', None)
        if college_id is None:
            print("Error: 'college_id' query parameter is missing.")
            return Response({'error': "'college_id' query parameter is required"}, status=status.HTTP_400_BAD_REQUEST)

        try:
            # Ensure the college_id corresponds to an existing college_master instance
            college_instance = get_object_or_404(college_master, pk=college_id)
        except Exception as e:
            print(f"Error: {str(e)}")
            return Response({'error': 'Invalid college_id or college does not exist'}, status=status.HTTP_400_BAD_REQUEST)

        # Check if file is present in the request
        if 'file' not in request.FILES:
            print("Error: No file uploaded.")
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']

        # Check if file is in Excel format
        if not file.name.endswith('.xlsx'):
            print("Error: File is not in Excel format.")
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            # Read the Excel file into a DataFrame
            df = pd.read_excel(file)
            print("File read successfully.")
        except Exception as e:
            print(f"Error reading file: {str(e)}")
            return Response({'error': f"Error reading file: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)

        # Validate columns
        if list(df.columns) != expected_columns:
            print(f"Invalid column format. Expected: {expected_columns}, Provided: {list(df.columns)}")
            return Response({
                'error': 'Invalid column format.',
                'expected_columns': expected_columns,
                'provided_columns': list(df.columns)
            }, status=status.HTTP_400_BAD_REQUEST)

        # Reorder columns (if necessary)
        df = df[expected_columns]
        print("Columns validated and reordered successfully.")

        # Prepare current date and time
        current_date_time = timezone.now()

        # Check for duplicate usernames in the Excel file
        duplicate_usernames = df[df.duplicated(subset=['user_name'], keep='first')]['user_name'].unique()
        if duplicate_usernames.size > 0:
            print(f"Duplicate usernames found in the Excel file: {duplicate_usernames}. Removing duplicates.")

        # Remove subsequent duplicates
        df = df.drop_duplicates(subset=['user_name'], keep='first')

        # Prepare login data
        login_data = df[['user_name', 'password']]
        login_data['college_id'] = college_id  # Use the college_id obtained from query param
        login_data['role'] = 'Student'  # Default role
        login_data.fillna('', inplace=True)  # Handle NaN values
        print("Login data prepared.")

        # Get existing users
        existing_users = set(login.objects.filter(user_name__in=login_data['user_name'], deleted=0).values_list('user_name', flat=True))
        print(f"Existing users fetched: {existing_users}")

        # Filter out existing users
        new_login_data = login_data[~login_data['user_name'].astype(str).isin(existing_users)]
        new_login_data = new_login_data.fillna('')

        new_login_records = []
        if not new_login_data.empty:
            print(f"New login data found: {len(new_login_data)} entries")
            new_login_records = new_login_data.to_dict(orient='records')
                # Check if there's any new data to insert

        # Prepare candidate data
        candidate_data = df[['user_name', 'batch_no']]
        candidate_data['college_id'] = college_id  # Use the college_id obtained from query param
        candidate_data['is_database'] = False
        candidate_data['dtm_upload'] = current_date_time
        candidate_data.fillna('', inplace=True)  # Handle NaN values
        print("Candidate data prepared.")

        # Get existing candidates
        existing_candidates = set(candidate_master.objects.filter(user_name__in=candidate_data['user_name']).values_list('user_name', flat=True))
        print(f"Existing candidates fetched: {existing_candidates}")

        # Filter out existing candidates
        new_candidate_data = candidate_data[~candidate_data['user_name'].astype(str).isin(existing_candidates)]
        new_candidate_data = new_candidate_data.fillna('')
        print(f"Filtered new candidate data: {new_candidate_data}")

        new_candidate_records = []
        if not new_candidate_data.empty:
            print(f"New candidate data found: {len(new_candidate_data)} entries")
            new_candidate_records = new_candidate_data.to_dict(orient='records')

        # Start transaction block
        try:
            with transaction.atomic():
                # Save new login data
                if new_login_records:
                    login_serializer = loginSerializerStuser(data=new_login_records, many=True)
                    if login_serializer.is_valid():
                        login_serializer.save()
                        print("New login data saved successfully.")
                    else:
                        print("Login data validation failed with errors:")
                        print(login_serializer.errors)
                        raise Exception("Login data validation failed.")

                # Save new candidate data
                if new_candidate_records:
                    candidate_serializer = candidateuserSerializerImport(data=new_candidate_records, many=True)
                    if candidate_serializer.is_valid():
                        candidate_serializer.save()
                        print("New candidate data saved successfully.")
                    else:
                        print("Candidate data validation failed with errors:")
                        print(candidate_serializer.errors)
                        raise Exception("Candidate data validation failed.")

        except Exception as e:
            print(f"Transaction failed: {str(e)}")
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Return success response with saved data
        print("Import process completed successfully.")
        return Response({
            'new_login_data': new_login_records,
            'new_candidate_data': new_candidate_records
        }, status=status.HTTP_201_CREATED)

class ExcelImportView_CandidateLASTCollege(APIView):
    def post(self, request, format=None):
        # Retrieve college_id from query parameters
        college_id = request.query_params.get('college_id')
        
        if not college_id:
            return Response({'error': 'College ID not provided'}, status=status.HTTP_400_BAD_REQUEST)

        # Validate college_id (e.g., check if it's a valid ID)
        if not college_master.objects.filter(id=college_id, deleted=0).exists():
            return Response({'error': 'Invalid college ID'}, status=status.HTTP_400_BAD_REQUEST)

        # Check if the file is in the request
        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)
        
        file = request.FILES['file']

        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            df = pd.read_excel(file)
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Define header mapping
        header_mapping = {
            'Batch No':'batch_no',
            'Student Name': 'students_name',

            'User Name**': 'user_name',
            'Reg No': 'registration_number',
            'Gender': 'gender',
            'Email ID': 'email_id',
            'Mobile Number': 'mobile_number',
            'Year**': 'year',
            'CGPA': 'cgpa',
            'Department**': 'department_id',
            '10th Mark': 'marks_10th',
            '12th Mark': 'marks_12th',
            'Semaster Wise': 'marks_semester_wise',
            'History Of Arrears': 'history_of_arrears',
            'Standing Arrears': 'standing_arrears',
            'No.Of.IT Offers': 'it_of_offers',
            'No.Of.Core Offers': 'core_of_offers',
            'No.Of.Offers': 'number_of_offers',
            'Password**': 'password'
        }

        # Rename columns
        df.rename(columns=header_mapping, inplace=True)

        # Process columns
        char_fields = ['user_name', 'year', 'password']
        for column in df.columns:
            if column in char_fields:
                df[column] = df[column].apply(clean_char_field)
            if df[column].dtype == 'object':
                df[column] = df[column].str.strip()

        # Apply department_id mapping
        try:
            df['department_id'] = df['department_id'].apply(get_department_id)
        except ValueError as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        mandatory_columns = ['user_name', 'department_id', 'year', 'password']
        for column in mandatory_columns:
            if column not in df.columns:
                return Response({'error': f'Mandatory column {column} is missing'}, status=status.HTTP_400_BAD_REQUEST)
        
        if df[mandatory_columns].isnull().any().any():
            return Response({'error': 'Mandatory fields cannot be null'}, status=status.HTTP_400_BAD_REQUEST)

        # Validate email and mobile number
        email_regex = re.compile(r'^\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b$')
        user_names = df['user_name']
        existing_users = set(login.objects.filter(user_name__in=user_names).values_list('user_name', flat=True))

        skipped_usernames = []
        added_usernames = []

        processed_usernames = set()
        valid_rows = []

        for index, row in df.iterrows():
            username = row['user_name']

            if username in existing_users or username in processed_usernames:
                skipped_usernames.append(username)
                continue  # Skip if username already exists or is a duplicate within the file

            processed_usernames.add(username)
            
            if not row['department_id']:
                return Response({'error': f'Department not found in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)

            year_value = str(row['year'])
            if year_value not in ['1', '2', '3', '4']:
                return Response({'error': f'Year is mismatch in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)

            if pd.notna(row['email_id']):
                if not isinstance(row['email_id'], str) or not email_regex.match(row['email_id']):
                    return Response({'error': f'Email ID is not in correct format in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)
        
            if pd.notna(row['mobile_number']):
                if len(str(int(row['mobile_number']))) != 10:
                    return Response({'error': f'Mobile number is not 10 digits in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)

            integer_fields = ['history_of_arrears', 'standing_arrears', 'core_of_offers', 'it_of_offers', 'number_of_offers']
            for field in integer_fields:
                if pd.notna(row[field]):
                    try:
                        value = float(row[field])
                        if value.is_integer() and 0 <= value <= 100:
                            row[field] = int(value)
                        else:
                            return Response({'error': f'{field.replace("_", " ").title()} must be an integer between 0 and 100 in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)
                    except ValueError:
                        return Response({'error': f'{field.replace("_", " ").title()} must be an integer between 0 and 100 in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)

            float_fields = ['cgpa', 'marks_10th', 'marks_12th']
            for field in float_fields:
                if pd.notna(row[field]):
                    try:
                        row[field] = float(row[field])
                    except ValueError:
                        return Response({'error': f'{field.replace("_", " ").title()} must be a number in row {index + 2}'}, status=status.HTTP_400_BAD_REQUEST)
    
            df.at[index, 'user_name'] = username

            valid_rows.append(row)
        
        df_valid = pd.DataFrame(valid_rows)
        df_valid['role'] = 'Student'
        df_valid['is_database'] = True
        df_valid['college_id'] = college_id  # Assign provided college_id to the dataframe

        optional_columns = ['batch_no','students_name', 'registration_number', 'gender', 'email_id', 'mobile_number',
                            'cgpa', 'marks_10th', 'marks_12th', 'marks_semester_wise',
                            'history_of_arrears', 'standing_arrears', 'number_of_offers', 'it_of_offers', 'core_of_offers', 'text']
        
        for column in optional_columns:
            if column in df_valid.columns:
                if df_valid[column].dtype == 'float64':  # For float columns
                    df_valid[column] = df_valid[column].fillna(0.0)
                elif df_valid[column].dtype == 'int64':  # For integer columns
                    df_valid[column] = df_valid[column].fillna(0)
                else:  # For other columns
                    df_valid[column] = df_valid[column].fillna(pd.NA)
            else:
                if column in ['cgpa', 'marks_10th', 'marks_12th']:
                    df_valid[column] = 0.0
                elif column in ['history_of_arrears', 'standing_arrears', 'number_of_offers', 'it_of_offers', 'core_of_offers']:
                    df_valid[column] = 0
                elif column == 'batch_no':
                    df_valid[column] = None
                else:
                    df_valid[column] = pd.NA
        
        df_valid['email_id'] = df_valid['email_id'].apply(lambda x: x if pd.notna(x) and '@' in str(x) else 'placeholder@example.com')
        
        df_valid = df_valid.where(pd.notnull(df_valid), None)

        login_data = df_valid[['email_id','mobile_number', 'user_name', 'password', 'college_id', 'role']]
        login_records = login_data.to_dict(orient='records')

        login_serializer = loginSerializerStu(data=login_records, many=True)
        
        if not login_serializer.is_valid():
            return Response(login_serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        candidate_data = df_valid[['college_id', 'students_name','batch_no', 'registration_number', 'gender', 'email_id', 'mobile_number',
                             'department_id', 'year', 'cgpa', 'marks_10th', 'marks_12th', 'marks_semester_wise',
                             'history_of_arrears', 'standing_arrears', 'number_of_offers', 'it_of_offers', 'core_of_offers', 'user_name', 'text', 'is_database']]
        candidate_records = candidate_data.to_dict(orient='records')

        candidate_serializer = candidateSerializerImport(data=candidate_records, many=True)

        if not candidate_serializer.is_valid():
            return Response(candidate_serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            with transaction.atomic():
                login_serializer.save()
                candidate_serializer.save()
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        
        return Response({'success': 'Data imported successfully'}, status=status.HTTP_201_CREATED)


class ExcelImportView_Questions(APIView):
    def post(self, request, format=None):

        # Extract data for the question_paper_master
        question_paper_name = request.data.get('question_paper_name')
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        folder_name = request.data.get('folder_name')
        remarks = request.data.get('remarks')
        print("remarks",remarks)


           # Build a list of the always‚Äêrequired values
        required_values = [
            question_paper_name,
            duration_of_test,
            topic,
            no_of_questions,
            upload_type,
            test_type,
        ]

        # Only require sub_topic if topic is NOT Softskills
        if topic != 'Softskills':
            required_values.append(sub_topic)

        if not all(required_values):
            return Response(
                {'error': 'Missing fields for question_paper_master'},
                status=status.HTTP_400_BAD_REQUEST
            )
        # Create a new question_paper_master entry
        question_paper_data = {
            'question_paper_name': question_paper_name,
            'duration_of_test': duration_of_test,
            'topic': topic,
            'sub_topic': sub_topic,
            'no_of_questions': no_of_questions,
            'upload_type': upload_type,
            'test_type': test_type,
            'folder_name': folder_name,
            'remarks':remarks,
            
        }

        question_paper_serializer = questionsPaperSerializer(data=question_paper_data)
        if question_paper_serializer.is_valid():
            question_paper_instance = question_paper_serializer.save()
            question_paper_id = question_paper_instance.id
        else:
            return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        print('Files:', request.FILES)

        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']

        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
            df.columns = [col.strip() for col in df.columns]
       

            print('DataFrame contents:')
            print(df.head())  # Print the first few rows of the DataFrame
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Mapping of Excel header names to actual column names
       
        header_mapping = {
            'Questions**': 'question_text',
            'Option A': 'option_a',
            'Option B': 'option_b',
            'Option C': 'option_c',
            'Option D': 'option_d',
            'Answer**': 'answer',
            'Mark**': 'mark',
            'Difficulty Level':'difficulty_level',
            'Explain Answer': 'explain_answer',
            

        }
        
        missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
        if missing_columns:
           return Response({'error': f'Missing columns in Excel: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

        df.rename(columns=header_mapping, inplace=True)
        

        # List of mandatory columns
        mandatory_columns = [
            'question_text',
            'answer',
            'mark',
            'difficulty_level'
        ]

        # Initialize error messages
        error_messages = []

        # Check for empty values in mandatory columns and record specific rows
        for col in mandatory_columns:
            if col in df.columns:
                missing_values = df[df[col].isnull()]
                if not missing_values.empty:
                    for index, row in missing_values.iterrows():
                        error_messages.append(f"Row {index + 1}: Column '{col}' is empty.")

        # Validate and convert answers
        if 'answer' in df.columns:
            for index, row in df.iterrows():
                answer = str(row['answer']).strip().upper()  # Normalize to uppercase
                if answer in ['A', 'B', 'C', 'D']:
                    df.at[index, 'answer'] = answer  # Valid answers
                elif answer in ['1', '2', '3', '4']:
                    df.at[index, 'answer'] = chr(ord('A') + int(answer) - 1)  # Convert 1-4 to A-D
                else:
                    error_messages.append(f"Row {index + 1}: Invalid answer '{row['answer']}'.")

        if error_messages:
            error_message = ' '.join(error_messages)
            return Response({'error': error_message}, status=status.HTTP_400_BAD_REQUEST)

        # Convert DataFrame to records and handle NaN values
        records = df.fillna('').to_dict(orient='records')

        for record in records:
            record['question_name_id'] = question_paper_id
            for key in record:
                if isinstance(record[key], str):
                    record[key] = record[key].strip()

        # Serialize and save the records
        serializer = questionsSerializerImport(data=records, many=True)
        print("Serializer: ", serializer)

        if serializer.is_valid():
            print("Before Saving..")
            serializer.save()
            print("After Saving..")
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            # Initialize a list to collect all errors
            detailed_errors = []
            print("Entering Detailed Error..")

            # Iterate over each error in the list of errors
            for idx, error_dict in enumerate(serializer.errors):
                for field, errors in error_dict.items():
                    if isinstance(errors, list):
                        for error in errors:
                            detailed_errors.append(f"Row {idx + 1}, Column '{field}': {error}")

            print('Deltailed Error: ', detailed_errors)
            # Return the collected errors
            return Response({'error': detailed_errors}, status=status.HTTP_400_BAD_REQUEST)


#------------------------------Rules-------------------------------------------------------------#

class rules_listView(generics.ListAPIView):
    queryset = rules.objects.filter(deleted=0)

    
    serializer_class = ruleSerializers

class rules_create(generics.CreateAPIView):
    queryset = rules.objects.all()
    serializer_class = ruleSerializers

class rules_Update(generics.RetrieveUpdateAPIView):
    queryset = rules.objects.all()
    serializer_class = ruleSerializers

@api_view(['PUT', 'PATCH'])
def delete_rules(request, pk):
    try:
        print("Entering Function..")
        rule = rules.objects.get(id=pk)

       
    except rules.DoesNotExist:
        return JsonResponse("rules not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    rule.deleted = 1
    rule.save()
 

    return JsonResponse("rules 'deleted' field updated successfully", safe=False)

#---------------------------------Password Reset----------------------------#
@api_view(['PUT'])
def update_login(request, user_name=None):
    try:
        login_to_update = login.objects.get(user_name=user_name)
    except login.DoesNotExist:
        return JsonResponse({"error": "Login not found"}, status=status.HTTP_404_NOT_FOUND)

    serializer = loginSerializer(instance=login_to_update, data=request.data, partial=True)
    
    if serializer.is_valid():
        serializer.save()
        print("Login Updated Successfully.")
    else:
        return JsonResponse(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    role = request.data.get('role')
    print('role: ', role)

    if role == 'Student':
        try:
            candidate = candidate_master.objects.get(user_name=user_name)
            candidate.email_id = request.data.get('email_id')
            college_id = request.data.get('college_id')
            if college_id:
                candidate.college_id = college_master.objects.get(id=college_id)
            candidate.save()
            print("Candidate Master Updated.")
        except candidate_master.DoesNotExist:
            return JsonResponse({"error": "Candidate not found"}, status=status.HTTP_404_NOT_FOUND)
        except college_master.DoesNotExist:
            return JsonResponse({"error": "College not found"}, status=status.HTTP_404_NOT_FOUND)

    elif role == 'Trainer':
        try:
            trainer = trainer_master.objects.get(user_name=user_name)
            trainer.email_id = request.data.get('email_id')
            trainer.save()
            print("Trainer Master Updated.")
        except trainer_master.DoesNotExist:
            return JsonResponse({"error": "Trainer not found"}, status=status.HTTP_404_NOT_FOUND)

    else:
        # ‚úÖ For other roles (Super admin, Training admin, Placement admin, Placement Officer),
        # just skip without returning an error
        print("No extra updates required for this role.")

    return JsonResponse({"message": "Login and related data updated successfully"})

@api_view(['PUT'])
def update_totalScore_test_candidate_map(request, pk=None):
    total_score_update = tests_candidates_map.objects.get(id=pk)
    serializer = testcandidatemapSerializers(instance=total_score_update, data=request.data, partial=True)

    if serializer.is_valid():
        serializer.save()
        print('Total score updated')
        return JsonResponse("Total score Updated Successfully", safe=False)
    return JsonResponse("Failed to Update total score")


@api_view(['PUT'])
def update_Avg_Marks_test_candidate_map(request, pk=None):
    avg_mark_update = tests_candidates_map.objects.get(id=pk)
    serializer = testcandidatemapSerializers(instance=avg_mark_update, data=request.data, partial=True)

    if serializer.is_valid():
        serializer.save()
        print('Avg mark is updated')
        return JsonResponse("Avg mark is  Updated Successfully", safe=False)
    return JsonResponse("Failed to Update Avg mark")




#---------------------------------Batch wise Test assign-------------------------------#

class TestCandidatesMapView(APIView):
    def post(self, request, format=None):

        test_name = request.data.get('test_name')
        test_type_id = request.data.get('test_type_id')
        question_type_id = request.data.get('question_type_id')
        skill_type_id = request.data.get('skill_type_id')
        company_name = request.data.get('company_name')  # Add company_name field
        company_email = request.data.get('company_email')  

        if not all([test_name, test_type_id, question_type_id]):
            return Response({'error': 'Missing fields for test_master'}, status=status.HTTP_400_BAD_REQUEST)
        
        is_company = False
        try:
            # Attempt to retrieve the test_type and set is_company accordingly
            print('Attempting to retrieve test_type with ID:', test_type_id)
            test_type_instance = test_type.objects.get(id=test_type_id)
            print('Retrieved test_type_instance:', test_type_instance)

            # Check if the test is company-specific
            if test_type_instance.test_type_categories == "Mock/Interview":
                is_company = True
                print('is_company set to True for company-specific test')
            else:
                print('is_company remains False as test is not company-specific')
                
        except test_type.DoesNotExist:
            print('Error: Invalid test_type_id - test_type with this ID does not exist')
            return Response({'error': 'Invalid test_type_id'}, status=status.HTTP_400_BAD_REQUEST)
        test_master_data = {
            'test_name': test_name,
            'test_type_id': test_type_id,
            'question_type_id': question_type_id,
            'skill_type_id': skill_type_id,
            'is_company':is_company
        }
        
        if company_name:
            test_master_data['company_name'] = company_name
        if company_email:
            test_master_data['company_email'] = company_email


        test_master_serializer = testsSerializersAdd(data=test_master_data)
        
        if not test_master_serializer.is_valid():
            print(f"Test master serializer errors: {test_master_serializer.errors}")
            return Response(test_master_serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        

        college_id = request.data.get('college_id', [])
        department_id = request.data.get('department_id', [])
        year = request.data.get('year')

        if not college_id or not department_id or not year:
            return Response({'error': 'college_id, department_id, and year are required fields.'}, status=status.HTTP_400_BAD_REQUEST)

        print("Batch No: ", year, college_id, department_id)

        # Filter candidates based on multiple college_ids and department_ids
        students = candidate_master.objects.filter(
            college_id__in=college_id,
            department_id__in=department_id,
            year=year,deleted=0
        )

        print("Students: ", students)
        data = []
        updated_candidates = []  # To store IDs of updated candidates

        current_date_and_time = datetime.now()  # Get the current date and time

        for student in students:
            print("Student id: ", student.id)
            test_candidate_data = {
                'test_name': request.data.get('test_name'),  # Assuming 'test_name' is provided in the request
                'question_id': request.data.get('question_id'),  # Assuming 'question_id' is provided in the request
                'student_id': student.id,
                'college_id': student.college_id.id,  # Use student.college_id.id for pk
                'department_id': student.department_id.id,  # Use student.department_id.id for pk
                'dtm_start': request.data.get('dtm_start'),
                'dtm_end': request.data.get('dtm_end'),
                'is_camera_on': request.data.get('is_camera_on'),
                'duration': request.data.get('duration'),
                'duration_type': request.data.get('duration_type'),
                'year': year,
                'rules_id': request.data.get('rules_id'),
                'need_candidate_info': request.data.get('need_candidate_info'),
                'dtm_created': current_date_and_time  # Add current date and time
            }

            serializer = testcandidatemapSerializers(data=test_candidate_data)
            
            print("Serializer: ", serializer)

            if not serializer.is_valid():
                print(f"serializer errors: {serializer.errors}")
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        


            with transaction.atomic():  # Use transaction to ensure atomicity
                test_master_serializer.save()
                print('Test master saved Successfully')
                serializer.save()
                data.append(serializer.data)
                print("Data.append: ", data)

                # Check and update candidate_master if needed
                if student.need_candidate_info is None and request.data.get('need_candidate_info') is True:
                    student.need_candidate_info = request.data.get('need_candidate_info')
                    student.save(update_fields=['need_candidate_info'])
                    updated_candidates.append(student.id)
        
        print("Data: ", data)
        return Response(data, status=status.HTTP_201_CREATED)


#---------------Non database test assign-------------------#
class NonDbTestAssign(APIView):
    def post(self, request):

        print('*****Request.data*****: ', request.data)

        test_name = request.data.get('test_name')
        test_type_id = request.data.get('test_type_id')
        question_type_id = request.data.get('question_type_id')
        skill_type_id = request.data.get('skill_type_id')
        company_name = request.data.get('company_name')  # Add company_name field
        company_email = request.data.get('company_email')  # Add company_email field
        created_by = request.data.get('created_by', 'System')
        college_id = request.data.get('college_id', [])
        college_name = request.data.get('college_name', [])
        college_group_id = request.data.get('college_group_id', [])
        batch_no = request.data.get('batch_no', [])
        
        dtm_upload = request.data.get('dtm_upload')

        if not all([test_name, test_type_id, question_type_id]):
            return Response({'error': 'Missing fields for test_master'}, status=status.HTTP_400_BAD_REQUEST)

        is_company = False
        try:
            # Attempt to retrieve the test_type and set is_company accordingly
            print('Attempting to retrieve test_type with ID:', test_type_id)
            test_type_instance = test_type.objects.get(id=test_type_id)
            print('Retrieved test_type_instance:', test_type_instance)

            # Check if the test is company-specific
            if test_type_instance.test_type_categories == "Mock/Interview":
                is_company = True
                print('is_company set to True for company-specific test')
            else:
                print('is_company remains False as test is not company-specific')
                
        except test_type.DoesNotExist:
            print('Error: Invalid test_type_id - test_type with this ID does not exist')
            return Response({'error': 'Invalid test_type_id'}, status=status.HTTP_400_BAD_REQUEST)
        test_master_data = {
            'test_name': test_name,
            'test_type_id': test_type_id,
            'question_type_id': question_type_id,
            'skill_type_id': skill_type_id,
            'is_company':is_company,
        }
        
        if company_name:
            test_master_data['company_name'] = company_name
        if company_email:
            test_master_data['company_email'] = company_email

        test_master_serializer = testsSerializersAdd(data=test_master_data)
        print('test_master_serializer: ', test_master_serializer)
        
        if not test_master_serializer.is_valid():
            print(f"Test master serializer errors: {test_master_serializer.errors}")
            return Response(test_master_serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        


        # Filter the students based on the constructed query

        if college_id:
            # Filter candidates based on multiple college_ids and department_ids
            students = candidate_master.objects.filter(
                is_database=False,
                college_id__in=college_id,
                deleted=0
            )
            print('college_id_students: ', students)
        # else:
        #     # Filter candidates based on multiple college_ids and department_ids
        #     students = candidate_master.objects.filter(
        #         college_id__college__in=college_name
        #     )
        #     print('college__students: ', students)
            
        if dtm_upload is not None:
            students = students.filter(
                dtm_upload=dtm_upload
            )
            print('dtm_upload students: ', students)

        if batch_no:
            students = students.filter(
            batch_no__in=batch_no
            )
            print('batch_no students: ', students)

        
        
        
        print('students: ', students)
        
        data = []
        updated_candidates = []  # To store IDs of updated candidates
        print("updated can",updated_candidates)
        current_date_and_time = datetime.now()

        for student in students:
            test_candidate_data = {
                'test_name': request.data.get('test_name'),
                'question_id': request.data.get('question_id'),
                'student_id': student.id,
                'college_id': student.college_id.id,
                'dtm_start': request.data.get('dtm_start'),
                'dtm_end': request.data.get('dtm_end'),
                 'dtm_start1': request.data.get('dtm_start'),
                'dtm_end1': request.data.get('dtm_end'),
                'is_camera_on': request.data.get('is_camera_on'),
                'duration': request.data.get('duration'),
                'duration_type': request.data.get('duration_type'),
                'rules_id': request.data.get('rules_id'),
                'need_candidate_info': request.data.get('need_candidate_info'),
                'dtm_created': timezone.now(),
                'created_by': created_by
            }

            serializer = NonDbTestAssignSerializer(data=test_candidate_data)
            

            if not serializer.is_valid():
                print(f"serializer errors: {serializer.errors}")
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
            
            with transaction.atomic():  # Use transaction to ensure atomicity
                test_master_serializer.save()
                print('Test master saved Successfully')
                
                serializer.save()
                data.append(serializer.data)
                # Check and update candidate_master if needed
                if student.need_candidate_info is None and request.data.get('need_candidate_info') is True:
                    student.need_candidate_info = request.data.get('need_candidate_info')
                    student.save(update_fields=['need_candidate_info'])
                    updated_candidates.append(student.id)
            
        return Response(data, status=status.HTTP_201_CREATED)


#-----------------------Get Unique Batch---------------------#

@api_view(['GET'])
def batch_list(request):
    batch_numbers = candidate_master.objects.filter(deleted=0).exclude(batch_no__isnull=True).values_list('batch_no', flat=True).distinct()
    return Response({'batch_numbers': list(batch_numbers)})

@api_view(['GET'])
def question_name_list(request):
    question_names = question_master.objects.filter(deleted=0).exclude(question_name__isnull=True).values_list('question_name', flat=True).distinct()
    return Response({'question_new': list(question_names)})

@api_view(['GET'])
def topic_list(request):
    topics = content_master.objects.filter(deleted=0).exclude(topic__isnull=True).values_list('topic', flat=True).distinct()
    return Response({'topics': list(topics)})


@api_view(['GET'])
def unique_test_type(request):
    test_types = test_type.objects.filter(deleted=0).values_list('test_type', flat=True).distinct()
    return Response({'test_type': list(test_types)})


@api_view(['GET'])
def MCQ_test_type(request):
    test_types = test_type.objects.filter(deleted=0, test_type='MCQ Test').values_list('test_type_categories', flat=True).distinct()

    return Response({"test_type": list(test_types)})

@api_view(['GET'])
def Coding_test_type(request):
    test_types = test_type.objects.filter(deleted=0, test_type='Coding Test').values_list('test_type_categories', flat=True).distinct()

    return Response({"test_type": list(test_types)})


@api_view(['GET'])
def unique_question_type(request):
    question_types = question_type.objects.filter(deleted=0).values_list('question_type', flat=True).distinct()

    return Response({"question_types": list(question_types)})


class candidates_one_Update(generics.RetrieveUpdateAPIView):
    queryset = candidate_master.objects.all()
    serializer_class = candidatesoneSerializer

    def update(self, request, *args, **kwargs):
        """
        Override update:
        - if 'password' is present in request.data, update login.password only.
        - otherwise, update candidate_master normally.
        """
        instance = self.get_object()  # candidate_master instance
        password = request.data.get("password", None)

        if password is not None:
            # find login row by user_name from candidate_master
            user_name = instance.user_name
            if not user_name:
                return Response({"error": "Candidate has no user_name"}, status=status.HTTP_400_BAD_REQUEST)

            login_obj = login.objects.filter(user_name=user_name).first()
            if not login_obj:
                return Response({"error": f"No login record for user_name {user_name}"}, status=status.HTTP_404_NOT_FOUND)

            login_obj.password = password
            login_obj.save()

            return Response({"success": True, "user_name": user_name, "password": password})

        # if password not in request, fall back to normal candidate_master update
        return super().update(request, *args, **kwargs)

#------------------------------------------Question Paper Master----------------------------------#



@api_view(['GET'])
def get_question_paper(request):
    remarks = request.GET.get('selectedTestTypeCategoryPass', '').strip()
    topic = request.GET.get('topic', '').strip()
    sub_topic = request.GET.get('sub_topic', '').strip()

    # print("üìù selectedTestTypeCategoryPass from frontend2:", remarks)
    # print("üìù topic from frontend:", topic)
    # print("üìù sub_topic from frontend:", sub_topic)

    questions_qs = question_paper_master.objects.filter(deleted=0)

    if remarks:
        questions_qs = questions_qs.filter(remarks=remarks)

    if topic:
        questions_qs = questions_qs.filter(topic__iexact=topic)

    if sub_topic and sub_topic.lower() != "softskills":
        questions_qs = questions_qs.filter(sub_topic__iexact=sub_topic)

    questions_data = questions_qs.order_by('-dtm_created').values(
        'id', 'question_paper_name', 'topic', 'sub_topic', 'test_type',
        'duration_of_test', 'no_of_questions', 'upload_type', 'dtm_created',
        'created_by', 'folder_name', 'is_testcase', 'remarks'
    )

    # for q in questions_data:
    #     print(f"üìå Question: {q.get('question_paper_name')} | Topic: {q.get('topic')} | SubTopic: {q.get('sub_topic')}")

    for question in questions_data:
        question['dtm_created'] = timezone.localtime(question['dtm_created'])

    return Response(list(questions_data))

class questionpapercreateAPIView(generics.CreateAPIView):
    queryset = question_paper_master.objects.all()
    serializer_class =questionsPaperSerializer

    def post(self, request, *args, **kwargs):
        print("Request data:", request.data)  
        #logger.info("Creating a new question paper")
        response = super().post(request, *args, **kwargs)
        #logger.info("Created a new question paper successfully")
        return response
from rest_framework import generics
from .models import question_paper_master
from .serializers import questionsPaperSerializer

class questionpaperUpdateAPIView(generics.RetrieveUpdateAPIView):
    queryset = question_paper_master.objects.all()
    serializer_class = questionsPaperSerializer

    def put(self, request, *args, **kwargs):
        # Step 1: Log the incoming request and question paper id
        print(f"PUT request received for updating Question Paper with ID: {kwargs.get('pk')}")

        # Step 2: Print the request data being sent
        print("Request data: ", request.data)

        # Call the superclass `put` method to perform the actual update
        response = super().put(request, *args, **kwargs)

        # Step 3: Log the successful response
        print(f"Question Paper with ID {kwargs.get('pk')} updated successfully.")

        # Step 4: Return the response
        return response

    def patch(self, request, *args, **kwargs):
        # Step 1: Log the incoming request and question paper id
        print(f"PATCH request received for partially updating Question Paper with ID: {kwargs.get('pk')}")

        # Step 2: Print the request data being sent
        print("Request data: ", request.data)

        # Call the superclass `patch` method to perform the partial update
        response = super().patch(request, *args, **kwargs)

        # Step 3: Log the successful response
        print(f"Question Paper with ID {kwargs.get('pk')} partially updated successfully.")

        # Step 4: Return the response
        return response

@api_view(['PUT', 'PATCH'])
def delete_question_paper(request, pk):
    #logger.info(f"Attempting to mark Courses with id {pk} as deleted")
    try:
        print("Entering Function..")
        questions=question_paper_master.objects.get(id=pk)

        print("questions: ",questions)
    except question_paper_master.DoesNotExist:
        return JsonResponse("Question Paper not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    questions.deleted = 1
    questions.save()

    #logger.info(f"Marked Courses with id {pk} as deleted successfully")

    print("questions: ",questions)

    return JsonResponse("questions paper 'deleted' field updated successfully", safe=False)



def get_last_added_question_paper(request):
    try:
        last_added_paper = question_paper_master.objects.filter(deleted=0).order_by('-id').first()
        serializer = questionsPaperSerializer(last_added_paper)
        return JsonResponse(serializer.data)
    except question_paper_master.DoesNotExist:
        return JsonResponse({'message': 'No question papers available'}, status=404)



#---------------------Questions Master with images--------------#


@api_view(['GET'])
def get_questions_IO(request):
    # Define a unique cache key
    cache_key = 'questions_IO_data'

    # Try to retrieve the data from the cache
    question_data = cache.get(cache_key)

    if not question_data:
        # Fetch the questions from the database
        questionset = question_master.objects.filter(deleted=0).select_related('question_name_id').values(
            'id',
            'question_name_id__id',
            'question_name_id__question_paper_name',
            'question_text',
            'question_image_data',
            'option_a_image_data',
            'option_b_image_data',
            'option_c_image_data',
            'option_d_image_data',
            'option_a',
            'option_b',
            'option_c',
            'option_d',
            'mark',
            'explain_answer',
            'answer',
        )

        # Process the data to encode images and shuffle the list
        def process_question(question):
            return {
                'id': question['id'],
                'question_name_id': question['question_name_id__id'],
                'question_paper_name': question['question_name_id__question_paper_name'],
                'question_text': question['question_text'],
                'question_image_data': base64.b64encode(question['question_image_data']).decode('utf-8') if question['question_image_data'] else None,
                'option_a_image_data': base64.b64encode(question['option_a_image_data']).decode('utf-8') if question['option_a_image_data'] else None,
                'option_b_image_data': base64.b64encode(question['option_b_image_data']).decode('utf-8') if question['option_b_image_data'] else None,
                'option_c_image_data': base64.b64encode(question['option_c_image_data']).decode('utf-8') if question['option_c_image_data'] else None,
                'option_d_image_data': base64.b64encode(question['option_d_image_data']).decode('utf-8') if question['option_d_image_data'] else None,
                'option_a': question['option_a'],
                'option_b': question['option_b'],
                'option_c': question['option_c'],
                'option_d': question['option_d'],
                'mark': question['mark'],
                'explain_answer': question['explain_answer'],
                'answer': question['answer'],
            }

        # Map the processing function over the queryset results and shuffle
        question_data = list(map(process_question, questionset))
        random.shuffle(question_data)

        # Cache the data with a timeout of 1 hour (3600 seconds)
        cache.set(cache_key, question_data, timeout=3600)

    # Return the cached or freshly generated data
    return Response(question_data)

@csrf_exempt
def upload_question(request):
    print('***1')
    if request.method == 'POST':
        print('****2')
        print('POST data:', request.POST)
        print('FILES data:', request.FILES)

        form = QuestionForm(request.POST, request.FILES)
        print('****3')
        if form.is_valid():
            print('*****4')
            question = form.save(commit=False)
            if 'question_image_data' in request.FILES:
                question.question_image_data = request.FILES['question_image_data'].read()
            if 'option_a_image_data' in request.FILES:
                question.option_a_image_data = request.FILES['option_a_image_data'].read()
            if 'option_b_image_data' in request.FILES:
                question.option_b_image_data = request.FILES['option_b_image_data'].read()
            if 'option_c_image_data' in request.FILES:
                question.option_c_image_data = request.FILES['option_c_image_data'].read()
            if 'option_d_image_data' in request.FILES:
                question.option_d_image_data = request.FILES['option_d_image_data'].read()
            if 'option_e_image_data' in request.FILES:
                question.option_e_image_data = request.FILES['option_e_image_data'].read()
          
            question.save()
            print('Question Created Successfully')
            return HttpResponse("Question created successfully")
    else:
        print('***1')
        form = QuestionForm()
        print('******2')
    return render(request, 'upload_image.html', {'form': form})

def update_question_OLD(request, question_id):
    question = get_object_or_404(question_master, id=question_id, deleted=0)

    if request.method == 'POST':
        form = QuestionForm(request.POST, request.FILES, instance=question)
        if form.is_valid():
            question = form.save(commit=False)
            if 'question_image_data' in request.FILES:
                question.question_image_data = request.FILES['question_image_data'].read()
            if 'option_a_image_data' in request.FILES:
                question.option_a_image_data = request.FILES['option_a_image_data'].read()
            if 'option_b_image_data' in request.FILES:
                question.option_b_image_data = request.FILES['option_b_image_data'].read()
            if 'option_c_image_data' in request.FILES:
                question.option_c_image_data = request.FILES['option_c_image_data'].read()
            if 'option_d_image_data' in request.FILES:
                question.option_d_image_data = request.FILES['option_d_image_data'].read()
            else:
                question.question_image_data = None
            question.save()
            return HttpResponse("Question updated successfully")
    else:
        form = QuestionForm(instance=question)

    return render(request, 'update_image.html', {'form': form})


@csrf_exempt
def update_question(request, question_id):
    # Retrieve the question object, or return a 404 error if not found
    question = get_object_or_404(question_master, id=question_id)
    
    print("Received POST data:", request.POST)
    print("Received FILES data:", request.FILES)
    
    if request.method == 'POST':
        # Convert invalid "null" string to None for mark field
        post_data = request.POST.copy()
        if post_data.get("mark") == "null":
            post_data["mark"] = None  # Convert to None
        
        print("Checking form validity...")

        form = QuestionFormMCQ(post_data, request.FILES, instance=question)
        
        if not form.is_valid():
            print("Form validation failed. Errors:", form.errors)
            return HttpResponse("Error: Invalid form data", status=400)

        print("Form is valid!")
        question = form.save(commit=False)
        
        # Handle file uploads for the image data fields
        for field in ['question_image_data', 'option_a_image_data', 'option_b_image_data',
                      'option_c_image_data', 'option_d_image_data', 'option_e_image_data']:
            if field in request.FILES:
                setattr(question, field, request.FILES[field].read())

        print("option_e received:", form.cleaned_data.get('option_e'))

        # Save the updated question object
        question.save()

        # Retrieve and update the related question_paper_master instance
        question_paper = question.question_name_id
        print('question_paper: ', question_paper)
        
        if question_paper:
            try:
                question_paper.dtm_created = datetime.now()
                question_paper.save()
                print('Question Paper DTM Updated Successfully')
            except Exception as e:
                print("Error updating question_paper:", str(e))

        return HttpResponse("Question updated successfully")

    # If GET request, display form with current question data
    else:
        form = QuestionFormMCQ(instance=question)

    return render(request, 'update_question.html', {'form': form})

def delete_question_IO(request, pk):
    #logger.info(f"Attempting to mark Questions with id {pk} as deleted")
    try:
        question = question_master.objects.get(id=pk)
    except question_master.DoesNotExist:
        return JsonResponse("Question not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    question.deleted = 1
    question.save()

    #logger.info(f"Marked Questions with id {pk} as deleted successfully")

    return JsonResponse("Question 'deleted' field updated successfully", safe=False)


def get_questions_Code(request):
    try:
        questionset = question_master.objects.filter(deleted=0).select_related('question_name_id').annotate(
            question_name_id_value=Case(
                When(question_name_id__isnull=False, then=F('question_name_id__id')),
                default=Value(None),
            ),
            question_paper_name_value=Case(
                When(question_name_id__isnull=False, then=F('question_name_id__question_paper_name')),
                default=Value(None),
            ),
        ).values(
            'id',
            'question_name_id_value',
            'question_paper_name_value',
            'question_text',
            'view_hint',
            'mark',
            'explain_answer',
            'answer',
            'negative_mark',
            'input_format',
             'difficulty_level',
            'question_image_data',  # Include raw binary image
        )

        question_data = [
            {
                'id': question['id'],
                'question_name_id': question['question_name_id_value'],
                'question_paper_name': question['question_paper_name_value'],
                'question_text': question['question_text'],
                'question_image_data': base64.b64encode(question['question_image_data']).decode('utf-8') if question['question_image_data'] else None,
                'view_hint': question['view_hint'],
                'mark': question['mark'],
                'explain_answer': question['explain_answer'],
                'answer': question['answer'],
                'negative_mark': question['negative_mark'],
                'input_format': question['input_format'],
                'difficulty_level':question['difficulty_level'],
            }
            for question in questionset
        ]

        random.shuffle(question_data)
        return JsonResponse(question_data, safe=False)

    except Exception as e:
        logger.error(f'Error occurred in get_questions_Code function: {e}')
        return JsonResponse({'error': 'An error occurred'}, status=500)


def upload_question_code(request):
    if request.method == 'POST':
        form = QuestionCodeForm(request.POST, request.FILES)
        if form.is_valid():
            question = form.save(commit=False)
            if 'question_image_data' in request.FILES:
                question.question_image_data = request.FILES['question_image_data'].read()
            else:
                question.question_image_data = None
                question.save()
            return HttpResponse("Question created successfully")
    else:
        form = QuestionCodeForm()
    return render(request, 'upload_image.html', {'form': form})

def update_question_code(request, question_id):
    question = get_object_or_404(question_master, id=question_id, deleted=0)

    if request.method == 'POST':
        form = QuestionCodeForm(request.POST, request.FILES, instance=question)
        if form.is_valid():
            question = form.save(commit=False)
            if 'question_image_data' in request.FILES:
                question.question_image_data = request.FILES['question_image_data'].read()
            question.save()
            return HttpResponse("Question updated successfully")
    else:
        form = QuestionCodeForm(instance=question)

    return render(request, 'update_image.html', {'form': form})



#-----------------------Getting All questions where question_paper_id--------------------------#


@api_view(['GET'])
def get_questions_Qp_id(request, question_name_id):
    # Fetch the required data using select_related and values
    questionset = question_master.objects.filter(deleted=0, question_name_id=question_name_id).select_related('question_name_id').values(
        'id',
        'question_name_id__id',
        'question_name_id__question_paper_name',
        'question_name_id__topic',
         'question_name_id__test_type',

        'question_name_id__is_testcase',
        'question_text',
        'question_image_data',
        'option_a_image_data',
        'option_b_image_data',
        'option_c_image_data',
        'option_d_image_data',
         'option_e_image_data',
        'option_a',
        'option_b',
        'option_c',
        'option_d',
        'option_e',
        'mark',
        'explain_answer',
        'answer',
        'mark_method',
        'input_format',
        'difficulty_level',
        'test_case1',
        'test_case2',
        'test_case3',
        'sections'
    )

    question_data = []
    for question in questionset:
        question_image_data = base64.b64encode(question['question_image_data']).decode('utf-8') if question['question_image_data'] else None
        option_a_image_data = base64.b64encode(question['option_a_image_data']).decode('utf-8') if question['option_a_image_data'] else None
        option_b_image_data = base64.b64encode(question['option_b_image_data']).decode('utf-8') if question['option_b_image_data'] else None
        option_c_image_data = base64.b64encode(question['option_c_image_data']).decode('utf-8') if question['option_c_image_data'] else None
        option_d_image_data = base64.b64encode(question['option_d_image_data']).decode('utf-8') if question['option_d_image_data'] else None
        option_e_image_data = base64.b64encode(question['option_e_image_data']).decode('utf-8') if question['option_e_image_data'] else None

        question_data.append({
            'id': question['id'],
            'question_name_id': question['question_name_id__id'],
            'question_paper_name': question['question_name_id__question_paper_name'],
            'topic': question['question_name_id__topic'],
            'test_type': question['question_name_id__test_type'],
            'is_testcase':question['question_name_id__is_testcase'],
            'question_text': question['question_text'],
            'question_image_data': question_image_data,
            'option_a_image_data': option_a_image_data,
            'option_b_image_data': option_b_image_data,
            'option_c_image_data': option_c_image_data,
            'option_d_image_data': option_d_image_data,
            'option_e_image_data': option_e_image_data,
            'option_a': question['option_a'],
            'option_b': question['option_b'],
            'option_c': question['option_c'],
            'option_d': question['option_d'],
            'option_e': question['option_e'],
            'mark': question['mark'],
            'explain_answer': question['explain_answer'],
            'answer': question['answer'],
            'mark_method': question['mark_method'],
            'input_format': question['input_format'],
            'test_case1':question['test_case1'],
            'test_case2':question['test_case2'],
            'test_case3':question['test_case3'],
            'sections': question['sections'],
            'difficulty_level':question['difficulty_level']
            
        })

    return JsonResponse(question_data, safe=False)

class questionsRetrieveUpdateAPIView_IO_code(generics.RetrieveUpdateAPIView):
    queryset = question_master.objects.all()
    serializer_class = questionsSerializer_code


    def update(self, request, *args, **kwargs):
        instance = self.get_object()
        response = super().update(request, *args, **kwargs)
        
        # Update the dtm_created field of the related question_paper_master
        question_paper = instance.question_name_id  # Adjust this based on your ForeignKey field name
        print('question_paper: ', question_paper)
        question_paper.dtm_created = datetime.now()
        question_paper.save()
        print('question_paper_saved....')

        return response

    def put(self, request, *args, **kwargs):
        # logger.info(f"Updating Questions with id {kwargs.get('pk')}")
        response = self.update(request, *args, **kwargs)
        # logger.info(f"Updated Questions with id {kwargs.get('pk')} successfully")
        return response

    def patch(self, request, *args, **kwargs):
        # logger.info(f"Partially updating Questions with id {kwargs.get('pk')}")
        response = self.update(request, *args, **kwargs)
        # logger.info(f"Partially updated Questions with id {kwargs.get('pk')} successfully")
        return response



class questionscreateAPIView_IO_code(generics.CreateAPIView):
    queryset = question_master.objects.all()
    serializer_class = questionsSerializer_code

    def post(self, request, *args, **kwargs):
        #logger.info("Creating a new Questions")
        response = super().post(request, *args, **kwargs)
        #logger.info("Created a new Questions successfully")
        return response


@api_view(['PUT'])
def update_Need_Candidate_info(request, studentID=None):
    n_info_list = tests_candidates_map.objects.filter(student_id=studentID)
    print('request.data: ', request.data)

    if not n_info_list.exists():
        return JsonResponse("No candidate info found for the given student ID", safe=False)

    for n_info in n_info_list:
        serializer = testcandidatemapSerializers(instance=n_info, data=request.data, partial=True)
        if serializer.is_valid():
            serializer.save()
            print('serializer: ', serializer)
        else:
            return JsonResponse("Failed to Update Need Candidate info, clg, dept, year", safe=False)

    print('Need Candidate info, clg, dept, year updated')
    return JsonResponse("Need Candidate info, clg, dept, year Updated Successfully", safe=False)


@api_view(['PUT'])
def update_clg_login(request, userName=None):
    clg = login.objects.get(user_name=userName)
    print('request.data: ', request.data)
    serializer = loginSerializer(instance=clg, data=request.data, partial=True)

    if serializer.is_valid():
        serializer.save()
        print('serializer: ', serializer)
        print('College updated')
        return JsonResponse("College Updated Successfully", safe=False)
    return JsonResponse("Failed to Update College. ")


@api_view(['GET'])
def get_candidate_login(request):
    # Subquery to fetch the password from the login table based on the user_name
    login_subquery = login.objects.filter(user_name=OuterRef('user_name')).values('password')[:1]

    # Fetch the candidates and annotate the password from the user_profile table
    candidatelist = candidate_master.objects.filter(deleted=0).annotate(
        password=Subquery(login_subquery)
    ).values(
        'id', 'user_name', 'students_name', 'password', 'college_id__college','college_id'
    )

    candidate_data = [
        {
            'student_id': candidate['id'],
            'user_name': candidate['user_name'],
            'student_name': candidate['students_name'],
            'password': candidate['password'],
            'college_name': candidate['college_id__college'],
            'college_id': candidate['college_id']
        }
        for candidate in candidatelist
    ]

    return Response(candidate_data)

class TestAssignFor_Selected(APIView):
    def post(self, request):
        stu_id = request.data.get('stu_id', [])
        if not isinstance(stu_id, list):
            return Response(
                {"error": "stu_id must be a list"},
                status=status.HTTP_400_BAD_REQUEST
            )

        test_name = request.data.get('test_name')
        question_id = request.data.get('question_id')

        print("üìå test_name:", test_name)
        print("üìå question_id:", question_id)

        # üîé 1) Get existing config for is_camera_on
        existing_test = tests_candidates_map.objects.filter(
            test_name=test_name,
            question_id=question_id
        ).order_by('-id').first()

        existing_is_camera_on = existing_test.is_camera_on if existing_test else None

        # =====================================================
        # ‚úÖ FALLBACK LOGIC (ONLY if question_id NOT received)
        # =====================================================
        question_ids_fallback = None
        no_of_question_fallback = None

        if not question_id:
            existing_test_for_questions = (
                tests_candidates_map.objects
                .filter(test_name=test_name)
                .exclude(question_ids__isnull=True)
                .order_by('-id')
                .first()
            )

            if existing_test_for_questions:
                question_ids_fallback = existing_test_for_questions.question_ids
                no_of_question_fallback = existing_test_for_questions.no_of_question

                print("üìå Fallback question_ids:", question_ids_fallback)
                print("üìå Fallback no_of_question:", no_of_question_fallback)

        # Decide final values
        final_question_id = question_id if question_id else None
        final_question_ids = question_ids_fallback if not question_id else None
        final_no_of_question = no_of_question_fallback if not question_id else None
        # =====================================================

        data = []

        for s_id in stu_id:
            try:
                student = candidate_master.objects.get(id=s_id, deleted=0)
            except candidate_master.DoesNotExist:
                return Response(
                    {"error": f"Student with id {s_id} does not exist"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # üîÅ Decide is_camera_on
            incoming_is_camera_on = request.data.get('is_camera_on', None)
            if incoming_is_camera_on is None:
                is_camera_on_value = existing_is_camera_on
            else:
                is_camera_on_value = incoming_is_camera_on

            # ‚úÖ Preparing data
            test_candidate_data = {
                'test_name': test_name,

                # Existing / fallback question logic
                'question_id': final_question_id,
                'question_ids': final_question_ids,
                'no_of_question': final_no_of_question,

                'college_id': student.college_id.id if student.college_id else None,
                'department_id': student.department_id.id if student.department_id else None,
                'year': student.year if student.year else None,
                'student_id': student.id,

                'dtm_start': request.data.get('dtm_start'),
                'dtm_end': request.data.get('dtm_end'),
                'dtm_start1': request.data.get('dtm_start'),
                'dtm_end1': request.data.get('dtm_end'),

                'is_camera_on': is_camera_on_value,
                'duration': request.data.get('duration'),
                'duration_type': request.data.get('duration_type'),
                'rules_id': request.data.get('rules_id'),
                'need_candidate_info': request.data.get('need_candidate_info'),
                'dtm_created': request.data.get('dtm_created'),
            }

            serializer = testcandidatemapSerializers(data=test_candidate_data)
            if serializer.is_valid():
                serializer.save()
                data.append(serializer.data)

                # Update candidate_master.need_candidate_info once
                if (
                    student.need_candidate_info is None
                    and request.data.get('need_candidate_info') is True
                ):
                    student.need_candidate_info = True
                    student.save(update_fields=['need_candidate_info'])
            else:
                print("‚ùå Serializer errors:", serializer.errors)
                return Response(
                    serializer.errors,
                    status=status.HTTP_400_BAD_REQUEST
                )

        return Response(data, status=status.HTTP_201_CREATED)


@api_view(['GET'])
def get_group_test_name(request, college_id=None):
    try:
        search = request.query_params.get('search', '')

        filters = {'deleted': 0}
        if college_id is not None:
            filters['college_id'] = college_id

        tests_candidates = tests_candidates_map.objects.filter(**filters).exclude(created_by='Student')

        if search:
            tests_candidates = tests_candidates.filter(
                Q(test_name__icontains=search)
            )

        # ‚úÖ Group by test_name, dtm_start1, dtm_end1
        tests_candidates = (
            tests_candidates
            .values('test_name', 'dtm_start1', 'dtm_end1','college_id')
            .annotate(
                student_count=Count('student_id'),
                active_student_count=Count('student_id', filter=Q(is_active=True)),
                reassigned_student_count=Count('student_id', filter=Q(is_reassigned=True)),
                latest_id=Max('id')   # ‚úÖ Track latest id per group
            )
        )

        # ‚úÖ Sort by latest_id (instead of dtm_created)
        tests_candidates = sorted(
            tests_candidates,
            key=lambda x: x['latest_id'] or 0,
            reverse=True
        )

        paginator = CustomPagination()
        paginated_data = paginator.paginate_queryset(tests_candidates, request)

        test_candidate_map_data = [
            {
                'test_name': row['test_name'],
                  'college_id': row['college_id'],
                'dtm_start': django_format_date(localtime(row['dtm_start1']), 'd-m-Y h:i A') if row['dtm_start1'] else "Not Available",
                'dtm_end': django_format_date(localtime(row['dtm_end1']), 'd-m-Y h:i A') if row['dtm_end1'] else "Not Available",
                'student_count': row['student_count'],
                'active_student_count': row['active_student_count'],
                'reassigned_student_count': row['reassigned_student_count'],
                'latest_id': row['latest_id'],  # ‚úÖ Expose latest id (optional, for debugging)
            }
            for row in paginated_data
        ]

        return paginator.get_paginated_response(test_candidate_map_data)

    except Exception as e:
        return Response({'error': str(e)}, status=500)

#_____________________________________________Company_master______________________________________________


class company_listView(generics.ListAPIView):
    queryset = company_master.objects.filter(deleted=0)
    serializer_class = companySerializer

    def get(self, request, *args, **kwargs):
        #logger.info("Fetching test types where deleted=0")
        return super().get(request, *args, **kwargs)

class company_create(generics.CreateAPIView):
    queryset = company_master.objects.all()
    serializer_class = companySerializer

    def post(self, request, *args, **kwargs):
        #logger.info("Creating a new test type")
        return super().post(request, *args, **kwargs)
class company_master_delete(generics.RetrieveDestroyAPIView):
    queryset = company_master.objects.all()
    serializer_class = companySerializer

   


class company_master_Update(generics.RetrieveUpdateAPIView):
    queryset = company_master.objects.all()
    serializer_class = companySerializer

    def put(self, request, *args, **kwargs):
        #logger.info(f"Updating test type with id {kwargs.get('pk')}")
        return super().put(request, *args, **kwargs)

    def patch(self, request, *args, **kwargs):
        #logger.info(f"Partially updating test type with id {kwargs.get('pk')}")
        return super().patch(request, *args, **kwargs)

@api_view(['PUT', 'PATCH'])
def delete_company_master(request, pk):
    try:
        #logger.info(f"Attempting to mark test type with id {pk} as deleted")
        company_mastervar = company_master.objects.get(id=pk)
    except company_master.DoesNotExist:
        logger.error(f"Test type with id {pk} not found")
        return JsonResponse("company_master not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    company_mastervar.deleted = 1
    company_mastervar.save()

    #logger.info(f"Marked test type with id {pk} as deleted")
    return JsonResponse("company_master 'deleted' field updated successfully", safe=False)

#______________________________________________________job_offers______________________________________________#



from collections import defaultdict
from rest_framework.decorators import api_view
from rest_framework.response import Response
from .models import job_offers

@api_view(['GET'])
def get_job(request):
    job_data = job_offers.objects.filter(deleted=0).prefetch_related(
        'college_id', 'department_id', 'skill_id'
    ).values(
        'id',
        'company_name',
        'post_name',
        'job_type',
        'company_profile',
        'college_id__college',
        'department_id__department',
        'skill_id__skill_name',
        'intern_fulltime',
        'on_off_campus',
        'marks_10th',
        'marks_12th',
        'cgpa',
        'gender',
        'year',
        'interview_date',
        'history_of_arrears',
        'standing_arrears',
        'location',
        'no_of_offers'
    )

    # Create a mapping for related fields
    job_dict = defaultdict(lambda: {
        'id': None,
        'company_name': None,
        'post_name': None,
        'job_type': None,
        'company_profile': None,
        'colleges': set(),
        'departments': set(),
        'skills': set(),
        'intern_fulltime': None,
        'on_off_campus': None,
        'marks_10th': None,
        'marks_12th': None,
        'cgpa': None,
        'gender': None,
        'year': None,
        'interview_date': None,
        'history_of_arrears': None,
        'standing_arrears': None,
        'location': None,
        'no_of_offers': None
    })

    for entry in job_data:
        job = job_dict[entry['id']]
        job.update(entry)

        # Only add non-null values
        if entry.get('college_id__college'):
            job['colleges'].add(entry['college_id__college'])
        if entry.get('department_id__department'):
            job['departments'].add(entry['department_id__department'])
        if entry.get('skill_id__skill_name'):
            job['skills'].add(entry['skill_id__skill_name'])

    # Convert sets to lists for serialization
    job_list = [
        {
            **job,
            'colleges': list(job['colleges']) if job['colleges'] else None,
            'departments': list(job['departments']) if job['departments'] else None,
            'skills': list(job['skills']) if job['skills'] else None,
        }
        for job in job_dict.values()
    ]

    return Response(job_list)

class jobUpdateAPIView(generics.RetrieveUpdateAPIView):
    # print("Job Update API Initialized")

    queryset = job_offers.objects.all()
    serializer_class = jobOffersSerializer

    def perform_update(self, serializer):
        """
        Called when a job is updated.
        """
        try:
            job_instance = serializer.save()
            print(f"Job instance updated: {job_instance}")
            self.create_eligible_students(job_instance)
        except Exception as e:
            print(f"Error in updating job: {e}")
            print(f"Serializer errors: {serializer.errors}")

    def create_eligible_students(self, job_instance):
        try:
            if not job_offers.objects.filter(id=job_instance.id).exists():
                raise ValueError(f"Job with id {job_instance.id} does not exist.")
            print(f"Job instance found: {job_instance}")

            # Step 1: Fetch all students based on college_id
            college_ids = job_instance.college_id.all().values_list('id', flat=True)
            print(f"College IDs for job {job_instance.id}: {college_ids}")
            all_students = candidate_master.objects.filter(college_id__in=college_ids, deleted=0)
            print(f"All students fetched for colleges: {[student.id for student in all_students]}")

            # Step 2: Existing eligible student records
            existing_students_ids = eligible_student_list.objects.filter(job_id=job_instance.id).values_list('students_id', flat=True)
            print(f"Existing eligible student IDs for job {job_instance.id}: {list(existing_students_ids)}")

            # Step 3: Create new ineligible students
            ineligible_students = [
                {'students_id': student.id, 'job_id': job_instance.id, 'is_eligible': False, 'round_of_interview': 'Interview Date'}
                for student in all_students if student.id not in existing_students_ids
            ]
            print(f"Ineligible students to save: {ineligible_students}")

            if ineligible_students:
                ineligible_serializer = eligible_studentSerializer(data=ineligible_students, many=True)
                if ineligible_serializer.is_valid(raise_exception=True):
                    ineligible_serializer.save()
                    print("New ineligible students saved.")
            else:
                print("No new ineligible students to save.")

            # Step 4: Filter and update eligible students
            eligible_candidates = self.filter_candidates(job_instance)
            eligible_ids = [candidate.id for candidate in eligible_candidates]
            print(f"Filtered eligible student IDs: {eligible_ids}")

            updated_count = eligible_student_list.objects.filter(
                job_id=job_instance.id,
                students_id__in=eligible_ids
            ).update(is_eligible=True)
            print(f"Updated {updated_count} eligible student records to is_eligible=True.")

        except Exception as e:
            print(f"Exception in create_eligible_students: {e}")

    def filter_candidates(self, job_instance):
        """
        Filter candidates eligible for the job based on criteria.
        """
        try:
            print(f"Filtering candidates for job: {job_instance.id}")

            # Correctly access ManyToManyField
            department_ids = list(job_instance.department_id.all().values_list('id', flat=True))
            college_ids = list(job_instance.college_id.all().values_list('id', flat=True))
            skill_ids = list(job_instance.skill_id.all().values_list('id', flat=True))

            print(f"department_ids for job {job_instance.id}: {department_ids}")
            print(f"college_ids for job {job_instance.id}: {college_ids}")
            print(f"skill_ids for job {job_instance.id}: {skill_ids}")

            # Create filter conditions
            filters = Q(deleted=0)

            if department_ids:
                filters &= Q(department_id__in=department_ids)
                print(f"Added department filter: {department_ids}")

            if college_ids:
                filters &= Q(college_id__in=college_ids)
                print(f"Added college filter: {college_ids}")

            if skill_ids:
                filters &= Q(skill_id__in=skill_ids)
                print(f"Added skill filter: {skill_ids}")

            criteria = {
                'year': job_instance.year,
                'marks_10th__gte': job_instance.marks_10th,
                'marks_12th__gte': job_instance.marks_12th,
                'cgpa__gte': job_instance.cgpa,
                'history_of_arrears__lte': job_instance.history_of_arrears,
                'standing_arrears__lte': job_instance.standing_arrears,
            }

            for field, value in criteria.items():
                if value is not None:
                    filters &= Q(**{field: value})
                    print(f"Added filter {field}: {value}")

            if job_instance.no_of_offers is not None:
                filters &= Q(number_of_offers__lte=job_instance.no_of_offers)
                print(f"Added no_of_offers filter: <= {job_instance.no_of_offers}")

            if job_instance.gender:
                if job_instance.gender == 'Male':
                    filters &= Q(gender__iexact='Male')
                elif job_instance.gender == 'Female':
                    filters &= Q(gender__iexact='Female')
                elif job_instance.gender == 'Both':
                    filters &= Q(gender__in=['Male', 'Female'])
                print(f"Added gender filter: {job_instance.gender}")

            print(f"Final filters: {filters}")

            candidates = candidate_master.objects.filter(filters)
            print('Filtered Candidates: ', candidates)

            candidate_count = candidates.count()
            print(f"Final count of candidates: [{candidate_count}]")
            print(f"Filtered eligible student IDs: {[candidate.id for candidate in candidates]}")

            return candidates

        except Exception as e:
            print(f"Exception in filter_candidates: {e}")
            return candidate_master.objects.none()

  
        
@api_view(['PUT', 'PATCH'])
def delete_job(request, pk):
    #logger.info(f"Attempting to mark job with id {pk} as deleted")
    try:
        print("Entering Function..")
        jobs=job_offers.objects.get(id=pk)

        print("job: ",jobs)
    except job_offers.DoesNotExist:
        return JsonResponse("job not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    jobs.deleted = 1
    jobs.save()

    #logger.info(f"Marked job with id {pk} as deleted successfully")

    print("course: ",jobs)

    return JsonResponse("course 'deleted' field updated successfully", safe=False)


#----------------------------Training admin Dashboard datas-------------------#

# Get Total Test Count

def get_distinct_test_name_count(request, college_id):
    # Perform the query to count distinct test names for the given college_id
    distinct_test_name_count = tests_candidates_map.objects.filter(college_id=college_id,deleted=0).values('test_name').distinct().count()
    
    # Return the count as a JSON response
    return JsonResponse({'distinct_test_name_count': distinct_test_name_count})



# Avg Score of Aptitude

@api_view(['GET'])
def get_avg_score_by_department(request, college_id, dtm_start):
    try:
        print('college_id: ', college_id)
        print('dtm_start: ', dtm_start)
        # Convert dtm_start to a datetime object
        dtm_start_date = timezone.make_aware(timezone.datetime.strptime(dtm_start, '%Y-%m-%d'))
        print('dtm_start: ', dtm_start_date)

        # Get all departments
        departments = department_master.objects.filter(deleted=0).values('id', 'department')

        # Calculate the average score for each department
        results = []
        for department in departments:
            avg_score = tests_candidates_map.objects.filter(
                college_id=college_id,
                dtm_start__date=dtm_start_date,
                question_id__test_type='MCQ Test',
                department_id=department['id'],
                deleted=0
            ).aggregate(avg_score=Avg('total_score'))['avg_score'] or 0

            results.append({
                'department_name': department['department'],
                'avg_score': avg_score
            })

        # Return the results as a JSON response
        return JsonResponse(results, safe=False, status=200)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


# Avg Score of Coding
@api_view(['GET'])
def avg_score_by_department_Coding(request, college_id, dtm_start):
    try:
        print('college_id: ', college_id)
        print('dtm_start: ', dtm_start)
        # Convert dtm_start to a datetime object
        dtm_start_date = timezone.make_aware(timezone.datetime.strptime(dtm_start, '%Y-%m-%d'))
        print('dtm_start: ', dtm_start_date)

        # Get all departments
        departments = department_master.objects.filter(deleted=0).values('id', 'department')

        # Calculate the average score for each department
        results = []
        for department in departments:
            avg_score = tests_candidates_map.objects.filter(
                college_id=college_id,
                dtm_start__date=dtm_start_date,
                question_id__test_type='Coding Test',
                department_id=department['id'],
                deleted=0
            ).aggregate(avg_score=Avg('total_score'))['avg_score'] or 0

            results.append({
                'department_name': department['department'],
                'avg_score': avg_score
            })

        # Return the results as a JSON response
        return JsonResponse(results, safe=False, status=200)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


#  College Topper


def get_max_score_by_department(request, college_id):
    try:
        # First, create a subquery to get the maximum total score per department
        subquery = tests_candidates_map.objects.filter(
            college_id=college_id,
            question_id__test_type='MCQ Test',
            total_score__isnull=False,
            department_id=OuterRef('department_id'),
            deleted=0
        ).values(
            'department_id'
        ).annotate(
            max_total_score=Max('total_score')
        ).values('max_total_score')

        # Then, filter the original query using this subquery to get the corresponding student names
        results = tests_candidates_map.objects.filter(
            college_id=college_id,
            question_id__test_type='MCQ Test',
            total_score__isnull=False,
            deleted=0,
            total_score=Subquery(subquery)  # Match the max score in each department
        ).values(
            'student_id__students_name',
            'department_id__department',
            'total_score'
        ).distinct()  # Ensure unique records in case of ties

        # Format the results as a list of dictionaries
        data = [
            {
                'student_name': result['student_id__students_name'],
                'department': result['department_id__department'],
                'max_total_score': result['total_score']
            }
            for result in results
        ]

        # Return the results as a JSON response
        return JsonResponse(data, safe=False, status=200)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)



def get_max_score_by_department_coding(request, college_id):
    try:
        # First, create a subquery to get the maximum total score per department
        subquery = tests_candidates_map.objects.filter(
            college_id=college_id,
            question_id__test_type='Coding Test',
            total_score__isnull=False,
            department_id=OuterRef('department_id'),
            deleted=0
        ).values(
            'department_id'
        ).annotate(
            max_total_score=Max('total_score')
        ).values('max_total_score')

        # Then, filter the original query using this subquery to get the corresponding student names
        results = tests_candidates_map.objects.filter(
            college_id=college_id,
            question_id__test_type='Coding Test',
            total_score__isnull=False,
            total_score=Subquery(subquery),  # Match the max score in each department
            deleted=0
        ).values(
            'student_id__students_name',
            'department_id__department',
            'total_score'
        ).distinct()  # Ensure unique records in case of ties

        # Format the results as a list of dictionaries
        data = [
            {
                'student_name': result['student_id__students_name'],
                'department': result['department_id__department'],
                'max_total_score': result['total_score']
            }
            for result in results
        ]

        # Return the results as a JSON response
        return JsonResponse(data, safe=False, status=200)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


# Count of company


def count_company_names(request):
    try:
        # Perform the query to count company_name entries
        result = company_master.objects.filter(deleted=0).aggregate(
            count_company_name=Count('company_name')
        )

        # Return the count as a JSON response
        return JsonResponse(result, status=200)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


#------------------------------Placement admin Dashboard datas-----------------------#


def get_distinct_test_name_count_today(request):
    try:
        # Get today's date
        today_date = date.today()

        # Perform the query to count distinct test_name where dtm_start is today's date
        distinct_test_name_count = tests_candidates_map.objects.filter(
            dtm_start__date=today_date,
            deleted=0
        ).values('test_name').distinct().count()

        # Return the count as JSON response
        return JsonResponse({'distinct_test_name_count': distinct_test_name_count}, status=200)
    
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


#__________________________________IMport MCQ   Questions____________________________#
import fitz  # PyMuPDF

def extract_text_and_images_from_docx_mcq(docx_path):
    # Open the DOCX file
    print(f"Opening DOCX file: {docx_path}")
    doc = docx.Document(docx_path)
    text = []
    images_binary = {}
    image_count = 0

    # Extract text from the document
    print("Extracting text from the document...")
    for para in doc.paragraphs:
        text.append(para.text)
        print(f"Extracted paragraph: {para.text}")

    # Extract images from the document
    print("Extracting images from the document...")
    for rel in doc.part.rels:
        target = doc.part.rels[rel].target_ref
        print(f"Found relationship: {rel}, target: {target}")
        if "image" in target:
            image_count = str(target).split('.')[0][-1]
            image = doc.part.rels[rel].target_part.blob
            images_binary[f"image_{image_count}"] = base64.b64encode(image).decode('utf-8')
            print(f"Extracted image {image_count}")

    # Return the extracted text and images
    print("Text and image extraction complete.")
    return '\n'.join(text), images_binary

def extract_text_and_images_from_pdf(file):
    print("Opening PDF file...")
    doc = fitz.open(stream=file.read(), filetype="pdf")
    text = ""
    images_binary = {}
    image_index = 1

    print("Extracting text and images from PDF...")
    for page_number in range(len(doc)):
        page = doc[page_number]
        text += page.get_text() + "\n"

        image_list = page.get_images(full=True)
        for img_index, img in enumerate(image_list):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            images_binary[f"image_{image_index}"] = base64.b64encode(image_bytes).decode("utf-8")
            print(f"Extracted image_{image_index} from page {page_number}")
            image_index += 1

    doc.close()
    return text, images_binary

# Function to remove serial numbers from question text
def remove_serial_number_mcq(question_text):
    cleaned_text = re.sub(r'^\d+\s?\)\s*', '', question_text)
    print(f"Removed serial number: '{question_text}' -> '{cleaned_text}'")
    return cleaned_text

def remove_option_choice_mcq(option_text):
    cleaned_text = re.sub(r'^[a-e]\s*?\)\s*', '', option_text)
    print(f"Removed option choice: '{option_text}' -> '{cleaned_text}'")
    return cleaned_text

# Function to create a JSON structure from the extracted text and images
def create_json_structure(text, images_binary):
    try:
        questions = []
        lines = text.split('\n')
        current_question = {}
        options = {}
        image_keys = list(images_binary.keys())
        image_index = 1
        unmatched_lines = []

        print("Creating JSON structure from extracted text...")

        # Define patterns for different parts of the question
        question_pattern = re.compile(r'^(question:|[0-9]+\)|[0-9]+\.)', re.IGNORECASE)
        sections_pattern = re.compile(r'^\s*sections:', re.IGNORECASE)

        question_image_pattern = re.compile(r'^\s*Image\d+\s?\)')
        option_a_pattern = re.compile(r'^\s*a\s?\)')
        option_b_pattern = re.compile(r'^\s*b\s?\)')
        option_c_pattern = re.compile(r'^\s*c\s?\)')
        option_d_pattern = re.compile(r'^\s*d\s?\)')
        option_e_pattern = re.compile(r'^\s*e\s?\)')

        answer_pattern = re.compile(r'^\s*c_ans:')
        explanation_pattern = re.compile(r'^\s*e_ans:')
        mark_pattern = re.compile(r'^\s*mark:')
        difficulty_level_pattern = re.compile(r'^\s*difficulty_level\s*:', re.IGNORECASE)

       
        mark_method_pattern = re.compile(r'^\s*mark_method:')


        # Loop through each line in the text
        collecting_question_text = False

        for line in lines:
            line = line.strip()

            if question_pattern.match(line):
                print(f"Found question: {line}")

                # If already collecting a question, save it
                if current_question:
                    current_question['options'] = options
                    questions.append(current_question)
                    print(f"Added question: {current_question}")
                    current_question = {}
                    options = {}

                question_text = remove_serial_number_mcq(line)
                question_text_parts = question_text.split(':', 1)
                if len(question_text_parts) > 1:
                    current_question['question_text'] = question_text_parts[1].strip()
                else:
                    current_question['question_text'] = question_text.strip()

                collecting_question_text = True  # Start collecting question text if it spans multiple lines
                continue
            
            # Continue collecting multiline question text
            if collecting_question_text:
                # If the next line is not an option or other known pattern, append it to question_text
                if not (question_image_pattern.match(line) or option_a_pattern.match(line) or option_b_pattern.match(line) or option_c_pattern.match(line) or option_d_pattern.match(line) or answer_pattern.match(line)):
                    current_question['question_text'] += " " + line.strip()  # Append to the question text
                    continue
                else:
                    collecting_question_text = False  # Stop collecting if an option or other pattern is found

            # If image comes next
            if question_image_pattern.match(line):
                current_question['question_image_data'] = f"data:image/png;base64,{images_binary[f'image_{image_index}']}"
                print(f"Found question_image_data: {current_question['question_image_data']}")
                image_index += 1  # Increment for question images
                continue
            
            # If option A comes next
            if option_a_pattern.match(line):
                print(f"Found option A: {line}")
                option_a_text = remove_option_choice_mcq(line)
                options['a'] = [option_a_text, False] if option_a_text else [f"data:image/png;base64,{images_binary[f'image_{image_index}']}", True]
                if option_a_text == '':
                    image_index += 1
                continue
            
            # Similarly, handle option B, C, D
            elif option_b_pattern.match(line):
                print(f"Found option B: {line}")
                option_b_text = remove_option_choice_mcq(line)
                options['b'] = [option_b_text, False] if option_b_text else [f"data:image/png;base64,{images_binary[f'image_{image_index}']}", True]
                if option_b_text == '':
                    image_index += 1
                continue
            
            elif option_c_pattern.match(line):
                print(f"Found option C: {line}")
                option_c_text = remove_option_choice_mcq(line)
                options['c'] = [option_c_text, False] if option_c_text else [f"data:image/png;base64,{images_binary[f'image_{image_index}']}", True]
                if option_c_text == '':
                    image_index += 1
                continue
            
            elif option_d_pattern.match(line):
                print(f"Found option D: {line}")
                option_d_text = remove_option_choice_mcq(line)
                options['d'] = [option_d_text, False] if option_d_text else [f"data:image/png;base64,{images_binary[f'image_{image_index}']}", True]
                if option_d_text == '':
                    image_index += 1
                continue
            elif option_e_pattern.match(line):
                print(f"Found option E: {line}")
                option_e_text = remove_option_choice_mcq(line)
                options['e'] = [option_e_text, False] if option_e_text else [f"data:image/png;base64,{images_binary[f'image_{image_index}']}", True]
                if option_e_text == '':
                    image_index += 1
                continue

            
            # Handle answer
            elif answer_pattern.match(line):
                current_question['answer'] = line.split(':', 1)[1].strip()
                print(f"Found answer: {current_question['answer']}")
                continue
            
            # Handle explanation
            elif explanation_pattern.match(line):
                current_question['explanation'] = line.split(':', 1)[1].strip()
                print(f"Found explanation: {current_question['explanation']}")
                continue
            
            # Handle marks and negative marks
            elif mark_pattern.match(line):
                current_question['marks'] = int(line.split(':', 1)[1].strip())
                print(f"Found marks: {current_question['marks']}")
                continue
            elif mark_method_pattern.match(line):
                current_question['mark_method'] = line.split(':', 1)[1].strip()
                print(f"Found mark_method: {current_question['mark_method']}")
                continue
            elif sections_pattern.match(line):
                current_question['sections'] = line.split(':', 1)[1].strip()
                print(f"Found sections: {current_question['sections']}")
                continue

            
            elif difficulty_level_pattern.match(line):
                current_question['difficulty_level'] = line.split(':', 1)[1].strip()
                print(f"Found difficulty level: {current_question['difficulty_level']}")
                continue


            
            # Catch any unmatched lines
            else:
                if line:  # Check if the line is not empty
                    unmatched_lines.append((line, "Unmatched pattern"))
                    print(f"Unmatched line: {line}")

        # Add the final question if it exists
        if current_question:
            current_question['options'] = options
            questions.append(current_question)
            print(f"Added final question: {current_question}")

        print("JSON structure creation complete.")
        return {"questions": questions, "unmatched_lines": unmatched_lines}

    
    except Exception as e:
        print(f"An unexpected error occurred: Please check the DOCX file. Error: {e}")

# Function to save unmatched lines to a DOCX file
def save_unmatched_lines_to_docx(unmatched_lines, output_path):
    print(f"Saving unmatched lines to DOCX file: {output_path}")
    doc = docx.Document()
    doc.add_heading('Unmatched Lines Report', level=1)
    for line, reason in unmatched_lines:
        doc.add_paragraph(f"Line: {line}")
        doc.add_paragraph(f"Reason: {reason}")
        doc.add_paragraph("\n")
    doc.save(output_path)
    print("Unmatched lines saved successfully.")

def decode_base64_image(base64_str):
    if base64_str.startswith('data:image'):
        # Split the base64 string to get the actual data
        header, encoded = base64_str.split(',', 1)
        return base64.b64decode(encoded)
    return None


@csrf_exempt
def import_questions_from_word(request):
    if request.method == 'POST':
        print("Received POST request for question import.")
        form = QuestionImportForm(request.POST, request.FILES)
        if form.is_valid():
            uploaded_file = request.FILES['docx_file']
            filename = uploaded_file.name.lower()
            print("DOCX file received for processing.")

            try:
                # Create a new question_paper_master entry
                question_paper_name = request.POST.get('question_paper_name')
                duration_of_test = request.POST.get('duration_of_test')
                topic = request.POST.get('topic')
                sub_topic = request.POST.get('sub_topic')
                no_of_questions = request.POST.get('no_of_questions')
                upload_type = request.POST.get('upload_type')
                test_type = request.POST.get('test_type')
                current_date_and_time = timezone.now()
                folder_name = request.POST.get('folder_name')

                        # Build a list of the always‚Äêrequired values
                required_values = [
                    question_paper_name,
                    duration_of_test,
                    topic,
                    no_of_questions,
                    upload_type,
                    test_type,
                ]

                # Only require sub_topic if topic is NOT Softskills
                if topic != 'Softskills':
                    required_values.append(sub_topic)

                if not all(required_values):
                    return Response(
                        {'error': 'Missing fields for question_paper_master'},
                        status=status.HTTP_400_BAD_REQUEST
                    )
                question_paper_data = {
                    'question_paper_name': question_paper_name,
                    'duration_of_test': duration_of_test,
                    'topic': topic,
                    'sub_topic': sub_topic,
                    'no_of_questions': no_of_questions,
                    'upload_type': upload_type,
                    'test_type': test_type,
                    'dtm_created': current_date_and_time,
                    'folder_name': folder_name
                }

                print("Creating question paper instance...")
                question_paper_instance = question_paper_master.objects.create(**question_paper_data)
                print(f"Created question paper instance: {question_paper_instance.id}")

                # Get the directory of the current script
                current_dir = os.path.dirname(os.path.abspath(__file__))
                output_json_path = os.path.join(current_dir, '../words/output.json')
                output_unmatched_lines_path = os.path.join(current_dir, '../words/unmatched_lines.docx')

                # Extract text and images from DOCX
                print("Extracting text and images from DOCX...")
              #  text, images_binary = extract_text_and_images_from_docx_mcq(docx_file)
                

                # Step 1: Choose extractor based on file type
                if filename.endswith('.docx'):
                    text, images_binary = extract_text_and_images_from_docx_mcq(uploaded_file)
                elif filename.endswith('.pdf'):
                    text, images_binary = extract_text_and_images_from_pdf(uploaded_file)
                else:
                    return HttpResponse("Unsupported file format. Please upload a .docx or .pdf file.", status=400)


                # Create JSON structure
                print("Creating JSON structure from extracted data...")
                data = create_json_structure(text, images_binary)

                # Save JSON to file
                print(f"Saving extracted data to JSON file: {output_json_path}")
                with open(output_json_path, 'w') as json_file:
                    json.dump(data, json_file, indent=4)

                # Save unmatched lines to DOCX file
                print(f"Saving unmatched lines to DOCX file: {output_unmatched_lines_path}")
                #save_unmatched_lines_to_docx(data['unmatched_lines'], output_unmatched_lines_path)

                print("Processing questions...")
                for ques in data["questions"]:

                    question_text = ques.get('question_text', '')
                    sections = ques.get('sections', '')
                    question_image_data = ques.get('question_image_data', '')
                    mark_method = ques.get('mark_method', '')
                    answer = ques.get('answer', '')
                    marks = ques.get('marks', 0)
                    difficulty_level = ques.get('difficulty_level', '')
                    explain_answer = ques.get('explanation', '')

                    if ques['options']:
                        print("Extracting options...")
                        options_a = ques['options'].get('a', ['', False])
                        options_b = ques['options'].get('b', ['', False])
                        options_c = ques['options'].get('c', ['', False])
                        options_d = ques['options'].get('d', ['', False])
                        options_e = ques['options'].get('e', ['', False])

                        option_a_image_data = options_a[0] if options_a[1] else ''
                        option_a = options_a[0] if not options_a[1] else ''

                        option_b_image_data = options_b[0] if options_b[1] else ''
                        option_b = options_b[0] if not options_b[1] else ''

                        option_c_image_data = options_c[0] if options_c[1] else ''
                        option_c = options_c[0] if not options_c[1] else ''

                        option_d_image_data = options_d[0] if options_d[1] else ''
                        option_d = options_d[0] if not options_d[1] else ''
                        
                        option_e_image_data = options_e[0] if options_e[1] else ''
                        option_e = options_e[0] if not options_e[1] else ''


                        print(f"Options extracted: A: {option_a}, B: {option_b}, C: {option_c}, D: {option_d}, E: {option_e}")
                    else:
                        print(f"Warning: No options found for question: {question_text}")

                    # Create an instance of the model
                    question = question_master(
                        question_name_id=question_paper_instance,
                        question_text=question_text or '',
                        question_image_data=decode_base64_image(question_image_data) if question_image_data else None,
                        option_a_image_data=decode_base64_image(option_a_image_data) if option_a_image_data else None,
                        option_b_image_data=decode_base64_image(option_b_image_data) if option_b_image_data else None,
                        option_c_image_data=decode_base64_image(option_c_image_data) if option_c_image_data else None,
                        option_d_image_data=decode_base64_image(option_d_image_data) if option_d_image_data else None,
                        option_e_image_data=decode_base64_image(option_e_image_data) if option_e_image_data else None,
                 
                        input_format="",
                        option_a=option_a or '',
                        option_b=option_b or '',
                        option_c=option_c or '',
                        option_d=option_d or '',
                        option_e=option_e or '',
                        answer=answer or '',
                        difficulty_level=difficulty_level or '',
                        mark=marks or 0,
                        mark_method=mark_method or '',
                        explain_answer=explain_answer or '',
                        sections=sections or '',
                    )

                    print("Saving question to the database...")
                    question.save()
                    print(f"Saved question: {question.id}")

                print("All questions processed and saved successfully.")
                
            except Exception as e:
                print("Error processing file:", e)
                return HttpResponse(f"Error processing file: {e}")
        else:
            print("Form is not valid.")
            return HttpResponse("Form is not valid.")
    else:
        print("GET request received; rendering import form.")
        form = QuestionImportForm()

    return render(request, 'import_questions.html', {'form': form})


#___________________________________IMPORT CODING QUESTION___________________________________________________#

def extract_text_and_images_from_docx(docx_path):
    doc = docx.Document(docx_path)
    text = []
    images_binary = {}
    image_count = 0

    for para in doc.paragraphs:
        text.append(para.text)

    for rel in doc.part.rels:
        target = doc.part.rels[rel].target_ref
        if "image" in target:
            image_count += 1
            image = doc.part.rels[rel].target_part.blob
            images_binary[f"image_{image_count}"] = base64.b64encode(image).decode('utf-8')

    return '\n'.join(text), images_binary

def extract_text_from_pdfs(pdf_file):
    text = ""
    with fitz.open(stream=pdf_file.read(), filetype="pdf") as doc:
        for page in doc:
            text += page.get_text()
    return text, {}  # No image support for now


def remove_serial_number(question_text):
    return re.sub(r'^\d+\s?\)\s*', '', question_text)


def create_json_structures(text, images_binary):
    questions = []
    lines = text.split('\n')
    current_question = {}
    image_index = 1
    input_format_lines = []
    explanation_lines = []
    test_case_lines = {}

    # Define regex patterns
    patterns = {
        "question": re.compile(r'^question:\s*(.*)', re.IGNORECASE),
        "input_format": re.compile(r'^input_format:\s*(.*)', re.IGNORECASE),
        "c_ans": re.compile(r'^c_ans:\s*(.*)', re.IGNORECASE),
        "e_ans": re.compile(r'^e_ans:\s*\[(.*)', re.IGNORECASE),  # Captures first line of explanation
        "mark": re.compile(r'^mark:\s*(\d+)', re.IGNORECASE),
        "test_case": re.compile(r'^(test_case\d+):\s*(.*)', re.IGNORECASE),
        "difficulty_level": re.compile(r'^difficulty_level:\s*(.*)', re.IGNORECASE),  
    }

    # Flags to track capturing
    capturing_explanation = False
    capturing_input_format = False
    capturing_test_case = None

    def append_current_question():
        if 'question' in current_question:
            if input_format_lines:
                current_question['input_format'] = '\n'.join(input_format_lines).strip()
            if explanation_lines:
                current_question['e_ans'] = '\n'.join(explanation_lines).strip()
            for key, value in test_case_lines.items():
                current_question[key] = '\n'.join(value).strip()
            questions.append(current_question.copy())
            current_question.clear()

    for line in lines:
        line = line.strip()
        
        if patterns["question"].match(line):
            append_current_question()
            current_question["question"] = patterns["question"].match(line).group(1)
            test_case_lines = {}  # Reset test cases
            input_format_lines = []
            explanation_lines = []
            capturing_explanation = False
            capturing_input_format = False
            capturing_test_case = None

        elif patterns["input_format"].match(line):
            capturing_input_format = True
            input_format_lines = [patterns["input_format"].match(line).group(1)]

        elif patterns["c_ans"].match(line):
            current_question["answers"] = [patterns["c_ans"].match(line).group(1)]

        elif patterns["mark"].match(line):
            current_question["marks"] = int(patterns["mark"].match(line).group(1))

        elif patterns["test_case"].match(line):  
            capturing_test_case = patterns["test_case"].match(line).group(1)  
            test_case_lines[capturing_test_case] = [patterns["test_case"].match(line).group(2)]  

        elif patterns["e_ans"].match(line):  
            capturing_explanation = True
            explanation_lines = [patterns["e_ans"].match(line).group(1).strip()]  # Start capturing first line of explanation
        elif patterns["difficulty_level"].match(line):  # üëà NEW block
            current_question["difficulty_level"] = patterns["difficulty_level"].match(line).group(1).strip()

        elif capturing_explanation:
            if line.endswith("]"):  # Stop capturing explanation when `]` is found
                explanation_lines.append(line[:-1].strip())  # Remove closing bracket and store the last line
                capturing_explanation = False
            else:
                explanation_lines.append(line.strip())  # Continue capturing multi-line explanation

        elif capturing_input_format:
            if any(pattern.match(line) for pattern in patterns.values()):  
                capturing_input_format = False
            else:
                input_format_lines.append(line)

        elif capturing_test_case:
            if any(pattern.match(line) for pattern in patterns.values()):  
                capturing_test_case = None
            else:
                test_case_lines[capturing_test_case].append(line)  

        elif capturing_explanation:
            if line.endswith("]"):  # ‚úÖ Stop capturing explanation when `]` is found
                explanation_lines.append(line[:-1])  # Remove closing bracket
                capturing_explanation = False
            else:
                explanation_lines.append(line)  # Continue capturing multi-line explanation

    append_current_question()
    return {"questions": questions}

@csrf_exempt
def import_questions(request):
    if request.method == 'POST':
        form = DocumentForm(request.POST, request.FILES)
        if form.is_valid():
            docfile = request.FILES['docfile']
            filename = docfile.name.lower()
            ext = os.path.splitext(docfile.name)[1].lower()

            print("DOCX file received for processing.")
            try:
                #text, images_binary = extract_text_and_images_from_docx(docfile)
                if filename.endswith(".docx"):
                    text, images_binary = extract_text_and_images_from_docx(docfile)
                elif filename.endswith(".pdf"):
                    text, images_binary = extract_text_from_pdfs(docfile)
                else:
                    return HttpResponse("Unsupported file type. Please upload a .docx or .pdf file.", status=400)
                data = create_json_structures(text, images_binary)

                # Create a new question_paper_master entry
                question_paper_name = request.POST.get('question_paper_name')
                duration_of_test = request.POST.get('duration_of_test')
                topic = request.POST.get('topic')
                sub_topic = request.POST.get('sub_topic')
                no_of_questions = request.POST.get('no_of_questions')
                upload_type = request.POST.get('upload_type')
                test_type = request.POST.get('test_type')
                current_date_and_time = timezone.now()
                #created_by = request.POST.get('created_by')
                folder_name = request.POST.get('folder_name')
                is_testcase = request.POST.get('is_testcase', 'false')  # Default to 'false' if not provided

                      # Convert string "true"/"false" to actual boolean True/False
                is_testcase = is_testcase.lower() in ['true', '1']


                if not all([question_paper_name, duration_of_test, topic, sub_topic, no_of_questions, upload_type]):
                    print("is_testcase:", is_testcase)
                    return HttpResponse("Missing fields for question_paper_master", status=400)
                is_testcase = request.POST.get('is_testcase', 'false').lower() in ['true', '1']

                question_paper_data = {
                    'question_paper_name': question_paper_name,
                    'duration_of_test': duration_of_test,
                    'topic': topic,
                    'sub_topic': sub_topic,
                    'no_of_questions': no_of_questions,
                    'upload_type': upload_type,
                    'test_type': test_type,
                   # 'created_by': created_by,
                    'dtm_created': current_date_and_time,
                    'folder_name': folder_name,
                    'is_testcase':is_testcase
                }

                question_paper_instance = question_paper_master.objects.create(**question_paper_data)

                for ques in data["questions"]:
                    print('ques: ', ques)
                    print('Extracted Question:', ques.get('question', ''))
                    print('Extracted Input Format:', ques.get('input_format', ''))
                    print('Extracted Explanation:', ques.get('e_ans', ''))
                    print('Extracted Test Case 1:', ques.get('test_case1', ''))
                    print('Extracted Test Case 2:', ques.get('test_case2', ''))
                    print('Extracted Test Case 3:', ques.get('test_case3', ''))
                    if 'question' in ques:
                        # Debugging: Print the data being processed
                        question_text = ques['question']
                        input_format = ques.get('input_format', '')
                        answers = ques.get('answers', [])
                        marks = ques.get('marks', '0')
                        explain_answer = ques.get('e_ans', '')
                        test_case1 = ques.get('test_case1','')  # Default to empty string if not present
                        test_case2 = ques.get('test_case2','')
                        test_case3 = ques.get('test_case3','')
                        difficulty_level = ques.get('difficulty_level','')
                        question_image_data = ques.get('question_image_data', '')

                        print(f"Processing question: {question_text}")
                        print(f"Input format: {input_format}")
                        print(f"Answers: {answers}")
                        print(f"Marks: {marks}")
                        print(f"Explanation: {explain_answer}")

                        # Remove brackets from explanation if present
                        if explain_answer.startswith('[') and explain_answer.endswith(']'):
                            explain_answer = explain_answer[1:-1]
                
                        print(f"Image data: {question_image_data}")
        
                        try:
                            marks = int(marks) if marks else 0  # Convert to int, set 0 if empty
                        except ValueError:
                            print("Invalid mark value, setting to 0")
                            marks = 0

                        print(f"Marks (after conversion): {marks}")

                        try:
                            # Save to temporary table
                            temp_question = question_master_temp.objects.create(
                                question_name_id=question_paper_instance,
                                question_text=question_text,
                                question_image_data=base64.b64decode(question_image_data) if question_image_data else None,
                                input_format=input_format,
                                answer=', '.join(answers),
                                mark=marks,
                                difficulty_level=difficulty_level,
                                explain_answer=explain_answer,
                                test_case1=test_case1,  # ‚úÖ Add test_case1
                                test_case2=test_case2,  # ‚úÖ Add test_case2
                                test_case3=test_case3   
                                                    )

                            print(f"Temp question saved: {temp_question}")

                            try:
                                question_data = {
                                    "question_name_id": question_paper_instance,
                                    "question_text": question_text,
                                    "question_image_data": base64.b64decode(question_image_data) if question_image_data else None,
                                    "input_format": input_format,
                                    "answer": ', '.join(answers),
                                    "mark": marks,
                                    "explain_answer": explain_answer,
                                    "difficulty_level":difficulty_level
                                }

                                # ‚úÖ Add test cases only if they exist
                                if test_case1 is not None:
                                    question_data["test_case1"] = test_case1
                                if test_case2 is not None:
                                    question_data["test_case2"] = test_case2
                                if test_case3 is not None:
                                    question_data["test_case3"] = test_case3

                                main_question = question_master.objects.create(**question_data)

                                print(f"Main question saved: {main_question}")

                            except Exception as e:
                                print(f"Error saving question: {e}")
                                return HttpResponse(f"Error saving or moving question: {e}")


                            print(f"Main question saved: {main_question}")

                            # Optionally delete the temporary question
                            temp_question.delete()

                        except Exception as e:
                            print(f"Error saving question: {e}")
                            return HttpResponse(f"Error saving or moving question: {e}")

                return HttpResponse("Questions imported and moved to main table successfully.")
            except Exception as e:
                print(f"Error processing file: {e}")
                return HttpResponse(f"Error processing file: {e}")
        else:
            return HttpResponse("Form is not valid.")
    else:
        form = DocumentForm()
        return render(request, 'import_coding.html', {'form': form})


#_________________________Training_schedule_sheet________________________________________________________#





#-----------------------------Course _ trainer_feedback-----------------------------------------#

class add_trainer_feedback(generics.CreateAPIView):
    queryset = course_trainer_feedback.objects.all()
    serializer_class = trainerfeedbackSerializer


@api_view(['GET'])
def get_trainer_feedback(request):
    # Use the `values` method to fetch only the needed fields
    feedback_data = course_trainer_feedback.objects.filter(deleted=0).select_related(
        'college_id', 'topic_id', 'trainer_id', 'department_id'
    ).filter(deleted=0).values(
        'id',
        'college_id__college',
        'department_id__department',
        'topic_id__topic',
        'trainer_id__trainer_name',
        'dtm_complete',
        'completion_status',
        'feedback'
    )

    return Response(feedback_data)
class update_trainer_feedback(generics.UpdateAPIView):
    queryset = course_trainer_feedback.objects.all()
    serializer_class = trainerfeedbackSerializer



@api_view(['PUT', 'PATCH'])
def delete_trainer_feedback(request, pk):
    try:
        print("Entering Function..")
        course = course_trainer_feedback.objects.get(id=pk)

        print("course: ", course)
    except course_trainer_feedback.DoesNotExist:
        return JsonResponse("course not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    course.deleted = 1
    course.save()
    print("logins: ", course)

    return JsonResponse("course 'deleted' field updated successfully", safe=False)

#------------------------Compiler---------------------#



# List of forbidden file operation functions
FORBIDDEN_FUNCTIONS = [
    r'\bfopen\b', r'\bfclose\b', r'\bfread\b', r'\bfwrite\b', r'\bfscanf\b', 
    r'\bfprintf\b', r'\bfgetc\b', r'\bfputc\b', r'\bfgets\b', r'\bfputs\b', 
    r'\bremove\b', r'\brename\b',r'\bfopen\b',r'\bfread\b',r'\bfwrite\b',r'\bstd::ifstream\b',r'\bstd::ofstream\b',r'\bstd::fstream\b'
]

def contains_forbidden_functions(code):
    """Check if the code contains any forbidden functions."""
    for func in FORBIDDEN_FUNCTIONS:
        if re.search(func, code):
            return True
    return False




def execute_python_code(code,inputs=""):

    try:
        

        addon="""
import builtins
# Define safe import and restricted open functions
def safe_import(name, globals=None, locals=None, fromlist=(), level=0):
    if name not in ['os',"globe","shutill",subprocess]:
        return original_import(name, globals, locals, fromlist, level)
    raise ImportError(f"Importing {name} is not allowed")

def restricted_open(*args, **kwargs):
    raise IOError("File opening is not allowed.")

# Save the original built-in functions
original_import = builtins.__import__
original_open = builtins.open

# Replace built-in functions with restricted versions
builtins.__import__ = safe_import
builtins.open = restricted_open

"""
        code=addon+"\n"+code
        #use subprocess to execute the code at terminal
        result = subprocess.run(
            ['python', '-c', code],
            capture_output=True,
            input=inputs,
            text=True,
            timeout=settings.CODE_EXECUTION_TIMEOUT #the program will raise timeout error if it exceeds settings.CODE_EXECUTION_TIMEOUTs of execution
        )
        return result.stdout or result.stderr
    except subprocess.TimeoutExpired:
        #time error is handled and the message is returned
        return {'error':'Execution timed out'}
    except Exception as e:
        return {'error': str(e)}




def execute_java_code(code,inputs=""):
    asset_path = settings.ASSET_DIR
    # Extract class name
    class_match = re.search(r'public\s+class\s+(\w+)', code)
    if not class_match:
        return 'No public class found'
    
    class_name = class_match.group(1)
    dir_path = os.path.abspath(os.path.join(asset_path,str(uuid.uuid4())))
    os.makedirs(dir_path)
    #file_path = os.path.join(dir_path, f'{class_name}.java')

    #using uuid to create temporary c file for execution
    temp_java_path = os.path.abspath(os.path.join(dir_path, f'{class_name}.java'))
    # print('temp_java_path_created...: ', temp_java_path)
    # logger.error("Temp Java PAth Created...: %s", temp_java_path)

    temp_exec_path = f'{class_name}'
    # print('temp_exec_path_created...: ', temp_exec_path)
    # logger.error("Temp Java Excecute PAth Created...: %s", temp_exec_path)

    #writing the code into temporary file
    with open(temp_java_path, 'w') as f:
        f.write(code)
    try:
        #compiling the file using subprocess at terminal
        compile_result = subprocess.run(
            ['javac', temp_java_path],
            capture_output=True,
            cwd=dir_path,
            text=True
        )

        # print('*******compile_result******')
        # logger.error("Compile Result...: %s", compile_result)
        #if program has syntax error return the error message
        if compile_result.returncode != 0:
            print("syntax error occured")
            return compile_result.stderr
        #return the programs output
        run_result = subprocess.run(
            ['java', '-Djava.security.manager', '-Djava.security.policy==java.policy', temp_exec_path],
            capture_output=True,
            input=inputs,
            text=True,
            cwd=dir_path,
            timeout=settings.CODE_EXECUTION_TIMEOUT
        )
        # print('*******Run Result*********')
        # logger.error("Run Result...: %s", run_result)
        return run_result.stdout or run_result.stderr
    except subprocess.TimeoutExpired:
        return 'Execution timed out'
    except Exception as e:
         return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    finally:
        shutil.rmtree(dir_path)
     

   
def execute_c_code(code,inputs=""):
    file_uuid=uuid.uuid4()
    asset_path = settings.ASSET_DIR
    #using uuid to create temporary c file for execution
    temp_c_path = os.path.abspath(os.path.join(asset_path, f'{file_uuid}.c'))
   # print('temp_path_created...: ', temp_c_path)
    #logger.error("Temp C Path Created...: %s", temp_c_path)

    temp_exec_path = os.path.abspath(os.path.join(asset_path, f'{file_uuid}'))
    # print('temp_exec_path_created...: ', temp_exec_path)
    #logger.error("Temp C Execute Path Created...: %s", temp_exec_path)

    # Check for forbidden file operations
    if contains_forbidden_functions(code):
        return "Error: Code contains forbidden file operations."
    #writing the code into temporary file
    with open(temp_c_path, 'w') as f:
        f.write(code)
    try:
        #compiling the file using subprocess at terminal
        compile_result = subprocess.run(
            ['gcc', temp_c_path, '-o', temp_exec_path],
            capture_output=True,
            #inputs=inputs,
            text=True
        )
        # print('compile_result: ', compile_result)
        #logger.error("Compile Result...: %s", compile_result)

        #if program has syntax error return the error message
        if compile_result.returncode != 0:
            print("syntax error occured")
            return compile_result.stderr
        #return the programs output
        # run_result = subprocess.run(
        #     [temp_exec_path],
        #     capture_output=True,
        #     text=True,
        #     timeout=settings.CODE_EXECUTION_TIMEOUT
        # )
        # Execute the compiled  program with inputs
        process = subprocess.Popen(
                [temp_exec_path],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
        )

            # Communicate with the process: send inputs and read outputs
        stdout, stderr = process.communicate(inputs)
        return stdout or stderr
    except subprocess.TimeoutExpired:
        return 'Execution timed out'
    except Exception as e:
         return f'error:{str(e)}'
    finally:
        if os.path.exists(temp_c_path):
            os.remove(temp_c_path)
        if os.path.exists(f"{temp_exec_path}"):
            os.remove(f"{temp_exec_path}")
        # print('files are deleted....')
        #logger.error("Files Delete in Assets")
        #subprocess.run(['rm', temp_c_path, temp_exec_path])

def execute_cpp_code(code,inputs=""):
    file_uuid=uuid.uuid4()
    asset_path = settings.ASSET_DIR
    file_path = os.path.abspath(os.path.join(asset_path, f'{file_uuid}.cpp'))
    # print('file_path_created...: ', file_path)
    logger.error("C++ File Path Created...: %s", file_path)

    exec_path = os.path.abspath(os.path.join(asset_path, f'{file_uuid}'))
    # print('exec_path_created...: ', exec_path)
    logger.error("C++ File Execute Path Created...: %s", exec_path)

    # Check for forbidden file operations
    if contains_forbidden_functions(code):
        return "Error: Code contains forbidden file operations."
   
    try:
        with open(file_path, 'w') as f:
            f.write(code)
        compile_result = subprocess.run(
            ['g++', file_path, '-o', exec_path],
            capture_output=True,
            text=True
        )
        # print('**********compiled**********')
        logger.error("Compile Result...: %s", compile_result)
        
        if compile_result.returncode != 0:
            return compile_result.stderr
        
        process = subprocess.Popen(
                [exec_path],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True)
        # print('*****run process***********')
        logger.error("Process Result...: %s", process)

            # Communicate with the process: send inputs and read outputs
        stdout, stderr = process.communicate(inputs)
        return stdout or stderr
    except subprocess.TimeoutExpired:
        return 'Execution timed out'
    finally:
        if os.path.exists(file_path):
            os.remove(file_path)
        if os.path.exists(f"{exec_path}"):
            os.remove(f"{exec_path}")

        # os.remove(file_path)
        # os.remove(f"{exec_path}.exe")
        # print('files are deleted....')
        logger.error("Files Delete in Assets")
        # subprocess.run(['rm', file_path, exec_path])






@api_view(['POST'])
def program_compiler(request):

    language_dict={
        "python":execute_python_code,
        "c":execute_c_code,
        "cpp":execute_cpp_code,
        "java":execute_java_code,
    }
    
    code = request.data.get('code')
    p_type = request.data.get('p_type')
    inputs=request.data.get('inputs')
    if p_type not in language_dict.keys():
        return Response({"result":"Unsupported language"})
    else:
        print(f"executing {p_type} code")
        return Response({"result":language_dict[p_type](code,inputs)})




def execute_code(p_type, code, inputs):
    language_dict = {
        "python": execute_python_code,
        "c": execute_c_code,
        "cpp": execute_cpp_code,
        "java": execute_java_code,
    }

    if p_type not in language_dict.keys():
        raise ValueError("Unsupported language")
    
    print('output: ', language_dict[p_type](code,inputs))

    return language_dict[p_type](code,inputs)


@csrf_exempt
@api_view(['POST'])
def test_candidates_answer_view_Com(request):
    print('Request.Data......: ', request.data)

    code = request.data.get('code')
    p_type = request.data.get('p_type')
    inputs = request.data.get('inputs')

    try:
        output = execute_code(p_type, code, inputs)  # This should return the code output
        print("Code Output: ", output)
        # Return the output in the response
        return JsonResponse({'message': 'Successfully updated output', 'output': output}, status=200)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)




@api_view(['GET'])
def candidate_info(request):
    user_name = request.GET.get('user_name', None)
    try:
        # Fetch candidate from database
        candidate = candidate_master.objects.get(user_name=user_name)
        need_candidate_info = candidate.need_candidate_info

        # Prepare response data
        if not need_candidate_info:
            # Special handling for when need_candidate_info is false
            response_data = {'message': 'Candidate info is not required'}
        else:
            # Normal handling when need_candidate_info is true
            response_data = {'need_candidate_info': need_candidate_info}

        return Response(response_data, status=status.HTTP_200_OK)

    except candidate_master.DoesNotExist:
        return Response({'error': 'Candidate not found'}, status=status.HTTP_404_NOT_FOUND)

    except Exception as e:
        # Handle unexpected errors
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)






#----------------------------Training admin Dashboard datas-------------------#


# Count of company


def count_company_names(request):
    try:
        # Perform the query to count company_name entries
        result = company_master.objects.aggregate(
            count_company_name=Count('company_name')
        )

        # Return the count as a JSON response
        return JsonResponse(result, status=200)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


#------------------------------Placement admin Dashboard datas-----------------------#


#---------------Student Course Progress----------------------#


@api_view(['GET'])
def course_progress(request, student_id):
    # Count distinct topics in course_content_feedback for the specified student
    course_completed_count = course_content_feedback.objects.filter(student_id=student_id,deleted=0).values('topic_id').distinct().count()
    
    # Count distinct topics in content_master
    content_master_count = content_master.objects.filter(deleted=0).values('id').distinct().count()
    
    # Calculate course in progress
    course_inprogress_count = content_master_count - course_completed_count
    
    results = {
        "Course_Inprogress": course_inprogress_count,
        "Course_Completed": course_completed_count
    }

    return Response(results)




@api_view(['GET'])
def get_tests_by_student(request, student_id):
    # Filter tests_candidates_map by student_id and select required fields
    tests = tests_candidates_map.objects.filter(student_id=student_id,deleted=0).values('test_name', 'total_score', 'is_active')
    
    return Response(list(tests))


#----------------Performance of students-------------------#


@api_view(['GET'])
def get_avg_total_score_by_month(request, student_id):
    # Perform the query
    result = tests_candidates_map.objects.filter(
        question_id__test_type='MCQ Test', 
        student_id=student_id , # Filter by student_id
        deleted=0
    ).annotate(
        month=ExtractMonth('dtm_start')
    ).values('month').annotate(
        avg_total_score=Avg('total_score')
    ).order_by('month')
    
    # Convert the QuerySet to a dictionary with months as keys
    result_dict = {item['month']: item['avg_total_score'] for item in result}

    # Create the final list with all months
    result_list = [
        {
            'month': calendar.month_abbr[month],
            'avg_total_score': result_dict.get(month, 0)
        }
        for month in range(1, 13)
    ]

    return Response(result_list)

#-----------------------newly-- student attendance performance-------------------------------#

def group_by_weekdays_NEW(data):
    weekdays = {'Monday': [], 'Tuesday': [], 'Wednesday': [], 'Thursday': [], 'Friday': [], 'Saturday': [], 'Sunday': []}
    for idx, row in data.iterrows():
        for column_name in data.columns[4:]:  # Assuming attendance starts from the 5th column
            value = row[column_name]
            if value == 'P':
                try:
                    date_obj = datetime.strptime(column_name, '%d-%b')
                    weekday = date_obj.strftime('%A')
                    weekdays[weekday].append(value)
                except ValueError:
                    # Handle invalid or empty dates if needed
                    pass
    return weekdays

def calculate_avg_performance_NEW(weekdays):
    avg_performance = {}
    for day, attendance in weekdays.items():
        total = len(attendance)
        present = attendance.count('P')
        avg_performance[day] = (present / total) * 100 if total else 0
    return avg_performance



#-------------------------------Student Request------------------------------------#


@api_view(['GET'])
def get_student_request(request):
    try:
        # Use select_related to optimize related field fetching
        stu_queries = student_request.objects.filter(deleted=0).select_related('student_id')
        
        # Efficiently fetch required fields
        formatted_data = [
            {
                'id': item.id,
                'student_id': item.student_id.id,
                'student_name': item.student_id.students_name,
                'dtm_request': item.dtm_request,
                'student_query': item.student_query,
                'approved_by': item.approved_by,
                'dtm_approved': item.dtm_approved,
                'dtm_student_update': item.dtm_student_update,
                'status': item.status,
            }
            for item in stu_queries
        ]
        
        return Response(formatted_data)
    
    except Exception as e:
        return Response({'error': str(e)}, status=500)


class student_request_createAPIView(generics.CreateAPIView):
    queryset = student_request.objects.all()
    serializer_class = studentRequestSerializer

    def perform_create(self, serializer):
        # Automatically set dtm_request to the current date and time
        serializer.save(dtm_request=datetime.now())

class student_request_UpdateAPIView(generics.RetrieveUpdateAPIView):
    queryset = student_request.objects.all()
    serializer_class =studentRequestSerializer

    def put(self, request, *args, **kwargs):
        # logger.info(f"Updating student_request with id {kwargs.get('pk')}")
        response = super().put(request, *args, **kwargs)
        # logger.info(f"Updated student_request with id {kwargs.get('pk')} successfully")
        return response

    def patch(self, request, *args, **kwargs):
        # logger.info(f"Partially updating student_request with id {kwargs.get('pk')}")
        response = super().patch(request, *args, **kwargs)
        # logger.info(f"Partially updated student_request with id {kwargs.get('pk')} successfully")
        return response



#----------------get LMS Updated id data-------------------#


@api_view(['GET'])
def update_LMS_id(request, id):
    # Get the content_master object by ID
    try:
        lms = content_master.objects.get(id=id)
    except content_master.DoesNotExist:
        return Response(status=404)

    # Serialize the content_master object
    serializer = contentSerializers(lms)
    
    return Response(serializer.data)



@api_view(['GET'])
def update_LMS_Topic_id(request, id):
    # Get the content_master object by ID
    try:
        lms = topic_master.objects.get(id=id)
    except topic_master.DoesNotExist:
        return Response(status=404)

    # Serialize the content_master object
    serializer = topicSerializers(lms)
    
    return Response(serializer.data)


@api_view(['GET'])
def get_test_type_category(request, test_name):
    try:
        cache_key = f'test_type_category_{test_name}'
        test_type_category = cache.get(cache_key)

        if not test_type_category:
            test_master_instance = test_master.objects.filter(
                test_name=test_name,
                deleted=0
            ).order_by('-id').first()

            if not test_master_instance:
                return Response({'error': 'Test name does not exist'}, status=404)

            test_type_category = test_master_instance.test_type_id.test_type_categories
            cache.set(cache_key, test_type_category, timeout=3600)

        return Response({'test_type_category': test_type_category})

    except Exception as e:
        return Response({'error': str(e)}, status=500)




#------------Need Candidate info-----------------------#


@api_view(['GET'])
def get_test_candidates_NeedInfo(request, username):
    candidates = tests_candidates_map.objects.filter(student_id__user_name=username,deleted=0).select_related('student_id')
    serializer = TestCandidateMapSerializerNeedInfo(candidates, many=True)
    return Response(serializer.data)


#---------------------Student Dasboard New--------------------------#

#--Total Test Taken--------#

@api_view(['GET'])
def active_tests_count(request, student_id):
    count = tests_candidates_map.objects.filter(is_active=True, student_id=student_id,deleted=0).count()
    return Response({'count': count})


#---Total no.of offers------#


@api_view(['GET'])
def get_number_of_offers(request, candidate_id):
    try:
        candidate = candidate_master.objects.get(id=candidate_id,deleted=0)
        number_of_offers = candidate.number_of_offers
    except candidate_master.DoesNotExist:
        return Response({'error': 'Candidate not found'}, status=404)
    return Response({'number_of_offers': number_of_offers})


#----Request count---------#


@api_view(['GET'])
def count_student_requests(request, student_id):
    try:
        request_count = student_request.objects.filter(student_id=student_id,deleted=0).count()
    except student_request.DoesNotExist:
        return Response({'error': 'Student not found'}, status=404)
    return Response({'request_count': request_count})


#------Apditute Avg Score------#

@api_view(['GET'])
def get_monthly_avg_total_score_apditute(request, student_id):
    try:
        # Subquery to get the question_type id where question_type is 'Apditute'
        question_type_subquery = question_type.objects.filter(
            question_type='Aptitude',deleted=0
        ).values('id')
        print('question_type_subquery: ', question_type_subquery)

        # Subquery to get the test_type id where test_type is 'MCQ Test'
        test_type_subquery = test_type.objects.filter(
            test_type='MCQ Test',deleted=0
        ).values('id')
        print('test_type_subquery: ', test_type_subquery)

        # Subquery to get the test_name from test_master where the question_type and test_type match
        test_name_subquery = test_master.objects.filter(
            question_type_id__in=Subquery(question_type_subquery),
            test_type_id__in=Subquery(test_type_subquery),deleted=0
        ).values('test_name')
        print('test_name_subquery: ', test_name_subquery)

        # Main query to get the average total score grouped by month
        monthly_avg_scores = tests_candidates_map.objects.filter(
            test_name__in=Subquery(test_name_subquery),
            student_id=student_id,deleted=0
        ).annotate(month=ExtractMonth('dtm_start')).values('month').annotate(avg_total_score=Avg('total_score')).order_by('month')

        print('monthly_avg_scores: ', monthly_avg_scores)

        # Convert month numbers to month names and create a full list with 0 defaults
        full_months = {i: {"month": calendar.month_abbr[i], "avg_score": 0} for i in range(1, 13)}
        
        print('full months: ', full_months)

        for entry in monthly_avg_scores:
            full_months[entry["month"]]["avg_score"] = entry["avg_total_score"]

        return Response(list(full_months.values()))
    except Exception as e:
        return Response({'error': str(e)}, status=500)


#------SoftSkills Avg Score------#

@api_view(['GET'])
def get_monthly_avg_total_score_softskill(request, student_id):
    try:
        # Subquery to get the question_type id where question_type is 'Apditute'
        question_type_subquery = question_type.objects.filter(
            question_type='Softskills',deleted=0
        ).values('id')
        print('question_type_subquery: ', question_type_subquery)

        # Subquery to get the test_type id where test_type is 'MCQ Test'
        test_type_subquery = test_type.objects.filter(
            test_type='MCQ Test',deleted=0
        ).values('id')
        print('test_type_subquery: ', test_type_subquery)

        # Subquery to get the test_name from test_master where the question_type and test_type match
        test_name_subquery = test_master.objects.filter(
            question_type_id__in=Subquery(question_type_subquery),
            test_type_id__in=Subquery(test_type_subquery),
            deleted=0
        ).values('test_name')
        print('test_name_subquery: ', test_name_subquery)

        # Main query to get the average total score grouped by month
        monthly_avg_scores = tests_candidates_map.objects.filter(
            test_name__in=Subquery(test_name_subquery),
            student_id=student_id,
            deleted=0
        ).annotate(month=ExtractMonth('dtm_start')).values('month').annotate(avg_total_score=Avg('total_score')).order_by('month')

        print('monthly_avg_scores: ', monthly_avg_scores)

        # Convert month numbers to month names and create a full list with 0 defaults
        full_months = {i: {"month": calendar.month_abbr[i], "avg_score": 0} for i in range(1, 13)}
        
        print('full months: ', full_months)

        for entry in monthly_avg_scores:
            full_months[entry["month"]]["avg_score"] = entry["avg_total_score"]

        return Response(list(full_months.values()))
    except Exception as e:
        return Response({'error': str(e)}, status=500)




#------Technical Avg Score------#

@api_view(['GET'])
def get_monthly_avg_total_score_technical(request, student_id):
    try:
        # Subquery to get the question_type id where question_type is 'Apditute'
        question_type_subquery = question_type.objects.filter(
            question_type='Technical',
            deleted=0
        ).values('id')
        print('question_type_subquery: ', question_type_subquery)

        # Subquery to get the test_type id where test_type is 'MCQ Test'
        test_type_subquery = test_type.objects.filter(
            test_type='MCQ Test',
            deleted=0
        ).values('id')
        print('test_type_subquery: ', test_type_subquery)

        # Subquery to get the test_name from test_master where the question_type and test_type match
        test_name_subquery = test_master.objects.filter(
            question_type_id__in=Subquery(question_type_subquery),
            test_type_id__in=Subquery(test_type_subquery),
            deleted=0
        ).values('test_name')
        print('test_name_subquery: ', test_name_subquery)

        # Main query to get the average total score grouped by month
        monthly_avg_scores = tests_candidates_map.objects.filter(
            test_name__in=Subquery(test_name_subquery),
            student_id=student_id,
            deleted=0
        ).annotate(month=ExtractMonth('dtm_start')).values('month').annotate(avg_total_score=Avg('total_score')).order_by('month')

        print('monthly_avg_scores: ', monthly_avg_scores)

        # Convert month numbers to month names and create a full list with 0 defaults
        full_months = {i: {"month": calendar.month_abbr[i], "avg_score": 0} for i in range(1, 13)}
        
        print('full months: ', full_months)

        for entry in monthly_avg_scores:
            full_months[entry["month"]]["avg_score"] = entry["avg_total_score"] if entry["avg_total_score"] is not None else 0

        return Response(list(full_months.values()))
    except Exception as e:
        return Response({'error': str(e)}, status=500)




#------Coding Avg Score------#


@api_view(['GET'])
def get_monthly_avg_total_score_Coding(request, student_id):
    try:
        # Subquery to get the test_type id where test_type is 'CodingTest'
        test_type_subquery = test_type.objects.filter(
            test_type='Coding Test',
            deleted=0
        ).values('id')

        # Subquery to get the test_name from test_master where the test_type matches
        test_name_subquery = test_master.objects.filter(
            test_type_id__in=Subquery(test_type_subquery),
            deleted=0
        ).values('test_name')

        # Main query to get the average total score grouped by month
        monthly_avg_scores = tests_candidates_map.objects.filter(
            test_name__in=Subquery(test_name_subquery),
            student_id=student_id,
            deleted=0
        ).annotate(month=ExtractMonth('dtm_start')).values('month').annotate(avg_total_score=Avg('total_score')).order_by('month')

        # Convert month numbers to abbreviated month names and create a full list with 0 defaults
        full_months = {i: {"month": calendar.month_abbr[i], "avg_score": 0} for i in range(1, 13)}

        for entry in monthly_avg_scores:
            full_months[entry["month"]]["avg_score"] = entry["avg_total_score"]

        return Response(list(full_months.values()))
    except Exception as e:
        return Response({'error': str(e)}, status=500)

#------------------Offer Chart where college id


#------------------number of offers --college_id--------

@api_view(['GET'])
def get_number_of_offers_college_id(request, college_id):
    try:
        # Filter candidate_master records by college_id
        candidates = candidate_master.objects.filter(college_id=college_id,deleted=0)
        
        # Aggregate the number of offers for all the candidates
        total_number_of_offers = sum(candidate.number_of_offers for candidate in candidates)

        return Response({'number_of_offers': total_number_of_offers})
    except Exception as e:
        return Response({'error': str(e)}, status=500)


#----Request count---college_id---------#


@api_view(['GET'])
def count_student_requests_college_id(request, college_id):
    try:
        # Filter candidate_master records by college_id
        candidate_ids = candidate_master.objects.filter(college_id=college_id,deleted=0).values_list('id', flat=True)
        
        # Count the number of student_request records with student_id in the filtered candidate ids
        request_count = student_request.objects.filter(student_id__in=candidate_ids).count()
        
        return Response({'request_count': request_count})
    except candidate_master.DoesNotExist:
        return Response({'error': 'College not found'}, status=404)



#----------------------student plan--------------------#


from django.db.models import Q, OuterRef, Subquery
from datetime import datetime

@api_view(['GET'])
def get_tests_candidates_map_MCQ(request, user_name):
    try:
        print("üì• API get_tests_candidates_map_MCQ triggered")
        print(f"üîç Input user_name: {user_name}")

        current_date = datetime.now().date()
        print(f"üìÜ Current date: {current_date}")

        # Define date filter
        date_filter = (
            Q(dtm_start__date__gte=current_date) |
            Q(dtm_start__date__lt=current_date, dtm_end__date__gte=current_date)
        )
        print("‚úÖ Date filter created")

        # Subquery to get test_type from test_master
        test_type_subquery = test_master.objects.filter(
            test_name=OuterRef('test_name')
        ).values('test_type_id__test_type')[:1]

        # Annotate test_type to tests_candidates_map
        annotated_candidates = tests_candidates_map.objects.annotate(
            test_type_from_master=Subquery(test_type_subquery)
        ).filter(
            Q(deleted=0),
            Q(student_id__user_name=user_name),
            Q(test_type_from_master='MCQ Test'),
            Q(is_active=False),
            date_filter
        ).select_related(
            'college_id', 'department_id', 'question_id', 'student_id', 'rules_id'
        ).values(
            'id',
            'test_name',
            'college_id__id',
            'college_id__college',
            'department_id__id',
            'department_id__department',
            'question_id__id',
            'question_id__question_paper_name',
            'student_id__id',
            'student_id__students_name',
            'student_id__user_name',
            'dtm_start',
            'dtm_end',
            'attempt_count',
            'is_camera_on',
            'is_active',
            'duration',
            'duration_type',
            'year',
            'rules_id__id',
            'rules_id__rule_name',
            'rules_id__instruction',
            'need_candidate_info',
            'total_score',
            'avg_mark',
            'test_type_from_master'  # include annotated field if needed
        )

        print(f"üìã Retrieved {len(annotated_candidates)} records")

        result = []
        for t in annotated_candidates:
            print(f"üì¶ Processing record ID: {t['id']}")
            result.append({
                'id': t['id'],
                'test_name': t['test_name'],
                'college_id_id': t['college_id__id'],
                'college_id': t['college_id__college'],
               
                'question_id': t['question_id__id'],
               
                'test_type': t['test_type_from_master'],  # updated here!
                'student_id': t['student_id__id'],
                'student_name': t['student_id__students_name'],
                'user_name': t['student_id__user_name'],
                'dtm_start': t['dtm_start'],
                'dtm_end': t['dtm_end'],
                'attempt_count': t['attempt_count'],
                'is_camera_on': t['is_camera_on'],
                'is_active': t['is_active'],
                'duration': t['duration'],
                'duration_type': t['duration_type'],
                'year': t['year'],
                'rules_id': t['rules_id__id'],
                'rules': t['rules_id__rule_name'],
                'instruction': t['rules_id__instruction'],
                'need_candidate_info': t['need_candidate_info'],
                'total_score': t['total_score'],
                'avg_mark': t['avg_mark']
            })

        print("‚úÖ Completed processing all records")
        return Response(result)

    except Exception as e:
        print(f"‚ùå Error occurred: {str(e)}")
        return Response({'error': str(e)}, status=500)


@api_view(['GET'])
def get_tests_candidates_map_Coding(request, user_name):
    try:
        current_date = datetime.now().date()
        print(f"\nüìÖ Current date: {current_date}")

        # Date filter logic
        date_filter = (
            Q(dtm_start__date__gte=current_date) |
            Q(dtm_start__date__lt=current_date, dtm_end__date__gte=current_date)
        )
        print("‚úÖ Date filter prepared")

        # Subquery to get test_type from test_master
        test_type_subquery = test_master.objects.filter(
            test_name=OuterRef('test_name')
        ).values('test_type_id__test_type')[:1]
        print("üîç Subquery prepared to fetch test_type from test_master")

        # Annotated queryset
        annotated_candidates = tests_candidates_map.objects.annotate(
            test_type_from_master=Subquery(test_type_subquery)
        ).filter(
            Q(deleted=0),
            Q(student_id__user_name=user_name),
            Q(test_type_from_master='Coding Test'),
            Q(is_active=False),
            date_filter
        ).select_related(
            'question_id', 'student_id', 'rules_id'
        ).values(
            'id',
            'test_name',
            'question_id__id',
            'student_id__id',
            'dtm_start',
            'dtm_end',
            'duration',
            'duration_type',
            'rules_id__instruction'
        )

        # Debug print statements
        print("üßÆ Query executed for tests_candidates_map")
        print(f"üìã Retrieved {annotated_candidates.count()} records")

        for c in annotated_candidates:
            print(f"‚û°Ô∏è Test: {c['test_name']}, Start: {c['dtm_start']}, End: {c['dtm_end']}")

        return Response(list(annotated_candidates))

    except Exception as e:
        print(f"‚ùå Error occurred: {e}")
        return Response({'error': str(e)}, status=500)


#----------------------PLACEMENT-----------------------#

@api_view(['GET'])
def get_tests_Reports_placement(request, college_id):
    # Fetch all test candidates for the given college that are not deleted
    tests_candidates = tests_candidates_map.objects.filter(
        deleted=0, college_id=college_id
    ).select_related(
    'department_id', 'question_id', 'student_id', 'college_id'
    )

    # List comprehension for constructing the response data
    test_candidate_map_data = [
        {
            'id': test.id,
            'test_name': test.test_name,
            'college_id': test.college_id.college if test.college_id else None,
            'department_id': test.department_id.department if test.department_id else None,
            'question_id': test.question_id.question_paper_name if test.question_id else None,
            'dtm_start': django_format_date(localtime(test.dtm_start), 'd-m-Y h:i A') if test.dtm_start else None,
            'dtm_end': django_format_date(localtime(test.dtm_end), 'd-m-Y h:i A') if test.dtm_end else None,
            'is_camera_on': test.is_camera_on,
            'is_active': test.is_active,
            'year': test.year,
            'need_candidate_info': test.need_candidate_info,
            'total_score': test.total_score if test.total_score is not None else 'AA',
            'avg_mark': test.avg_mark,
            'student_id': test.student_id.id if test.student_id else None,
            'student_name': test.student_id.students_name if test.student_id else None,
            'user_name': test.student_id.user_name if test.student_id else None,
            'email_id': test.student_id.email_id if test.student_id else None,
            'mobile_number': test.student_id.mobile_number if test.student_id else None,
            'gender': test.student_id.gender if test.student_id else None,
            'registration_number': test.student_id.registration_number if test.student_id else None,
        }
        for test in tests_candidates
    ]

    return Response(test_candidate_map_data)



from django.db.models import F

@api_view(['GET'])
def get_tests_Reports_placement_Candidates(request):
    """
    Fetch placement test candidate reports filtered by college_id and test_name (via query params).
    Example:
    /api/tests-reports-candidates/placement/?test_name=VMIT_22_10&college_id=67
    """
    # ‚úÖ Fetch query params
    search = request.query_params.get('search', '')
    test_name = request.query_params.get('test_name', '')
    college_id = request.query_params.get('college_id', None)  # ‚úÖ get from query param
    toggle_state = request.query_params.get('toggle_state', 'all')
    avg_mark_filter = request.query_params.get('avg_mark', None)

    # Optional filters
    student_name = request.query_params.get('student_name', None)
    user_name = request.query_params.get('user_name', None)
    department_id = request.query_params.get('department_id', None)
    year = request.query_params.get('year', None)

    # ‚úÖ Base filters
    filters = {'deleted': 0}

    if test_name:
        filters['test_name'] = test_name
    if college_id:
        filters['college_id__id'] = int(college_id)  # ‚úÖ must convert to int

    if student_name:
        filters['student_id__students_name'] = student_name
    if user_name:
        filters['student_id__user_name'] = user_name
    if department_id:
        filters['department_id__department'] = department_id
    if year:
        filters['year'] = year

    # ‚úÖ Query dataset
    tests_candidates = tests_candidates_map.objects.filter(**filters).select_related(
        'department_id',
        'student_id',
        'college_id'
    )

    # ‚úÖ Search across multiple fields
    if search:
        tests_candidates = tests_candidates.filter(
            Q(student_id__students_name__icontains=search) |
            Q(student_id__registration_number__icontains=search) |
            Q(department_id__department__icontains=search) |
            Q(student_id__user_name__icontains=search)
        )

    # ‚úÖ Toggle filters
    if toggle_state == 'active':
        tests_candidates = tests_candidates.filter(is_active=True)
    elif toggle_state == 'inactive':
        tests_candidates = tests_candidates.filter(is_active=False)
    elif toggle_state == 'reassigned':
        tests_candidates = tests_candidates.filter(is_reassigned=True)
    tests_candidates = tests_candidates.order_by('-dtm_start')

    # ‚úÖ avg_mark filter
    if avg_mark_filter:
        conditions = Q()
        for filter_item in avg_mark_filter.split(","):
            filter_item = filter_item.strip()
            if filter_item.startswith(">"):
                conditions |= Q(avg_mark__gt=float(filter_item[1:]))
            elif filter_item.startswith("<"):
                conditions |= Q(avg_mark__lt=float(filter_item[1:]))
            elif "-" in filter_item:
                min_val, max_val = map(float, filter_item.split("-"))
                conditions |= Q(avg_mark__gte=min_val, avg_mark__lte=max_val)
            else:
                conditions |= Q(avg_mark=float(filter_item))
        tests_candidates = tests_candidates.filter(conditions)

    # ‚úÖ Unique filter values for dropdowns
    unique_student_names = tests_candidates.values_list('student_id__students_name', flat=True).distinct()
    unique_user_names = tests_candidates.values_list('student_id__user_name', flat=True).distinct()
    unique_departments = tests_candidates.values_list('department_id__department', flat=True).distinct()
    unique_years = tests_candidates.values_list('year', flat=True).distinct()

    # ‚úÖ Pagination
    paginator = CustomPagination()
    paginated_data = paginator.paginate_queryset(
        tests_candidates.values(
            'id', 'test_name', 'college_id__id', 'college_id__college',
            'department_id__department', 'student_id__id',
            'student_id__students_name', 'student_id__user_name',
            'student_id__email_id', 'student_id__mobile_number',
            'student_id__registration_number', 'dtm_start_test',
            'dtm_start', 'dtm_end', 'capture_duration', 'is_active',
            'year', 'avg_mark', 'is_reassigned', 'attempt_count'
        ),
        request
    )

    # ‚úÖ Prepare serialized response
    test_candidate_map_data = []
    for testing in paginated_data:
        dtm_start_formatted = django_format_date(localtime(testing['dtm_start']), 'd-m-Y h:i A')
        dtm_end_formatted = django_format_date(localtime(testing['dtm_end']), 'd-m-Y h:i A')
        dtm_startT_formatted = django_format_date(localtime(testing['dtm_start_test']), 'd-m-Y h:i A')

        password = None
        if testing['student_id__user_name']:
            password_obj = login.objects.filter(user_name=testing['student_id__user_name']).first()
            password = password_obj.password if password_obj else None

        test_candidate_map_data.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
            'collegeId': testing['college_id__id'],
            'college_id': testing['college_id__college'],
            'department_id': testing['department_id__department'],
            'registration_number': testing['student_id__registration_number'],
            'email_id': testing['student_id__email_id'],
            'mobile_number': testing['student_id__mobile_number'],
            'student_id': testing['student_id__id'],
            'student_name': testing['student_id__students_name'],
            'user_name': testing['student_id__user_name'],
            'dtm_start': dtm_start_formatted,
            'dtm_start_test': dtm_startT_formatted,
            'dtm_end': dtm_end_formatted,
            'capture_duration': testing['capture_duration'],
            'is_active': testing['is_active'],
            'year': testing['year'],
            'avg_mark': testing['avg_mark'],
            'is_reassigned': testing['is_reassigned'],
            'attempt_count': testing['attempt_count'],
            'password': password,
        })

    # ‚úÖ Response
    response_data = {
        'count': paginator.page.paginator.count,
        'next': paginator.get_next_link(),
        'previous': paginator.get_previous_link(),
        'results': test_candidate_map_data,
        'student_name': list(unique_student_names),
        'user_name': list(unique_user_names),
        'Department': list(unique_departments),
        'year': list(unique_years),
    }

    return Response(response_data)

@api_view(['GET'])
def get_candidate_all_job_offers(request):
    try:
        # Fetch all jobs that are not deleted and include related fields
        jobs = job_offers.objects.filter(deleted=0).select_related(
            'college_id',
            'department_id'
        ).prefetch_related(
            'skill_id'
        )

        if not jobs.exists():
            return Response({'error': 'No jobs found'}, status=404)

        all_candidates_data = []

        # Using list comprehension and Django ORM's conditional aggregation
        job_candidates = []
        for job in jobs:
            filters = Q(deleted=0)
            
            # Apply filters based on job attributes
            filters &= Q(college_id=job.college_id) if job.college_id else filters
            filters &= Q(department_id=job.department_id) if job.department_id else filters
            filters &= Q(gender=job.gender) if job.gender else filters
            filters &= Q(marks_10th__gte=job.marks_10th) if job.marks_10th else filters
            filters &= Q(marks_12th__gte=job.marks_12th) if job.marks_12th else filters
            filters &= Q(cgpa__gte=job.cgpa) if job.cgpa else filters
            filters &= Q(history_of_arrears__lte=job.history_of_arrears) if job.history_of_arrears is not None else filters
            filters &= Q(standing_arrears__lte=job.standing_arrears) if job.standing_arrears is not None else filters
            filters &= Q(skill_id__in=job.skill_id.values_list('id', flat=True)) if job.skill_id.exists() else filters

            candidates = candidate_master.objects.filter(filters).select_related(
                'college_id',
                'department_id'
            ).prefetch_related(
                'skill_id'
            )
            
            for candidate in candidates:
                skill_ids = list(candidate.skill_id.values_list('id', flat=True))
                job_candidates.append({
                    'job_id': job.id,
                    'student_id': candidate.id,
                    'college_id': candidate.college_id.college if candidate.college_id else None,
                    'students_name': candidate.students_name,
                    'user_name': candidate.user_name,
                    'registration_number': candidate.registration_number,
                    'gender': candidate.gender,
                    'email_id': candidate.email_id,
                    'mobile_number': candidate.mobile_number,
                    'year': candidate.year,
                    'cgpa': candidate.cgpa,
                    'department_id': candidate.department_id.department if candidate.department_id else None,
                    'marks_10th': candidate.marks_10th,
                    'marks_12th': candidate.marks_12th,
                    'marks_semester_wise': candidate.marks_semester_wise,
                    'history_of_arrears': candidate.history_of_arrears,
                    'standing_arrears': candidate.standing_arrears,
                    'number_of_offers': candidate.number_of_offers,
                    'text': candidate.text,
                    'it_of_offers': candidate.it_of_offers,
                    'core_of_offers': candidate.core_of_offers,
                    'skill_id': skill_ids
                })

        return Response(job_candidates)

    except Exception as e:
        return Response({'error': str(e)}, status=500)
#-----------Students Test Schedule-----------------------#

@api_view(['GET'])
def get_students_test_schedule(request, user_name):
    # Step 1: Fetch the test candidates data
    tests_candidates = list(tests_candidates_map.objects.filter(
        deleted=0,
        student_id__user_name=user_name
    ).values(
        'id', 
        'test_name', 
        'question_id__id', 
        'question_id__question_paper_name', 
        'question_id__test_type', 
        'dtm_start', 
        'dtm_end', 
        'is_active', 
        'need_candidate_info', 
        'total_score'  # Include total_score to conditionally display it
    ))

    # Step 2: Fetch the test master data
    test_names = [tc['test_name'] for tc in tests_candidates]
    test_master_data = test_master.objects.filter(
        deleted=0, 
        test_name__in=test_names
    ).values(
        'test_name', 
        'test_type_id__test_type_categories'  # Fetch test_type_category from test_master
    )

    # Step 3: Create a dictionary to map test_name to test_type_category
    test_type_category_map = {tm['test_name']: tm['test_type_id__test_type_categories'] for tm in test_master_data}

    # Step 4: Add the test_type_category to each test candidate and conditionally set total_score
    for tc in tests_candidates:
        test_type_category = test_type_category_map.get(tc['test_name'], None)
        tc['test_type_category'] = test_type_category

        # Conditionally set total_score to None if test_type_category is not "Assessment"
        if test_type_category != 'Assessment':
            tc['total_score'] = None

    # Step 5: Return the combined result
    return Response(tests_candidates)

#---------------------Questions Master with images--------------#
def get_questions_IO_filter(request, question_id):
    # Fetch the required data using select_related and values
    questionset = question_master.objects.filter(deleted=0, question_name_id=question_id).select_related('question_name_id').values(
        'id',
        'question_name_id__id',
        'question_name_id__question_paper_name',
        'question_text',
        'question_image_data',
        'option_a_image_data',
        'option_b_image_data',
        'option_c_image_data',
        'option_d_image_data',
        'option_a',
        'option_b',
        'option_c',
        'option_d',
        'view_hint',
        'mark',
        'explain_answer',
        'answer',
        'difficulty_level',
        'input_format'
    )

    question_data = []
    for question in questionset:
        question_image_data = base64.b64encode(question['question_image_data']).decode('utf-8') if question['question_image_data'] else None
        option_a_image_data = base64.b64encode(question['option_a_image_data']).decode('utf-8') if question['option_a_image_data'] else None
        option_b_image_data = base64.b64encode(question['option_b_image_data']).decode('utf-8') if question['option_b_image_data'] else None
        option_c_image_data = base64.b64encode(question['option_c_image_data']).decode('utf-8') if question['option_c_image_data'] else None
        option_d_image_data = base64.b64encode(question['option_d_image_data']).decode('utf-8') if question['option_d_image_data'] else None

        question_data.append({
            'id': question['id'],
            'question_name_id': question['question_name_id__id'],
            'question_paper_name': question['question_name_id__question_paper_name'],
            'question_text': question['question_text'],
            'question_image_data': question_image_data,
            'option_a_image_data': option_a_image_data,
            'option_b_image_data': option_b_image_data,
            'option_c_image_data': option_c_image_data,
            'option_d_image_data': option_d_image_data,
            'option_a': question['option_a'],
            'option_b': question['option_b'],
            'option_c': question['option_c'],
            'option_d': question['option_d'],
            'view_hint': question['view_hint'],
            'mark': question['mark'],
            'explain_answer': question['explain_answer'],
            'answer': question['answer'],
           'difficulty_level': question['difficulty_level'],
            'input_format': question['input_format'],
        })

    random.shuffle(question_data)
    return JsonResponse(question_data, safe=False)

@api_view(['GET'])
def get_tests_candidates_map_testName(request, test_name, college_id=None):
    """
    Fetch test candidates filtered by test_name and (optional) college_id.
    """
    filters = {
        'deleted': 0,
        'test_name': test_name
    }

    if college_id:  # ‚úÖ filter only if passed
        filters['college_id__id'] = college_id

    # ‚úÖ Fetch related data
    tests_candidates = tests_candidates_map.objects.filter(**filters).select_related(
        'rules_id', 
        'department_id', 
        'question_id', 
        'student_id', 
        'college_id'
    ).values(
        'id',
        'test_name',
        'college_id__college',
        'college_id__id',
        'department_id__department',
        'department_id__id',
        'question_id__id',
        'question_id__question_paper_name',
        'question_id__test_type',
        'student_id__id',
        'student_id__students_name',
        'student_id__user_name',
        'rules_id__id',
        'rules_id__rule_name',
        'rules_id__instruction',
        'dtm_start',
        'dtm_end',
        'dtm_start1',
        'dtm_end1',
        'attempt_count',
        'is_camera_on',
        'is_active',
        'duration',
        'duration_type',
        'year',
        'need_candidate_info',
        'total_score',
        'avg_mark',
        'dtm_created'
    )

    # ‚úÖ Serialize data
    test_candidate_map_data = []
    for testing in tests_candidates:
        test_candidate_map_data.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
            'college_id_id': testing['college_id__id'],
            'college_id': testing['college_id__college'],
            'department_id_id': testing['department_id__id'],
            'department_id': testing['department_id__department'],
            'question_id': testing['question_id__id'],
            'question_paper_name': testing['question_id__question_paper_name'],
            'test_type': testing['question_id__test_type'],
            'student_id': testing['student_id__id'],
            'student_name': testing['student_id__students_name'],
            'user_name': testing['student_id__user_name'],
            'dtm_start': testing['dtm_start'],
            'dtm_end': testing['dtm_end'],
            'dtm_start1': testing['dtm_start1'],
            'dtm_end1': testing['dtm_end1'],
            'attempt_count': testing['attempt_count'],
            'is_camera_on': testing['is_camera_on'],
            'is_active': testing['is_active'],
            'duration': testing['duration'],
            'duration_type': testing['duration_type'],
            'year': testing['year'],
            'rules_id': testing['rules_id__id'],
            'rules': testing['rules_id__rule_name'],
            'instruction': testing['rules_id__instruction'],
            'need_candidate_info': testing['need_candidate_info'],
            'total_score': testing['total_score'],
            'avg_mark': testing['avg_mark'],
            'dtm_created': testing['dtm_created'],
        })

    return Response(test_candidate_map_data)

class CourseScheduleMapView(APIView):
    def post(self, request, format=None):
        print("üì• Incoming Request Data:", request.data)

        college_id = request.data.get('college_id', [])
        department_id = request.data.get('department_id', [])
        year = request.data.get('year', [])
        batch_no_list = request.data.get('batch_no', [])
        topic_ids = request.data.get('topic_id', [])

        print(f"üè´ College IDs: {college_id}")
        print(f"üè¢ Department IDs: {department_id}")
        print(f"üìö Years: {year}")
        print(f"üë• Batch Nos: {batch_no_list}")
        print(f"üìò Topic IDs: {topic_ids}")

        if not college_id or not year or not topic_ids:
            return Response({'error': 'college_id, year, and topic_ids are required fields.'}, status=status.HTTP_400_BAD_REQUEST)

        filter_kwargs = {
            'college_id__in': college_id,
            'year__in': year,
        }
        if department_id:
            filter_kwargs['department_id__in'] = department_id
        if batch_no_list:
            filter_kwargs['batch_no__in'] = batch_no_list

        print(f"üîç Filtering candidate_master with: {filter_kwargs}")
        students = candidate_master.objects.filter(**filter_kwargs)
        print(f"üéì Total students found: {students.count()}")

        # ‚úÖ Get trainer_ids from all selected batch_nos
        trainers = trainer_master.objects.filter(batch_no__in=batch_no_list)
        trainer_ids = list(trainers.values_list('id', flat=True))
        print(f"üë®‚Äçüè´ Trainer IDs from batch: {trainer_ids}")

        # ‚úÖ Join batch_no list into a single string for storage
        batch_no_str = ", ".join(batch_no_list)

        data = []
        current_date_and_time = datetime.now()

        for student in students:
            print(f"üßë Mapping schedule for student: {student.user_name} (ID: {student.id})")
            for topic_id in topic_ids:
                # ‚ùå Skip if record already exists for same student and topic
                if course_schedule.objects.filter(student_id=student.id, topic_id=topic_id, deleted=0).exists():
                    print(f"‚õî Skipping duplicate for {student.user_name} - Topic {topic_id}")
                    continue

                print(f"‚û°Ô∏è Creating for Topic: {topic_id} with Trainers: {trainer_ids}")

                test_candidate_data = {
                    'topic_id': topic_id,
                    'student_id': student.id,
                    'college_id': student.college_id.id,
                    'department_id': student.department_id.id if student.department_id else None,
                    'dtm_start_student': request.data.get('dtm_start_student'),
                    'dtm_end_student': request.data.get('dtm_end_student'),
                    'dtm_start_trainer': request.data.get('dtm_start_trainer'),
                    'dtm_end_trainer': request.data.get('dtm_end_trainer'),
                    'dtm_of_training': request.data.get('dtm_of_training'),
                    'year': student.year,
                    'trainer_ids': trainer_ids,
                    'batch_no': batch_no_str,  # ‚úÖ Fixed: store batch list as single string
                    'dtm_created': current_date_and_time
                }

                print("üì§ Saving data:", test_candidate_data)

                serializer = courseScheduleSerializer(data=test_candidate_data)
                if serializer.is_valid():
                    serializer.save()
                    data.append(serializer.data)
                    print(f"‚úÖ Saved for student: {student.user_name}")
                else:
                    print(f"‚ùå Validation failed for {student.user_name}:", serializer.errors)
                    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        print(f"üì¶ Total schedules created: {len(data)}")
        return Response({'message': f'{len(data)} records created'}, status=status.HTTP_201_CREATED)

@api_view(['GET'])
def get_content_master_subTopic(request, topic_name):
    if not topic_name:
        return Response({'error': 'Topic name is required.'}, status=status.HTTP_400_BAD_REQUEST)

    # Fetch the id and sub_topic based on the topic name
    topics = content_master.objects.filter(topic=topic_name,deleted=0).values('id', 'sub_topic')
    if not topics.exists():
        return Response({'error': f'No topics found for the given topic name: {topic_name}'}, status=status.HTTP_404_NOT_FOUND)

    return Response(list(topics), status=status.HTTP_200_OK)


@api_view(['GET'])
def students_course_content_view(request):
    user_name = request.query_params.get('user_name')
    question_type = request.query_params.get('question_type')  # optional
    skill_type = request.query_params.get('skill_type')        # optional
    current_date_time = timezone.now()

    print("====================================")
    print(f"üì• API Triggered for user_name: {user_name}")
    print(f"üïí Current datetime: {current_date_time}")
    print(f"üîé Filters: question_type={question_type}, skill_type={skill_type}")
    print("====================================")

    if not user_name:
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        candidate = get_object_or_404(candidate_master, user_name=user_name)
        student_id = candidate.id
        batch_no = candidate.batch_no
        college_id = candidate.college_id_id

        print(f"‚úÖ Found candidate ‚û§ ID: {student_id}, Batch: {batch_no}, College ID: {college_id}")

        data = []
        seen_topic_keys = set()

        # --------------------------
        # Build base filters for topic
        # --------------------------
        topic_filters = {}
        if question_type:
            topic_filters["topic_id__question_type_id__question_type"] = question_type
        if skill_type:
            topic_filters["topic_id__skill_type_id__skill_type"] = skill_type

        # --------------------------
        # 1. course_schedule (student-based)
        # --------------------------
        print("\nüîç Checking course_schedule for student_id...")
        course_schedules = course_schedule.objects.filter(
            deleted=0,
            student_id=student_id,
            dtm_start_student__lte=current_date_time,
            dtm_end_student__gte=current_date_time,
            **topic_filters  # apply optional filters
        ).select_related("topic_id")

        print(f"üìö course_schedule entries found: {course_schedules.count()}")

        for cs in course_schedules:
            topic = cs.topic_id
            if not topic:
                continue

            topic_key = f"{(topic.topic or '').strip().lower()}__{(topic.sub_topic or '').strip().lower()}"

            if topic_key not in seen_topic_keys:
                seen_topic_keys.add(topic_key)
                data.append({
                    'id': cs.id,
                    'source': 'course_schedule',
                    'topic': topic.topic,
                    'sub_topic': topic.sub_topic,
                    'Content_URL': topic.content_url,
                    'worksheet_link': getattr(topic, "worksheet_link", None),
                    'Actual_Content': topic.actual_content,
                    'Start_Date': cs.dtm_start_student,
                    'End_Date': cs.dtm_end_student,
                    'student_id': student_id,
                })

        # --------------------------
        # 2. training_schedule (college_id + batch_no)
        # --------------------------
        print("\nüîç Checking training_schedule for college_id + batch_no...")
        training_records = training_schedule.objects.filter(
            college_id=college_id,
            batch_no=batch_no,
            dtm_start_student__lte=current_date_time,
            dtm_end_student__gte=current_date_time,
            deleted=0,
            **topic_filters  # apply optional filters
        ).exclude(status="Completed").select_related("topic_id")

        print(f"üèãÔ∏è training_schedule entries found: {training_records.count()}")

        for ts in training_records:
            topic = ts.topic_id
            if not topic:
                continue

            topic_key = f"{(topic.topic or '').strip().lower()}__{(topic.sub_topic or '').strip().lower()}"

            if topic_key not in seen_topic_keys:
                seen_topic_keys.add(topic_key)
                data.append({
                    'id': ts.id,
                    'source': 'training_schedule',
                    'topic': topic.topic,
                    'sub_topic': topic.sub_topic,
                    'Content_URL': topic.content_url,
                    'worksheet_link': getattr(topic, "worksheet_link", None),
                    'Actual_Content': topic.actual_content,
                    'Start_Date': ts.dtm_start_trainer,
                    'End_Date': ts.dtm_end_trainer,
                    'student_id': student_id,
                })

        print(f"\n‚úÖ Final response ready ‚Äî Total unique topics: {len(data)}")
        return Response(data, status=status.HTTP_200_OK)

    except Exception as e:
        print("‚ùå Exception occurred:")
        traceback.print_exc()
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

@api_view(['DELETE'])
def delete_question_paper_by_name(request, question_paper_name):
    try:
        question_paper = get_object_or_404(question_paper_master, question_paper_name=question_paper_name)
        question_paper.delete()
        return Response({'message': 'Question paper deleted successfully'}, status=status.HTTP_200_OK)
    except Exception as e:
        return Response({'error': f'Error occurred while trying to delete the question paper: {str(e)}'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_candidate_user_name(request):
    user_name = request.query_params.get('user_name')

    if not user_name:
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        # Fetch candidate queryset with prefetch of skills
        candidates = candidate_master.objects.filter(
            deleted=0,
            user_name=user_name
        ).select_related('college_id', 'department_id')\
         .prefetch_related('skill_id')\
         .distinct()

        # Use list comprehension to build the response
        candidate_data = [
            {
                'id': candidate.id,
                'college_id': candidate.college_id.id if candidate.college_id else None,
                'college_id__college': candidate.college_id.college if candidate.college_id else None,
                'students_name': candidate.students_name,
                'user_name': candidate.user_name,
                'registration_number': candidate.registration_number,
                'gender': candidate.gender,
                'email_id': candidate.email_id,
                'mobile_number': candidate.mobile_number,
                'year': candidate.year,
                'cgpa': candidate.cgpa,
                'department_id': candidate.department_id.id if candidate.department_id else None,
                'department_id__department': candidate.department_id.department if candidate.department_id else None,
                'marks_10th': candidate.marks_10th,
                'marks_12th': candidate.marks_12th,
                'marks_semester_wise': candidate.marks_semester_wise,
                'history_of_arrears': candidate.history_of_arrears,
                'standing_arrears': candidate.standing_arrears,
                'number_of_offers': candidate.number_of_offers,
                'text': candidate.text,
                'it_of_offers': candidate.it_of_offers,
                'core_of_offers': candidate.core_of_offers,
                'resume_link': candidate.resume_link,
                'photo_link': candidate.photo_link,
                'skill_id': [skill.id for skill in candidate.skill_id.all()]
            }
            for candidate in candidates
        ]

        return Response(candidate_data, status=status.HTTP_200_OK)

    except Exception as e:
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)




@api_view(['GET'])
def candidate_info(request):
    user_name = request.GET.get('user_name', None)

    if not user_name:
        return Response({'error': 'user_name parameter is required'}, status=status.HTTP_400_BAD_REQUEST)

    # Define cache key
    cache_key = f'candidate_info_{user_name}'
    # Attempt to retrieve data from cache
    cached_data = cache.get(cache_key)

    if cached_data:
        # If data is found in cache, return it
        return Response(cached_data, status=status.HTTP_200_OK)

    try:
        # Fetch candidate from database
        candidate = candidate_master.objects.get(user_name=user_name, deleted=0)
        need_candidate_info = candidate.need_candidate_info

        # Prepare response data
        if not need_candidate_info:
            # Special handling for when need_candidate_info is false
            response_data = {'message': 'Candidate info is not required'}
            # Cache the result for future requests
            cache.set(cache_key, response_data, timeout=900)  # 15 mins
        else:
            # Normal handling when need_candidate_info is true
            response_data = {'need_candidate_info': need_candidate_info}

        return Response(response_data, status=status.HTTP_200_OK)

    except candidate_master.DoesNotExist:
        return Response({'error': 'Candidate not found'}, status=status.HTTP_404_NOT_FOUND)

    except Exception as e:
        # Handle unexpected errors
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



@api_view(['PUT'])
def update_candidate_info(request):
    user_name = request.data.get('user_name')
    need_candidate_info = request.data.get('need_candidate_info', False)  # Default to False if not provided

    if not user_name:
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        candidate = candidate_master.objects.get(user_name=user_name)
        candidate.need_candidate_info = need_candidate_info
        candidate.save()

        return Response({'success': f'Updated need_candidate_info for user {user_name}'}, status=status.HTTP_200_OK)

    except candidate_master.DoesNotExist:
        return Response({'error': 'Candidate not found'}, status=status.HTTP_404_NOT_FOUND)


@api_view(['GET'])
def get_department_info(request):
    """
    Retrieve department information based on provided college IDs.
    """
    # Retrieve `college_id` values from query parameters
    college_ids = request.query_params.getlist('college_id')
    
    if not college_ids:
        return Response(
            {"error": "No college_ids provided"}, 
            status=status.HTTP_400_BAD_REQUEST
        )

    try:
        # Query the database for department information
        results = candidate_master.objects.filter(
            college_id__in=college_ids,
            department_id__isnull=False,
            deleted=0
        ).values(
            department_id_value=F('department_id__id'),
            department_name_value=F('department_id__department')
        ).distinct()

        # Return results
        return Response(list(results), status=status.HTTP_200_OK)

    except candidate_master.DoesNotExist:
        return Response(
            {"error": "No data found for the given college_ids"}, 
            status=status.HTTP_404_NOT_FOUND
        )
    except Exception as e:
        # Handle unexpected errors gracefully
        return Response(
            {"error": f"An unexpected error occurred: {str(e)}"}, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )



@api_view(['GET'])
def get_department_info_jd(request):
    """
    Retrieve department information based on provided college IDs.
    If 'all' is included in the college_ids, fetch data for all colleges.
    """
    # Retrieve `college_id` values from query parameters
    college_ids = request.query_params.getlist('college_id')

    if not college_ids:
        return Response(
            {"error": "No college_ids provided"}, 
            status=status.HTTP_400_BAD_REQUEST
        )

    try:
        # Determine whether to filter by college_id or fetch all
        query_filter = {} if 'all' in college_ids else {'college_id__in': college_ids}
        query_filter['department_id__isnull'] = False
        query_filter['deleted'] = 0

        # Query the database
        results = candidate_master.objects.filter(**query_filter).values(
            department_id_value=F('department_id__id'),
            department_name_value=F('department_id__department')
        ).distinct()

        # Return results
        return Response(list(results), status=status.HTTP_200_OK)

    except candidate_master.DoesNotExist:
        return Response(
            {"error": "No data found for the given college_ids"}, 
            status=status.HTTP_404_NOT_FOUND
        )
    except Exception as e:
        # Handle unexpected errors gracefully
        return Response(
            {"error": f"An unexpected error occurred: {str(e)}"}, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

@api_view(['GET'])
def get_department_info_LMS(request):
    college_ids = request.query_params.getlist('college_id')

    if not college_ids:
        return Response(
            {"error": "No college_ids provided"},
            status=status.HTTP_400_BAD_REQUEST
        )

    try:
        # Ensure all college_ids are integers
        college_ids = [int(cid) for cid in college_ids]

        # Fetch department IDs and names via subquery using `values_list` and set()
        qs = candidate_master.objects.filter(
            college_id__in=college_ids,
            department_id__isnull=False,deleted=0
        ).values(
            'department_id__id',
            'department_id__department'
        )

        # Use set to remove duplicates (faster than .distinct())
        department_set = {
            (item['department_id__id'], item['department_id__department'])
            for item in qs
        }

        # Format the response
        results = [
            {'department_id_value': dept_id, 'department_name_value': dept_name}
            for dept_id, dept_name in department_set
        ]

        return Response(results, status=status.HTTP_200_OK)

    except Exception as e:
        return Response(
            {"error": f"An unexpected error occurred: {str(e)}"},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )


@api_view(['GET'])
def get_candidate_details(request):
    """
    Retrieve candidate details based on the provided username.
    """
    user_name = request.query_params.get('user_name')

    if not user_name:
        return Response(
            {"error": "The 'user_name' parameter is required."}, 
            status=status.HTTP_400_BAD_REQUEST
        )

    try:
        # Query database for the given username
        candidates = candidate_master.objects.filter(
            user_name=user_name,deleted=0
        ).values(
            'id',  # Use the field name directly instead of F()
            'college_id',
            'department_id'
        )

        if not candidates.exists():
            return Response(
                {"message": "No candidates found for the given username."}, 
                status=status.HTTP_404_NOT_FOUND
            )

        return Response(list(candidates), status=status.HTTP_200_OK)

    except Exception as e:
        return Response(
            {"error": f"An unexpected error occurred: {str(e)}"}, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )



#------------------------college with Logo------------------------------#

from rest_framework.pagination import PageNumberPagination

from django.utils.encoding import force_str

@api_view(['GET'])
def get_colleges_clg(request):
    try:
        search = request.query_params.get('search', '')  # Get search term from query params

        # Base query
        queryset = college_master.objects.filter(deleted=0).order_by('-id').values(
            'id',
            'college',
            'college_logo',
            
            'college_code',
            'college_group',
            'spoc_name',
            'spoc_no',
            'email',
          
            'level_of_access',
            'stay_incharge_name',
            'stay_incharge_no',
            'trans_incharge_name',
            'trans_incharge_no'
        )

        # Apply filtering if search term is provided
        if search:
            queryset = queryset.filter(
                Q(college__icontains=search) | Q(college_group__icontains=search)
            )

        # Apply pagination
        paginator = PageNumberPagination()
        paginator.page_size = 10
        paginated_queryset = paginator.paginate_queryset(queryset, request)

        # Prepare paginated data with logo encoding
        college_data = [
            {
                'id': college['id'],
                'college': college['college'],
              
                'college_code': college['college_code'],
                'college_group': college['college_group'],
                'spoc_name': college['spoc_name'],
                'spoc_no': college['spoc_no'],
                'email': college['email'],
               
                'level_of_access': college['level_of_access'],
               
               
                'stay_incharge_name': college['stay_incharge_name'],
                'stay_incharge_no': college['stay_incharge_no'],
                'trans_incharge_name': college['trans_incharge_name'],
                'trans_incharge_no': college['trans_incharge_no'],
                'college_logo': base64.b64encode(college['college_logo']).decode('utf-8')
                                if college['college_logo'] else None
            }
            for college in paginated_queryset
        ]

        return paginator.get_paginated_response(college_data)

    except Exception as e:
        return Response({'error': str(e)}, status=500)


@csrf_exempt
def upload_collegeold(request):
    if request.method == 'POST':
        form = CollegeForm(request.POST, request.FILES)
        if form.is_valid():
            college_name = form.cleaned_data.get('college').strip()
            college_group = form.cleaned_data.get('college_group')

            # Duplicate check according to your rules:
            if not college_group:
                # If college_group not provided, check if college alone exists (case-insensitive)
                exists = college_master.objects.filter(
                    college__iexact=college_name,
                    deleted=0
                ).exists()
                if exists:
                    return JsonResponse(
                        {'message': f"College '{college_name}' already exists."},
                        status=409
                    )
            else:
                # If college_group provided, check if the exact tuple exists
                exists = college_master.objects.filter(
                    college__iexact=college_name,
                    college_group=college_group,
                    deleted=0
                ).exists()
                if exists:
                    return JsonResponse(
                        {'message': f"College '{college_name}' with group '{college_group}' already exists."},
                        status=409
                    )

            # No duplicates found, save the new college
            college = form.save(commit=False)

            # Generate college_code
            words = college_name.split()
            if len(words) == 1:
                college_code = words[0].upper()
            elif len(words) == 2:
                college_code = words[0][:3].upper() + words[1][0].upper()
            else:
                college_code = "".join(word[0] for word in words).upper()

            college.college_code = college_code

            # Save logo if uploaded
            if 'college_logo' in request.FILES:
                college.college_logo = request.FILES['college_logo'].read()

            college.save()

            logger.info(f"College '{college_name}' created with code '{college_code}'")
            return JsonResponse(
                {'message': f"College '{college_name}' created successfully with code '{college_code}'."},
                status=200
            )

        else:
            # Form not valid
            logger.error(f"Form errors: {form.errors}")
            return JsonResponse({'message': 'Invalid data', 'errors': form.errors}, status=400)

    else:
        # For GET request, render form (optional)
        form = CollegeForm()
        return render(request, 'upload_college.html', {'form': form})

@csrf_exempt
def upload_college(request):
    if request.method == 'POST':
        form = CollegeForm(request.POST, request.FILES)
        if form.is_valid():
            college_name = form.cleaned_data.get('college').strip()
            college_group = form.cleaned_data.get('college_group', '').strip()

            # ‚úÖ Check if college already exists in the same group (case-insensitive)
            if college_master.objects.filter(
                college__iexact=college_name,
                college_group__iexact=college_group,
                deleted=0
            ).exists():
                return JsonResponse(
                    {'message': f"College '{college_name}' already exists in group '{college_group}'."},
                    status=409
                )

            # Passed all duplicate checks
            college = form.save(commit=False)

            # Generate college_code
            words = college_name.split()
            if len(words) == 1:
                college_code = words[0].upper()
            elif len(words) == 2:
                college_code = words[0][:3].upper() + words[1][0].upper()
            else:
                college_code = "".join(word[0] for word in words).upper()

            college.college_code = college_code

            if 'college_logo' in request.FILES:
                college.college_logo = request.FILES['college_logo'].read()

            college.save()

            logger.info(f"College '{college_name}' created with code '{college_code}'")
            return JsonResponse(
                {'message': f"College '{college_name}' created successfully with code '{college_code}'."},
                status=200
            )
        else:
            logger.error(f"Form errors: {form.errors}")
            return JsonResponse({'message': 'Invalid data', 'errors': form.errors}, status=400)

    else:
        form = CollegeForm()
        return render(request, 'upload_college.html', {'form': form})

@csrf_exempt
def update_college(request, college_id):
    college = get_object_or_404(college_master, id=college_id)

    if request.method == 'POST':
        form = CollegeFormUpdate(request.POST, request.FILES, instance=college)
        
        # Debugging form validity
        if form.is_valid():
            college = form.save(commit=False)

            # Handle the college_logo field separately
            if 'college_logo' in request.FILES:
                college.college_logo = request.FILES['college_logo'].read()
            # else:
            #     college.college_logo = None
           
            college.save()

            # Log success and send response
            logger.info("College Updated Successfully")
            return HttpResponse("College updated successfully")
        else:
            # If form is not valid, print the errors for debugging
            logger.error("Form is not valid: %s", form.errors)
            return HttpResponse("Form is not valid, check the errors")
    else:
        form = CollegeFormUpdate(instance=college)

    return render(request, 'update_college.html', {'form': form})



def view_college_data(request, college_id):
    college = get_object_or_404(college_master, id=college_id)
    return render(request, 'view_college_data.html', {'college': college})



#___________________________________________Eligible_students_____________________________________#

@api_view(['GET'])
def get_eligible_studentsall(request):
    # Filter the eligible students based on your criteria
    eligible_students_data = eligible_student_list.objects.filter(deleted=0).values(
        'id',
        'students_id__id',  
        'students_id__students_name',  
        'students_id__user_name',
        'students_id__department_id__department',
        'students_id__mobile_number',
        'students_id__registration_number',
        'students_id__year',
        'students_id__email_id',  # Access related object's field (candidate_master id)
       # 'students_id__skill_id__skill_name',  # Access related object's field (candidate_master name)
        'students_id__gender',
        'students_id__college_id__college',
        'students_id__cgpa',
        'announcement',
        'job_id__id',  # Access related object's field (job_offers id)
        'job_id__company_name',  # Access related object's field (job_offers company name)
        'job_id__company_profile',
        'job_id__location',
        'job_id__interview_date',
        'round_of_interview',
       
        'is_accept',
        'is_eligible'
    )
    
    # Convert the QuerySet to a list of dictionaries
    eligible_students_list = list(eligible_students_data)

    return Response(eligible_students_list)
@api_view(['GET'])
def get_registered_count(request):
    # Annotate each job with the count of accepted students
    eligible_students_data = eligible_student_list.objects.filter(is_accept=True,deleted=0).values(
        'job_id__id',  # Job ID
        'job_id__company_name',  # Job Company Name
        'job_id__company_profile',
        'job_id__location',
        'job_id__interview_date'
    ).annotate(
        accepted_students_count=Count('id')  # Count of students who accepted the job
    ).distinct()

    # Convert the QuerySet to a list of dictionaries
    eligible_students_list = list(eligible_students_data)

    return Response(eligible_students_list)

@api_view(['GET'])
def get_eligible_students(request):
    job_id = request.query_params.get('job_id', None)

    if not job_id:
        return Response({'error': 'job_id is required'}, status=400)

    try:
        # Filter the eligible students based on job_id
        eligible_students_data = eligible_student_list.objects.filter(job_id_id=job_id, is_eligible=True,deleted=0).values(
            'id',
            'students_id__id',  # Access related object's field (candidate_master id)
            'students_id__students_name',  # Access related object's field (candidate_master name)
            'students_id__department_id__department',
            'students_id__mobile_number',
            'students_id__registration_number',
            'students_id__year',
            'students_id__email_id',  # Access related object's field (candidate_master id)
            #'students_id__skill_id__skill_name',  # Access related object's field (candidate_master name)
            'students_id__gender',
            'students_id__college_id',
            'students_id__cgpa',
            'announcement',
            'job_id__id',  # Access related object's field (job_offers id)
            'job_id__company_name',  # Access related object's field (job_offers company name)
            'round_of_interview',
            'whatsapp_text'
        )
        
        # Convert the QuerySet to a list of dictionaries
        eligible_students_list = list(eligible_students_data)

        return Response(eligible_students_list)

    except Exception as e:
        print('Exception:', str(e))
        return Response({'error': str(e)}, status=500)

@api_view(['GET'])
def get_eligible_students_count(request):
    # Get clg_id from query parameters
    clg_id = request.GET.get('clg_id')

    if not clg_id:
        return Response({'error': 'clg_id parameter is required'}, status=400)

    # Step 1: Get all job offers for the given college
    job_offers_with_clg = job_offers.objects.filter(
        college_id=clg_id,
        deleted=0
    ).values('id', 'company_name')

    # Step 2: Get counts for eligible students and add jobs without eligible students
    eligible_students_data = []
    for job in job_offers_with_clg:
        # Check if there are eligible students for the job
        student_count = eligible_student_list.objects.filter(
            students_id__college_id=clg_id,
            job_id__id=job['id'],
            is_eligible=True,deleted=0
        ).count()

        # Append the job with the student count (0 if no eligible students)
        eligible_students_data.append({
            'job_id__id': job['id'],
            'job_id__company_name': job['company_name'],
            'student_count': student_count
        })

    return Response(eligible_students_data)

@csrf_exempt
@api_view(['GET'])
def get_database_candidate(request):
    cache_key = 'database_candidate_list'
    cached_data = cache.get(cache_key)

    if cached_data:
        logger.info(f'[CACHE HIT] {cache_key}')
        return Response(cached_data)

    logger.info(f'[CACHE MISS] {cache_key}')

    try:
        # Fetch candidates with related college, department, and login info
        candidatelist = (
            candidate_master.objects.filter(deleted=0, is_database=True)
            .select_related('college_id', 'department_id')
            .values(
                'id',
                'college_id__college', 
                'college_id__college_group', 
                'batch_no',
                'students_name',
                'user_name',
                'registration_number',
                'gender',
                'email_id',
                'mobile_number',
                'year',
                'cgpa',
                'department_id__department',
                'marks_10th',
                'marks_12th',
                'history_of_arrears',
                'standing_arrears',
                'it_of_offers',
                'core_of_offers',
                'number_of_offers',
            )
            .distinct()
        )

        candidatelist = list(candidatelist)

        user_passwords = {
            login['user_name']: login['password']
            for login in login.objects.filter(
                user_name__in=[candidate['user_name'] for candidate in candidatelist],
                deleted=0

            ).values('user_name', 'password')
        }

        for candidate in candidatelist:
            candidate['password'] = user_passwords.get(candidate['user_name'], '')
            if candidate['students_name'] == '0.0':
                candidate['students_name'] = ''

        # Cache the result for 1 hour (3600 seconds)
        cache.set(cache_key, candidatelist, timeout=300)

        return Response(candidatelist)

    except Exception as e:
        logger.error(f'Error in get_database_candidate: {str(e)}')
        return Response({'error': str(e)}, status=500)


@csrf_exempt
  # Caches the view for 1 hour
@api_view(['GET'])
def get_nondb_candidate(request):
    cache_key = 'nondb_candidate_list'
    candidate_data = cache.get(cache_key)

    if candidate_data:
        logger.info(f'[CACHE HIT] {cache_key}')
        return JsonResponse(candidate_data, safe=False)

    logger.info(f'[CACHE MISS] {cache_key}')

    try:
        # Fetch candidates with related college info, filtering by is_database=False
        candidatelist = (
            candidate_master.objects.filter(deleted=0, is_database=False)
            .select_related('college_id')
            .values(
                'id',
                'user_name',
                'dtm_upload',
                'college_id__college',
                'college_id__college_group',
                'batch_no',
            )
            .distinct()
        )

        candidatelist = list(candidatelist)

        # Get login info by user_name
        user_passwords = {
            login_data['user_name']: login_data['password']
            for login_data in login.objects.filter(
                user_name__in=[c['user_name'] for c in candidatelist],deleted=0

            ).values('user_name', 'password')
        }

        # Reorder and inject password
        reordered_candidates = []
        for candidate in candidatelist:
            password = user_passwords.get(candidate['user_name'], None)
            reordered_candidates.append({
                'id': candidate['id'],
                'user_name': candidate['user_name'],
                'password': password,
                'dtm_upload': candidate.get('dtm_upload'),
                'college_id__college': candidate.get('college_id__college'),
                'college_group': candidate.get('college_id__college_group'),
                'batch_no': candidate.get('batch_no'),
            })

        # Store in cache for future requests
        cache.set(cache_key, reordered_candidates, timeout=300)

        return JsonResponse(reordered_candidates, safe=False)

    except Exception as e:
        logger.error(f"Error in get_nondb_candidate: {str(e)}")
        return JsonResponse({'error': str(e)}, status=500)




#-----------------------------------------------------------------------------#

@csrf_exempt
def update_eligible_student(request, job_id_value,round_of_interview_value):
    print(f"Received request for updating students with Job ID: {job_id_value}")
    print(request)
    
   
    print("round_of_interview",round_of_interview_value)
    if not round_of_interview_value:
        return HttpResponse("Error: round_of_interview query parameter is required.", status=400)

    try:
        # Retrieve all eligible student records based on job_id and round_of_interview
        #eligible_students = eligible_student_list.objects.filter(job_id_id=job_id_value, round_of_interview=round_of_interview_value,is_eligible=True)
        if round_of_interview_value == 'Interview Date':
            # Include both eligible and non-eligible students for 'Interview Date'
            eligible_students = eligible_student_list.objects.filter(job_id_id=job_id_value, round_of_interview=round_of_interview_value,deleted=0)
        else:
            # For other rounds, only include eligible students
            eligible_students = eligible_student_list.objects.filter(job_id_id=job_id_value, round_of_interview=round_of_interview_value, is_eligible=True,deleted=0)
        
        
        print("eligible_students",eligible_students)
        if not eligible_students.exists():
            return HttpResponse("Error: No eligible students found for the given criteria.", status=404)

        print(f"Retrieved {eligible_students.count()} eligible students")
    except Exception as e:
        print(f"Error occurred: {e}")
        return HttpResponse(f"Error: {e}", status=404)

    if request.method == 'POST':
        # Loop through each eligible student and update their details
        for eligible_student in eligible_students:
            form = EligibleStudentListForm(request.POST, request.FILES, instance=eligible_student)
            if form.is_valid():
                # Only update announcement if provided in the request
                if 'announcement' in request.POST:
                    eligible_student.announcement = request.POST.get('announcement')  # Use the input from the form

                # Only update the announcement image if provided in the request
                if 'announcement_image' in request.FILES:
                    file = request.FILES['announcement_image']
                    eligible_student.announcement_image = file.read()

                # Save the updated student data
                form.save()
            else:
                # If any form is invalid, return an error response with form errors
                return HttpResponse(f"Form errors: {form.errors}", status=400)

        print("All students updated successfully")
       
        
    else:
        # Prepopulate the form with data from the first student in the queryset
        form = EligibleStudentListForm(instance=eligible_students.first())

    return render(request, 'update_eligible_student.html', {'form': form, 'eligible_students': eligible_students})

@api_view(['GET'])
def get_eligible_students_round(request):
    round_of_interview = request.query_params.get('round_of_interview', None)

    if not round_of_interview:
        return Response({'error': 'round_of_interview is required'}, status=400)

    try:
        # Filter the eligible students based on round_of_interview
        eligible_students_data = eligible_student_list.objects.filter(round_of_interview=round_of_interview).values(
            'id',
            'students_id__id',  # Access related object's field (candidate_master id)
                 
        )
        
        # Convert the QuerySet to a list of dictionaries
        eligible_students_list = list(eligible_students_data)

        return Response(eligible_students_list)

    except Exception as e:
        print('Exception:', str(e))
        return Response({'error': str(e)}, status=500)

#---------------------Update Upload Shortlisted Cadidate----------------#

class UpdateEligibleStudentListView_REG_No(APIView):
    def post(self, request, format=None):
        if 'file' not in request.FILES:
            print("No file uploaded")
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)
        
        file = request.FILES['file']
        
        if not file.name.endswith('.xlsx'):
            print("File is not in Excel format")
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            df = pd.read_excel(file)
            print("Excel file read successfully")
        except Exception as e:
            print(f"Error reading Excel file: {str(e)}")
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        round_of_interview = request.data.get('round_of_interview')
        job_id_value = request.data.get('job_id')
        print('round_of_interview: ', round_of_interview)
        print('jobId: ', job_id_value)

        if not round_of_interview:
            return Response({'error': 'round_of_interview parameter is required'}, status=status.HTTP_400_BAD_REQUEST)
        
        if not job_id_value:
            return Response({'error': 'jobId parameter is required'}, status=status.HTTP_400_BAD_REQUEST)

        for _, row in df.iterrows():
            reg_no = row.get('Reg No')
            if not reg_no:
                continue

            eligible_ids = eligible_student_list.objects.filter(
                students_id__registration_number=reg_no,
                job_id=job_id_value,deleted=0
            )
            if eligible_ids.exists():
                eligible_ids.update(round_of_interview=round_of_interview)
            else:
                # Handle case where no eligible student list record exists
                print(f"No eligible student list record found for candidate with reg_no {reg_no} and job_id {job_id_value}")
                continue

        return Response({'success': 'Eligible student list updated successfully'}, status=status.HTTP_200_OK)

class UpdateEligibleStudentListView(APIView):
    def post(self, request, format=None):
        print("Received POST request")

        # Check for file in request.FILES
        if 'file' not in request.FILES:
            print("No file uploaded")
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']
        print(f"Uploaded file name: {file.name}")

        # Validate file format
        if not file.name.endswith('.xlsx'):
            print("File is not in Excel format")
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
            print("Excel file read successfully")
        except Exception as e:
            print(f"Error reading Excel file: {str(e)}")
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Get parameters from request data
        round_of_interview = request.data.get('round_of_interview')
        job_id_value = request.data.get('job_id')

        print(f"Round of Interview: {round_of_interview}")
        print(f"Job ID: {job_id_value}")

        # Validate parameters
        if not round_of_interview:
            print("round_of_interview parameter is missing")
            return Response({'error': 'round_of_interview parameter is required'}, status=status.HTTP_400_BAD_REQUEST)

        if not job_id_value:
            print("job_id parameter is missing")
            return Response({'error': 'job_id parameter is required'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            # Fetch job type from job_offers based on job_id_value
            job = job_offers.objects.get(id=job_id_value)
            job_type = job.job_type  # Assuming 'job_type' is a field in job_offers (IT or Core)
            print(f"Job Type: {job_type}")

            struct = f'{job.company_name}_{job.post_name}_{round_of_interview}'

            errors = []

            with transaction.atomic():
                # Prepare data for updates
                students_to_update = [
                    {
                        'reg_no': row.get('Reg No**'),
                        'student_name': row.get('Student Name')
                    }
                    for index, row in df.iterrows()
                    if not (pd.isna(row.get('Reg No**')) or str(row.get('Reg No**')).strip() == '') and
                       not (pd.isna(row.get('Student Name')) or str(row.get('Student Name')).strip() == '')
                ]

                if not students_to_update:
                    errors.append("No valid records found in the file.")
                    print("No valid records found in the file.")
                    return Response({'error': errors}, status=status.HTTP_400_BAD_REQUEST)

                # Retrieve and update eligible students
                eligible_students = eligible_student_list.objects.filter(
                    job_id=job_id_value,
                    students_id__registration_number__in=[s['reg_no'] for s in students_to_update],deleted=0
                )

                # Update the round_of_interview status
                for student in eligible_students:
                    student.round_of_interview = round_of_interview
                    student.batch_name = struct
                    student.save()
                    print(f"Updated round_of_interview for student with Reg No: {student.students_id.registration_number}")

                # Only update candidate_master fields if round_of_interview is "Offer"
                if round_of_interview == 'Offer':
                    for student in eligible_students:
                        candidate = candidate_master.objects.filter(
                            registration_number=student.students_id.registration_number,deleted=0
                        ).first()
                        if candidate:
                            if job_type == 'IT':
                                candidate.it_of_offers = (candidate.it_of_offers or 0) + 1
                            elif job_type == 'Core':
                                candidate.core_of_offers = (candidate.core_of_offers or 0) + 1
                            candidate.is_offered = True
                            candidate.save()
                            print(f"Updated {job_type.lower()}_of_offers for candidate with Reg No: {candidate.registration_number}")

        except job_offers.DoesNotExist:
            print(f"Job ID {job_id_value} not found")
            return Response({'error': 'Job not found'}, status=status.HTTP_404_NOT_FOUND)
        except eligible_student_list.DoesNotExist:
            print(f"Eligible students not found for job ID {job_id_value}")
            return Response({'error': 'Eligible students not found'}, status=status.HTTP_404_NOT_FOUND)
        except candidate_master.DoesNotExist:
            print(f"Candidate not found in candidate_master")
            return Response({'error': 'Candidate not found'}, status=status.HTTP_404_NOT_FOUND)
        except ValueError as ve:
            print(f"ValueError occurred: {str(ve)}")
            return Response({'error': str(ve)}, status=status.HTTP_400_BAD_REQUEST)
        except Exception as e:
            print(f"An unexpected error occurred: {str(e)}")
            return Response({'error': f"An unexpected error occurred: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)

        if errors:
            print(f"Errors encountered: {errors}")
            return Response({'error': errors}, status=status.HTTP_400_BAD_REQUEST)

        print("Eligible student list updated successfully")
        return Response({'success': 'Eligible student list updated successfully'}, status=status.HTTP_200_OK)

@api_view(['PUT', 'PATCH'])
def update_is_accept(request, pk):
    try:
        print("Entering Function..")
        candidates=eligible_student_list.objects.get(id=pk)
        ##logger.info('Fetching test-candidate-map ')

        print("accept_candidates: ",candidates)
    except eligible_student_list.DoesNotExist:
        return JsonResponse("tests not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    candidates.is_accept = True
    candidates.round_of_interview = 'Registered'
    candidates.save()
    ##logger.info('test-candidates updated')
    print("candidates_accepted: ",candidates)

    return JsonResponse("tests_candidates_map 'deleted' field updated successfully", safe=False)

@api_view(['PUT', 'PATCH'])
def update_is_decline(request, pk):
    try:
        print("Entering Function..")
        candidates=eligible_student_list.objects.get(id=pk)
        ##logger.info('Fetching test-candidate-map ')

        print("accept_candidates: ",candidates)
    except eligible_student_list.DoesNotExist:
        return JsonResponse("tests not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    candidates.is_accept = False
    candidates.save()
    ##logger.info('test-candidates updated')
    print("candidates_accepted: ",candidates)

    return JsonResponse("tests_candidates_map 'deleted' field updated successfully", safe=False)



@csrf_exempt
@cache_page(60 * 60)  # Optional: apply per-view cache
def get_questions_IO_filter_mcq(request, question_id):
    cache_key = f'questions_IO_filter_mcq_{question_id}'
    question_data = cache.get(cache_key)

    if question_data:
        logger.info(f'[CACHE HIT] {cache_key}')
        return JsonResponse(question_data, safe=False)

    logger.info(f'[CACHE MISS] {cache_key}')
    
    questions = question_master.objects.filter(
        deleted=0,
        question_name_id=question_id
    ).select_related('question_name_id').only(
        'id', 'question_name_id__id', 'question_name_id__question_paper_name',
        'question_text', 'question_image_data',
        'option_a_image_data', 'option_b_image_data',
        'option_c_image_data', 'option_d_image_data',
        'option_a', 'option_b', 'option_c', 'option_d',
        'mark', 'explain_answer', 'answer', 'input_format'
    )

    question_data = []
    for q in questions:
        def encode(img): return base64.b64encode(img).decode('utf-8') if img else None

        question_data.append({
            'id': q.id,
            'question_name_id': q.question_name_id.id,
            'question_paper_name': q.question_name_id.question_paper_name,
            'question_text': q.question_text,
            'question_image_data': encode(q.question_image_data),
            'option_a_image_data': encode(q.option_a_image_data),
            'option_b_image_data': encode(q.option_b_image_data),
            'option_c_image_data': encode(q.option_c_image_data),
            'option_d_image_data': encode(q.option_d_image_data),
            'option_a': q.option_a,
            'option_b': q.option_b,
            'option_c': q.option_c,
            'option_d': q.option_d,
            'mark': q.mark,
            'explain_answer': q.explain_answer,
            'answer': q.answer,
            'input_format': q.input_format,
        })

    random.shuffle(question_data)
    cache.set(cache_key, question_data, timeout=3600)

    return JsonResponse(question_data, safe=False)
@csrf_exempt
@cache_page(60 * 60)
def get_questions_IO_filter_mcq_practice(request, test_name):
    try:
        print(f"üì• Step 1: Received request for MCQ Questions with test_name: {test_name}")

        # Step 2: Fetch test entry
        test_entry = tests_candidates_map.objects.filter(test_name=test_name, deleted=0).first()
        print(f"üîç Step 2: test_entry = {test_entry}")

        if not test_entry:
            return JsonResponse({'error': 'Invalid test_name or test not found'}, status=404)

        # Step 3: Extract only question_ids (ignore question_paper_id)
        question_ids_list = test_entry.question_ids or []

        if not question_ids_list:
            return JsonResponse({'error': 'No question_ids found in test entry'}, status=400)

        # Step 4: Check cache
        cache_key = f'questions_IO_filter_mcq_{test_name}'
        question_data = cache.get(cache_key)

        if question_data:
            print(f"‚úÖ [CACHE HIT] Returning cached data for {cache_key}")
            return JsonResponse(question_data, safe=False)

        # Step 5: Fetch questions from DB using only question_ids
        questions = question_master.objects.filter(
            deleted=0,
            id__in=question_ids_list
        ).only(
            'id', 'question_text', 'question_image_data',
            'option_a_image_data', 'option_b_image_data',
            'option_c_image_data', 'option_d_image_data',
            'option_a', 'option_b', 'option_c', 'option_d',
            'mark', 'explain_answer', 'answer', 'input_format'
        )

        def encode(img):
            return base64.b64encode(img).decode('utf-8') if img else None

        # Step 6: Serialize and encode question data (without question_name_id)
        question_data = [{
            'id': q.id,
            'question_text': q.question_text,
            'question_image_data': encode(q.question_image_data),
            'option_a_image_data': encode(q.option_a_image_data),
            'option_b_image_data': encode(q.option_b_image_data),
            'option_c_image_data': encode(q.option_c_image_data),
            'option_d_image_data': encode(q.option_d_image_data),
            'option_a': q.option_a,
            'option_b': q.option_b,
            'option_c': q.option_c,
            'option_d': q.option_d,
            'mark': q.mark,
            'explain_answer': q.explain_answer,
            'answer': q.answer,
            'input_format': q.input_format,
        } for q in questions]

        # Step 7: Shuffle and cache
        random.shuffle(question_data)
        cache.set(cache_key, question_data, timeout=3600)

        # Step 8: Return final response
        return JsonResponse(question_data, safe=False)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)

@csrf_exempt
@cache_page(60 * 10)  # Cache the full view response for 10 minutes
def get_questions_IO_filter_code(request, question_id):
    cache_key = f'question_data_codes_{question_id}'
    logger.error("Cache Key: %s", cache_key)

    question_data = cache.get(cache_key)

    if question_data:
        logger.error(f'Cache hit for key: {cache_key}')
        return JsonResponse(question_data, safe=False)

    logger.error(f'Cache miss for key (DB): {cache_key}')

    questionset = (
        question_master.objects
        .filter(deleted=0, question_name_id=question_id)
        .select_related('question_name_id')
        .values(
            'id',
            'question_text',
            'mark',
            'input_format',
            'explain_answer',
            'answer',
            'question_name_id__is_testcase',
            'test_case1',
            'test_case2',
            'test_case3'
        )
    )

    def parse_test_cases(q):
        test_cases = []
        for key in ['test_case1', 'test_case2', 'test_case3']:
            test_case = q.pop(key, None)
            if test_case:
                match = re.search(r"Input:\s*(.*?)\s*Output:\s*(.*?)$", test_case, re.DOTALL)
                if match:
                    input_data = match.group(1).strip()
                    expected_output = match.group(2).strip().split(":")[-1].strip()
                    test_cases.append({"input": input_data, "expected": expected_output})
        return test_cases

    question_data = [
        {**q, 'testCases': parse_test_cases(dict(q))}  # Ensure original q isn't mutated
        for q in questionset
    ]

    random.shuffle(question_data)
    cache.set(cache_key, question_data, timeout=600)

    return JsonResponse(question_data, safe=False)

@csrf_exempt
def get_questions_IO_filter_code_practice(request, test_name):
    try:
        print(f"\nüì• Fetching Coding Questions for test_name: {test_name}")
        print("‚û°Ô∏è Entering Function..")

        # Step 1: Get test entry
        test_entry = tests_candidates_map.objects.filter(test_name=test_name,deleted=0).first()
        if not test_entry:
            print("‚ùå test_entry not found for given test_name.")
            return JsonResponse({'error': 'Invalid test_name or test not found'}, status=404)
        
        print(f"‚úÖ test_entry found: {test_entry}")

        # Step 2: Extract question_ids only (ignore question_id / paper)
        question_ids_list = test_entry.question_ids or []

        print(f"üìã question_ids_list: {question_ids_list}")
        if not question_ids_list:
            print("‚ö†Ô∏è Missing question_ids.")
            return JsonResponse({'error': 'No question_ids found in test entry'}, status=400)

        # Step 3: Query only with those question_ids
        print("üîç Querying question_master table with question_ids only...")
        questionset = (
            question_master.objects
            .filter(deleted=0, id__in=question_ids_list)
            .select_related('question_name_id')
            .values(
                'id',
                'question_text',
                'mark',
                'input_format',
                'explain_answer',
                'answer',
                'question_name_id__is_testcase',
                'test_case1',
                'test_case2',
                'test_case3'
            )
        )

        print(f"üì¶ Total questions fetched from DB: {questionset.count()}")

        def parse_test_cases(q):
            test_cases = []
            for key in ['test_case1', 'test_case2', 'test_case3']:
                test_case = q.pop(key, None)
                if test_case:
                    match = re.search(r"Input:\s*(.*?)\s*Output:\s*(.*?)$", test_case, re.DOTALL)
                    if match:
                        input_data = match.group(1).strip()
                        expected_output = match.group(2).strip().split(":")[-1].strip()
                        test_cases.append({"input": input_data, "expected": expected_output})
            return test_cases

        question_data = [
            {**q, 'testCases': parse_test_cases(dict(q))}
            for q in questionset
        ]

        print(f"‚úÖ Parsed question_data length: {len(question_data)}")
        random.shuffle(question_data)

        return JsonResponse(question_data, safe=False)

    except Exception as e:
        print(f"‚ùå Unexpected error: {str(e)}")
        return JsonResponse({'error': str(e)}, status=500)

def encode_image(image_data):
    return base64.b64encode(image_data).decode('utf-8') if image_data else None





@api_view(['GET'])
def get_tests_ansnwers_filter(request):
    # Directly apply filters
    student_id = request.GET.get('student_id')
    test_name = request.GET.get('test_name')
    question_id = request.GET.get('question_id')

    # Fetch data using ORM with related fields and filters
    test_candidate_answer_data = tests_candidates_answers.objects.annotate(
        answer_length=Length('answer')
    ).filter(
        deleted=0, 
        student_id=student_id, 
        test_name=test_name, 
        question_id=question_id, 
        submission_compile_code__isnull=True,
        answer_length__gt=0
    ).select_related('student_id', 'question_id').order_by('-id').values(
        'result',
        'question_id'
    )

    # Rename the fields to match your desired structure
    test_candidate_answer_data = [
        {
            'result': testans['result'],
            'question_id': testans['question_id']
        }
        for testans in test_candidate_answer_data
    ]

    return Response(test_candidate_answer_data)


@api_view(['GET'])
def get_total_marks(request, student_id_value, test_name_value):
    total_marks = tests_candidates_answers.objects.filter(
        student_id=student_id_value,
        test_name=test_name_value,
        deleted=0
    ).aggregate(total_marks=Sum('result'))['total_marks']  # Sum of the 'result' field
    print('total_marks: ', total_marks)

    return Response({'total_marks': total_marks if total_marks is not None else 0})




@api_view(['DELETE'])
def delete_student_answers(request, student_id):
    try:
        # Query to delete the records for the given student_id
        count, _ = tests_candidates_answers.objects.filter(student_id=student_id).delete()

        if count > 0:
            return Response({'message': f'{count} records deleted.'}, status=status.HTTP_204_NO_CONTENT)
        else:
            return Response({'error': 'No records found for the given student_id.'}, status=status.HTTP_404_NOT_FOUND)
    except Exception as e:
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



@api_view(['GET'])
def get_trainer_by_userName(request, userName):
    try:
        # Fetch trainers with the given username and not deleted
        trainer = trainer_master.objects.filter(user_name=userName, deleted=0)
        # Serialize the data
        serializer = trainerSerializer(trainer, many=True)
        return Response(serializer.data)
    except Exception as e:
        return Response({'error': str(e)}, status=500)
		


@api_view(['GET'])
def get_distinct_dtm_uploads(request, college_id):
    try:
        # Filter the candidate_master table based on college_id and is_database = False
        distinct_dtm_uploads = candidate_master.objects.filter(
            Q(college_id=college_id) & Q(is_database=False) & Q(deleted=0)
        ).order_by('-dtm_upload').values_list('dtm_upload', flat=True).distinct()

        # Return the distinct dtm_upload values
        return Response({
            'distinct_dtm_uploads': list(distinct_dtm_uploads)
        }, status=status.HTTP_200_OK)

    except Exception as e:
        # Handle any errors
        return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)




@api_view(['GET'])
def get_tests_candidates_camera(request,id):
    try:
        # Fetch all test-candidate mappings with related data in one query
        tests_candidates = tests_candidates_map.objects.filter(deleted=0,id=id).values(
            'id', 
          'is_camera_on',
        )

        # Convert the queryset into a list of dictionaries
        test_candidate_map_data = list(tests_candidates)

        return Response(test_candidate_map_data)
    except Exception as e:
        return Response({'error': str(e)}, status=500)



@api_view(['GET'])
def get_eligible_student_count_rounds(request):
    # Get the round_of_interview and job_id from the request parameters
    round_of_interview = request.query_params.get('round_of_interview')
    job_name = request.query_params.get('job_name')


    if not round_of_interview or not job_name:
        return Response({"error": "round_of_interview and job_id are required parameters."}, status=status.HTTP_400_BAD_REQUEST)

    # Query the eligible_student_list model
    count = eligible_student_list.objects.filter(round_of_interview=round_of_interview, job_id__company_name=job_name,is_eligible=True,deleted=0 ).count()
    if count == 0:
        return Response({"count": count, "message": "No eligible students found for the given round and job name."}, status=status.HTTP_200_OK)

    return Response({"count": count}, status=status.HTTP_200_OK)


@api_view(['GET'])
def get_candidate_offers_count(request, college_id):
    try:
        # Filter by college_id and count the number of offers
        count_offers = candidate_master.objects.filter(college_id=college_id, deleted=0).count()

        # Return the count in the response
        return Response({"total_offers": count_offers}, status=status.HTTP_200_OK)

    except candidate_master.DoesNotExist:
        # Handle the case where the college_id does not exist
        return Response({"error": "College ID not found."}, status=status.HTTP_404_NOT_FOUND)
    except Exception as e:
        # Handle any other exceptions
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



@api_view(['GET'])
def get_eligible_students_job_id(request, job_id, round_of_interview):
    try:
        # Retrieve the relevant student information directly
        students_data = eligible_student_list.objects.filter(
            job_id=job_id,
            round_of_interview=round_of_interview,
            is_eligible=True, deleted=0
        ).select_related('students_id').values(
            'students_id__id',
            'students_id__students_name',
            'students_id__registration_number',
            'students_id__department_id__department',
            'students_id__email_id',
            'students_id__mobile_number',
            'students_id__year',
            'students_id__cgpa',
            'students_id__marks_10th',
            'students_id__marks_12th',
            'students_id__history_of_arrears',
            'students_id__standing_arrears',
        )

        # Return the data as a response
        return Response(list(students_data), status=status.HTTP_200_OK)

    except Exception as e:
        # Handle any exceptions
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_round_of_interview_count(request):
    try:
        college_id_value = request.query_params.get('college_id', None)
        company_name_value = request.query_params.get('company_name', None)
        department_name_value = request.query_params.get('department_name', None)
        print('department_name_value: ', department_name_value)

        # Start with the base query
        base_query = eligible_student_list.objects.filter(
            students_id__college_id=college_id_value, deleted=0
        )

        # Conditionally add the company name filter if it's provided
        if company_name_value:
            base_query = base_query.filter(
                job_id__company_name=company_name_value
            )
            print('company base query: ', base_query)
        
        # Conditionally add the department filter if provided
        if department_name_value:
            base_query = base_query.filter(
                students_id__department_id__department__iexact=department_name_value
            )
            print('department base query: ', base_query)

        # Group by 'round_of_interview' and count the number of records for each round status
        round_of_interview_counts = base_query.values(
            'round_of_interview'  # Group by round_of_interview status
        ).annotate(
            student_count=Count('id')  # Count number of students for each round_of_interview status
        ).order_by('round_of_interview')
        
        print('rounds of interview: ', round_of_interview_counts)

        # Convert the QuerySet to a list of dictionaries
        round_of_interview_list = list(round_of_interview_counts)

        return Response(round_of_interview_list)

    except Exception as e:
        print(f"Error: {str(e)}")
        return Response({'error': str(e)}, status=500)




@api_view(['GET'])
def get_registered_count_by_company(request):
    try:
        college_id_value = request.query_params.get('college_id', None)
        department_name_value = request.query_params.get('department_name', None)

        # Create a base queryset
        base_query = eligible_student_list.objects.filter(
            students_id__college_id=college_id_value,
            is_accept=True ,deleted=0 # Only count registered students

        )

        # Conditionally filter by department_name_value if it's not None
        if department_name_value:
            base_query = base_query.filter(
                students_id__department_id__department=department_name_value
            )

        # Group by company name (from job_id) and get the count of registered students
        company_student_counts = base_query.values(
            'job_id__company_name',  # Group by company name from job_id
            'job_id__interview_date'
        ).annotate(
            registered_count=Count('id')  # Count number of students for each company
        ).order_by('job_id__company_name')  # Optional: Order by company name

        # Convert the QuerySet to a list of dictionaries
        company_student_count_list = list(company_student_counts)

        return Response(company_student_count_list)

    except Exception as e:
        print(f"Error: {str(e)}")
        return Response({'error': str(e)}, status=500)



@api_view(['GET'])
def distinct_job_companies(request):
    # Query to get distinct company names and ids
    # Use distinct() to ensure unique rows
    distinct_companies = job_offers.objects.filter(deleted=0).values('company_name').distinct()

    # Serialize the data
    # Since distinct() is used, the result should already be unique
    return Response(list(distinct_companies))


# Mapping of round_of_interview to corresponding email subject
round_subject_mapping = {
    'Interview Date': "Interview Date Announcement",
    'Registered': "Registration Confirmation",
    'Preplacement Talk': "Preplacement Talk Details",
    'Round1': "First Round Interview Details",
    'Round2': "second Round Interview Details",
     'Round3': "Third Round Interview Details",
    'Round4': "Fourth Round Interview Details",
    'Round5': "Final Round Interview Details",
   
   
    'Offer': "Congratulations! You've Received an Offer"
}

def send_emails(email_messages):
    try:
        send_mass_mail(email_messages, fail_silently=False)
        logger.info("Emails sent successfully.")
    except Exception as e:
        logger.error(f"Error sending emails: {e}")

@csrf_exempt
def send_email_to_students(request, job_id_value, round_of_interview_value):
    try:
        print(f"Fetching students for Job ID: {job_id_value}, Round: {round_of_interview_value}")
        logger.info(f"Fetching students for Job ID: {job_id_value}, Round: {round_of_interview_value}")
        
        # Fetch eligible students
        eligible_students = eligible_student_list.objects.filter(job_id_id=job_id_value, round_of_interview=round_of_interview_value,deleted=0)

        if not eligible_students.exists():
            print("No eligible students found.")
            logger.warning("No eligible students found.")
            return JsonResponse({"error": "No eligible students found for the given criteria"}, status=404)
        
        print(f"Found {eligible_students.count()} eligible students.")
        logger.info(f"Found {eligible_students.count()} eligible students.")

        # Determine the subject based on the round_of_interview_value
        email_subject = round_subject_mapping.get(round_of_interview_value, "Important Announcement")
        from_email = "selvisiddhu061996@gmail.com"

        # Prepare the list of emails for send_mass_mail
        email_messages = []
        for eligible_student in eligible_students:
            student_name = eligible_student.students_id.students_name  # Assuming students_id FK has students_name field
            email_body = f"""Dear {student_name},

{eligible_student.announcement}

Regards,
Campus Connections
www.campusconnection.co.in
"""
            email = (email_subject, email_body, from_email, [eligible_student.students_id.email_id])
            
            # Add to email messages list
            email_messages.append(email)
            
            # Print details at each step
            print(f"Prepared email for {student_name} with email {eligible_student.students_id.email_id}.")
            logger.info(f"Prepared email for {student_name} with email {eligible_student.students_id.email_id}.")

        # Send emails in a separate thread for faster execution
        email_thread = threading.Thread(target=send_emails, args=(email_messages,))
        email_thread.start()
        
        print("Emails are being sent in the background.")
        logger.info("Emails are being sent in the background.")
        return JsonResponse({"message": "Emails are being sent in the background"}, status=200)

    except Exception as e:
        logger.error(f"Error occurred during email sending: {e}")
        print(f"Error occurred: {e}")
        return JsonResponse({"error": str(e)}, status=500)

@api_view(['GET'])
def get_test_attendance_summary(request):
    try:
        college_id = request.query_params.get('college_id')
        dtm_start = request.query_params.get('dtm_start')

        if not college_id or not dtm_start:
            return Response({'error': 'Both college_id and dtm_start are required.'}, status=400)

        dtm_start_date = datetime.strptime(dtm_start, '%Y-%m-%d').date()

        # Retrieve tests by college_id and dtm_start date
        test_records = tests_candidates_map.objects.filter(
            college_id=college_id,
            dtm_start__date=dtm_start_date, deleted=0
        ).values('test_name', 'dtm_start', 'dtm_submit')

        # Dictionary to hold the aggregated data
        test_summary = {}

        for record in test_records:
            test_name = record['test_name']
            if test_name not in test_summary:
                test_summary[test_name] = {
                    'test_name': test_name,
                    'total_present': 0,
                    'total_absent': 0
                }

        # Convert the dictionary to a list of results
        result_list = list(test_summary.values())

        return Response(result_list)

    except Exception as e:
        print(f"Error: {str(e)}")
        return Response({'error': str(e)}, status=500)



@csrf_exempt
def upload_screenshot(request, pk):
    if request.method == 'POST':
        form = ScreenshotsForm(request.POST, request.FILES)
        if form.is_valid():
            # Get the screenshot file from the request
            screenshot_file = request.FILES.get('screenshots')

            # Create an instance of the model, but don't save it yet
            instance = form.save(commit=False)

            # Read the uploaded file as binary and save it to the binary field
            if screenshot_file:
                instance.screenshots = screenshot_file.read()

            # Set additional fields
            instance.dtm_created = timezone.now()  # Auto-set the created timestamp

            # Fetch the related tests_candidates_map instance
            test_candidate = get_object_or_404(tests_candidates_map, pk=pk)
            instance.test_candidate_id = test_candidate
            
            instance.save()

            return JsonResponse({"message": "Screenshot uploaded successfully"}, status=200)

    else:
        form = ScreenshotsForm()

    return render(request, 'upload_screenshot.html', {'form': form})


@api_view(['GET'])
def get_student_announcement(request, students_id):
    # Fetch all records matching the students_id
    student_entries = eligible_student_list.objects.filter(students_id=students_id, deleted=0)
    
    if not student_entries.exists():
        return JsonResponse({'error': 'No announcements found for this student'}, status=status.HTTP_404_NOT_FOUND)
    
    # Prepare the response data as a list of dictionaries using map and lambda
    data = list(map(lambda entry: {
        'announcement': entry.announcement,
        'announcement_image': base64.b64encode(entry.announcement_image).decode('utf-8') if entry.announcement_image else None
    }, student_entries))
    
    # Return the list of dictionaries
    return JsonResponse(data, safe=False, status=status.HTTP_200_OK)


@api_view(['GET'])
def get_eligible_student_Reports(request):
    # Get the round_of_interview (status) and company_name from the request parameters
    round_of_interview_status = request.query_params.get('round_of_interview')
    job_name = request.query_params.get('job_name')

    # Validate required parameters
    if not round_of_interview_status or not job_name:
        return Response({"error": "round_of_interview and company_name are required parameters."}, status=status.HTTP_400_BAD_REQUEST)

    # Define valid round statuses
    valid_round_options = ['Registered', 'Interview Date', 'Preplacement Talk', 'Round1', 'Round2','Round3','Round4','Round5', 'Offer']

    # Check if the round_of_interview_status is valid
    if round_of_interview_status not in valid_round_options:
        return Response({"error": f"Invalid round_of_interview status. Must be one of {valid_round_options}."}, status=status.HTTP_400_BAD_REQUEST)

    # Query the eligible_student_list model to get student details filtered by status and company
    students = eligible_student_list.objects.filter(
        round_of_interview=round_of_interview_status,
        job_id__company_name=job_name, deleted=0
    ).values(
        'students_id__students_name',
        'students_id__registration_number',
        'students_id__department_id__department',
        'students_id__email_id',
        'students_id__mobile_number',
        'students_id__cgpa',
        'students_id__marks_10th',
        'students_id__marks_12th',
         'students_id__history_of_arrears',
        'students_id__standing_arrears',
        'students_id__gender',
       
        'job_id__company_name'  # Include company name in the response
    )

    # If no students match the criteria, return a 404 response
    if not students.exists():
        return Response({"error": "No students found for the given criteria."}, status=status.HTTP_404_NOT_FOUND)

    # Convert the QuerySet to a list for the response
    student_data = list(students)

    # Return the student data in the response
    return Response({"students": student_data}, status=status.HTTP_200_OK)

@api_view(['GET'])
def getRoundOfInterviews_API(request):
    try:
        # Fetch distinct round_of_interview values
        rounds = eligible_student_list.objects.filter(deleted=0).values_list('round_of_interview', flat=True).distinct()
        
        # Convert queryset to a list and return as a response
        return Response({"rounds": list(rounds)}, status=status.HTTP_200_OK)
    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_400_BAD_REQUEST)


@api_view(['GET'])
def get_unique_topics_and_subtopics(request):
    # Fetch unique topics and subtopics using distinct
    unique_data = content_master.objects.filter(deleted=0).values('topic', 'sub_topic').distinct()

    # Format the response as a list of dictionaries containing unique topics and subtopics
    unique_topics_and_subtopics = list(unique_data)

    return Response(unique_topics_and_subtopics)


def get_max_score_by_department_placement(request, college_id):
    type_category = request.GET.get('typeCategory')  # Get typeCategory from request

    try:
        if type_category:
            # Step 1: Get the test_type_ids based on typeCategory
            test_types = test_type.objects.filter(
                test_type='MCQ Test', 
                test_type_categories=type_category, 
                deleted=0
            )
            if not test_types.exists():
                return JsonResponse({'error': 'Invalid typeCategory'}, status=400)
            type_ids = test_types.values_list('id', flat=True)
        else:
            test_types = test_type.objects.filter(test_type='MCQ Test', deleted=0)
            if not test_types.exists():
                return JsonResponse({'error': 'No test types found'}, status=400)
            type_ids = test_types.values_list('id', flat=True)

        # Step 2: Get the test_names for the given type_ids
        test_names = test_master.objects.filter(test_type_id__in=type_ids, deleted=0).values_list('test_name', flat=True)


        # Step 3: Create a subquery to get the maximum total score per department
        subquery = tests_candidates_map.objects.filter(
            college_id=college_id,
            question_id__test_type='MCQ Test',
            test_name__in=test_names,  # Filter by test names
            total_score__isnull=False,
            department_id=OuterRef('department_id'),
            deleted=0
        ).values('department_id').annotate(
            max_total_score=Max('total_score')
        ).values('max_total_score')

        print('subquery: ', Subquery(subquery))

        # Step 4: Filter the original query using this subquery to get the corresponding student names
        results = tests_candidates_map.objects.filter(
            college_id=college_id,
            question_id__test_type='MCQ Test',
            test_name__in=test_names,  # Filter by test names
            total_score__isnull=False,
            total_score=Subquery(subquery),  # Match the max score in each department
            deleted=0
        ).values(
            'student_id__students_name',
            'department_id__department',
            'total_score'
        ).distinct()  # Ensure unique records in case of ties

        print('results: ', results)

        # Format the results as a list of dictionaries
        data = [
            {
                'student_name': result['student_id__students_name'],
                'department': result['department_id__department'],
                'max_total_score': result['total_score']
            }
            for result in results
        ]

        # Return the results as a JSON response
        return JsonResponse(data, safe=False, status=200)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)



def get_max_score_by_department_coding_placement(request, college_id):
    type_category = request.GET.get('typeCategory')  # Get typeCategory from request

    try:
        if type_category:
            # Step 1: Get the test_type_ids based on typeCategory
            test_types = test_type.objects.filter(
                test_type='Coding Test', 
                test_type_categories=type_category, 
                deleted=0
            )
            if not test_types.exists():
                return JsonResponse({'error': 'Invalid typeCategory'}, status=400)
            type_ids = test_types.values_list('id', flat=True)
        else:
            test_types = test_type.objects.filter(test_type='Coding Test', deleted=0)
            if not test_types.exists():
                return JsonResponse({'error': 'No test types found'}, status=400)
            type_ids = test_types.values_list('id', flat=True)

        # Step 2: Get the test_names for the given type_ids
        test_names = test_master.objects.filter(test_type_id__in=type_ids, deleted=0).values_list('test_name', flat=True)


        # Step 3: Create a subquery to get the maximum total score per department
        subquery = tests_candidates_map.objects.filter(
            college_id=college_id,
            question_id__test_type='Coding Test',
            test_name__in=test_names,  # Filter by test names
            total_score__isnull=False,
            department_id=OuterRef('department_id'),
            deleted=0
        ).values('department_id').annotate(
            max_total_score=Max('total_score')
        ).values('max_total_score')

        print('subquery: ', Subquery(subquery))

        # Step 4: Filter the original query using this subquery to get the corresponding student names
        results = tests_candidates_map.objects.filter(
            college_id=college_id,
            question_id__test_type='Coding Test',
            test_name__in=test_names,  # Filter by test names
            total_score__isnull=False,
            total_score=Subquery(subquery),  # Match the max score in each department
            deleted=0
        ).values(
            'student_id__students_name',
            'department_id__department',
            'total_score'
        ).distinct()  # Ensure unique records in case of ties

        print('results: ', results)

        # Format the results as a list of dictionaries
        data = [
            {
                'student_name': result['student_id__students_name'],
                'department': result['department_id__department'],
                'max_total_score': result['total_score']
            }
            for result in results
        ]

        # Return the results as a JSON response
        return JsonResponse(data, safe=False, status=200)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)

@api_view(['GET'])
def get_candidate_request(request):
    """
    Fetch all non-deleted candidates with their related college and department data.
    """
    try:
        # Use select_related for related field optimization and only fetch required fields
        candidate_data = candidate_master.objects.filter(deleted=0).select_related(
            'college_id', 'department_id'
        ).values(
            'id',
            'students_name',
            'user_name',
            'registration_number',
            'gender',
            'email_id',
            'mobile_number',
            'year',
            'cgpa',
            'marks_10th',
            'marks_12th',
            'marks_semester_wise',
            'history_of_arrears',
            'standing_arrears',
            'number_of_offers',
            'text',
            'it_of_offers',
            'core_of_offers',
            'college_id__college',   # Access related college field
            'college_id__id',        # Access related college ID
            'department_id__department',  # Access related department field
            'department_id__id'      # Access related department ID
        )

        # Return the fetched data directly as a list
        return Response(candidate_data, status=200)

    except candidate_master.DoesNotExist:
        # Handle specific case if no records are found
        return Response({"error": "No candidates found"}, status=404)

    except Exception as e:
        # General exception handling
        return Response({'error': f"An unexpected error occurred: {str(e)}"}, status=500)


#---------------------------------------------------------------------------------------------#


@api_view(['GET'])
def get_notification_count(request):
    """
    Get the count of notifications for pending student requests.
    """
    try:
        # Query the pending student requests
        stu_queries = student_request.objects.filter(deleted=0, status='pending').select_related('student_id')
        
        # Serialize the data if you need the count
        stu_count = stu_queries.count()

        # Return the response with the count
        return Response({"notification_count": stu_count}, status=200)

    except Exception as e:
        # Handle any unexpected errors
        return Response({"error": str(e)}, status=500)
   
#------------------------------------------------------------------------------------------#

class StudentRequestListAPIView(APIView):
    def get(self, request, *args, **kwargs):
        try:
            # Query only required fields + join with candidate_master for user_name
            results = student_request.objects.filter(
                Q(student_query__isnull=False) & ~Q(student_query=""),
                deleted=0
            ).values(
                'id',
                'student_query',
                'student_id',
                'student_id__user_name',   # üëà fetch user_name from candidate_master
                'status'
            )[:50]

            # Optionally rename the key for clarity
            data = []
            for r in results:
                data.append({
                    'id': r['id'],
                    'student_query': r['student_query'],
                    'student_id': r['student_id'],
                    'user_name': r['student_id__user_name'],  # mapped user_name
                    'status': r['status'],
                })

            return Response(data, status=200)
        except Exception as e:
            return Response({'error': str(e)}, status=500)
		

#----------------------------------------------------------------------------------------------#

class UpdateStatusAPIView(APIView):
    def put(self, request, student_id):
        status_value = request.data.get('status')
        approved_by = request.data.get('approved_by')
        # Validate the status value
        if status_value not in ['Accepted', 'Declined', 'Completed']:
            return Response({'error': 'Invalid status'}, status=status.HTTP_400_BAD_REQUEST)

        # Fetch all student request objects for the given student_id
        student_requests = student_request.objects.filter(student_id=student_id, deleted=0)
        
        if not student_requests.exists():
            return Response({'error': 'No student requests found for the given student ID'}, status=status.HTTP_404_NOT_FOUND)

        # Update the status field for all matching records
        updated_requests = []
        for student_request_instance in student_requests:
            student_request_instance.status = status_value
            student_request_instance.dtm_approved = datetime.now() 
            student_request_instance.approved_by = approved_by 
            student_request_instance.save()
            updated_requests.append(student_request_instance)

        # Serialize the updated objects
        serializer = studentRequestSerializer(updated_requests, many=True)

        return Response(serializer.data, status=status.HTTP_200_OK)  

#--------------------------------------------------------------------------------#

class CheckStudentRequestStatusAPIView(APIView):
    def get(self, request, student_id):
        try:
            # Filter the student requests by student_id and get the most recent one
            stu_queries = student_request.objects.filter(student_id=student_id, deleted=0).values('status').first()
            
            if not stu_queries:
                return Response({'error': 'No request found for this student'}, status=status.HTTP_404_NOT_FOUND)
            
            # Return the status of the most recent request
            return Response({'status': stu_queries['status']}, status=status.HTTP_200_OK)
        
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


def get_test_type_categories(request, test_type_value):
    try:
        # Query to get test_type_categories
        test_type_categories = test_type.objects.filter(
            test_type=test_type_value, deleted=0
        ).values_list('test_type_categories', flat=True)

        if not test_type_categories:
            return JsonResponse({'error': 'No categories found for the specified test type'}, status=404)

        return JsonResponse(list(test_type_categories), safe=False, status=200)
    
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)



#_________________________________trainers_report_____________________________#


from .models import trainers_report
from .serializers import trainer_ReportSerializers

# Create API view for trainers_report
class TrainersReportCreateAPIView(generics.CreateAPIView):
    queryset = trainers_report.objects.all()
    serializer_class = trainer_ReportSerializers

    def post(self, request, *args, **kwargs):
        # Create the trainers_report entry
        response = super().post(request, *args, **kwargs)

        # Extract data from the newly created trainers_report
        try:
            report_data = request.data
            course_schedule_id = report_data.get('course_schedule_id')
            status = report_data.get('status')

            if course_schedule_id and status:
                # Fetch the related course_schedule entry
                course_schedule_entry = course_schedule.objects.get(id=course_schedule_id, deleted=0)

                # Identify matching course_schedule entries
                matching_schedules = course_schedule.objects.filter(
                    trainer_id=course_schedule_entry.trainer_id,
                    dtm_start_trainer=course_schedule_entry.dtm_start_trainer,
                    dtm_end_trainer=course_schedule_entry.dtm_end_trainer,
                    dtm_of_training=course_schedule_entry.dtm_of_training,
                    college_id=course_schedule_entry.college_id,
                    topic_id=course_schedule_entry.topic_id,deleted=0
                )

                # Update the status column for all matching course_schedule entries
                matching_schedules.update(status=status)

                print(f"Updated status for {matching_schedules.count()} course_schedule entries.")

        except Exception as e:
            print(f"Error during status update: {str(e)}")

        return response

class TrainersReportCreateTrainingAPIView(generics.CreateAPIView):
    queryset = trainers_report.objects.all()
    serializer_class = trainer_ReportSerializerstrain

    def post(self, request, *args, **kwargs):
        print("üöÄ POST request received at TrainersReportCreateTrainingAPIView")
        print("üì¶ Incoming request data:", request.data)

        course_schedule_id = request.data.get('course_schedule_id')
        status_val = request.data.get('status')

        if not course_schedule_id:
            print("‚ùå course_schedule_id is missing in request.")
            return Response({"error": "course_schedule_id is required"}, status=status.HTTP_400_BAD_REQUEST)

        try:
            # Step 1: Lookup the training_schedule using course_schedule_id
            print(f"üîç Looking up training_schedule with id={course_schedule_id}")
            schedule_entry = training_schedule.objects.get(id=course_schedule_id, deleted=0)
            print("üìå Found training_schedule entry:", schedule_entry)

            # Step 2: Inject training_schedule_id into request data
            mutable_data = request.data.copy()
            mutable_data['training_schedule_id'] = course_schedule_id  # map incoming course_schedule_id to training_schedule_id
            print("üì• Mapped course_schedule_id to training_schedule_id in data.")

            # Step 3: Validate and save report
            serializer = self.get_serializer(data=mutable_data)
            print("üõ†Ô∏è Validating report serializer...")
            serializer.is_valid(raise_exception=True)
            self.perform_create(serializer)
            print("‚úÖ Report saved successfully.")

            # Step 4: Update all matching training_schedule entries‚Äô status
            if status_val:
                print("üîÑ Updating matching training_schedule status...")
                matching_schedules = training_schedule.objects.filter(
                    trainer_id=schedule_entry.trainer_id,
                    dtm_start_trainer=schedule_entry.dtm_start_trainer,
                    dtm_end_trainer=schedule_entry.dtm_end_trainer,
                    dtm_of_training=schedule_entry.dtm_of_training,
                    college_id=schedule_entry.college_id,
                    topic_id=schedule_entry.topic_id,
                    deleted=0
                )
                updated_count = matching_schedules.update(status=status_val)
                print(f"‚úÖ Updated status for {updated_count} training_schedule entries.")

            return Response(serializer.data, status=status.HTTP_201_CREATED)

        except training_schedule.DoesNotExist:
            print(f"‚ùå No training_schedule found with id={course_schedule_id}")
            return Response({"error": "Invalid course_schedule_id"}, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            print(f"‚ùå Unexpected error: {str(e)}")
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# Retrieve, Update, Destroy API view for trainers_report
class TrainersReportUpdateAPIView(generics.RetrieveUpdateDestroyAPIView):
    queryset = trainers_report.objects.all()
    serializer_class = trainer_ReportSerializers

    def put(self, request, *args, **kwargs):
        response = super().put(request, *args, **kwargs)
        return response

    def patch(self, request, *args, **kwargs):
        response = super().patch(request, *args, **kwargs)
        return response

# Custom delete function to mark as deleted
@api_view(['PUT', 'PATCH'])
def delete_trainers_report(request, pk):
    try:
        # Fetch the record by its primary key (id)
        trainer_report = trainers_report.objects.get(id=pk)
    except trainers_report.DoesNotExist:
        return JsonResponse("Trainer report not found", status=404)

    # Mark the 'deleted' field as 1 instead of removing the object
    trainer_report.deleted = 1
    trainer_report.save()

    return JsonResponse("Trainer report 'deleted' field updated successfully", safe=False)


@api_view(['GET'])
def get_trainer_topics_by_username(request, user_name):
    # Query to get unique topics, subtopics, and course_schedule_id for the given user_name
    trainer_topics = course_schedule.objects.filter(
        Q(trainer_id__trainer_name=user_name) & Q(deleted=0)
    ).values('topic_id__topic', 'topic_id__sub_topic').annotate(
        course_schedule_id=Min('id')  # Take the minimum id for each unique topic/sub_topic pair
    ).distinct()

    # Format the data to return unique topics and subtopics with course_schedule_id
    topics_data = [
        {
            'course_schedule_id': topic['course_schedule_id'],
            'topic': topic['topic_id__topic'],
            'sub_topic': topic['topic_id__sub_topic']
        }
        for topic in trainer_topics
    ]

    return Response(topics_data)


@csrf_exempt
def update_trainer(request, user_names):
    print("Fetching trainer with user_name:", user_names)
    trainer = get_object_or_404(trainer_master, user_name=user_names)
    print("Trainer fetched:", trainer)

    if request.method == 'POST':
        print("POST request received. Binding form with POST data and FILES.")
        form = TrainerMasterForm(request.POST, request.FILES, instance=trainer)
        print("Form created:", form)

        if form.is_valid():
            print("Form is valid.")
            trainer = form.save(commit=False)
            print("Trainer form saved, but not yet committed.")

            # Handle the photo file as binary data
            if 'photo' in request.FILES:
                trainer.photo = request.FILES['photo'].read()
                print("Photo uploaded and saved as binary data.")
            else:
                trainer.photo = None
                print("No photo uploaded. Photo field set to None.")
            
            # Handle the resume file and extract HTML-formatted text
            if 'resume' in request.FILES:
                trainer.resume = request.FILES['resume']
                print("Resume uploaded and saved.")

                # Extract HTML from resume based on file type
                resume_file = request.FILES['resume']
                file_type = resume_file.content_type

                extracted_html = ''
                if file_type == 'application/pdf':
                    extracted_html = extract_html_from_pdf(resume_file)
                elif file_type in ['application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'application/msword']:
                    extracted_html = extract_html_from_word(resume_file)

                # Update remarks with extracted HTML content
                trainer.remarks = extracted_html
                print("Extracted HTML from resume and saved in remarks.")

            # Save the updated trainer
            trainer.save()
            print("Trainer saved successfully.")

            if 'skills' in request.POST:
                skills = json.loads(request.POST['skills'])
                trainer.skill_id.set(skills)
                print("Skills updated:", skills)

            return HttpResponse("Trainer updated successfully")
        else:
            print("Form is not valid:", form.errors)
    else:
        print("GET request received. Populating form with existing trainer data.")
        form = TrainerMasterForm(instance=trainer)

    print("Rendering update_trainer.html template.")
    return render(request, 'update_trainer.html', {'form': form})

def extract_html_from_pdf(pdf_file):
    html_content = "<div>"
    # Open the PDF file with fitz
    with fitz.open(stream=pdf_file.read(), filetype="pdf") as pdf:
        for page_num in range(pdf.page_count):
            page = pdf[page_num]
            # Extract HTML format
            page_html = page.get_text("html")
            soup = BeautifulSoup(page_html, 'html.parser')
            html_content += soup.prettify() + "<br><br>"
    html_content += "</div>"
    return html_content

def extract_html_from_word(word_file):
    html_content = "<div>"
    doc = Document(io.BytesIO(word_file.read()))
    for para in doc.paragraphs:
        # Convert paragraphs to HTML format, retaining tables
        if para.style.name == 'Normal':
            html_content += f"<p>{para.text}</p>"
        elif para.style.name == 'Heading':
            html_content += f"<h2>{para.text}</h2>"
    html_content += "</div>"
    return html_content

@csrf_exempt
def update_trainer(request, user_names):
    print("Fetching trainer with user_name:", user_names)
    trainer = get_object_or_404(trainer_master, user_name=user_names)
    print("Trainer fetched:", trainer)

    if request.method == 'POST':
        print("POST request received. Binding form with POST data and FILES.")
        form = TrainerMasterForm(request.POST, request.FILES, instance=trainer)
        print("Form created with POST data and FILES:", form)

        if form.is_valid():
            print("Form is valid.")
            trainer = form.save(commit=False)
            print("Trainer form saved, but not yet committed.")

            # Handle the photo file as binary data
            if 'photo' in request.FILES:
                print("Photo file found in request.FILES.")
                trainer.photo = request.FILES['photo'].read()
                print("Photo uploaded and saved as binary data.")
            else:
                trainer.photo = None
                print("No photo uploaded. Photo field set to None.")
            
            # Handle the resume file and extract text
            if 'resume' in request.FILES:
                print("Resume file found in request.FILES.")
                trainer.resume = request.FILES['resume']
                print("Resume uploaded and saved.")

                # Extract text from resume based on file type
                resume_file = request.FILES['resume']
                file_type = resume_file.content_type
                print("Resume file type detected:", file_type)

                extracted_text = ''
                if file_type == 'application/pdf':
                    print("Extracting text from PDF resume.")
                    extracted_text = extract_text_from_pdf(resume_file)
                    print("Extracted text from PDF:", extracted_text)
                elif file_type in ['application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'application/msword']:
                    print("Extracting text from Word resume.")
                    extracted_text = extract_text_from_word(resume_file)
                    print("Extracted text from Word document:", extracted_text)

                # Update remarks with extracted text
                trainer.remarks = extracted_text
                print("Extracted text saved to remarks.")

            # Save the updated trainer
            trainer.save()
            print("Trainer saved successfully.")

            if 'skills' in request.POST:
                skills = json.loads(request.POST['skills'])
                print("Skills data received:", skills)
                trainer.skill_id.set(skills)
                print("Skills updated:", skills)

            logger.info("Trainer updated successfully")
            return HttpResponse("Trainer updated successfully")
        else:
            print("Form is not valid. Errors:", form.errors)
    else:
        print("GET request received. Populating form with existing trainer data.")
        form = TrainerMasterForm(instance=trainer)

    print("Rendering update_trainer.html template.")
    return render(request, 'update_trainer.html', {'form': form})

def extract_text_from_pdf(pdf_file):
    print("Starting text extraction from PDF file.")
    text = ""
    with fitz.open(stream=pdf_file.read(), filetype="pdf") as pdf:
        print("PDF opened successfully. Total pages:", pdf.page_count)
        for page_num in range(pdf.page_count):
            print("Extracting text from page:", page_num + 1)
            page = pdf[page_num]
            page_text = page.get_text("text")
            print("Text extracted from page:", page_text)
            text += page_text
    print("Finished text extraction from PDF. Total text length:", len(text))
    return text

def extract_text_from_word(word_file):
    print("Starting text extraction from Word document.")
    text = ""
    doc = Document(io.BytesIO(word_file.read()))
    print("Word document opened successfully. Total paragraphs:", len(doc.paragraphs))
    for i, para in enumerate(doc.paragraphs):
        print(f"Extracting text from paragraph {i + 1}: {para.text}")
        text += para.text + "\n"
    print("Finished text extraction from Word document. Total text length:", len(text))
    return text


@api_view(['POST'])
def add_trainer_username(request):
    # Extract 'user_name' from the request data
    user_name = request.data.get('user_name')
    
    # Check if 'user_name' is provided
    if not user_name:
        return Response({"error": "user_name is required."}, status=status.HTTP_400_BAD_REQUEST)
    
    try:
        # Create a new instance of trainer_master with only the user_name field
        trainer = trainer_master.objects.create(user_name=user_name)
        trainer.save()
        
        # Return a success response
        return Response({"message": "Trainer user_name added successfully."}, status=status.HTTP_201_CREATED)
    
    except Exception as e:
        # Handle any exceptions that occur
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['PUT', 'PATCH'])
def update_is_terms(request, user_names):
    try:
        print("Entering Function..")
        candidates = trainer_master.objects.get(user_name=user_names)  # Use correct field name here

        print("trainer terms: ", candidates)
    except trainer_master.DoesNotExist:
        return JsonResponse("Trainer not found", status=404)

    # Update the 'is_terms' field
    is_terms = request.data.get('is_terms', None)
    if is_terms is not None:
        candidates.is_terms = is_terms
        candidates.save()
        print("trainer updated: ", candidates)
        return JsonResponse("Trainer updated successfully", safe=False)
    else:
        return JsonResponse("Invalid data", status=400)


@api_view(['PUT', 'PATCH'])
def update_is_edit(request, user_names):
    try:
        print("Entering Function..")
        candidates = trainer_master.objects.get(user_name=user_names)  # Use correct field name here

        print("trainer terms: ", candidates)
    except trainer_master.DoesNotExist:
        return JsonResponse("Trainer not found", status=404)

    # Update the 'is_terms' field
    is_edit = request.data.get('is_edit', None)
    if is_edit is not None:
        candidates.is_edit = is_edit
        candidates.save()
        print("trainer updated: ", candidates)
        return JsonResponse("Trainer updated successfully", safe=False)
    else:
        return JsonResponse("Invalid data", status=400)

@api_view(['GET'])
def get_trainer_status(request, user_names):
    try:
        # Fetch the trainer based on user_names
        trainer = trainer_master.objects.get(user_name=user_names,deleted=0)
        
        # Serialize the trainer data, passing the request context
        serializer = trainerSerializer(trainer, context={'request': request})
        print(serializer.data)  # Log serialized data to check fields

        return Response(serializer.data, status=status.HTTP_200_OK)
    
    except trainer_master.DoesNotExist:
        return Response({"detail": "Trainer not found"}, status=status.HTTP_404_NOT_FOUND)

class GetAcceptedStudentRequests(APIView):
    def get(self, request, user_name, *args, **kwargs):
        # Fetch candidate_master instance with given user_name
        try:
            candidate = candidate_master.objects.get(user_name=user_name,deleted=0)
        except candidate_master.DoesNotExist:
            return Response({'error': 'Candidate with the provided user_name does not exist'}, status=status.HTTP_404_NOT_FOUND)

        # Fetch student_request records with status 'Accepted' for the candidate
        accepted_requests = student_request.objects.filter(student_id=candidate, status="Accepted",deleted=0)

        # Serialize the data
        serializer = studentRequestSerializer(accepted_requests, many=True)
        return Response(serializer.data, status=status.HTTP_200_OK)



def send_wp_message(eligibleStudentList):
    try:
        account_sid = 'ACb3b93246373039e50f5643ada2325424'
        auth_token = '2320ee6a18f56d722293b6f048620944'
        whatsapp_from = 'whatsapp:+14155238886'
        client = Client(account_sid, auth_token)
        for eligibleStudent in eligibleStudentList:
           
            whatsapp_to = (f'whatsapp:{eligibleStudent.students_id.mobile_number}')

            whatsapp_text = eligibleStudent.announcement if eligibleStudent.announcement else "Default message"

            try:
                message = client.messages.create(
                    body=whatsapp_text,
                    from_=whatsapp_from,
                    to=whatsapp_to
                )
                print(f"Message sent to {eligibleStudent.students_id.students_name} ({eligibleStudent.students_id.mobile_number}): {message.sid}")
            except Exception as e:
                print(f"Failed to send message to {eligibleStudent.students_id.students_name} ({eligibleStudent.students_id.mobile_number}): {str(e)}")

    except Exception as e:
        logger.error(f"Error sending whatsapp message: {e}")



@api_view(['GET'])
def send_whatsapp_to_studentols(request, job_id, round_of_interview):
    try:
        eligibleStudentList = eligible_student_list.objects.filter(
            job_id=job_id,
            round_of_interview=round_of_interview, deleted=0
        )

        if not eligibleStudentList.exists():
            print("No eligible students found.")
            logger.warning("No eligible students found.")
            return JsonResponse({"error": "No eligible students found for the given criteria"}, status=404)
        print(f"Found {eligibleStudentList.count()} eligible students")
        logger.info(f"Found {eligibleStudentList.count()} eligible students.")

        whatsapp_thread = threading.Thread(target=send_wp_message, args=(eligibleStudentList,))
        whatsapp_thread.start()
        print("Whatsapp Messages are being sent in the background.")
        logger.info("Whatsapp Messages are being sent in the background.")
    
        return JsonResponse({"message": "WhatsApp messages triggered successfully"})

    except Exception as e:
        print("Error:", e)
        return JsonResponse({"message": str(e)}, status=500)

@api_view(['GET'])
def filter_candidates_download(request):
    # Get filter parameters from the request query parameters
    college_id = request.query_params.get('college_id', None)
    department_id = request.query_params.get('department_id', None)
    year = request.query_params.get('year', None)
    marks_10th = request.query_params.get('marks_10th', None)
    marks_12th = request.query_params.get('marks_12th', None)
    cgpa = request.query_params.get('cgpa', None)
    history_of_arrears = request.query_params.get('history_of_arrears', None)
    standing_arrears = request.query_params.get('standing_arrears', None)
    number_of_offers = request.query_params.get('number_of_offers', None)  # Fixed whitespace issue
    gender = request.query_params.get('gender', None)
    # Start with all candidate records
    candidates = candidate_master.objects.filter(deleted=0)

    # Apply filters based on query parameters
    if college_id:
        candidates = candidates.filter(college_id=college_id)

    if department_id:
        candidates = candidates.filter(department_id=department_id)

    if year:
        candidates = candidates.filter(year=year)

    if marks_10th:
        candidates = candidates.filter(marks_10th__gte=marks_10th)

    if marks_12th:
        candidates = candidates.filter(marks_12th__gte=marks_12th)

    if cgpa:
        candidates = candidates.filter(cgpa__gte=cgpa)

    if history_of_arrears:
        candidates = candidates.filter(history_of_arrears__lte=history_of_arrears)

    if standing_arrears:
        candidates = candidates.filter(standing_arrears__lte=standing_arrears)

    if number_of_offers:
        candidates = candidates.filter(number_of_offers__lte=number_of_offers)
    if gender and gender != 'Both':
        candidates = candidates.filter(gender=gender)
    # Serialize the filtered candidates
    serializer = candidatesSerializer(candidates, many=True)
    return Response(serializer.data, status=status.HTTP_200_OK)

@api_view(['GET'])
def get_unique_company_count(request, college):
    try:
        # Get candidate IDs that belong to the specified college from candidate_master
        candidate_ids = candidate_master.objects.filter(college_id=college,deleted=0).values_list('id', flat=True)
        
        # Filter job_offers based on college_id and count unique company_name
        unique_company_count = job_offers.objects.filter(college_id=college,deleted=0).values('company_name').distinct().count()

        return Response({
            'college_id': college,
            'unique_company_count': unique_company_count
        })
    except Exception as e:
        return Response({
            'error': str(e)
        }, status=400)


@api_view(['GET'])
def get_total_job_offers(request, college):
    try:
        # Filter job_offers based on college_id and count all job offers (no distinct)
        total_job_offers = job_offers.objects.filter(college_id=college,deleted=0).aggregate(total_offers=Count('no_of_offers'))['total_offers']

         # Filter job_offers based on college_id and count unique company_name
        job_count = job_offers.objects.filter(college_id=college,deleted=0).values('company_name').count()

        return Response({
            'college_id': college,
            'job_offer_count': job_count
        })
    except Exception as e:
        return Response({
            'error': str(e)
        }, status=400)


@api_view(['GET'])
def get_skill_type_by_test_name(request):
    # Get the test_name from query parameters (or request body if needed)
    testsname = request.query_params.get('test_name')

    if not testsname:
        return Response({'error': 'test_name parameter is required.'}, status=status.HTTP_400_BAD_REQUEST)
    
    # Filter the test_master based on the provided test_name
    test = get_object_or_404(test_master, test_name=testsname)

    # Get the skill_type_id's skill_type from the filtered test_master
    if test.skill_type_id:
        skill_type_value = test.skill_type_id.skill_type
        return Response({'skill_type': skill_type_value}, status=status.HTTP_200_OK)
    else:
        return Response({'error': 'Skill type not found for the given test_name.'}, status=status.HTTP_404_NOT_FOUND)



@api_view(['GET'])
def get_trainer_all_Reports(request):
    try:
        # Fetch trainers with related skills using prefetch_related for ManyToMany field
        trainers = trainer_master.objects.filter(deleted=0).prefetch_related('skill_id')

        # Serialize the data
        serializer = trainerSerializerSkills(trainers, many=True, context={'request': request})

        return Response(serializer.data)
    except Exception as e:
        return Response({'error': str(e)}, status=500)


@api_view(['GET'])
def get_trainer_skills(request):
    try:
        # Fetch distinct skills directly using related trainer_master field
        skills = skill_type.objects.filter(
            trainer_master__deleted=0
        ).distinct()

        # Serialize the unique skills
        serializer = skilltypeSerializertrainer(skills, many=True)
        
        return Response(serializer.data)
    except Exception as e:
        return Response({'error': str(e)}, status=500)


@api_view(['GET'])
def get_login_data(request):
    # Fetch the 'user_name' parameter from the query parameters
    username = request.GET.get('user_name')

    # Debug the received parameter
    print(f"Received username parameter: {username}")

    if username:
        try:
            # Fetch the user data based on the provided 'user_name'
            user = login.objects.get(user_name=username,deleted=0)
            serializer = loginSerializerupdatepass(user)
            return Response(serializer.data, status=status.HTTP_200_OK)
        except login.DoesNotExist:
            return Response({'error': 'User not found'}, status=status.HTTP_404_NOT_FOUND)
    else:
        return Response({'error': 'Username parameter is missing'}, status=status.HTTP_400_BAD_REQUEST)

@api_view(['GET'])
def get_login_update(request):
    # Fetch the 'user_name' parameter from the query parameters
    username = request.GET.get('user_name')

    print(f"Received username parameter: {username}")

    if username:
        try:
            # Fetch the user data based on the provided 'user_name'
            user = login.objects.get(user_name=username, deleted=0)

            # Manually build the response
            user_data = {
                "id": user.id,
                "user_name": user.user_name,
                "password": user.password,
                "college_id": user.college_id.id if user.college_id else None,
                "college_name": user.college_id.college if user.college_id else None,
                "role": user.role,
                "email_id": user.email_id,
                "remarks": user.remarks,               # üëà added
                "mobile_number": user.mobile_number    # üëà added
            }

            return Response(user_data, status=status.HTTP_200_OK)
        except login.DoesNotExist:
            return Response({'error': 'User not found'}, status=status.HTTP_404_NOT_FOUND)
    else:
        return Response({'error': 'Username parameter is missing'}, status=status.HTTP_400_BAD_REQUEST)



#_______________________________________aNNOUNCEMENT_________________________________________ 

@csrf_exempt
def upload_announcement(request):
    if request.method == 'POST':
        print("Received POST request", request)
        try:
            form = CCAnnouncementForm(request.POST, request.FILES)  # Include request.FILES for handling the image

            if form.is_valid():
                print("Form is valid")
                
                # Announcement text from the form
                announcement_text = form.cleaned_data['announcement']
                print(f"Announcement text: {announcement_text}")

                # Image handling
                announcement_image = request.FILES.get('announcement_image')  # Handle image file separately
                if announcement_image:
                    print(f"Received image: {announcement_image.name}")
                else:
                    print("No image file received")

                # Extract login_ids from the request
                login_ids = request.POST.get('login_ids')
                if login_ids:
                    try:
                        login_ids = json.loads(login_ids)  # Parse JSON string to list
                    except json.JSONDecodeError:
                        return HttpResponse("Invalid login_ids format", status=400)
                    
                    # Fetch users based on the provided login_ids
                    users = login.objects.filter(id__in=login_ids,deleted=0)
                    print(f"Number of users found by login_ids: {users.count()}")

                    if not users.exists():
                        return HttpResponse(f"No users found for the provided login IDs: {login_ids}", status=404)
                else:
                    # Fall back to role-based user fetching if no login_ids are provided
                    role = form.cleaned_data['role']  # Get the selected role
                    print(f"Selected role: {role}")

                    users = login.objects.filter(role=role,deleted=0)
                    print(f"Number of users found by role: {users.count()}")

                    if not users.exists():
                        return HttpResponse(f"No users found for the selected role: {role}", status=404)

                # Create announcements for each user found
                for user in users:
                    print(f"Creating announcement for user: {user}")
                    announcement = comman_announcement(
                        announcement=announcement_text,
                        login_id=user,  # Associate the announcement with the user's login_id
                        announcement_image=announcement_image.read() if announcement_image else None,
                        dtm_start=timezone.now()  # Automatically set the start time
                    )
                    announcement.save()
                    print(f"Announcement created with ID: {announcement.id}")

                return HttpResponse(f"Announcements created successfully for {users.count()} users")
            else:
                print("Form is not valid")
                print(form.errors)
                return HttpResponse("Form is not valid", status=400)

        except Exception as e:
            # Log the exception and return a generic error message
            print(f"An error occurred: {e}")
            return HttpResponse("An unexpected error occurred. Please try again later.", status=500)
    else:
        print("Received GET request")
        form = CCAnnouncementForm()

    return render(request, 'add_announcement_form.html', {'form': form})

@csrf_exempt
def update_announcement(request, announcement_id):
    # Fetch the announcement based on its ID or return a 404 error
    announcement = get_object_or_404(comman_announcement, id=announcement_id)

    if request.method == 'POST':
        form = CCAnnouncementForm(request.POST)
        if form.is_valid():
            # Get the updated form data
            role = form.cleaned_data['role']
            announcement_text = form.cleaned_data['announcement']
            announcement_image = request.FILES.get('announcement_image')

            # Fetch users with the selected role
            users = login.objects.filter(role=role)

            if not users.exists():
                return HttpResponse(f"No users found for the selected role: {role}", status=404)

            # Update the announcement for each user with the selected role
            for user in users:
                # Check if the announcement exists for the user, if not, create it
                announcement.login_id = user
                announcement.announcement = announcement_text

                # If a new image is uploaded, update it; otherwise, keep the existing image
                if announcement_image:
                    announcement.announcement_image = announcement_image.read()

                # Update the timestamp for modification
                announcement.dtm_start = timezone.now()

                # Save the updated announcement
                announcement.save()

            return HttpResponse(f"Announcement updated successfully for role: {role}")
    else:
        # Pre-fill the form with the existing announcement data
        initial_data = {
            'announcement': announcement.announcement,
            'role': announcement.login_id.role  # Pre-fill the form with the current role
        }
        form = CCAnnouncementForm(initial=initial_data)

    return render(request, 'update_announcement_form.html', {'form': form, 'announcement': announcement})

@api_view(['GET'])
def get_announcements(request):
    # Query all announcements
    announcements = comman_announcement.objects.filter(deleted=0).values(
        'id',
        'candidate_id',
        'login_id',
        'trainer_id',
        'announcement_image',
        'dtm_start',
    )

    # Prepare the data with Base64 encoding for announcement images using list comprehension
    announcement_data = [
        {
            'id': announcement['id'],
            'candidate_id': announcement['candidate_id'],
            'login_id': announcement['login_id'],
            'trainer_id': announcement['trainer_id'],
            'announcement_image': base64.b64encode(announcement['announcement_image']).decode('utf-8') 
                                   if announcement['announcement_image'] else None,
            'dtm_start': announcement['dtm_start'].isoformat() if announcement['dtm_start'] else None,
        }
        for announcement in announcements
    ]

    return JsonResponse(announcement_data, safe=False)


@api_view(['PUT', 'PATCH'])
def delete_comman_annoucement(request, pk):
   
    try:
        comman = comman_announcement.objects.get(id=pk)
    except comman_announcement.DoesNotExist:
        logger.error(f"Comman announce with id {pk} not found")
        return Response("comman announce not found", status=404)

    comman.deleted = 1
    comman.save()



#_____________________________________________placement_announcement__________________________#

@csrf_exempt
def upload_placement_announcement(request):
    if request.method == 'POST':
        print("Received POST request", request)
        try:
            form = PlacementAnnouncementForm(request.POST, request.FILES)  # Handle the form including files

            if form.is_valid():
                print("Form is valid")
                
                # Extract announcement text and image
                announcement_text = form.cleaned_data['announcement']
                announcement_image = request.FILES.get('announcement_image')  # Handle image file separately
                candidate_id = form.cleaned_data.get('candidate_id')
                role = form.cleaned_data.get('role')  # Get the selected role

                print(f"Announcement text: {announcement_text}")
                print(f"Candidate ID: {candidate_id}")
                print(f"Selected role: {role}")
                
                # **Handle candidate-only announcement (if role is None)**
                if not role:  # If role is None or empty
                    print("Creating announcement only for the selected candidate")
                    announcement = comman_announcement(
                        announcement=announcement_text,
                        candidate_id=candidate_id,  # Set the candidate_id
                        login_id=None,  # No login_id since it's a candidate-only announcement
                        announcement_image=announcement_image.read() if announcement_image else None,
                        dtm_start=timezone.now()
                    )
                    announcement.save()
                    print(f"Announcement created for candidate ID: {candidate_id}")

                    return HttpResponse(f"Announcement created for candidate ID: {candidate_id}")

                # Handle role or login_ids based announcements
                else:
                    # Extract login_ids from the request (only process if role is provided)
                    login_ids = request.POST.get('login_ids')
                    if login_ids:
                        try:
                            login_ids = json.loads(login_ids)  # Parse JSON string to list
                        except json.JSONDecodeError:
                            return HttpResponse("Invalid login_ids format", status=400)

                        # Fetch users based on the provided login_ids
                        users = login.objects.filter(id__in=login_ids,deleted=0)
                        print(f"Number of users found by login_ids: {users.count()}")
                    else:
                        # Fetch users based on the selected role
                        users = login.objects.filter(role=role,deleted=0)
                        print(f"Number of users found by role: {users.count()}")

                        if not users.exists():
                            return HttpResponse(f"No users found for the selected role: {role}", status=404)

                    # Create announcements for each user if users were found
                    for user in users:
                        print(f"Creating announcement for user: {user}")
                        announcement = comman_announcement(
                            announcement=announcement_text,
                            login_id=user,  # Associate the announcement with the user's login_id
                            candidate_id=candidate_id if candidate_id else None,  # Set candidate_id if provided
                            announcement_image=announcement_image.read() if announcement_image else None,
                            dtm_start=timezone.now()  # Automatically set the start time
                        )
                        announcement.save()
                        print(f"Announcement created with ID: {announcement.id}")

                    return HttpResponse(f"Announcements created successfully for {users.count()} users")

            else:
                print("Form is not valid")
                print(form.errors)
                return HttpResponse(f"Form is not valid: {form.errors}", status=400)

        except Exception as e:
            print(f"An error occurred: {e}")
            return HttpResponse(f"An unexpected error occurred: {e}", status=500)

    else:
        form = PlacementAnnouncementForm()

    return render(request, 'add_place_announce.html', {'form': form})




@api_view(['GET'])
def get_login_roles(request):
    try:
        # Fetch distinct roles
        roles_data = login.objects.filter(deleted=0).values('role').distinct()

        # Format the roles data
        formatted_roles_data = [{'id': role['role'], 'label': role['role']} for role in roles_data]

        return Response(formatted_roles_data)
    except Exception as e:
        logger.error(f'Error occurred in get_login_roles function: {e}')
        return Response({'error': 'An error occurred'}, status=500)
    



#____________________________________Test Report_____________________________________________________________#



@cache_page(60 * 60)
@api_view(['GET'])
def get_total_score(request, id):
    try:
        test_candidate = tests_candidates_map.objects.get(pk=id,deleted=0)
    except tests_candidates_map.DoesNotExist:
        return Response({'error': 'Test candidate not found'}, status=status.HTTP_404_NOT_FOUND)
    
    return Response({'total_score': test_candidate.total_score})



@api_view(['GET'])
def get_test_reports(request):
    # Get filter parameters from the request
    test_name = request.GET.get('test_name', "").strip()
    college_id = request.GET.get('college_id', "").strip()
    department_id = request.GET.get('department', "").strip()
    year = request.GET.get('year', "").strip()

    print("\n=========== API Request ===========")
    print(f"Received Parameters - test_name: {test_name}, college_id: {college_id}, department_id: {department_id}, year: {year}")

    # Base query for test reports
    reports = test_reports.objects.filter(deleted=0).select_related('college_id', 'department_id')

    print("\nStep 1: Initial Query (Before Filtering)")
    print(list(reports.values('test_name', 'college_id', 'department_id', 'year', 'students_count')))

    # Apply filters dynamically
    if test_name:
        reports = reports.filter(test_name=test_name)
        print("\nStep 2: Filtered by Test Name")
        print(list(reports.values('test_name', 'college_id', 'department_id', 'year', 'students_count')))

    if college_id:
        reports = reports.filter(college_id=college_id)
        print("\nStep 3: Filtered by College ID")
        print(list(reports.values('test_name', 'college_id', 'department_id', 'year', 'students_count')))

    # Convert department_id to a list for filtering
    if department_id:
        department_list = [int(dep) for dep in department_id.split(',')]  # Convert to list
        reports = reports.filter(department_id__in=department_list)
        print("\nStep 4: Filtered by Department ID")
        print(list(reports.values('test_name', 'college_id', 'department_id', 'year', 'students_count')))

    if year:
        reports = reports.filter(year=year)
        print("\nStep 5: Filtered by Year")
        print(list(reports.values('test_name', 'college_id', 'department_id', 'year', 'students_count')))

    # Debugging: Check filtered data before aggregation
    print("\nStep 6: Data Before Grouping (Aggregation)")
    print(list(reports.values('test_name', 'college_id', 'department_id', 'year', 'students_count')))

    # Subquery for fetching `dtm_start` and `dtm_end`
    test_candidate_map = tests_candidates_map.objects.filter(
        test_name=OuterRef('test_name'),deleted=0
    ).values('dtm_start', 'dtm_end')

    reports = reports.annotate(
        dtm_start=Subquery(test_candidate_map.values('dtm_start')[:1]),
        dtm_end=Subquery(test_candidate_map.values('dtm_end')[:1]),
    )

    # **Dynamic Grouping Logic**
    if college_id and not department_id and not year:
        group_by_fields = ['test_name', 'college_id__college']
    elif college_id and year and not department_id:
        group_by_fields = ['test_name', 'college_id__college', 'year']
    elif college_id and department_id and not year:
        group_by_fields = ['test_name', 'college_id__college', 'department_id__department']
    elif college_id and department_id and year:
        group_by_fields = ['test_name', 'college_id__college', 'department_id__department', 'year']
    elif department_id and not college_id and not year:
        group_by_fields = ['test_name', 'department_id__department']
    elif department_id and year and not college_id:
        group_by_fields = ['test_name', 'department_id__department', 'year']
    else:
        group_by_fields = ['test_name', 'college_id__college']

    print("\nStep 7: Grouping By Fields:", group_by_fields)

   
    grouped_reports = reports.values(*group_by_fields).annotate(
        total_students=Sum('students_count')
    )

    print("\nStep 8: Data After Grouping (Aggregation)")
    print(list(grouped_reports))

    # Formatting response
    data = []
    for report in grouped_reports:
        formatted_report = {
            'test_name': report['test_name'],
            'college_name': report.get('college_id__college', 'All') if college_id else 'All',
            'department_name': report.get('department_id__department', 'All') if department_id else 'All',
            'year': report.get('year', 'All') if year else 'All',
            'total_students': report['total_students'],
            'dtm_start': report.get('dtm_start'),
            'dtm_end': report.get('dtm_end'),
        }
        data.append(formatted_report)

    print("\nStep 9: Final API Response")
    print(data)

    return Response(data)

@api_view(['GET'])
def get_distinct_test_data(request):
    test_name = request.query_params.get('test_name')
    college_id = request.query_params.get('college_id')
    print('college_id: ', college_id)
    department_id = request.query_params.get('department_id')
    year = request.query_params.get('year')

    # Initialize filters based on parameters provided
    
    filters = {'deleted': 0}
    if college_id:
        filters['college_id'] = college_id
    if test_name:
        filters['test_name'] = test_name
    if department_id:
        filters['department_id'] = department_id
    if year:
        filters['year'] = year

    # Fetch distinct test_name, filtered by the parameters provided
    distinct_test_names = tests_candidates_map.objects.filter(**filters).values('test_name').distinct()

    # Fetch distinct colleges, filtered by test_name if provided
    college_filters = filters.copy()
    if 'test_name' in filters:
        college_filters = {'test_name': filters['test_name']}
    if college_id:
        college_filters['college_id'] = college_id
    distinct_colleges = tests_candidates_map.objects.filter(**college_filters).select_related('college_id').values(
        'college_id', 'college_id__college'
    ).distinct()

    # Fetch distinct departments, filtered by college_id and test_name if provided
    department_filters = {k: v for k, v in filters.items() if k in ['college_id', 'test_name']}
    distinct_departments = tests_candidates_map.objects.filter(**department_filters).select_related('department_id').values(
        'department_id', 'department_id__department'
    ).exclude(department_id__isnull=True).distinct()

    # Fetch distinct years, filtered by college_id and test_name if provided
    year_filters = {k: v for k, v in filters.items() if k in ['college_id', 'test_name']}
    distinct_years = tests_candidates_map.objects.filter(**year_filters).values('year').exclude(year__isnull=True).distinct()

    # Create response data
    data = {
        "distinct_test_names": list(distinct_test_names),
        "distinct_colleges": [
            {"college_id": item["college_id"], "college_name": item["college_id__college"]} 
            for item in distinct_colleges
        ],
        "distinct_departments": [
            {"department_id": item["department_id"], "department_name": item["department_id__department"]} 
            for item in distinct_departments
        ],
        "distinct_years": list(distinct_years),
    }

    return Response(data)



@api_view(['GET'])
def get_test_reports_placement(request):
    # Get filter parameters from the request
    test_name = request.GET.get('test_name')
    college_ids = request.GET.get('college_id')
    department_id = request.GET.get('department_id')
    year = request.GET.get('year')

    # Start with filtering out deleted reports
    reports = test_reports.objects.filter(deleted=0, college_id=college_ids)

    # Apply additional filters if provided
    if test_name:
        reports = reports.filter(test_name=test_name)
    if department_id:
        reports = reports.filter(department_id=department_id)
    if year:
        reports = reports.filter(year=year)

    # Check if no filters for test_name, college_id, department_id, and year are provided
    if not (test_name or department_id or year):
        # Group by test_name if no filters are provided
        grouped_reports = reports.values('test_name').annotate(total_students=Sum('students_count'))
        # Return data grouped by test_name with summed students_count
        data = [
            {
                'test_name': report['test_name'], 
                'department_name': 'All',
                'year': 'All',
                'total_students': report['total_students']
            } 
            for report in grouped_reports
        ]
    else:
        # Group by college_id, department_id, and year, and sum the students_count if any filters are provided
        grouped_reports = reports.values('college_id', 'college_id__college', 'department_id', 'department_id__department', 'year', 'test_name')\
                                 .annotate(total_students=Sum('students_count'))
        # Serialize the data to include all fields
        data = [
            {
                'test_name': report['test_name'],
                'college_name': report['college_id__college'],
                'department_name': report['department_id__department'],
                'year': report['year'],
                'total_students': report['total_students']
            }
            for report in grouped_reports
        ]

    # Return the serialized data
    return Response(data)

@api_view(['GET'])
def get_completed_reports_cc(request):
    # Get filter parameters from the request
    test_name = request.GET.get('test_name')
    college_ids = request.GET.get('college_id')
    department_id = request.GET.get('department_id')
    year = request.GET.get('year')

    # Clean the test_name if it ends with a slash
    if test_name and test_name.endswith('/'):
        test_name = test_name.rstrip('/')

    # Start with filtering out deleted reports
    reports = tests_candidates_map.objects.filter(deleted=0, is_active=True).exclude(created_by='Student')

    # Apply additional filters if provided
    if test_name:
        reports = reports.filter(test_name__icontains=test_name)  # Use icontains for partial, case-insensitive match

    if college_ids and college_ids != 'All':
        reports = reports.filter(college_id__college__icontains=college_ids)

       # reports = reports.filter(college_id__college=college_ids)
    if department_id and department_id != 'All':
        department_list = [d.strip() for d in department_id.split(',')]
        reports = reports.filter(department_id__department__in=department_list)
    if year and year != 'All':
        year_list = [y.strip() for y in year.split(',')]
        reports = reports.filter(year__in=year_list)


    # Fetch related data using select_related for efficiency
    tests_candidates = reports.select_related(
        'rules_id', 
        'department_id', 
        'question_id', 
        'student_id', 
        'college_id'
    ).values(
        'id',
        'test_name',
        'college_id__college',
        'department_id__department',
        'question_id__id',
        'question_id__question_paper_name',
        'student_id__id',
        'student_id__students_name',
        'student_id__user_name',
        'student_id__email_id',
        'student_id__mobile_number',
        'student_id__gender',
        'student_id__registration_number',
        'rules_id__rule_name',
        'rules_id__instruction',
        'dtm_start',
        'dtm_end',
        'dtm_start_test',
        'capture_duration',
        'is_active',
        'duration',
        'year',
        'need_candidate_info',
        'total_score',
        'avg_mark',
    )

    # Format the datetime fields
    test_candidate_map_data = []
    for testing in tests_candidates:
        dtm_start_formatted = django_format_date(localtime(testing['dtm_start']), 'd-m-Y h:i A') if testing['dtm_start'] else None
        dtm_end_formatted = django_format_date(localtime(testing['dtm_end']), 'd-m-Y h:i A') if testing['dtm_end'] else None
        dtm_startT_formatted = django_format_date(localtime(testing['dtm_start_test']), 'd-m-Y h:i A') if testing['dtm_start_test'] else None

        test_candidate_map_data.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
            'college_id': testing['college_id__college'],
            'department_id': testing['department_id__department'],
            'question_id_id': testing['question_id__id'],
            'question_id': testing['question_id__question_paper_name'],
            'student_id': testing['student_id__id'],
            'registration_number': testing['student_id__registration_number'],
            'email_id': testing['student_id__email_id'],
            'mobile_number': testing['student_id__mobile_number'],
            'gender': testing['student_id__gender'],
            'student_name': testing['student_id__students_name'],
            'user_name': testing['student_id__user_name'],
            'dtm_start': dtm_start_formatted,
            'dtm_end': dtm_end_formatted,
            'dtm_start_test': dtm_startT_formatted,
            'capture_duration': testing['capture_duration'],
            'is_active': testing['is_active'],
            'duration': testing['duration'],
            'year': testing['year'],
            'total_score': testing['total_score'],
            'avg_mark': testing['avg_mark'],
        })

    return Response(test_candidate_map_data)


@csrf_exempt
def upload_and_import_testreport(request):
    if request.method == 'POST':
        # Check if a file was uploaded
        file = request.FILES.get('file')
        if not file:
            return JsonResponse({'error': 'No file provided'}, status=400)

        try:
            # Read the Excel file using pandas
            df = pd.read_excel(file)
            df.columns = df.columns.str.strip().str.lower()  # Normalize column names

            # Print all column names to verify
            print("Column names from the Excel file:", df.columns.tolist())

            # Header mapping (normalized to lowercase)
            header_mapping = {
                'test_name': 'test_name',
                'login id': 'user_name',  # Adjusted for case
                'start date': 'dtm_start',
                'end date': 'dtm_end',
                'total score': 'total_score',
                'avg mark': 'avg_mark',
                'is_camera_on': 'is_camera_on',
                'duration_type': 'duration_type',
            }

            # Check if required columns are present
            missing_columns = [col for col in header_mapping if col not in df.columns]
            if missing_columns:
                return JsonResponse({'error': f'Missing columns in Excel: {", ".join(missing_columns)}'}, status=400)

            # Convert the DataFrame's column names
            df.rename(columns=header_mapping, inplace=True)

            # Check for mandatory columns and handle missing values
            mandatory_columns = ['test_name', 'user_name', 'dtm_start', 'dtm_end', 'total_score']
            for col in mandatory_columns:
                if col in df.columns:
                    missing_values = df[df[col].isnull()]
                    if not missing_values.empty:
                        error_messages = [f"Row {index + 1}: Column '{col}' is empty." for index in missing_values.index]
                        return JsonResponse({'error': error_messages}, status=400)

            # Replace NaN values in boolean and numeric fields with appropriate defaults
            df['is_camera_on'] = df['is_camera_on'].fillna(False)  # Replace NaN with False for is_camera_on
            df['avg_mark'] = df['avg_mark'].fillna(0)  # Replace NaN with 0 for avg_mark (or use another default)

            # Downcast object dtype arrays to avoid FutureWarnings
            df = df.infer_objects()

            # Iterate through the rows and process each entry
            for index, row in df.iterrows():
                try:
                    # Fetch user_name (Login ID)
                    login_id = str(row['user_name']).strip()
                    print(f"Login ID (user_name): {login_id}")

                    if not login_id:
                        return JsonResponse({'error': f"Missing or invalid Login ID in row {index + 1}"}, status=400)

                    # Fetch the student from candidate_master
                    student = candidate_master.objects.get(user_name=login_id,deleted=0)
                    print(f"Found student: {student.user_name} (id: {student.id})")

                    # Check if the test_name and student_id already exist in the database
                    if tests_candidates_map.objects.filter(student_id=student, test_name=row['test_name']).exists():
                        return JsonResponse({'error': f"Row {index + 1}: Data with test_name '{row['test_name']}' and Login Id '{student.user_name}' already exists."}, status=400)


                    # Create or update the test candidate mapping
                    tests_candidates_map.objects.get_or_create(
                        student_id=student,
                        test_name=row['test_name'],
                        defaults={
                            'dtm_start': row['dtm_start'],  # Ensure datetime format
                            'dtm_end': row['dtm_end'],
                            'total_score': row['total_score'],
                            'avg_mark': row['avg_mark'],  # Ensure avg_mark is numeric
                            'is_camera_on': bool(row['is_camera_on']),  # Explicitly cast to bool
                            'duration_type': row.get('duration_type', None),
                            'is_upload_type': 'Campus Team',
                            'is_active': False,  # Set is_active to False initially
                            'college_id': student.college_id,
                            'department_id': student.department_id,
                            'year': student.year,
                        }
                    )

                    # Then update is_active to True, triggering the update trigger
                    tests_candidates_map.objects.filter(
                        student_id=student,
                        test_name=row['test_name'],deleted=0
                    ).update(is_active=True)

                except candidate_master.DoesNotExist:
                    return JsonResponse({'error': f"Student with Login ID '{login_id}' not found in row {index + 1}"}, status=400)
                except Exception as e:
                    print(f"Error processing row {index + 1}: {str(e)}")
                    return JsonResponse({'error': f"Error processing row {index + 1}: {str(e)}"}, status=500)

            return JsonResponse({'message': 'Import successful'}, status=200)

        except Exception as e:
            return JsonResponse({'error': str(e)}, status=500)

    return JsonResponse({'error': 'Invalid method'}, status=405)


@csrf_exempt
def update_testreportol(request):
    if request.method == 'POST':
        # Check if a file was uploaded
        file = request.FILES.get('file')
        if not file:
            return JsonResponse({'error': 'No file provided'}, status=400)

        try:
            # Read the Excel file using pandas
            df = pd.read_excel(file)
            df.columns = df.columns.str.strip().str.lower()  # Normalize column names

            # Print all column names to verify
            print("Column names from the Excel file:", df.columns.tolist())

            # Header mapping (normalized to lowercase)
            header_mapping = {
                'test_name': 'test_name',
                'login id': 'user_name',  # Adjusted for case
                'start date': 'dtm_start',
                'end date': 'dtm_end',
                'total score': 'total_score',
                'avg mark': 'avg_mark',
                'is_camera_on': 'is_camera_on',
                'duration_type': 'duration_type',
            }

            # Check if required columns are present
            missing_columns = [col for col in header_mapping if col not in df.columns]
            if missing_columns:
                return JsonResponse({'error': f'Missing columns in Excel: {", ".join(missing_columns)}'}, status=400)

            # Convert the DataFrame's column names
            df.rename(columns=header_mapping, inplace=True)

            # Check for mandatory columns and handle missing values
            mandatory_columns = ['test_name', 'user_name', 'dtm_start', 'dtm_end', 'total_score']
            for col in mandatory_columns:
                if col in df.columns:
                    missing_values = df[df[col].isnull()]
                    if not missing_values.empty:
                        error_messages = [f"Row {index + 1}: Column '{col}' is empty." for index in missing_values.index]
                        return JsonResponse({'error': error_messages}, status=400)

            # Replace NaN values in boolean and numeric fields with appropriate defaults
            df['is_camera_on'] = df['is_camera_on'].fillna(False)  # Replace NaN with False for is_camera_on
            df['avg_mark'] = df['avg_mark'].fillna(0)  # Replace NaN with 0 for avg_mark (or use another default)

            # Downcast object dtype arrays to avoid FutureWarnings
            df = df.infer_objects()

            # Iterate through the rows and process each entry
            for index, row in df.iterrows():
                try:
                    # Fetch user_name (Login ID)
                    login_id = str(row['user_name']).strip()
                    print(f"Login ID (user_name): {login_id}")

                    if not login_id:
                        return JsonResponse({'error': f"Missing or invalid Login ID in row {index + 1}"}, status=400)

                    # Fetch the student from candidate_master
                    student = candidate_master.objects.get(user_name=login_id,deleted=0)
                    print(f"Found student: {student.user_name} (id: {student.id})")

                    # Fetch the existing record
                    candidate_record = tests_candidates_map.objects.filter(student_id=student, test_name=row['test_name'],deleted=0).first()

                    if not candidate_record:
                        return JsonResponse({'error': f"Row {index + 1}: No existing record found for test_name '{row['test_name']}' and Login Id '{student.user_name}'."}, status=400)

                    # Update the test candidate mapping
                    candidate_record.dtm_start = row['dtm_start']  # Ensure datetime format
                    candidate_record.dtm_end = row['dtm_end']
                    candidate_record.total_score = row['total_score']
                    candidate_record.avg_mark = row['avg_mark']  # Ensure avg_mark is numeric
                    candidate_record.is_camera_on = bool(row['is_camera_on'])  # Explicitly cast to bool
                    candidate_record.duration_type = row.get('duration_type', None)
                   # candidate_record.is_active = True  # Set is_active to True on update
                    candidate_record.save()

                except candidate_master.DoesNotExist:
                    return JsonResponse({'error': f"Student with Login ID '{login_id}' not found in row {index + 1}"}, status=400)
                except Exception as e:
                    print(f"Error processing row {index + 1}: {str(e)}")
                    return JsonResponse({'error': f"Error processing row {index + 1}: {str(e)}"}, status=500)

            return JsonResponse({'message': 'Update successful'}, status=200)

        except Exception as e:
            return JsonResponse({'error': str(e)}, status=500)

    return JsonResponse({'error': 'Invalid method'}, status=405)

@api_view(['GET'])
def job_offers_count(request):
    try:
        # Get the count of job_offers records
        count = job_offers.objects.filter(deleted=0).count()
        return JsonResponse({'job_offers_count': count}, status=200)
    except Exception as e:
        # Handle any unexpected errors
        return JsonResponse({'error': str(e)}, status=500)

@api_view(['GET'])
def accepted_students_count(request):
    # Count the number of records where is_accept=True
    accepted_count = eligible_student_list.objects.filter(is_accept=True,deleted=0).count()
    
    # Return the count as JSON response
    return JsonResponse({'Registered_count': accepted_count})




#--------------------CC  Dashboard------------------------#

def get_test_candidates_count_aptitude(request):
    try:
        # Get query parameters from the request
        college_id = request.GET.get('college_id')

        # Get the question type instance (for 'Aptitude')
        question_type_instance = question_type.objects.filter(question_type='Aptitude', deleted=0).first()

        if not question_type_instance:
            return JsonResponse({'error': 'Question type not found'}, status=404)

        # Base query: Get test names from app_test_master and filter by question_type_id
        if college_id:
            # Filter test names based on college_id if provided
            test_master_data = test_master.objects.filter(
                question_type_id=question_type_instance.id,
                deleted=0,
                test_name__in=tests_candidates_map.objects.filter(deleted=0, college_id=college_id).exclude(created_by='Student').values_list('test_name', flat=True)
            )
        else:
            # No college_id provided, filter without it
            test_master_data = test_master.objects.filter(
                question_type_id=question_type_instance.id,
                deleted=0,
                test_name__in=tests_candidates_map.objects.filter(deleted=0).values_list('test_name', flat=True)
            )

        # Get the count of the records
        count = test_master_data.count()

        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


def get_test_candidates_count_technical(request):
    try:
        # Get query parameters from the request
        college_id = request.GET.get('college_id')

        # Get the question type instance (for 'Aptitude')
        question_type_instance = question_type.objects.filter(question_type='Technical', deleted=0).first()

        if not question_type_instance:
            return JsonResponse({'error': 'Question type not found'}, status=404)

        # Base query: Get test names from app_test_master and filter by question_type_id
        if college_id:
            # Filter test names based on college_id if provided
            test_master_data = test_master.objects.filter(
                question_type_id=question_type_instance.id,
                deleted=0,
                test_name__in=tests_candidates_map.objects.filter(deleted=0, college_id=college_id).exclude(created_by='Student').values_list('test_name', flat=True)
            )
        else:
            # No college_id provided, filter without it
            test_master_data = test_master.objects.filter(
                question_type_id=question_type_instance.id,
                deleted=0,
                test_name__in=tests_candidates_map.objects.filter(deleted=0).values_list('test_name', flat=True)
            )

        # Get the count of the records
        count = test_master_data.count()

        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)



@api_view(['GET'])
def request_count_cc(request):
    try:
        college_id = request.GET.get('college_id')
        print("üìå Received college_id:", college_id)

        candidate_ids = candidate_master.objects.filter(deleted=0)
        if college_id:
            candidate_ids = candidate_ids.filter(college_id=college_id)
        candidate_ids = candidate_ids.values_list('id', flat=True)
        print(f"üìå Candidate IDs for college {college_id}:", list(candidate_ids))

        # Count all student_requests with status='Pending'
        student_request_count = student_request.objects.filter(
            student_id__in=candidate_ids,
            status='Pending',
            deleted=0
        ).count()
        print("üìå Total student_request count:", student_request_count)

        # Count all test_requests with status='Requested'
        test_request_count = tests_candidates_map.objects.filter(
            student_id__in=candidate_ids,
            status='Requested',
            deleted=0
        ).count()
        print("üìå Total test_request count:", test_request_count)

        # Combine counts
        request_count = student_request_count + test_request_count
        print("üìå Final request_count:", request_count)

        return Response({'request_count': request_count})

    except candidate_master.DoesNotExist:
        print("‚ùå College not found")
        return Response({'error': 'College not found'}, status=404)
    except Exception as e:
        print("‚ùå Exception occurred:", str(e))
        return Response({'error': str(e)}, status=500)

@api_view(['GET'])
def get_avg_score_by_department_cc(request):
    try:
        college_id = request.GET.get('college_id')
        dtm_start = request.GET.get('dtm_start')

        if not dtm_start:
            return JsonResponse({'error': 'dtm_start is required'}, status=400)

        # Convert dtm_start to datetime
        dtm_start_date = timezone.make_aware(timezone.datetime.strptime(dtm_start, '%Y-%m-%d'))

        # Filter base queryset
        base_qs = tests_candidates_map.objects.filter(
            deleted=0,
            dtm_start__date=dtm_start_date,
            question_id__test_type='MCQ Test',
            total_score__isnull=False
        ).exclude(created_by='Student') 

        if college_id:
            base_qs = base_qs.filter(college_id=college_id)

        # Perform single query aggregation by department_id
        department_scores = base_qs.values('department_id').annotate(
            avg_score=Avg('total_score')
        )

        # Build department ID to name map
        dept_map = {
            dept['id']: dept['department']
            for dept in department_master.objects.filter(deleted=0).values('id', 'department')
        }

        # Format final results
        results = [
            {
                'department_name': dept_map.get(entry['department_id'], 'Unknown'),
                'avg_score': round(entry['avg_score'] or 0, 2)
            }
            for entry in department_scores
        ]

        return JsonResponse(results, safe=False, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)

@api_view(['GET'])
def avg_score_by_department_Coding_cc(request):
    try:
        college_id = request.GET.get('college_id')
        dtm_start = request.GET.get('dtm_start')

        if not dtm_start:
            return JsonResponse({'error': 'dtm_start is required'}, status=400)

        # Convert to datetime
        dtm_start_date = timezone.make_aware(timezone.datetime.strptime(dtm_start, '%Y-%m-%d'))

        # Build the base query
        base_qs = tests_candidates_map.objects.filter(
            deleted=0,
            dtm_start__date=dtm_start_date,
            question_id__test_type='Coding Test',
            total_score__isnull=False
        ).exclude(created_by='Student') 

        if college_id:
            base_qs = base_qs.filter(college_id=college_id)

        # Aggregate once by department
        department_scores = base_qs.values('department_id').annotate(
            avg_score=Avg('total_score')
        )

        # Map department IDs to names
        dept_map = {
            dept['id']: dept['department']
            for dept in department_master.objects.filter(deleted=0).values('id', 'department')
        }

        # Final output format
        results = [
            {
                'department_name': dept_map.get(entry['department_id'], 'Unknown'),
                'avg_score': round(entry['avg_score'] or 0, 2)
            }
            for entry in department_scores
        ]

        return JsonResponse(results, safe=False, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


@api_view(['GET'])
def get_College_topper_mcq_cc(request):
    try:
        college_id = request.GET.get('college_id')
        test_type = request.GET.get('test_type')  # "MCQTest" or "Coding Test" or "All"

        # Step 1: Base queryset
        queryset = tests_candidates_map.objects.filter(
            deleted=0,
        ).exclude(created_by='Student')

        # üîπ Filter test_type only if not "All"
        if test_type and test_type.lower() != 'all':
            queryset = queryset.filter(question_id__test_type=test_type)

        if college_id:
            queryset = queryset.filter(college_id=college_id)

        # Step 2: Group by student, get total marks and test count
        student_stats = queryset.values(
            'student_id',
            'student_id__students_name',
            'department_id__department'
        ).annotate(
            total_marks=Sum('avg_mark'),
            test_count=Count('id')
        )

        # Step 3: Compute normalized average
        results = []
        for s in student_stats:
            if s['test_count'] > 0 and s['total_marks'] is not None:
                normalized_avg = s['total_marks'] / s['test_count']  # average per test
                results.append({
                    'student_name': s['student_id__students_name'],
                    'department': s['department_id__department'],
                    'avg_mark': round(normalized_avg)
                })

        # Step 4: Sort + take top 5
        results = sorted(results, key=lambda x: x['avg_mark'], reverse=True)[:5]

        return JsonResponse(results, safe=False)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


@api_view(['GET'])
def get_announcements_cc(request):
    try:
        role = request.GET.get('role')
        collegeId = request.GET.get('college_id')

        # Base announcements
        announcements = comman_announcement.objects.filter(deleted=0)

        # Filter for Placement Officer by college
        if role == 'Placement Officer' and collegeId:
            announcements = announcements.filter(login_id__college_id=collegeId)

        # Deduplicate by announcement text
        unique_announcements = defaultdict(lambda: None)
        for announcement in announcements:
            image_base64 = (
                base64.b64encode(announcement.announcement_image).decode("utf-8")
                if announcement.announcement_image else None
            )
            if announcement.announcement not in unique_announcements:
                unique_announcements[announcement.announcement] = {
                    "announcement": announcement.announcement,
                    "announcement_image": image_base64
                }

        return JsonResponse(list(unique_announcements.values()), safe=False, status=200)

    except comman_announcement.DoesNotExist:
        return JsonResponse({"error": "No announcements found"}, status=404)

    except Exception as e:
        return JsonResponse({"error": str(e)}, status=400)


@api_view(['GET'])
def get_job_offers_announcement(request):
    try:
        collegeId = request.GET.get('college_id')  # can be None

        # Base queryset: only non-null, non-empty announcements
        job_offers_data = job_offers.objects.filter(
            deleted=0,
            announcement__isnull=False
        ).exclude(announcement__exact="").distinct()

        # Filter by collegeId if provided
        if collegeId:
            job_offers_data = job_offers_data.filter(college_id__id=collegeId)

        # Prepare response
        offers_list = []
        for job in job_offers_data:
            offers_list.append({
                "announcement": job.announcement,
                "company_name": job.company_name,
                "post_name": job.post_name,
                "job_type": job.job_type,
                "intern_fulltime": job.intern_fulltime,
                "post_name_description": job.post_name_description,
                "announcement_image": None
            })

        return JsonResponse(offers_list, safe=False, status=200)

    except job_offers.DoesNotExist:
        return JsonResponse({"error": "No job offers found"}, status=404)

    except Exception as e:
        return JsonResponse({"error": str(e)}, status=400)

@api_view(['GET'])
def get_offer_chart_cc(request):
    try:
        # Get college_id from the request query parameters, if available
        college_id = request.query_params.get('college_id', None)
        
        # Base queryset: filter by deleted=0
        queryset = candidate_master.objects.filter(deleted=0)

        # If college_id is provided, filter by college_id
        if college_id:
            queryset = queryset.filter(college_id=college_id)
        
        # Select only the necessary fields
        candidatelist = queryset.select_related('college_id', 'department_id').values(
            'number_of_offers',  
            'it_of_offers', 
            'core_of_offers'
        ).distinct()

        # Return the final list of filtered data
        return Response(list(candidatelist))

    except Exception as e:
        return Response({'error': str(e)}, status=500)


@api_view(['GET'])
def get_upcomming_interview_cc(request):
    try:
        # Fetch college_id and department_name from request.GET
        college_id_value = request.GET.get('college_id', None)
        department_name_value = request.GET.get('department_name', None)
        print('department_name_value: ', department_name_value)

        # Create a base queryset without filters
        base_query = eligible_student_list.objects.filter(
            deleted=0,
            is_accept=True,  # Only count registered students
              job_id__deleted=0
        )

        # Conditionally filter by college_id if provided
        if college_id_value:
            base_query = base_query.filter(
                students_id__college_id=college_id_value
            )

        # Conditionally filter by department_name if provided
        if department_name_value:
            base_query = base_query.filter(
                students_id__department_id=department_name_value
            )

        # Group by company name (from job_id) and get the count of registered students
        company_student_counts = base_query.values(
            'job_id__company_name',  # Group by company name from job_id
            'job_id__interview_date'
        ).annotate(
            registered_count=Count('id')  # Count number of students for each company
        ).order_by('job_id__company_name')  # Optional: Order by company name

        # Convert the QuerySet to a list of dictionaries
        company_student_count_list = list(company_student_counts)

        # Format the interview date to 'dd-mm-yy hh:mm AM/PM'
        for item in company_student_count_list:
            interview_date = item['job_id__interview_date']
            if interview_date:
                formatted_date = interview_date.strftime('%d-%m-%y %I:%M %p')  # Format to dd-mm-yy hh:mm AM/PM
                item['job_id__interview_date'] = formatted_date

        return Response(company_student_count_list)

    except Exception as e:
        print(f"Error: {str(e)}")
        return Response({'error': str(e)}, status=500)



@api_view(['GET'])
def get_offer_status_cc(request):
    try:
        college_id_value = request.query_params.get('college_id', None)
        company_name_value = request.query_params.get('company_name', None)

        # ‚úÖ Start with base query (filter out deleted data from eligible_student_list and job_offers)
        base_query = eligible_student_list.objects.filter(
            deleted=0,
            job_id__deleted=0,
            is_eligible=True
        )

        # ‚úÖ Apply college_id filter (if provided)
        if college_id_value:
            base_query = base_query.filter(
                students_id__college_id=college_id_value
            )

        # ‚úÖ Apply company_name filter (if provided)
        if company_name_value:
            base_query = base_query.filter(
                job_id__company_name=company_name_value
            )

        # ‚úÖ Group and count by round_of_interview
        round_of_interview_counts = base_query.values(
            'round_of_interview'
        ).annotate(
            student_count=Count('id')
        ).order_by('round_of_interview')

        # ‚úÖ Return response
        return Response(list(round_of_interview_counts))

    except Exception as e:
        print(f"Error: {str(e)}")
        return Response({'error': str(e)}, status=500)

@api_view(['GET'])
def get_distinct_companies(request):
    try:
        college_id = request.GET.get('college_id', None)

        # Base query
        job_offer_qs = job_offers.objects.filter(deleted=0)

        # Filter if college_id is passed (ManyToMany)
        if college_id:
            job_offer_qs = job_offer_qs.filter(college_id__in=[college_id])

        # Get distinct company names
        distinct_companies = job_offer_qs.values('company_name').distinct()

        # Clean empty or null names
        company_names = [
            {'company_name': item['company_name']}
            for item in distinct_companies if item['company_name']
        ]

        return Response(company_names)

    except Exception as e:
        return Response({'error': str(e)}, status=500)

@api_view(['GET'])
def get_company_count_cc(request):
    try:
        college_id = request.GET.get('college_id', None)

        # Filter base: only non-deleted job_offers
        job_offer_qs = job_offers.objects.filter(deleted=0)

        if college_id:
            # Filter by college_id as well
            job_offer_qs = job_offer_qs.filter(college_id=college_id)

        # Count unique company names
        unique_company_count = job_offer_qs.values('company_name').distinct().count()

        return Response({
            'college_id': college_id if college_id else None,
            'unique_company_count': unique_company_count
        })

    except Exception as e:
        return Response({
            'error': str(e)
        }, status=400)

@api_view(['GET'])
def accepted_students_count_by_college(request):
    college_id = request.GET.get('college_id', None)

    accepted_count = eligible_student_list.objects.filter(deleted=0, is_accept=True)

    if college_id:
        accepted_count = accepted_count.filter(students_id__college_id=college_id)

    accepted_count = accepted_count.count()

    return JsonResponse({'college_accepted_count': accepted_count})

@api_view(['GET'])
def get_total_job_offers_cc(request): 
    try:
        # Get college_id from query parameters
        college_id = request.GET.get('college_id', None)

        # Start with the base queryset
        job_query = job_offers.objects.filter(deleted=0)  # Start with all jobs

        # Apply filter if college_id is provided
        if college_id:
            job_query = job_query.filter(college_id=college_id)

        # Count unique company names in the filtered queryset
        job_count = job_query.values('company_name').distinct().count()

        return Response({
            'job_offer_count': job_count
        })
    except Exception as e:
        return Response({
            'error': str(e)
        }, status=400)


@csrf_exempt
def update_testreport(request):
    if request.method == 'POST':
        # Check if a file was uploaded
        file = request.FILES.get('file')
        if not file:
            return JsonResponse({'error': 'No file provided'}, status=400)

        try:
            # Read the Excel file using pandas
            df = pd.read_excel(file)
            df.columns = df.columns.str.strip().str.lower()  # Normalize column names

            # Print all column names to verify
            print("Column names from the Excel file:", df.columns.tolist())

            # Header mapping (normalized to lowercase)
            header_mapping = {
                'test_name': 'test_name',
                'login id': 'user_name',  # Adjusted for case
                'start date': 'dtm_start',
                'end date': 'dtm_end',
                'total score': 'total_score',
                'avg mark': 'avg_mark',
                'is_camera_on': 'is_camera_on',
                'duration_type': 'duration_type',
            }

            # Check if required columns are present
            missing_columns = [col for col in header_mapping if col not in df.columns]
            if missing_columns:
                return JsonResponse({'error': f'Missing columns in Excel: {", ".join(missing_columns)}'}, status=400)

            # Convert the DataFrame's column names
            df.rename(columns=header_mapping, inplace=True)

            # Check for mandatory columns and handle missing values
            mandatory_columns = ['test_name', 'user_name', 'dtm_start', 'dtm_end', 'total_score']
            for col in mandatory_columns:
                if col in df.columns:
                    missing_values = df[df[col].isnull()]
                    if not missing_values.empty:
                        error_messages = [f"Row {index + 1}: Column '{col}' is empty." for index in missing_values.index]
                        return JsonResponse({'error': error_messages}, status=400)

            # Replace NaN values in boolean and numeric fields with appropriate defaults
            df['is_camera_on'] = df['is_camera_on'].fillna(False)  # Replace NaN with False for is_camera_on
            df['avg_mark'] = df['avg_mark'].fillna(0)  # Replace NaN with 0 for avg_mark (or use another default)

            # Downcast object dtype arrays to avoid FutureWarnings
            df = df.infer_objects()

            # Iterate through the rows and process each entry
            for index, row in df.iterrows():
                try:
                    # Fetch user_name (Login ID)
                    login_id = str(row['user_name']).strip()
                    print(f"Login ID (user_name): {login_id}")

                    if not login_id:
                        return JsonResponse({'error': f"Missing or invalid Login ID in row {index + 1}"}, status=400)

                    # Fetch the student from candidate_master
                    student = candidate_master.objects.get(user_name=login_id,deleted=0)
                    print(f"Found student: {student.user_name} (id: {student.id})")

                    # Fetch the existing record
                    candidate_record = tests_candidates_map.objects.filter(student_id=student, test_name=row['test_name'],deleted=0).first()

                    if not candidate_record:
                        return JsonResponse({'error': f"Row {index + 1}: No existing record found for test_name '{row['test_name']}' and Login Id '{student.user_name}'."}, status=400)

                    # Update the test candidate mapping
                    candidate_record.dtm_start = row['dtm_start']  # Ensure datetime format
                    candidate_record.dtm_end = row['dtm_end']
                    candidate_record.total_score = row['total_score']
                    candidate_record.avg_mark = row['avg_mark']  # Ensure avg_mark is numeric
                    candidate_record.is_camera_on = bool(row['is_camera_on'])  # Explicitly cast to bool
                    candidate_record.duration_type = row.get('duration_type', None)
                   # candidate_record.is_active = True  # Set is_active to True on update
                    candidate_record.save()

                except candidate_master.DoesNotExist:
                    return JsonResponse({'error': f"Student with Login ID '{login_id}' not found in row {index + 1}"}, status=400)
                except Exception as e:
                    print(f"Error processing row {index + 1}: {str(e)}")
                    return JsonResponse({'error': f"Error processing row {index + 1}: {str(e)}"}, status=500)

            return JsonResponse({'message': 'Update successful'}, status=200)

        except Exception as e:
            return JsonResponse({'error': str(e)}, status=500)

    return JsonResponse({'error': 'Invalid method'}, status=405)



@api_view(['GET'])
def get_test_answers(request):
    # Get 'test_name' and 'student_id' from query parameters
    test_name = request.GET.get('test_name')
    student_id = request.GET.get('student_id')
    
    if not test_name or not student_id:
        return Response({"error": "test_name and student_id are required"}, status=400)

    # Fetch the relevant test answers from the database
    answers = tests_candidates_answers.objects.filter(test_name=test_name, student_id=student_id,deleted=0).values('question_id', 'answer')
    
    # Format the response as a dictionary with {id: answer}
    response_data = {item['question_id']: item['answer'] for item in answers}

    # Return the response
    return Response(response_data)


class FilteredStudentRequests(View):
    def get(self, request):
        college_id = request.GET.get('college_id')

        print('Header...College_id1: ', college_id)

        if not college_id:
            return JsonResponse({'error': 'college_id is required'}, status=400)

        # Get the student_ids associated with the college_id
        student_ids = candidate_master.objects.filter(college_id=college_id,deleted=0).values_list('id', flat=True)

        # Filter student_request entries
        requests = student_request.objects.filter(student_id__in=student_ids, status='Pending',deleted=0)

        # Prepare the response data
        response_data = [
            {
                'student_id': req.student_id.id,
                'user_name': req.student_id.user_name, 
                'dtm_request': req.dtm_request,
                'student_query': req.student_query,
                'approved_by': req.approved_by,
                'dtm_approved': req.dtm_approved,
                'is_query_type': req.is_query_type,
            }
            for req in requests
        ]

        return JsonResponse(response_data, safe=False)

class JobRequestCount(View):
    def get(self, request):
        college_id = request.GET.get('college_id')

        print('Header...College_id2: ', college_id)

        if not college_id:
            return JsonResponse({'error': 'college_id is required'}, status=400)

        # Get the student_ids associated with the college_id
        student_ids = candidate_master.objects.filter(college_id=college_id,deleted=0).values_list('id', flat=True)

        # Count the student_request entries
        count = student_request.objects.filter(student_id__in=student_ids, status='Pending',deleted=0).count()

        return JsonResponse({'count': count})

@api_view(['GET'])
def get_distinct_test_data_place(request):

    collegeId = request.GET.get('college_id')
    
    # Fetch distinct test_name
    distinct_test_names = tests_candidates_map.objects.filter(college_id=collegeId,deleted=0).values('test_name').distinct()

    # Fetch distinct college_id and related college_name
    distinct_colleges = tests_candidates_map.objects.select_related('college_id').values(
        'college_id', 'college_id__college').distinct()

    # Fetch distinct department_id and related department_name, excluding null values
    distinct_departments = tests_candidates_map.objects.select_related('department_id').values(
        'department_id', 'department_id__department').exclude(department_id__isnull=True).distinct()

    # Fetch distinct years, excluding null values
    distinct_years = tests_candidates_map.objects.values('year').exclude(year__isnull=True).distinct()

    # Create response data
    data = {
        "distinct_test_names": list(distinct_test_names),
        "distinct_colleges": [{"college_id": item["college_id"], "college_name": item["college_id__college"]} for item in distinct_colleges],
        "distinct_departments": [{"department_id": item["department_id"], "department_name": item["department_id__department"]} for item in distinct_departments],
        "distinct_years": list(distinct_years)
    }

    return Response(data)

class QuestionPaperUpdateView(UpdateAPIView):
    serializer_class = QuestionPaperSerializers
    queryset = question_paper_master.objects.all()

    def get_object(self):
        # Get 'id' from query parameters
        paper_id = self.request.query_params.get('id', None)
        if not paper_id:
            return Response({"error": "ID parameter is required."}, status=status.HTTP_400_BAD_REQUEST)

        # Fetch the object or return a 404
        obj = get_object_or_404(question_paper_master, id=paper_id)
        return obj

    def update(self, request, *args, **kwargs):
        # Perform the update using the standard UpdateAPIView process
        partial = kwargs.pop('partial', False)  # Allows partial updates if needed
        instance = self.get_object()
        serializer = self.get_serializer(instance, data=request.data, partial=partial)
        if serializer.is_valid():
            self.perform_update(serializer)
            return Response(serializer.data)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


def get_question_paper_by_id(request, id):
    try:
        question_paper = get_object_or_404(question_paper_master, id=id)
        serializer = QuestionPaperSerializers(question_paper)
        return JsonResponse(serializer.data, safe=False, status=200)
    except question_paper_master.DoesNotExist:
        return JsonResponse({'error': 'Question Paper not found'}, status=404)
    



@csrf_exempt
def add_question_mcq(request):
    print('***1')
    if request.method == 'POST':
        print('****2')
        print('POST data:', request.POST)
        print('FILES data:', request.FILES)

        form = QuestionForm(request.POST, request.FILES)
        print('****3')
        if form.is_valid():
            print('*****4')
            question = form.save(commit=False)
            if 'question_image_data' in request.FILES:
                question.question_image_data = request.FILES['question_image_data'].read()
            if 'option_a_image_data' in request.FILES:
                question.option_a_image_data = request.FILES['option_a_image_data'].read()
            if 'option_b_image_data' in request.FILES:
                question.option_b_image_data = request.FILES['option_b_image_data'].read()
            if 'option_c_image_data' in request.FILES:
                question.option_c_image_data = request.FILES['option_c_image_data'].read()
            if 'option_d_image_data' in request.FILES:
                question.option_d_image_data = request.FILES['option_d_image_data'].read()
            if 'option_e_image_data' in request.FILES:
                question.option_e_image_data = request.FILES['option_e_image_data'].read()
           
            question.save()
            print('Question Created Successfully')
            

            # Retrieve the related question_paper_master instance
            question_paper = question.question_name_id
            print('question_paper: ', question_paper)
            if question_paper:

                # Update the dtm_created field to the current date and time
                question_paper.dtm_created = datetime.now()
                print('question_paper.dtm_created: ', question_paper.dtm_created)
                question_paper.save()
                print('Question Paper DTM Updated Succesfully')

            return HttpResponse("Question created successfully")
        else:
            print('Form is not valid:', form.errors)
    else:
        print('***1')
        form = QuestionForm()
        print('******2')
    return render(request, 'upload_image.html', {'form': form})




class add_questions_code(generics.CreateAPIView):
    queryset = question_master.objects.all()
    serializer_class = questionsSerializer_code

    def create(self, request, *args, **kwargs):
        # Call the parent class's create method to create the question instance
        serializer = self.get_serializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        question = serializer.save()

        # Retrieve the related QuestionPaper instance through the foreign key
        question_paper = question.question_name_id  # Foreign Key reference
        if question_paper:
            # Update the dtm_created field to the current date and time
            question_paper.dtm_created = datetime.now()
            question_paper.save()
            print('Question Paper DTM Updated Successfully')

        # Return the response
        return Response(serializer.data, status=status.HTTP_201_CREATED)



class questionpapercreateAPIView_place(generics.CreateAPIView):
    queryset = question_paper_master.objects.all()
    serializer_class =questionsPaperSerializer_Place

    def post(self, request, *args, **kwargs):
        print("Request data:", request.data)  
        #logger.info("Creating a new question paper")
        response = super().post(request, *args, **kwargs)
        #logger.info("Created a new question paper successfully")
        return response


class ExcelImportView_Questions_place(APIView):
    def post(self, request, format=None):

        print('request.data: ', request.data)
        # Extract data for the question_paper_master
        question_paper_name = request.data.get('question_paper_name')
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        created_by = request.data.get('created_by')
        folder_name = request.data.get('folder_name')
        remarks = request.data.get('remarks')
        print("remarks",remarks)
           # Build a list of the always‚Äêrequired values
        required_values = [
            question_paper_name,
            duration_of_test,
            topic,
            no_of_questions,
            upload_type,
            test_type,
        ]

        # Only require sub_topic if topic is NOT Softskills
        if topic != 'Softskills':
            required_values.append(sub_topic)

        if not all(required_values):
            return Response(
                {'error': 'Missing fields for question_paper_master'},
                status=status.HTTP_400_BAD_REQUEST
            )
        # Create a new question_paper_master entry
        question_paper_data = {
            'question_paper_name': question_paper_name,
            'duration_of_test': duration_of_test,
            'topic': topic,
            'sub_topic': sub_topic,
            'no_of_questions': no_of_questions,
            'upload_type': upload_type,
            'test_type': test_type,
            'created_by': created_by,
            'folder_name': folder_name,
            'remarks':remarks,

        }

        question_paper_serializer = questionsPaperSerializer_Place(data=question_paper_data)
        if question_paper_serializer.is_valid():
            question_paper_instance = question_paper_serializer.save()
            question_paper_id = question_paper_instance.id
        else:
            return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        print('Files:', request.FILES)

        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']

        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
            df.columns = [col.strip() for col in df.columns]
       

            print('DataFrame contents:')
            print(df.head())  # Print the first few rows of the DataFrame
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Mapping of Excel header names to actual column names
        header_mapping = {
            'Questions**': 'question_text',
            'Option A': 'option_a',
            'Option B': 'option_b',
            'Option C': 'option_c',
            'Option D': 'option_d',
            'Answer**': 'answer',
            'Mark**': 'mark',
            'Difficulty Level': 'difficulty_level',
            'Explain Answer': 'explain_answer',
            
        }
        
        missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
        if missing_columns:
           return Response({'error': f'Missing columns in Excel: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

        df.rename(columns=header_mapping, inplace=True)
        

        # List of mandatory columns
        mandatory_columns = [
            'question_text',
            'answer',
            'mark',
            'difficulty_level'
        ]

        # Initialize error messages
        error_messages = []

        # Check for empty values in mandatory columns and record specific rows
        for col in mandatory_columns:
            if col in df.columns:
                missing_values = df[df[col].isnull()]
                if not missing_values.empty:
                    for index, row in missing_values.iterrows():
                        error_messages.append(f"Row {index + 1}: Column '{col}' is empty.")

        # Validate and convert answers
        if 'answer' in df.columns:
            for index, row in df.iterrows():
                answer = str(row['answer']).strip().upper()  # Normalize to uppercase
                if answer in ['A', 'B', 'C', 'D']:
                    df.at[index, 'answer'] = answer  # Valid answers
                elif answer in ['1', '2', '3', '4']:
                    df.at[index, 'answer'] = chr(ord('A') + int(answer) - 1)  # Convert 1-4 to A-D
                else:
                    error_messages.append(f"Row {index + 1}: Invalid answer '{row['answer']}'.")

        if error_messages:
            error_message = ' '.join(error_messages)
            return Response({'error': error_message}, status=status.HTTP_400_BAD_REQUEST)

        # Convert DataFrame to records and handle NaN values
        records = df.fillna('').to_dict(orient='records')

        for record in records:
            record['question_name_id'] = question_paper_id
            for key in record:
                if isinstance(record[key], str):
                    record[key] = record[key].strip()

        # Serialize and save the records
        serializer = questionsSerializerImport(data=records, many=True)
        print("Serializer: ", serializer)

        if serializer.is_valid():
            print("Before Saving..")
            serializer.save()
            print("After Saving..")
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            # Initialize a list to collect all errors
            detailed_errors = []
            print("Entering Detailed Error..")

            # Iterate over each error in the list of errors
            for idx, error_dict in enumerate(serializer.errors):
                for field, errors in error_dict.items():
                    if isinstance(errors, list):
                        for error in errors:
                            detailed_errors.append(f"Row {idx + 1}, Column '{field}': {error}")

            print('Deltailed Error: ', detailed_errors)
            # Return the collected errors
            return Response({'error': detailed_errors}, status=status.HTTP_400_BAD_REQUEST)


@csrf_exempt
def import_questions_from_word_place(request):
    if request.method == 'POST':
        form = QuestionImportForm(request.POST, request.FILES)
        if form.is_valid():
            uploaded_file = request.FILES['docx_file']
            filename = uploaded_file.name.lower()
            print("DOCX file received for processing.")
            try:

                # Create a new question_paper_master entry
                question_paper_name = request.POST.get('question_paper_name')
                duration_of_test = request.POST.get('duration_of_test')
                topic = request.POST.get('topic')
                sub_topic = request.POST.get('sub_topic')
                no_of_questions = request.POST.get('no_of_questions')
                upload_type = request.POST.get('upload_type')
                test_type = request.POST.get('test_type')
                current_date_and_time = timezone.now()  # Use timezone-aware datetime
                created_by = request.POST.get('created_by')
                folder_name = request.POST.get('folder_name')
                        # Build a list of the always‚Äêrequired values
                required_values = [
                    question_paper_name,
                    duration_of_test,
                    topic,
                    no_of_questions,
                    upload_type,
                    test_type,
                ]

                # Only require sub_topic if topic is NOT Softskills
                if topic != 'Softskills':
                    required_values.append(sub_topic)

                if not all(required_values):
                    return Response(
                        {'error': 'Missing fields for question_paper_master'},
                        status=status.HTTP_400_BAD_REQUEST
                    )
                question_paper_data = {
                    'question_paper_name': question_paper_name,
                    'duration_of_test': duration_of_test,
                    'topic': topic,
                    'sub_topic': sub_topic,
                    'no_of_questions': no_of_questions,
                    'upload_type': upload_type,
                    'test_type': test_type,
                    'dtm_created': current_date_and_time,
                    'created_by': created_by,
                    'folder_name': folder_name
                }

                question_paper_instance = question_paper_master.objects.create(**question_paper_data)


                # Get the directory of the current script
                current_dir = os.path.dirname(os.path.abspath(__file__))
                output_json_path = os.path.join(current_dir, '../words/output.json')
                output_unmatched_lines_path = os.path.join(current_dir, '../words/unmatched_lines.docx')

                # Extract text and images from DOCX
                print("Extracting text and images from DOCX...")
                #text, images_binary = extract_text_and_images_from_docx_mcq(docx_file)
                print("Uploaded file name:", filename)

                if filename.endswith('.docx'):
                    print("Processing as DOCX...")
                    text, images_binary = extract_text_and_images_from_docx_mcq(uploaded_file)
                elif filename.endswith('.pdf'):
                    print("Processing as PDF...")
                    text, images_binary = extract_text_and_images_from_pdf(uploaded_file)
                else:
                    return HttpResponse("Unsupported file format. Please upload a .docx or .pdf file.", status=400)

                # Create JSON structure
                print("Creating JSON structure from extracted data...")
                data = create_json_structure(text, images_binary)

                # Save JSON to file
                print(f"Saving extracted data to JSON file: {output_json_path}")
                with open(output_json_path, 'w') as json_file:
                    json.dump(data, json_file, indent=4)

                # Save unmatched lines to DOCX file
                print(f"Saving unmatched lines to DOCX file: {output_unmatched_lines_path}")
                #save_unmatched_lines_to_docx(data['unmatched_lines'], output_unmatched_lines_path)

                print("Processing questions...")
                for ques in data["questions"]:

                    question_text = ques.get('question_text', '')
                    question_image_data = ques.get('question_image_data', '')
                    sections=ques.get('sections','')
                    answer = ques.get('answer', '')
                    marks = ques.get('marks', 0)
                    mark_method = ques.get('mark_method', '')
                    difficulty_level = ques.get('difficulty_level', '')
                    explain_answer = ques.get('explanation', '')

                    if ques['options']:
                        print("Extracting options...")
                        options_a = ques['options'].get('a', ['', False])
                        options_b = ques['options'].get('b', ['', False])
                        options_c = ques['options'].get('c', ['', False])
                        options_d = ques['options'].get('d', ['', False])
                        options_e = ques['options'].get('e', ['', False])
                        option_a_image_data = options_a[0] if options_a[1] else ''
                        option_a = options_a[0] if not options_a[1] else ''

                        option_b_image_data = options_b[0] if options_b[1] else ''
                        option_b = options_b[0] if not options_b[1] else ''

                        option_c_image_data = options_c[0] if options_c[1] else ''
                        option_c = options_c[0] if not options_c[1] else ''

                        option_d_image_data = options_d[0] if options_d[1] else ''
                        option_d = options_d[0] if not options_d[1] else ''
                        
                        option_e_image_data = options_e[0] if options_e[1] else ''
                        option_e = options_e[0] if not options_e[1] else ''

                        print(f"Options extracted: A: {option_a}, B: {option_b}, C: {option_c}, D: {option_d},E: {option_e}")
                    else:
                        print(f"Warning: No options found for question: {question_text}")

                    # Create an instance of the model
                    question = question_master(
                        question_name_id=question_paper_instance,
                        question_text=question_text or '',
                        question_image_data=decode_base64_image(question_image_data) if question_image_data else None,
                        option_a_image_data=decode_base64_image(option_a_image_data) if option_a_image_data else None,
                        option_b_image_data=decode_base64_image(option_b_image_data) if option_b_image_data else None,
                        option_c_image_data=decode_base64_image(option_c_image_data) if option_c_image_data else None,
                        option_d_image_data=decode_base64_image(option_d_image_data) if option_d_image_data else None,
                        option_e_image_data=decode_base64_image(option_e_image_data) if option_e_image_data else None,
                      
                        input_format="",
                        option_a=option_a or '',
                        option_b=option_b or '',
                        option_c=option_c or '',
                        option_d=option_d or '',
                        option_e=option_e or '',
                        answer=answer or '',
                        difficulty_level=difficulty_level or '',
                        mark_method=mark_method or '',
                        sections=sections or "",
                        mark=marks or 0,
                        explain_answer=explain_answer or '',
                       
                    )

                    print("Saving question to the database...")
                    question.save()
                    print(f"Saved question: {question.id}")

                print("All questions processed and saved successfully.")

            except Exception as e:
                print("Error processing file:", e)
                return HttpResponse(f"Error processing file: {e}")
        else:
            print("Form is not valid.")
            return HttpResponse("Form is not valid.")
    else:
        print("GET request received; rendering import form.")
        form = QuestionImportForm()

    return render(request, 'import_questions.html', {'form': form})



@csrf_exempt
def import_questions_place(request):
    if request.method == 'POST':
        print("Received POST request")

        form = DocumentForm(request.POST, request.FILES)
        if not form.is_valid():
            print("Form is not valid.")
            return HttpResponse("Form is not valid.")

        print("Form is valid")
        docfile = request.FILES['docfile']
        filename = docfile.name.lower()
        ext = os.path.splitext(docfile.name)[1].lower()
        print(f"File received: {filename}")

        try:
            if filename.endswith(".docx"):
                text, images_binary = extract_text_and_images_from_docx(docfile)
            elif filename.endswith(".pdf"):
                text, images_binary = extract_text_from_pdfs(docfile)
            else:
                print("Unsupported file type")
                return HttpResponse("Unsupported file type. Please upload a .docx or .pdf file.", status=400)

            data = create_json_structures(text, images_binary)
            print("Extracted data:", data)

            # Metadata extraction
            question_paper_name = request.POST.get('question_paper_name')
            duration_of_test = request.POST.get('duration_of_test')
            topic = request.POST.get('topic')
            sub_topic = request.POST.get('sub_topic')
            no_of_questions = request.POST.get('no_of_questions')
            upload_type = request.POST.get('upload_type')
            test_type = request.POST.get('test_type')
            folder_name = request.POST.get('folder_name')
            created_by = request.POST.get('created_by')
            is_testcase = request.POST.get('is_testcase', 'false').lower() in ['true', '1']
            current_date_and_time = timezone.now()
            print("question_paper_name:", question_paper_name)
            print("duration_of_test:", duration_of_test)
            print("topic:", topic)
            print("sub_topic:", sub_topic)
            print("no_of_questions:", no_of_questions)
            print("upload_type:", upload_type)
            print("folder_name:", folder_name)

            if not all([question_paper_name, duration_of_test, topic, sub_topic, no_of_questions, upload_type, folder_name]):
                print("Missing required fields for question paper")
                return HttpResponse("Missing fields for question_paper_master", status=400)

            question_paper_instance = question_paper_master.objects.create(
                question_paper_name=question_paper_name,
                duration_of_test=duration_of_test,
                topic=topic,
                sub_topic=sub_topic,
                no_of_questions=no_of_questions,
                upload_type=upload_type,
                test_type=test_type,
                dtm_created=current_date_and_time,
                created_by=created_by,
                folder_name=folder_name,
                is_testcase=is_testcase
            )
            print(f"Question paper created: {question_paper_instance}")

            for ques in data["questions"]:
                if 'question' in ques:
                    question_text = ques['question']
                    input_format = ques.get('input_format', '')
                    answers = ques.get('answers', [])
                    marks = ques.get('marks', '0')
                    test_case1 = ques.get('test_case1', '')
                    test_case2 = ques.get('test_case2', '')
                    test_case3 = ques.get('test_case3', '')
                    difficulty_level = ques.get('difficulty_level','')
                    explain_answer = ques.get('e_ans', '')
                    question_image_data = ques.get('question_image_data', '')

                    print(f"\nProcessing question: {question_text}")
                    print(f"Input Format: {input_format}, Marks: {marks}, Answers: {answers}")

                    if explain_answer.startswith('[') and explain_answer.endswith(']'):
                        explain_answer = explain_answer[1:-1]

                    try:
                        marks = int(marks) if marks else 0
                    except ValueError:
                        print("Invalid mark format. Setting to 0.")
                        marks = 0

                    try:
                        temp_question = question_master_temp.objects.create(
                            question_name_id=question_paper_instance,
                            question_text=question_text,
                            question_image_data=base64.b64decode(question_image_data) if question_image_data else None,
                            input_format=input_format,
                            answer=', '.join(answers),
                            mark=marks,
                            explain_answer=explain_answer,
                            difficulty_level=difficulty_level,
                            test_case1=test_case1,
                            test_case2=test_case2,
                            test_case3=test_case3
                        )
                        print("Temporary question saved:", temp_question)

                        question_data = {
                            "question_name_id": question_paper_instance,
                            "question_text": question_text,
                            "question_image_data": base64.b64decode(question_image_data) if question_image_data else None,
                            "input_format": input_format,
                            "answer": ', '.join(answers),
                            "mark": marks,
                            "explain_answer": explain_answer,
                            "test_case1": test_case1,
                            "test_case2": test_case2,
                            "test_case3": test_case3,
                            "difficulty_level":difficulty_level
                        }

                        main_question = question_master.objects.create(**question_data)
                        print("Main question saved:", main_question)

                        temp_question.delete()

                    except Exception as e:
                        print("Error saving question:", str(e))
                        return HttpResponse(f"Error saving or moving question: {e}")

            return HttpResponse("Questions imported and moved to main table successfully.")
        except Exception as e:
            print("Error processing file:", str(e))
            return HttpResponse(f"Error processing file: {e}")
    else:
        form = DocumentForm()
        return render(request, 'import_coding.html', {'form': form})


@api_view(['GET'])
def get_question_paper_place(request):
    collegeName = request.GET.get('college_name')
    questions_data = question_paper_master.objects.filter(deleted=0, created_by=collegeName).order_by(
        '-dtm_created'
    ).values(
        'id', 'question_paper_name', 'topic', 'sub_topic', 'test_type',
        'duration_of_test', 'no_of_questions', 'upload_type', 'dtm_created','is_testcase'
    )

    # Convert dtm_created to local time zone
    for question in questions_data:
        question['dtm_created'] = timezone.localtime(question['dtm_created'])

    return Response(list(questions_data))


class test_reports_update_test_name(generics.UpdateAPIView):
    serializer_class = testReportsSerializer_testname

    def get_queryset(self):
        test_name = self.request.data.get('testName')
        print(f"Querying for test_name: {test_name}")  # Add logging
        return test_reports.objects.filter(test_name=test_name,deleted=0)  # Use correct model

    def put(self, request, *args, **kwargs):
        print(f"Request data: {request.data}")  # Log the entire request data
        queryset = self.get_queryset()
        if not queryset.exists():
            print("Test not found")  # Add logging
            return Response({"detail": "Not found."}, status=status.HTTP_404_NOT_FOUND)
        
        response_data = []
        for instance in queryset:
            serializer = self.get_serializer(instance, data=request.data, partial=False)
            serializer.is_valid(raise_exception=True)
            self.perform_update(serializer)
            response_data.append(serializer.data)
        
        print("Update successful")  # Add logging
        return Response(response_data, status=status.HTTP_200_OK)

    def patch(self, request, *args, **kwargs):
        print(f"Request data: {request.data}")  # Log the entire request data
        queryset = self.get_queryset()
        if not queryset.exists():
            print("Test not found")  # Add logging
            return Response({"detail": "Not found."}, status=status.HTTP_404_NOT_FOUND)
        
        response_data = []
        for instance in queryset:
            serializer = self.get_serializer(instance, data=request.data, partial=True)
            serializer.is_valid(raise_exception=True)
            self.perform_update(serializer)
            response_data.append(serializer.data)
        
        print("Partial update successful")  # Add logging
        return Response(response_data, status=status.HTTP_200_OK)


@api_view(['GET'])
def get_database_candidate_placement(request):
    try:
        collegeId = request.GET.get('college_id')
        # Fetch candidates with related college and department, filtering by is_database=True
        candidatelist = candidate_master.objects.filter(deleted=0, is_database=True, college_id=collegeId)\
            .select_related('college_id', 'department_id')\
            .values(
                'id', 
             'college_id__college',  # Get college name
             'college_id__college_group',
                'batch_no',
                'students_name',
                'user_name',
            'registration_number',
                'gender',
                'email_id',
                'mobile_number',
                'year',
                'cgpa',
                'department_id__department',  # Department name
               
                
                'marks_10th',
                'marks_12th',
                
                'history_of_arrears',
                'standing_arrears',
                'it_of_offers',
                'core_of_offers',
                
               
                'number_of_offers',
    # Get department name
            ).distinct()

        # Convert the queryset to a list to manipulate individual fields
        candidatelist = list(candidatelist)
        user_passwords = {
            login['user_name']: login['password']
            for login in login.objects.filter(
                user_name__in=[candidate['user_name'] for candidate in candidatelist]
            ).values('user_name', 'password')
        }

        # Add password to each candidate and handle '0.0' replacement
        for candidate in candidatelist:
            candidate['password'] = user_passwords.get(candidate['user_name'], '')
            if candidate['students_name'] == '0.0':
                candidate['students_name'] = ''
        
        
        return Response(candidatelist)
    except Exception as e:
        return Response({'error': str(e)}, status=500)

@api_view(['GET'])
def get_nondb_candidate_placement(request):
    try:
        collegeId = request.GET.get('college_id')
        # Fetch candidates with related college information, filtering by is_database=False
        candidatelist = candidate_master.objects.filter(is_database=False, college_id=collegeId, deleted=0)\
            .select_related('college_id')\
            .values(
                'user_name', 
                'dtm_upload',
                'college_id__college',  # Fetch the college name
                'college_id__college_group', 
                'batch_no',
            ).distinct()

        # Convert the queryset to a list to manipulate individual fields
        candidatelist = list(candidatelist)

        # Fetch login information for each candidate by user_name
        user_passwords = {
            login['user_name']: login['password']
            for login in login.objects.filter(
                user_name__in=[candidate['user_name'] for candidate in candidatelist],deleted=0
            ).values('user_name', 'password')
        }

        # Add password to each candidate, placing it after user_name
        reordered_candidates = []
        for candidate in candidatelist:
            password = user_passwords.get(candidate['user_name'], None)
            # Reorder keys to place 'password' after 'user_name'
            reordered_candidate = {
                'user_name': candidate['user_name'],
                'password': password,
                'dtm_upload': candidate.get('dtm_upload'),
                'college_id__college': candidate.get('college_id__college'),
                'college_group': candidate.get('college_id__college_group'),
                'batch_no': candidate.get('batch_no'),
            }
            reordered_candidates.append(reordered_candidate)

        # Return the candidates with the password field included
        return JsonResponse(reordered_candidates, safe=False)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


@api_view(['GET'])
def Trainer_course_content_view_invoice(request):
    user_name = request.query_params.get('user_name')
    current_date_time = timezone.now()  # Use timezone-aware datetime

    # Print the user_name and current time for debugging
    print(f"Received user_name: {user_name}")
    print(f"Current DateTime: {current_date_time}")

    if not user_name:
        print("Error: user_name is missing")
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        # Fetch trainer
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id
        print(f"Trainer found: ID={trainer_id}, Name={trainer.trainer_name}")

        # Fetch course schedules
        course_schedules = course_schedule.objects.filter(
            deleted=0,
            trainer_id=trainer_id,
            dtm_start_trainer__lte=current_date_time,
            dtm_end_trainer__gte=current_date_time
        ).select_related('topic_id', 'college_id')  # Ensure college_id is included

        # Print the number of course schedules found
        print(f"Course schedules found: {course_schedules.count()}")

        # Create a unique data dictionary using distinct for topics
        unique_data = {}
        for cs in course_schedules:
            topic = cs.topic_id.topic
            if topic not in unique_data:
                unique_data[topic] = {
                    'id': cs.id,
                    'topic': topic,
                    'collegeName': cs.college_id.college,  # Add college name
                    'trainer_name': trainer.trainer_name,
                    # Directly access the trainer's fields
                    'bank_name': trainer.bank_name,
                    'branch_name': trainer.branch_name,
                    'account_no': trainer.account_no,
                    'ifsc_code': trainer.ifsc_code,
                    'address': trainer.address,
                    'city': trainer.city,
                    'pan_number': trainer.pan_number,

                    # Initialize dates
                    'Start_Date': cs.dtm_start_trainer,
                    'End_Date': cs.dtm_end_trainer,
                }

            # Fetch invoice details for the current course schedule
            invoice = invoice_form.objects.filter(course_schedule_id=cs.id).first()
            if invoice:
                invoice_serializer = invoice_formserializer(invoice)

                # Flatten the invoice data
                for key, value in invoice_serializer.data.items():
                    unique_data[topic][key] = value  # Map each key to the top-level object

        # Convert unique data dictionary to a list
        data = list(unique_data.values())

        # Print the final data being returned
        print(f"Data to be returned: {data}")

        return Response(data, status=status.HTTP_200_OK)

    except Exception as e:
        # Print error message for debugging
        print(f"Error occurred: {str(e)}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


#___________________________________________________Dashboard__________________________________________#


def get_aptitute_test_stu(request):
    try:
        username = request.GET.get('username')
        category = request.GET.get('categories')

        qt = question_type.objects.filter(question_type='Aptitude', deleted=0).only('id').first()
        if not qt:
            return JsonResponse({'error': 'Question type not found'}, status=404)

        if not username:
            return JsonResponse({'error': 'Username required'}, status=400)

        # Optimize candidate test map query
        active_tests = tests_candidates_map.objects.select_related('student_id').filter(
            deleted=0,
            student_id__user_name=username,
            is_active=True
        ).values_list('test_name', flat=True)

        # Build filters
        filters = Q(question_type_id=qt.id, deleted=0, test_name__in=active_tests)
        if category:
            filters &= Q(test_type_id__test_type_categories=category)

        count = test_master.objects.filter(filters).only('id').count()

        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


def get_technical_test_stu(request):
    try:
        start_time = time.time()

        username = request.GET.get('username')
        category = request.GET.get('categories')

        qt = question_type.objects.filter(question_type='Technical', deleted=0).only('id').first()
        if not qt:
            return JsonResponse({'error': 'Question type not found'}, status=404)

        if not username:
            return JsonResponse({'error': 'Username is required'}, status=400)

        active_tests = tests_candidates_map.objects.select_related('student_id').filter(
            deleted=0,
            student_id__user_name=username,
            is_active=True
        ).values_list('test_name', flat=True)

        filters = Q(question_type_id=qt.id, deleted=0, test_name__in=active_tests)
        if category:
            filters &= Q(test_type_id__test_type_categories=category)

        count = test_master.objects.only('id').filter(filters).count()

        print(f"‚è±Ô∏è Execution Time: {time.time() - start_time:.4f} seconds")

        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


def get_number_of_offers_stu(request):
    offer_type = request.GET.get('offer')
    username = request.GET.get('username')

    try:
        candidate = candidate_master.objects.filter(deleted=0).only(
            'it_of_offers', 'core_of_offers', 'number_of_offers'
        ).get(user_name=username, deleted=0)

        number_of_offers = (
            candidate.it_of_offers if offer_type == 'IT' else
            candidate.core_of_offers if offer_type == 'Core' else
            candidate.number_of_offers
        )

    except candidate_master.DoesNotExist:
        number_of_offers = 0

    return JsonResponse({'number_of_offers': number_of_offers})

def get_student_skill_percentage(request):
    username = request.GET.get('username')
    start_date = request.GET.get('start_date')
    categories = request.GET.get('categories')

    dtm_start_date = None
    if start_date:
        dtm_start_date = timezone.make_aware(
            timezone.datetime.strptime(start_date, '%Y-%m-%d')
        )
        print('dtm_start (converted): ', dtm_start_date)

    # Get the student object
    student = candidate_master.objects.filter(deleted=0).get(user_name=username)
    print(f"Student: {student}")

    # Quants tests
    quants_tests = test_master.objects.filter(
        question_type_id__question_type='Aptitude',
        skill_type_id__skill_type='Quants',
        deleted=0,
        test_type_id__test_type_categories='PracticeTest',
    ).values_list('test_name', flat=True)

    quants_test_candidates = tests_candidates_map.objects.filter(
        student_id=student,
        test_name__in=quants_tests,
        deleted=0,
         created_by='Student'
    )

    if dtm_start_date:
        quants_test_candidates = quants_test_candidates.filter(dtm_start__date=dtm_start_date.date())

    quants_total_score = quants_test_candidates.aggregate(avg_mark=Sum('avg_mark'))['avg_mark'] or 0

    # Repeat for Logical
    logical_tests = test_master.objects.filter(
        question_type_id__question_type='Aptitude',
        skill_type_id__skill_type='Logical',
        deleted=0,
        test_type_id__test_type_categories='PracticeTest',
    ).values_list('test_name', flat=True)

    logical_test_candidates = tests_candidates_map.objects.filter(
        student_id=student,
        test_name__in=logical_tests,
        deleted=0,
         created_by='Student'
    )
    if dtm_start_date:
        logical_test_candidates = logical_test_candidates.filter(dtm_start__date=dtm_start_date.date())

    logical_total_score = logical_test_candidates.aggregate(avg_mark=Sum('avg_mark'))['avg_mark'] or 0

    # Repeat for Verbal
    verbal_tests = test_master.objects.filter(
        question_type_id__question_type='Aptitude',
        skill_type_id__skill_type='Verbal',
        deleted=0,
        test_type_id__test_type_categories='PracticeTest',
    ).values_list('test_name', flat=True)

    verbal_test_candidates = tests_candidates_map.objects.filter(
        student_id=student,
        test_name__in=verbal_tests,
        deleted=0,
         created_by='Student'
    )
    if dtm_start_date:
        verbal_test_candidates = verbal_test_candidates.filter(dtm_start__date=dtm_start_date.date())

    verbal_total_score = verbal_test_candidates.aggregate(avg_mark=Sum('avg_mark'))['avg_mark'] or 0

    percentages = {
        'quants': quants_total_score,
        'logical': logical_total_score,
        'verbal': verbal_total_score
    }

    return JsonResponse(percentages)

@api_view(['GET'])
def get_test_type_categories_stu(request):
    try:
        # Fetch distinct test type categories where deleted = 0
        test_categories = test_type.objects.filter(deleted=0).values('test_type_categories').distinct()
        print('test_categories: ', test_categories)

        # Convert the QuerySet to a list
        categories = [{'categories': cat['test_type_categories']} for cat in test_categories]
        print('categories: ', categories)

        return Response(categories)

    except Exception as e:
        return Response({'error': str(e)}, status=500)




def get_technical_test_reports_stu(request):
    username = request.GET.get('username')
    start_date = request.GET.get('start_date')
    categories = request.GET.get('categories')

    dtm_start_date = timezone.make_aware(timezone.datetime.strptime(start_date, '%Y-%m-%d'))
    print('dtm_start (converted): ', dtm_start_date)

    # Get the student object
    student = candidate_master.objects.get(user_name=username,deleted=0)
    print(f"Student: {student}")

    # Get the tests for Quants from the test_master and apply filtering based on categories
    mcq_tests = test_master.objects.filter(
        question_type_id__question_type='Technical',
        test_type_id__test_type='MCQ Test',
         test_type_id__test_type_categories='PracticeTest',
         deleted=0
    )
    
    # if categories:
    #     mcq_tests = mcq_tests.filter(test_type_id__test_type_categories=categories)

    mcq_tests = mcq_tests.values_list('test_name', flat=True)
    print(f"Quants Tests: {list(mcq_tests)}")

    # Filter the test candidates for Quants tests
    mcq_test_candidates = tests_candidates_map.objects.filter(
        student_id=student,
        test_name__in=mcq_tests,deleted=0, created_by='Student'
    )

    if start_date:
        mcq_test_candidates = mcq_test_candidates.filter(dtm_start__date=dtm_start_date)
    
    print(f"Quants Test Candidates: {mcq_test_candidates}")

    # Calculate the total score for Quants
    mcq_total_score = mcq_test_candidates.aggregate(avg_mark=Sum('avg_mark'))['avg_mark'] or 0
    print(f"Quants Total Score: {mcq_total_score}")

    # Repeat the same for Logical and Verbal
    coding_tests = test_master.objects.filter(
        question_type_id__question_type='Technical',
        test_type_id__test_type='Coding Test',
        test_type_id__test_type_categories='PracticeTest',
        deleted=0
    )
    
    # if categories:
    #     coding_tests = coding_tests.filter(test_type_id__test_type_categories=categories)

    coding_tests = coding_tests.values_list('test_name', flat=True)
    print(f"Logical Tests: {list(coding_tests)}")

    coding_test_candidates = tests_candidates_map.objects.filter(
        student_id=student,
        test_name__in=coding_tests,deleted=0, created_by='Student'
    )

    if start_date:
        coding_test_candidates = coding_test_candidates.filter(dtm_start__date=dtm_start_date)

    print(f"Logical Test Candidates: {coding_test_candidates}")

    coding_total_score = coding_test_candidates.aggregate(avg_mark=Sum('avg_mark'))['avg_mark'] or 0
    print(f"Logical Total Score: {coding_total_score}")


    # Construct the response with all skill percentages
    percentages = {
        'mcq': mcq_total_score,
        'coding': coding_total_score
    }
    print(f"Percentages: {percentages}")

    return JsonResponse(percentages)



@api_view(['GET'])
def get_upcoming_tests_schedules(request):
    username = request.GET.get('username')
    today = timezone.now().date()

    def format_time(dt):
        return dt.strftime("%I:%M %p") if dt else ""

    upcoming_tests = tests_candidates_map.objects.filter(
        dtm_start__date__gte=today,
        student_id__user_name=username,deleted=0
    ).annotate(
        date=TruncDate('dtm_start')
    ).values('date').distinct()

    response_data = []

    for test in upcoming_tests:
        date = test['date']
        date_str = date.strftime("%Y-%m-%d")

        # Subqueries for each test type
        aptitude_tests = tests_candidates_map.objects.filter(
            dtm_start__date=date,deleted=0,
            test_name__in=test_master.objects.filter(
                question_type_id__question_type='Aptitude',deleted=0
            ).values_list('test_name', flat=True)
        ).values('dtm_start', 'dtm_end')

        technical_mcq_tests = tests_candidates_map.objects.filter(
            dtm_start__date=date,deleted=0,
            test_name__in=test_master.objects.filter(
                Q(question_type_id__question_type='Technical') & Q(test_type_id__test_type='MCQ Test')
            ).values_list('test_name', flat=True)
        ).values('dtm_start', 'dtm_end')

        technical_coding_tests = tests_candidates_map.objects.filter(
            dtm_start__date=date,deleted=0,
            test_name__in=test_master.objects.filter(
                Q(question_type_id__question_type='Technical') & Q(test_type_id__test_type='Coding Test')
            ).values_list('test_name', flat=True)
        ).values('dtm_start', 'dtm_end')

        softskills_tests = tests_candidates_map.objects.filter(
            dtm_start__date=date,deleted=0,
            test_name__in=test_master.objects.filter(
                question_type_id__question_type='Softskills'
            ).values_list('test_name', flat=True)
        ).values('dtm_start', 'dtm_end')

        # Use list comprehensions with set to remove duplicates
        aptitude_times = sorted(set([
            f"{format_time(apt['dtm_start'])} - {format_time(apt['dtm_end'])}"
            for apt in aptitude_tests
        ]))

        technical_mcq_times = sorted(set([
            f"{format_time(mcq['dtm_start'])} - {format_time(mcq['dtm_end'])}"
            for mcq in technical_mcq_tests
        ]))

        technical_coding_times = sorted(set([
            f"{format_time(coding['dtm_start'])} - {format_time(coding['dtm_end'])}"
            for coding in technical_coding_tests
        ]))

        softskills_times = sorted(set([
            f"{format_time(ss['dtm_start'])} - {format_time(ss['dtm_end'])}"
            for ss in softskills_tests
        ]))

        response_data.append({
            'date': date_str,
            'aptitude': ', '.join(aptitude_times) if aptitude_times else "--",
            'technical_mcq': ', '.join(technical_mcq_times) if technical_mcq_times else "--",
            'technical_coding': ', '.join(technical_coding_times) if technical_coding_times else "--",
            'softskills': ', '.join(softskills_times) if softskills_times else "--"
        })

    return Response(response_data)

@api_view(['GET'])
def course_schedule_list_view_stu(request):
    # Get username from request query params
    username = request.GET.get('username')
    today = now()

    # Query to filter by dtm_start_student >= today and student_id__username
    schedules = course_schedule.objects.filter(
        dtm_start_student__gte=today,
        student_id__user_name=username,deleted=0
    ).values(
        'dtm_start_student', 
        'topic_id__topic', 
        'topic_id__skill_type_id__skill_type'
    )

    # Format the dtm_start_student to 'ddth Mon yyyy'
    formatted_schedules = []
    for schedule in schedules:
        dtm_start_student = schedule['dtm_start_student']
        formatted_date = dtm_start_student.strftime('%d{S} %b %Y').replace('{S}', get_day_suffix(dtm_start_student.day))
        formatted_schedules.append({
            'dtm_start_student': formatted_date,
            'topic': schedule['topic_id__topic'],
            'skill_type': schedule['topic_id__skill_type_id__skill_type']
        })

    return Response(formatted_schedules)

def get_day_suffix(day):
    """Return the suffix for the day number (st, nd, rd, th)."""
    if 11 <= day <= 13:
        return 'th'
    else:
        return {1: 'st', 2: 'nd', 3: 'rd'}.get(day % 10, 'th')

from collections import OrderedDict
from itertools import chain
import time
import tracemalloc


@api_view(['GET']) 
def stu_news_updates(request):
    username = request.GET.get('username')
    print("üì• Username received:", username)
    
    # Querysets
    student_entries = eligible_student_list.objects.filter(students_id__user_name=username,deleted=0)
    global_announcements = comman_announcement.objects.filter(deleted=0)

    print("üîç Eligible student entries found:", student_entries.count())
    print("üì¢ Global announcements found:", global_announcements.count())

    # Combine both querysets
    combined_announcements = list(chain(student_entries, global_announcements))

    # Create an ordered dict to preserve order and avoid duplicates
    unique_announcements = OrderedDict(
        (entry.announcement, {
            'announcement': entry.announcement,
            'announcement_image': base64.b64encode(entry.announcement_image).decode('utf-8') if entry.announcement_image else None
        })
        for entry in combined_announcements if entry.announcement
    )

    data = list(unique_announcements.values())
    print("‚úÖ Total unique announcements collected:", len(data))

    if not data:
        print("‚ùå No valid announcements found for the student.")
        return JsonResponse({'error': 'No valid announcements found'}, status=status.HTTP_404_NOT_FOUND)

    print("‚úÖ Returning announcements data.")
    return JsonResponse(data, safe=False, status=status.HTTP_200_OK)





@api_view(['GET'])
def get_student_course_details(request):
    username = request.GET.get('username')

    if not username:
        return Response({'error': 'username is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        candidate = get_object_or_404(candidate_master, user_name=username)
        student_id = candidate.id

        latest_reports_subquery = trainers_report.objects.filter(
            course_schedule_id=OuterRef('course_schedule_id'),deleted=0
        ).order_by('-id')

        latest_reports = trainers_report.objects.filter(
            course_schedule_id__student_id=student_id,deleted=0
        ).annotate(
            latest_report_id=Subquery(latest_reports_subquery.values('id')[:1])
        ).filter(
            id=F('latest_report_id')
        ).select_related(
            'course_schedule_id__topic_id__skill_type_id',
            'course_schedule_id__topic_id'
        )

        data = [
            {
                'topic': report.course_schedule_id.topic_id.topic,
                'sub_topic': report.course_schedule_id.topic_id.sub_topic,
                'skill_type': report.course_schedule_id.topic_id.skill_type_id.skill_type if report.course_schedule_id.topic_id.skill_type_id else None,
                'status': report.status
            }
            for report in latest_reports
        ]

        return Response(data, status=status.HTTP_200_OK)

    except Exception as e:
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)





#----------------08-10-2024 (Trainer Dashboard)----------------------------#

@api_view(['GET'])
def Trainer_course_content_view_TrainingSchedule(request):
    user_name = request.query_params.get('user_name')
    current_date_time = timezone.now()

    print(f"Received user_name: {user_name}")
    print(f"Current DateTime: {current_date_time}")

    if not user_name:
        print("Error: user_name is missing")
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        # Fetch trainer
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id
        print(f"Trainer found: ID={trainer_id}, Name={trainer.trainer_name}")

        # ‚úÖ Fetch course_schedules using trainer_ids list
        course_schedules = course_schedule.objects.filter(
            deleted=0,
            trainer_ids__contains=[trainer_id],  # <-- updated
            dtm_start_trainer__lte=current_date_time,
            dtm_end_trainer__gte=current_date_time
        ).select_related('topic_id', 'college_id', 'topic_id__skill_type_id')

        print(f"Course schedules found: {course_schedules.count()}")

        # Prepare unique data
        unique_data = {
            (cs.topic_id.topic, cs.topic_id.sub_topic, cs.topic_id.skill_type_id.skill_type, cs.dtm_start_trainer, cs.dtm_end_trainer, cs.college_id): {
                'id': cs.id,
                'topic': cs.topic_id.topic,
                'sub_topic': cs.topic_id.sub_topic,
                'skill': cs.topic_id.skill_type_id.skill_type,
                'Start_Date': cs.dtm_start_trainer.strftime('%d{S} %b %Y').replace('{S}', get_day_suffix(cs.dtm_start_trainer.day)),
                'End_Date': cs.dtm_end_trainer,
                'college_id': cs.college_id.college,
            }
            for cs in course_schedules
        }

        print(f"Unique data extracted: {unique_data}")

        return Response(list(unique_data.values()), status=status.HTTP_200_OK)

    except Exception as e:
        print(f"Error occurred: {str(e)}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
@api_view(['GET'])
def Trainer_course_content_view_TestSchedule(request):
    user_name = request.query_params.get('user_name')
    current_date_time = timezone.now()

    if not user_name:
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id

        # ‚úÖ Updated to support trainer_ids list
        course_schedules = course_schedule.objects.filter(
            deleted=0,
            trainer_ids__contains=[trainer_id],  # ‚úÖ List match instead of FK
            dtm_start_trainer__lte=current_date_time,
            dtm_end_trainer__gte=current_date_time
        ).select_related('topic_id', 'college_id', 'department_id')

        response_data = []
        seen_dates = set()

        for cs in course_schedules:
            today = timezone.now().date()

            upcoming_tests = tests_candidates_map.objects.filter(
                college_id=cs.college_id,
                department_id=cs.department_id,
                dtm_start__lte=cs.dtm_end_trainer,
                dtm_end__gte=cs.dtm_start_trainer ,deleted=0
            ).annotate(
                date=TruncDate('dtm_start')
            ).values('date').distinct()

            for test in upcoming_tests:
                date = test['date']
                date_str = date.strftime("%Y-%m-%d")

                if date_str in seen_dates:
                    continue
                seen_dates.add(date_str)

                aptitude_times = set()
                technical_mcq_times = set()
                technical_coding_times = set()
                softskills_times = set()

                aptitude_tests = tests_candidates_map.objects.filter(
                    dtm_start__date=date,deleted=0,
                    test_name__in=test_master.objects.filter(
                        question_type_id__question_type='Aptitude'
                    ).values_list('test_name', flat=True)
                ).values('dtm_start', 'dtm_end')

                technical_mcq_tests = tests_candidates_map.objects.filter(
                    dtm_start__date=date,deleted=0,
                    test_name__in=test_master.objects.filter(
                        Q(question_type_id__question_type='Technical') &
                        Q(test_type_id__test_type='MCQ Test')
                    ).values_list('test_name', flat=True)
                ).values('dtm_start', 'dtm_end')

                technical_coding_tests = tests_candidates_map.objects.filter(
                    dtm_start__date=date,deleted=0,
                    test_name__in=test_master.objects.filter(
                        Q(question_type_id__question_type='Technical') &
                        Q(test_type_id__test_type='Coding Test')
                    ).values_list('test_name', flat=True)
                ).values('dtm_start', 'dtm_end')

                softskills_tests = tests_candidates_map.objects.filter(
                    dtm_start__date=date,deleted=0,
                    test_name__in=test_master.objects.filter(
                        question_type_id__question_type='Softskills'
                    ).values_list('test_name', flat=True)
                ).values('dtm_start', 'dtm_end')

                format_time = lambda dt: dt.strftime("%I:%M %p") if dt else ""

                for apt in aptitude_tests:
                    aptitude_times.add(f"{format_time(apt['dtm_start'])} - {format_time(apt['dtm_end'])}")

                for mcq in technical_mcq_tests:
                    technical_mcq_times.add(f"{format_time(mcq['dtm_start'])} - {format_time(mcq['dtm_end'])}")

                for coding in technical_coding_tests:
                    technical_coding_times.add(f"{format_time(coding['dtm_start'])} - {format_time(coding['dtm_end'])}")

                for ss in softskills_tests:
                    softskills_times.add(f"{format_time(ss['dtm_start'])} - {format_time(ss['dtm_end'])}")

                response_data.append({
                    'date': date_str,
                    'aptitude': ', '.join(aptitude_times) if aptitude_times else "--",
                    'technical_mcq': ', '.join(technical_mcq_times) if technical_mcq_times else "--",
                    'technical_coding': ', '.join(technical_coding_times) if technical_coding_times else "--",
                    'softskills': ', '.join(softskills_times) if softskills_times else "--"
                })

        return Response({'success': True, 'data': response_data})
    
    except trainer_master.DoesNotExist:
        return Response({'error': 'Trainer not found'}, status=status.HTTP_404_NOT_FOUND)


@api_view(['GET'])
def Trainer_course_content_view_status(request):
    user_name = request.query_params.get('user_name')
    current_date_time = timezone.now()

    print(f"Received user_name: {user_name}")
    print(f"Current DateTime: {current_date_time}")

    if not user_name:
        print("Error: user_name is missing")
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id
        print(f"Trainer found: ID={trainer_id}, Name={trainer.trainer_name}")

        # ‚úÖ Use trainer_ids (list field) instead of trainer_id FK
        course_schedules = course_schedule.objects.filter(
            deleted=0,
            trainer_ids__contains=[trainer_id],
            dtm_start_trainer__lte=current_date_time,
            dtm_end_trainer__gte=current_date_time
        ).select_related('topic_id', 'college_id')

        print(f"Course schedules found: {course_schedules.count()}")

        unique_data = {
            (
                cs.topic_id.topic if cs.topic_id else 'N/A',
                cs.topic_id.sub_topic if cs.topic_id else 'N/A',
                cs.topic_id.skill_type_id.skill_type if cs.topic_id and cs.topic_id.skill_type_id else 'N/A',
                cs.dtm_start_trainer,
                cs.dtm_end_trainer,
                cs.college_id.college if cs.college_id else 'N/A'
            ): {
                'id': cs.id,
                'topic': cs.topic_id.topic if cs.topic_id else 'N/A',
                'sub_topic': cs.topic_id.sub_topic if cs.topic_id else 'N/A',
                'skill': cs.topic_id.skill_type_id.skill_type if cs.topic_id and cs.topic_id.skill_type_id else 'N/A',
                'Start_Date': cs.dtm_start_trainer,
                'End_Date': cs.dtm_end_trainer,
                'college_id': cs.college_id.college if cs.college_id else 'N/A',
                'status': (
                    trainers_report.objects.filter(course_schedule_id=cs.id).first().status
                    if trainers_report.objects.filter(course_schedule_id=cs.id).exists()
                    else 'N/A'
                )
            }
            for cs in course_schedules
        }

        print(f"Unique data extracted: {unique_data}")

        data = list(unique_data.values())
        print(f"Data to be returned: {data}")

        return Response(data, status=status.HTTP_200_OK)

    except Exception as e:
        print(f"Error occurred: {str(e)}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def Trainer_course_content_view_Test_aptitude(request): 
    user_name = request.query_params.get('user_name')
    current_date_time = timezone.now()

    print(f"Received user_name: {user_name}")
    print(f"Current DateTime: {current_date_time}")

    if not user_name:
        print("Error: user_name is missing")
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id
        print(f"Trainer found: ID={trainer_id}, Name={trainer.trainer_name}")

        unique_data = []
        test_schedule_seen = set()

        # ‚úÖ Use trainer_ids list field
        course_schedules = course_schedule.objects.filter(
            deleted=0,
            trainer_ids__contains=[trainer_id],
            dtm_start_trainer__lte=current_date_time,
            dtm_end_trainer__gte=current_date_time
        ).select_related('topic_id', 'college_id', 'department_id')

        print(f"Course schedules found: {course_schedules.count()}")

        for cs in course_schedules:
            print(f"Processing course schedule: {cs.id} (Start: {cs.dtm_start_trainer}, End: {cs.dtm_end_trainer})")

            test_schedules = tests_candidates_map.objects.filter(
                college_id=cs.college_id,
                department_id=cs.department_id,
                dtm_start__lte=cs.dtm_end_trainer,
                dtm_end__gte=cs.dtm_start_trainer
            ).select_related('college_id', 'department_id')

            print(f"Matching test schedules found: {test_schedules.count()} for course {cs.id}")

            for test in test_schedules:
                test_key = (test.test_name, test.dtm_start, test.dtm_end, test.college_id, test.department_id)

                if test_key not in test_schedule_seen:
                    test_schedule_seen.add(test_key)

                    test_master_details = test_master.objects.filter(test_name=test.test_name,deleted=0).first()

                    if test_master_details:
                        aptitude_count = test_master.objects.filter(
                            test_name=test.test_name,
                            question_type_id__question_type='Aptitude',deleted=0
                        ).count()

                        test_data = {
                            'test_name': test.test_name,
                            'dtm_start': test.dtm_start,
                            'dtm_end': test.dtm_end,
                            'college': test.college_id.college if test.college_id else 'N/A',
                            'department': test.department_id.department if test.department_id else 'N/A',
                            'question_type': test_master_details.question_type_id.question_type if test_master_details.question_type_id else 'N/A',
                            'aptitude_question_count': aptitude_count
                        }

                        unique_data.append({
                            'id': cs.id,
                            'Start_Date': cs.dtm_start_trainer,
                            'End_Date': cs.dtm_end_trainer,
                            'college_name': cs.college_id.college,
                            'department_name': cs.department_id.department,
                            'test_schedules': [test_data]
                        })

        if not unique_data:
            print("No relevant test schedules found for any course schedules.")
            return Response({'message': 'No relevant test schedules found'}, status=status.HTTP_200_OK)

        print(f"Data to be returned: {unique_data}")
        unique_count = len(unique_data)

        return Response({'count': unique_count}, status=status.HTTP_200_OK)

    except Exception as e:
        print(f"Error occurred: {str(e)}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

@api_view(['GET'])
def Trainer_course_content_view_Test_Tech(request): 
    user_name = request.query_params.get('user_name')
    current_date_time = timezone.now()

    print(f"Received user_name: {user_name}")
    print(f"Current DateTime: {current_date_time}")

    if not user_name:
        print("Error: user_name is missing")
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        # Fetch trainer
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id
        print(f"Trainer found: ID={trainer_id}, Name={trainer.trainer_name}")

        unique_data = []
        test_schedule_seen = set()

        # ‚úÖ Filter course_schedule where trainer_ids contains this trainer_id
        course_schedules = course_schedule.objects.filter(
            deleted=0,
            trainer_ids__contains=[trainer_id],
            dtm_start_trainer__lte=current_date_time,
            dtm_end_trainer__gte=current_date_time
        ).select_related('topic_id', 'college_id', 'department_id')

        print(f"Course schedules found: {course_schedules.count()}")

        for cs in course_schedules:
            print(f"Processing course schedule: {cs.id} (Start: {cs.dtm_start_trainer}, End: {cs.dtm_end_trainer})")

            test_schedules = tests_candidates_map.objects.filter(
                college_id=cs.college_id,
                department_id=cs.department_id,
                dtm_start__lte=cs.dtm_end_trainer,
                dtm_end__gte=cs.dtm_start_trainer,deleted=0
            ).select_related('college_id', 'department_id')

            print(f"Matching test schedules found: {test_schedules.count()} for course {cs.id}")

            for test in test_schedules:
                test_key = (test.test_name, test.dtm_start, test.dtm_end, test.college_id, test.department_id)

                if test_key not in test_schedule_seen:
                    test_schedule_seen.add(test_key)

                    test_master_details = test_master.objects.filter(test_name=test.test_name,deleted=0).first()

                    if test_master_details:
                        technical_count = test_master.objects.filter(
                            test_name=test.test_name,
                            question_type_id__question_type='Technical',deleted=0
                        ).count()

                        test_data = {
                            'test_name': test.test_name,
                            'dtm_start': test.dtm_start,
                            'dtm_end': test.dtm_end,
                            'college': test.college_id.college if test.college_id else 'N/A',
                            'department': test.department_id.department if test.department_id else 'N/A',
                            'question_type': test_master_details.question_type_id.question_type if test_master_details.question_type_id else 'N/A',
                            'technical_question_count': technical_count
                        }

                        unique_data.append({
                            'id': cs.id,
                            'Start_Date': cs.dtm_start_trainer,
                            'End_Date': cs.dtm_end_trainer,
                            'college_name': cs.college_id.college,
                            'department_name': cs.department_id.department,
                            'test_schedules': [test_data]
                        })

        if not unique_data:
            print("No relevant test schedules found for any course schedules.")
            return Response({'message': 'No relevant test schedules found'}, status=status.HTTP_200_OK)

        print(f"Data to be returned: {unique_data}")
        return Response({'count': len(unique_data)}, status=status.HTTP_200_OK)

    except Exception as e:
        print(f"Error occurred: {str(e)}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def Trainer_Test_reports_data(request):
    user_name = request.query_params.get('user_name')
    department_name = request.query_params.get('department')
    date_param = request.query_params.get('date')
    current_date_time = timezone.now()

    if not user_name:
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id

        # Initialize filters
        filters = {
            'deleted': 0,
            'trainer_ids__contains': [trainer_id],  # ‚úÖ Adjusted for list-based field
            'dtm_start_trainer__lte': current_date_time,
            'dtm_end_trainer__gte': current_date_time,
        }

        # Validate the provided date and add to filters if present
        if date_param:
            try:
                date = timezone.datetime.strptime(date_param, '%Y-%m-%d').date()
                filters['dtm_start_trainer__date'] = date
            except ValueError:
                return Response({'error': 'Invalid date format. Use YYYY-MM-DD.'}, status=status.HTTP_400_BAD_REQUEST)

        if department_name:
            filters['department_id__department'] = department_name

        # Query course_schedule with trainer_ids list
        course_schedules = course_schedule.objects.filter(**filters).select_related(
            'topic_id', 'college_id', 'department_id'
        )

        total_pass = 0
        total_fail = 0
        counted_tests = set()

        for cs in course_schedules:
            pass_tests = tests_candidates_map.objects.filter(
                dtm_start__date=date if date_param else timezone.now().date(),
                college_id=cs.college_id,
                department_id=cs.department_id,
                avg_mark__gte=40,deleted=0
            ).distinct()

            fail_tests = tests_candidates_map.objects.filter(
                dtm_start__date=date if date_param else timezone.now().date(),
                college_id=cs.college_id,
                department_id=cs.department_id,
                avg_mark__lt=40,deleted=0
            ).distinct()

            for test in pass_tests:
                if test.id not in counted_tests:
                    total_pass += 1
                    counted_tests.add(test.id)

            for test in fail_tests:
                if test.id not in counted_tests:
                    total_fail += 1
                    counted_tests.add(test.id)

        return Response({
            'success': True,
            'data': {
                'pass_count': total_pass,
                'fail_count': total_fail
            }
        })

    except trainer_master.DoesNotExist:
        return Response({'error': 'Trainer not found'}, status=status.HTTP_404_NOT_FOUND)

@api_view(['GET']) 
def Trainer_feedback_count_view(request):
    user_name = request.query_params.get('user_name')
    department_name = request.query_params.get('department')
    date_param = request.query_params.get('date')  # Date parameter from request

    if not user_name:
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        # Fetch trainer by user_name
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id
        print('‚úÖ Trainer Found:', trainer.trainer_name, '| ID:', trainer_id)

        # Initialize filters
        filters = {
            'deleted': 0,
            'trainer_ids__contains': [trainer_id],  # ‚úÖ FIXED: Use trainer_ids list
        }

        # Add department filter if provided
        if department_name:
            filters['department_id__department'] = department_name

        # Parse and add date filter if provided
        if date_param:
            try:
                date = parse_date(date_param)
                if not date:
                    raise ValueError
                filters['dtm_start_trainer__date'] = date
            except ValueError:
                return Response({'error': 'Invalid date format. Use YYYY-MM-DD.'}, status=status.HTTP_400_BAD_REQUEST)

        print('üîç Filters Used:', filters)

        # Fetch matching course schedules
        course_schedules = course_schedule.objects.filter(**filters)
        print(f"üìò Total course schedules found: {course_schedules.count()}")

        # Count feedbacks
        feedback_counts = course_schedules.values('feedback').annotate(count=Count('feedback'))
        print('üìä Feedback counts:', feedback_counts)

        # Initialize feedback summary
        feedback_summary = {
            'Good': 0,
            'Poor': 0,
            'Excellent': 0,
            'Average': 0
        }

        for feedback in feedback_counts:
            feedback_type = feedback['feedback']
            count = feedback['count']
            if feedback_type in feedback_summary:
                feedback_summary[feedback_type] = count

        return Response({
            'feedback_summary': feedback_summary
        }, status=status.HTTP_200_OK)

    except trainer_master.DoesNotExist:
        return Response({'error': 'Trainer not found'}, status=status.HTTP_404_NOT_FOUND)
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


from django.http import FileResponse, Http404
import os

def download_resumeOL(request, trainer_id):
    try:
        # Get the trainer object using the trainer_id
        trainer = trainer_master.objects.get(id=trainer_id)
        
        # Ensure the trainer has a resume file
        if not trainer.resume:
            raise Http404("Resume not found")

        # Serve the file for download
        resume_path = trainer.resume.path
        response = FileResponse(open(resume_path, 'rb'), as_attachment=True, filename=os.path.basename(resume_path))
        return response

    except trainer_master.DoesNotExist:
        raise Http404("Trainer not found")
    except Exception as e:
        raise Http404("Error downloading resume: " + str(e))

from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib import colors
from django.http import FileResponse, Http404
import io
from .models import trainer_master  # Adjust import based on your project structure

def download_resume(request, trainer_id):
    try:
        # Get the trainer object using the trainer_id
        trainer = trainer_master.objects.get(id=trainer_id)
        
        # Ensure the trainer has text in the remarks column
        if not trainer.remarks:
            raise Http404("No resume text available in remarks")

        # Create an in-memory PDF file
        buffer = io.BytesIO()
        pdf = canvas.Canvas(buffer, pagesize=A4)
        
        # Define styling
        pdf.setFont("Helvetica-Bold", 14)
        pdf.drawString(40, 800, f"{trainer.trainer_name}")
        
        # Switch to regular font for body text
        pdf.setFont("Helvetica", 12)
        y = 780  # Starting y-coordinate

        # Parse the remarks text into sections
        resume_sections = trainer.remarks.split("\n")
        
        # Define formatting rules
        line_spacing = 15
        section_spacing = 25

        # Draw each section with structured formatting
        for line in resume_sections:
            if line.strip():  # Skip empty lines
                if any(header in line for header in ["Objective", "EDUCATIONAL QUALIFICATION", "Professional Summary", "Technical Skills"]):
                    # Set font to bold for section headings
                    pdf.setFont("Helvetica-Bold", 12)
                    y -= section_spacing
                else:
                    pdf.setFont("Helvetica", 12)
                    y -= line_spacing

                pdf.drawString(40, y, line.strip())

                # Check for page overflow and add a new page if needed
                if y < 50:
                    pdf.showPage()
                    y = 780
                    pdf.setFont("Helvetica", 12)

        # Finalize and save the PDF
        pdf.showPage()
        pdf.save()

        # Serve the PDF file as a response
        buffer.seek(0)
        return FileResponse(buffer, as_attachment=True, filename=f"{trainer.trainer_name}_resume.pdf")

    except trainer_master.DoesNotExist:
        raise Http404("Trainer not found")
    except Exception as e:
        raise Http404("Error generating resume PDF: " + str(e))

class InvoiceFormCreateView(generics.CreateAPIView):
    queryset = invoice_form.objects.all()
    serializer_class = invoice_formserializer


def trainer_college_name(request):
    # Get the username from the request
    userName = request.GET.get('username', None)
    
    # Ensure the username is provided
    if not userName:
        return JsonResponse({'error': 'Username is required'}, status=400)

    # Get today's date
    today_date = datetime.now().strftime('%d-%m-%Y')

    # Fetch the trainer's course schedule details based on the current date and get only the first result
    candidate = course_schedule.objects.filter(
        deleted=0,
        trainer_id__user_name=userName,
        dtm_start_trainer__lte=datetime.now(),  # Trainer should have started
        dtm_end_trainer__gte=datetime.now()  # Trainer should not have ended
    ).select_related('college_id').first()  # Fetch the first matching record

    # If no candidate or college is found, return an error
    if not candidate or not candidate.college_id:
        return JsonResponse({'error': 'No college found for the trainer'}, status=404)

    # Return the college information as a JSON response
    return JsonResponse({
        'college': candidate.college_id.college  # Return the name of the first college
    })


@api_view(['GET'])
def trainer_news_updates(request):
    
    username = request.GET.get('username')
    # Fetch all records matching the students_id
    student_entries = comman_announcement.objects.filter(login_id__user_name=username,deleted=0)
    
    if not student_entries.exists():
        return JsonResponse({'error': 'No announcements found for this student'}, status=status.HTTP_404_NOT_FOUND)
    
    # Prepare the response data as a list of dictionaries using map and lambda
    data = list(map(lambda entry: {
        'announcement': entry.announcement,
        'announcement_image': base64.b64encode(entry.announcement_image).decode('utf-8') if entry.announcement_image else None
    }, student_entries))
    
    # Return the list of dictionaries
    return JsonResponse(data, safe=False, status=status.HTTP_200_OK)



@api_view(['POST'])
def create_job_offer(request):
    try:
        # Print the incoming request data
        print("Request Data:", request.data)

        # Initialize the serializer with the incoming data
        serializer = jobOfferSerializer(data=request.data)
        
        # Print the serializer status before validation
        print("Serializer Initialized:", serializer)

        # Check if the serializer data is valid
        if serializer.is_valid():
            print("Validation Passed:", serializer.validated_data)
            
            # Save the job offer if validation passed
            serializer.save()
            
            # Print the saved data
            print("Saved Data:", serializer.data)
            
            return Response(serializer.data, status=201)
        else:
            # Print validation errors if any
            print("Validation Errors:", serializer.errors)
            
            return Response(serializer.errors, status=400)  # Return validation errors
    except Exception as e:
        # Print the exception error
        print("Exception Occurred:", str(e))
        
        return Response({'error': str(e)}, status=500)
    
@api_view(['GET'])
def get_job_offers(request):
    try:
        # Fetch job offers with related data (foreign keys, many-to-many fields)
        job_offers_data = job_offers.objects.filter(deleted=0).select_related(
            'college_id'
        ).prefetch_related(
            'department_id', 'skill_id'  # Many-to-many relationships
        ).values(
            'id',
            'company_name',
            'company_profile',
            'post_name',
            'interview_date',
            'year',
            'location',
            'packages',
            'college_id__college',  # Access related fields
            'college_id__id',
            'department_id__department'
        )

        # Dictionary to group data by job offer 'id'
        grouped_data = defaultdict(lambda: {
            'id': None,
            'company_name': '',
            'company_profile': '',
            'post_name': '',
            'interview_date': '',
            'year': '',
            'location': '',
            'packages': '',
            'colleges': set(),
            'departments': set(),
            'college_ids': set()
        })

        # Loop through the data and group college and department fields
        for job in job_offers_data:
            job_id = job['id']
            grouped_data[job_id]['id'] = job_id
            grouped_data[job_id]['company_name'] = job['company_name']
            grouped_data[job_id]['company_profile'] = job['company_profile']
            grouped_data[job_id]['post_name'] = job['post_name']
            grouped_data[job_id]['interview_date'] = job['interview_date']
            grouped_data[job_id]['year'] = job['year']
            grouped_data[job_id]['location'] = job['location']
            grouped_data[job_id]['packages'] = job['packages']
            
            # Add colleges and departments to the respective sets
            if job['college_id__college']:
                grouped_data[job_id]['colleges'].add(job['college_id__college'])
            if job['department_id__department']:
                grouped_data[job_id]['departments'].add(job['department_id__department'])
            if job['college_id__id']:
                grouped_data[job_id]['college_ids'].add(job['college_id__id'])

        # Convert sets to lists and prepare the final result
        job_offers_list = [
            {
                **job_data,
                'colleges': list(job_data['colleges']),
                'departments': list(job_data['departments']),
                'college_ids': list(job_data['college_ids'])
            }
            for job_data in grouped_data.values()
        ]

        # Return the cached or freshly fetched data
        return Response(job_offers_list)

    except Exception as e:
        # In case of an exception, return the error with a 500 status
        return Response({'error': str(e)}, status=500)





@api_view(['GET'])
def get_invoice_form(request):
    try:
        # Fetch all invoice forms, using select_related and values for efficient querying
        invoice_list = invoice_form.objects.filter(deleted=0).select_related('college_id', 'trainer_id').values(
            'id',
            'college_id',  # Assuming this is an ID field (foreign key)
            'college_id__college',  # Assuming college is a field in the related College model
            'payment_status',
            'trainer_id__address',  # Assuming this is an ID field (foreign key)
            'trainer_id__trainer_name',  # Assuming trainer_name is a field in Trainer model
           'trainer_id__bank_name',  # Assuming this is an ID field (foreign key)
            'trainer_id__branch_name', 
            'trainer_id__ifsc_code',  # Assuming this is an ID field (foreign key)
            'trainer_id__account_no', 
            'trainer_id__city',  # Assuming this is an ID field (foreign key)
            'trainer_id__pan_number', 
            'misc_expenses',
            'travel_expenses',
            'food_allowance',
             'misc_expenses_text',
            'travel_expenses_text',
            'food_allowance_text',
            'misc_expenses_type',
            'overall_feedback',
            'dtm_start',
            'dtm_end',
            'travel_amount',
            'print_amount',
            'food_amount',
            'travel_days',
            'print_days',
            'food_days',
            'training_amount',
            'training_days',
            'invoice_no',
            'schedule_date'
        ).distinct()

        # Convert the queryset to a list of dictionaries
        invoice_data = list(invoice_list)

        return Response(invoice_data, status=200)

    except Exception as e:
        return Response({'error': str(e)}, status=500) 

@api_view(['PATCH'])  # Allow PATCH method
def update_payment_status(request):
    # The same logic to update payment status

    try:
        invoice_id = request.query_params.get('id')  # Get the ID from the query params
        if not invoice_id:
            return Response({'error': 'Invoice ID is required'}, status=400)

        invoice = invoice_form.objects.get(id=invoice_id)
        invoice.payment_status = "Paid"
        invoice.save()

        return Response({'message': 'Payment status updated successfully'}, status=200)

    except invoice_form.DoesNotExist:
        return Response({'error': 'Invoice not found'}, status=404)
    except Exception as e:
        return Response({'error': str(e)}, status=500)


class UpdateScheduleDateView(generics.UpdateAPIView):
    queryset = invoice_form.objects.all()
    serializer_class = InvoiceDateUpdateSerializer
    lookup_field = 'id'  # Use 'id' instead of 'pk'


#------------------------------15-10-2024----------------------------------#


def job_offer_update_announcement(request):
    # Get the offer_id and new_announcement from the GET parameters
    offer_id = request.GET.get('offer_id')
    new_announcement = request.GET.get('announcement')

    if not offer_id or not new_announcement:
        return JsonResponse({'status': 'error', 'message': 'Missing parameters.'}, status=400)

    try:
        # Update the specific job offer by its ID
        offer = job_offers.objects.filter(id=offer_id,deleted=0).update(
            announcement=new_announcement,
            dtm_modified=timezone.now()
        )

        if offer:  # Check if any rows were updated
            return JsonResponse({'status': 'success', 'message': 'Announcement updated successfully.'})
        else:
            return JsonResponse({'status': 'error', 'message': 'Job offer not found.'}, status=404)

    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)}, status=500)

@csrf_exempt
def send_email_to_Placement(request):
    try:
        # Retrieve parameters from the request
        college_ids = request.POST.get('college_ids', '')
        post_name = request.POST.get('post_name')
        department = request.POST.get('departments')
        company_name = request.POST.get('company_name')
        attach_file = request.FILES.get('attach_file')  # Get the file from request.FILES
        
        # Debugging: Print received values
       #  print('Received college_ids:', college_ids)
       #  print('Received post_name:', post_name)
       #  print('Received department:', department)
       #  print('Received company_name:', company_name)
       #  print('Received attach_file:', attach_file)
        
        # Convert college_ids to a list of integers
        college_ids = list(map(int, college_ids.split(','))) if college_ids else []
      #  print('Parsed college_ids:', college_ids)

        # Fetch eligible students (login data)
        login_data = login.objects.filter(college_id__in=college_ids,deleted=0)
       # print('Login data count:', login_data.count())

        if not login_data.exists():
          #  print("No eligible students found.")
            return JsonResponse({"error": "No eligible students found for the given criteria"}, status=404)

        # Prepare email details
        email_subject = f"New job posting: {post_name}"
        from_email = "selvisiddhu061996@gmail.com"
       # print('Email subject:', email_subject)
        
        # Prepare email messages
        email_messages = []
        for data in login_data:
            user_name = data.user_name
           # print(f'Processing user {user_name} with role {data.role}')
            
            if data.role == 'Placement Officer':
                to_email = data.email_id
                email_body = f"""Dear {user_name},

We are pleased to inform you about a new job opportunity.

Company Name: {company_name}
Post Name: {post_name}
Department: {department}

Regards,
Campus Connections Team
www.campusconnection.co.in
"""
                email = EmailMessage(
                    email_subject,
                    email_body,
                    from_email,
                    [to_email]
                )
        
                # Attach the file only if one was provided
                if attach_file:
                    try:
                        print(f"Attaching file {attach_file.name} to email for {user_name}")
                        email.attach(attach_file.name, attach_file.read(), attach_file.content_type)
                    except Exception as e:
                        print(f"Failed to attach file for {user_name}: {e}")
        
                email_messages.append(email)
        
        # Check if any emails were prepared
        if not email_messages:
            print("No emails to send for Placement Officer.")
            return JsonResponse({"message": "No Placement Officer emails found for the selected colleges."}, status=404)

        # Send emails in a separate thread
        print("Starting email thread to send emails...")
        email_thread = threading.Thread(target=send_emails_placement_job_posting, args=(email_messages,))
        email_thread.start()

        print("Emails are being sent in the background.")
        return JsonResponse({"message": "Emails are being sent in the background"}, status=200)

    except Exception as e:
        print(f"Error occurred: {e}")
        return JsonResponse({"error": str(e)}, status=500)



def send_emails_placement_job_posting(email_messages):
    for email in email_messages:
        print(f"Sending email to {email.to}")
        email.send()
    print("All emails sent.")

from .serializers import TestCandidateMapSerializerLey

class TestCandidateMapUpdateViewKeys(generics.UpdateAPIView):
    queryset = tests_candidates_map.objects.all()
    serializer_class = TestCandidateMapSerializerLey

    # Override partial_update to handle PATCH request
    def partial_update(self, request, *args, **kwargs):
        instance = self.get_object()
        
        # Update only the capture_passkey field
        instance.capture_passkey = request.data.get('capture_passkey', instance.capture_passkey)
        instance.save()

        serializer = self.get_serializer(instance)
        return Response(serializer.data, status=status.HTTP_200_OK)


def update_capture_durations(request):
    # Get the 'id' and 'capture_duration' from the GET request
    test_candidate_id = request.GET.get('id')
    new_capture_duration = request.GET.get('capture_duration')

    if test_candidate_id and new_capture_duration:
        # Fetch the specific test candidate record using the provided 'id'
        test_candidate = get_object_or_404(tests_candidates_map, id=test_candidate_id)

        # Update the 'capture_duration' field
        test_candidate.capture_duration = new_capture_duration
        test_candidate.save()  # Save the changes

        # Return a success response
        return JsonResponse({
            'status': 'success',
            'message': f'Test candidate with id {test_candidate_id} updated successfully.',
            'capture_duration': new_capture_duration
        })
    
    # Return an error response if either 'id' or 'capture_duration' is missing
    return JsonResponse({
        'status': 'error',
        'message': 'Both id and capture_duration are required.'
    }, status=400)


@api_view(['POST'])
def add_invoice(request):
    try:
        print("Received request data:", request.data)

        # Create a new invoice_form instance
        invoice = invoice_form()

        # Assign fields from the request data
        college_id = request.data.get('college_id')
        trainer_id = request.data.get('trainer_id')

        # Debug foreign key handling
        print("Received college_id:", college_id)
        print("Received trainer_id:", trainer_id)

        # Retrieve foreign key objects for college_id and trainer_id
        try:
            invoice.college_id = college_master.objects.get(id=college_id)
            print("College found and assigned:", invoice.college_id)
        except college_master.DoesNotExist:
            return JsonResponse({"error": "College not found"}, status=status.HTTP_404_NOT_FOUND)

        try:
            invoice.trainer_id = trainer_master.objects.get(id=trainer_id)
            print("Trainer found and assigned:", invoice.trainer_id)
        except trainer_master.DoesNotExist:
            return JsonResponse({"error": "Trainer not found"}, status=status.HTTP_404_NOT_FOUND)

        # Enforce unique invoice_no
        invoice_no = request.data.get('invoice_no')
        if invoice_no and invoice_form.objects.filter(invoice_no=invoice_no).exists():
            return JsonResponse({"error": "Invoice number already exists"}, status=status.HTTP_400_BAD_REQUEST)
        invoice.invoice_no = invoice_no

        # Calculate the training days and payment
        try:
            print("Filtering course_schedule for trainer_id and college_id...")
            schedule_qs = course_schedule.objects.filter(
                trainer_id=trainer_id,
                college_id=college_id,deleted=0
            )
            print("Initial course_schedule count:", schedule_qs.count())

            print("Filtering by status='Completed'...")
            completed_schedule_qs = schedule_qs.filter(status="Completed")
            print("Count after status filtering (Completed):", completed_schedule_qs.count())
            
            if completed_schedule_qs.count() == 0:
                return JsonResponse({"error": "Training Feedback form not submitted. You cannot receive payment until the feedback is completed."}, 
                                     status=status.HTTP_400_BAD_REQUEST)
            print("Filtering distinct training days...")
            training_days_qs = completed_schedule_qs.values('dtm_of_training').distinct()
            print("Distinct training days:", training_days_qs)

            training_days_count = len(training_days_qs)
            print("Final calculated training days count:", training_days_count)

            print("Fetching trainer payment...")
            trainer_payment_qs = completed_schedule_qs.values_list('trainer_payment', flat=True).distinct()

            if trainer_payment_qs.exists():
                try:
                    trainer_payment = float(trainer_payment_qs.first() or 0)
                    print("Trainer payment:", trainer_payment)
                except ValueError:
                    trainer_payment = 0
                    print("Trainer payment is invalid; defaulting to 0.")
            else:
                trainer_payment = 0
                print("Trainer payment not found; defaulting to 0.")

            training_amount = training_days_count * trainer_payment
            invoice.training_amount = training_amount
            invoice.training_days = training_days_count
            print(f"Calculated training_amount: {training_days_count} * {trainer_payment} = {training_amount}")
            
            food_amount = 0  # Initialize the food_amount variable here
            food_values = completed_schedule_qs.values_list('food', flat=True).distinct()
            print("Distinct food values:", food_values)

            if 'By Campus' in food_values:
                food_rate_per_day = 100  # Fixed rate per day
                food_amount = training_days_count * food_rate_per_day
                invoice.food_amount = food_amount
                print(f"Calculated food_amount: {training_days_count} * {food_rate_per_day} = {food_amount}")
            else:
                # Default food_amount to 0 if food is not "By Campus"
                invoice.food_amount = 0
                print("Food amount not calculated as food is not 'By Campus'.")

        except Exception as e:
            print("Error calculating training days or payment:", str(e))
            return JsonResponse({"error": "Failed to calculate training days or payment"}, status=status.HTTP_400_BAD_REQUEST)

        # Assign other fields
        invoice.misc_expenses_type = request.data.get('misc_expenses_type')
        invoice.overall_feedback = request.data.get('overall_feedback')
        invoice.travel_amount = request.data.get('travel_amount',0)
        invoice.print_amount = request.data.get('print_amount',0)
        invoice.travel_days = request.data.get('travel_days',0)

        # Assign the new `is_tds_deduct` field
        is_tds_deduct = request.data.get('is_tds_deduct', False)
        invoice.is_tds_deduct = bool(is_tds_deduct)  # Ensure it's a boolean value
        print("is_tds_deduct assigned:", invoice.is_tds_deduct)

        # Optional file handling
        invoice.misc_expenses = request.FILES.get('misc_expenses', None)
        invoice.travel_expenses = request.FILES.get('travel_expenses', None)
        invoice.food_allowance = request.FILES.get('food_allowance', None)

        if invoice.misc_expenses:
            try:
                invoice.misc_expenses_text = extract_text_from_file(invoice.misc_expenses)
                print("Extracted text for misc_expenses_text:", invoice.misc_expenses_text)
            except Exception as e:
                print("Failed to extract text for misc_expenses:", str(e))

        if invoice.travel_expenses:
            try:
                invoice.travel_expenses_text = extract_text_from_file(invoice.travel_expenses)
                print("Extracted text for travel_expenses_text:", invoice.travel_expenses_text)
            except Exception as e:
                print("Failed to extract text for travel_expenses:", str(e))

        if invoice.food_allowance:
            try:
                invoice.food_allowance_text = extract_text_from_file(invoice.food_allowance)
                print("Extracted text for food_allowance_text:", invoice.food_allowance_text)
            except Exception as e:
                print("Failed to extract text for food_allowance:", str(e))

        # Save the invoice
        invoice.save()
        print("Invoice saved successfully!")

        return JsonResponse({
            "message": "Invoice added successfully!",
            "training_days": training_days_count,
            "training_amount": training_amount,
            "food_amount": food_amount,
            "is_tds_deduct": invoice.is_tds_deduct
        }, status=status.HTTP_201_CREATED)

    except Exception as e:
        print("Error occurred while adding invoice:", str(e))
        return JsonResponse({"error": f"Failed to add invoice: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)



def extract_text_from_file(file):
    """Extract text from PDF file."""
    extracted_text = ''
    print(f"Extracting text from file: {file.name}")

    try:
        with fitz.open(stream=file.read(), filetype="pdf") as pdf:
            for page in pdf:
                page_text = page.get_text()
                extracted_text += page_text
                print(f"Extracted text from page: {page_text[:100]}...")  # Print first 100 characters
    except Exception as e:
        print(f"Error processing PDF file {file.name}: {e}")

    return extracted_text


@api_view(['GET'])
def get_latest_job_offer(request):
    try:
        # Get college_id from query parameters
        college_id = request.query_params.get('college_id')
        
        if not college_id:
            return Response({"error": "college_id is required"}, status=400)

        # Filter by college_id, order by id descending, and get the latest entry
        job_offer = job_offers.objects.filter(college_id=college_id,deleted=0).order_by('-id').values(
            'company_name', 'company_profile', 'post_name', 'post_name_description'
        ).first()
        
        if job_offer:
            return Response(job_offer)
        else:
            return Response({"message": "No job offers found for this college_id"}, status=404)
    
    except Exception as e:
        return Response({"error": str(e)}, status=500)





@api_view(['GET'])
def job_type_count(request):
    # Get the `college_id` and `job_type` parameters from the query string
    college_id = request.query_params.get('college_id')
    job_type = request.query_params.get('job_type', 'IT')  # Default to 'IT' if job_type is not provided

    # Filter jobs by job_type, and apply college_id filter if it's provided
    jobs = job_offers.objects.filter(job_type=job_type,deleted=0)
    
    if college_id:
        jobs = jobs.filter(college_id=college_id)
    
    # Count the filtered jobs
    job_count = jobs.count()
    
    # Return the count in the response
    return Response({"job_count": job_count})


@api_view(['GET'])
def job_type_count_core(request):
    # Get the `college_id` and `job_type` parameters from the query string
    college_id = request.query_params.get('college_id')
    job_type = request.query_params.get('job_type', 'Core')  # Default to 'IT' if job_type is not provided

    # Filter jobs by job_type, and apply college_id filter if it's provided
    jobs = job_offers.objects.filter(job_type=job_type,deleted=0)
    
    if college_id:
        jobs = jobs.filter(college_id=college_id)
    
    # Count the filtered jobs
    job_count = jobs.count()
    
    # Return the count in the response
    return Response({"job_count": job_count})





@api_view(['GET'])
def check_username_exists(request):
    # Retrieve the username from the request query parameters
    username = request.query_params.get('username', '').lower()

    # Check if a matching username exists in the database (case insensitive)
    status = login.objects.filter(user_name__iexact=username, deleted=0).exists()

    # Return true if found, otherwise false
    return Response({"status": status})



@api_view(['GET'])
def get_distinct_announcements(request):
    announcements = (
        comman_announcement.objects
        .filter(deleted=0) 
        .values('announcement', 'announcement_image')
        .distinct()
    )

    # Collect ids for each unique announcement and image
    response_data = []
    for item in announcements:
        ids = list(
            comman_announcement.objects
            .filter(
                announcement=item['announcement'],
                announcement_image=item['announcement_image'],deleted=0
            )
            .values_list('id', flat=True)
        )

        # Handle the image - Check if it's a memoryview or a file, then encode in base64
        announcement_image = None
        if item['announcement_image']:
            if isinstance(item['announcement_image'], memoryview):
                # If it's a memoryview, directly encode it
                announcement_image = base64.b64encode(item['announcement_image']).decode('utf-8')
            else:
                # If it's a file, open and read the file
                with item['announcement_image'].open('rb') as img_file:
                    image_content = img_file.read()
                    announcement_image = base64.b64encode(image_content).decode('utf-8')

        response_data.append({
            'id': ids,
            'announcement': item['announcement'],
            'announcement_image': announcement_image
        })

    return Response(response_data)


@api_view(['PUT'])
def update_comman_announcement(request):
    # Bind the request data to the form
    form = AnnouncementUpdateForm(request.data, request.FILES)
    
    # Check if the form is valid
    if form.is_valid():
        ids = form.cleaned_data['ids']
        announcement_text = form.cleaned_data.get('announcement')
        announcement_image = form.cleaned_data.get('announcement_image')
        
        # Fetch the announcements to be updated
        announcements_to_update = comman_announcement.objects.filter(id__in=ids)
        
        # Update the announcement text if provided
        if announcement_text is not None:
            announcements_to_update.update(announcement=announcement_text)
        
        # Update the announcement image as binary data if provided
        if announcement_image:
            image_content = announcement_image.read()  # Read binary content from the uploaded file
            for announcement in announcements_to_update:
                announcement.announcement_image = image_content
                announcement.save()
        
        return Response({"message": "Announcement(s) updated successfully"}, status=status.HTTP_200_OK)
    
    else:
        # Return form errors if the data is invalid
        return Response({"errors": form.errors}, status=status.HTTP_400_BAD_REQUEST)



@api_view(['PUT'])
def delete_comman_announcement(request):
    try:
        # Get the list of ids from the request
        ids = request.data.get('ids', [])
        
        print('ids: ', ids)

        # Ensure 'ids' is a flat list of integers
        if isinstance(ids, str):
            ids = json.loads(ids)  # Deserialize if it's a JSON string
        if any(isinstance(i, list) for i in ids):
            ids = [item for sublist in ids for item in sublist]  # Flatten nested lists

        if not all(isinstance(i, int) for i in ids):
            return Response({"error": "Invalid ID format; expected a list of integers."}, status=status.HTTP_400_BAD_REQUEST)

        print('ids*****: ', ids)
        # Update the 'deleted' field to 1 for the given ids
        comman_announcement.objects.filter(id__in=ids).update(deleted=1)

        return Response({"message": "Announcement(s) marked as deleted successfully"}, status=status.HTTP_200_OK)

    except Exception as e:
        import traceback
        print(traceback.format_exc())  # Log the error
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



#-----12-11-2024------------------




@api_view(['GET'])
def get_unique_job_offers(request):
    try:
        # Get college_id from query parameters
        college_id = request.query_params.get('college_id')

        if not college_id:
            return Response({"error": "college_id is required"}, status=400)

        # Filter job offers by college_id and exclude deleted entries
        job_offers_queryset = job_offers.objects.filter(college_id=college_id, deleted=0).distinct()

        # Prepare data with department_id and skill_id as lists
        job_offers_data = []
        for job in job_offers_queryset:
            department_data = [
                {
                    "department_id": dept.id,
                    "department_name": dept.department  # Replace 'department' with the actual field name in your model
                }
                for dept in job.department_id.all()  # Access related departments
            ]

            skill_data = [
                {
                    "skill_is": skill.id,
                    "skill_name": skill.skill_name  # Replace 'department' with the actual field name in your model
                }
                for skill in job.skill_id.all()  # Access related departments
            ]

            job_offers_data.append({
                # "id": job.id,
                "company_name": job.company_name,
                "company_profile": job.company_profile,
                "post_name": job.post_name,
                "post_name_description": job.post_name_description,
                "intern_fulltime": job.intern_fulltime,
                "job_type": job.job_type,
                "on_off_campus": job.on_off_campus,
                "cgpa": job.cgpa,
                "marks_10th": job.marks_10th,
                "marks_12th": job.marks_12th,
                "gender": job.gender,
                "history_of_arrears": job.history_of_arrears,
                "standing_arrears": job.standing_arrears,
                "interview_date": job.interview_date,
                "year": job.year,
                "location": job.location,
                "no_of_offers": job.no_of_offers,
                "packages": job.packages,
                "department_data": department_data, 
                "skill_data":skill_data,
                # Add other fields as necessary
            })

        return Response(job_offers_data, status=200)
    except Exception as e:
        return Response({"error": str(e)}, status=400)

@api_view(['GET'])
def trainer_popup_getting(request):
    print('trainer popup function working....')

    user_name = request.GET.get('user_name')
    if not user_name:
        return Response(
            {"error": "The 'user_name' query parameter is required."},
            status=status.HTTP_400_BAD_REQUEST
        )
    try:
        trainer = trainer_master.objects.filter(deleted=0, user_name=user_name).first()
        if trainer:
            # Explicitly return the Boolean value
            return Response({"trainer_popup": bool(trainer.trainer_popup)}, status=status.HTTP_200_OK)
        else:
            return Response(
                {"error": "Trainer not found or does not match the criteria."},
                status=status.HTTP_404_NOT_FOUND
            )
    except Exception as e:
        return Response(
            {"error": f"An error occurred: {str(e)}"},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )



@api_view(['PUT'])  # Use PUT for updates
def update_trainer_popup(request):
    print('Update trainer popup function working...')
    
    # Get the user_name from the request data
    user_name = request.data.get('user_name')

    if not user_name:
        return Response(
            {"error": "The 'user_name' field is required."},
            status=status.HTTP_400_BAD_REQUEST
        )
    
    try:
        # Find the trainer by user_name
        trainer = trainer_master.objects.filter(deleted=0, user_name=user_name).first()
        
        if trainer:
            # Update the trainer_popup field to False
            trainer.trainer_popup = False
            trainer.save()

            return Response(
                {
                    "message": f"Trainer '{user_name}' updated successfully.",
                    "trainer_popup": trainer.trainer_popup,
                },
                status=status.HTTP_200_OK
            )
        else:
            return Response(
                {"error": "Trainer not found or does not match the criteria."},
                status=status.HTTP_404_NOT_FOUND
            )
    except Exception as e:
        return Response(
            {"error": f"An error occurred: {str(e)}"},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

#________________________________________Newly added_________________#



@api_view(['GET'])
def get_candidates_testReports(request):
    # Fetch test candidates with necessary related fields
    tests_candidates = tests_candidates_map.objects.filter(deleted=0, is_active=True).select_related(
        'department_id', 'question_id', 'student_id', 'college_id'
    )

    # Fetch related test_master records in bulk
    test_master_data = {
        test.test_name: test.question_type_id.question_type if test.question_type_id else None
        for test in test_master.objects.all()
    }
    test_master_skill = {
        test.test_name: test.skill_type_id.skill_type if test.skill_type_id else None
        for test in test_master.objects.all()
    }

    # Fetch the total tests assigned for each student
    assigned_tests_count = tests_candidates_map.objects.filter(deleted=0).values(
        'student_id'
    ).annotate(total_assigned=Count('id'))
    assigned_tests_dict = {entry['student_id']: entry['total_assigned'] for entry in assigned_tests_count}

    # Group by student and aggregate data
    grouped_data = {}
    for test in tests_candidates:
        student_id = test.student_id.id if test.student_id else None
        if not student_id:
            continue

        if student_id not in grouped_data:
            grouped_data[student_id] = {
                'student_name': test.student_id.students_name if test.student_id else None,
                'registration_number': test.student_id.registration_number if test.student_id else None,
                'year': test.year,
                'department': test.department_id.department if test.department_id else None,
                'total_tests_taken': 0,
                'test_breakdown': {},  # Breakdown by question_type
                'test_skill':{},
                'total_assigned_tests': assigned_tests_dict.get(student_id, 0)  # Fetch total tests assigned
            }

        # Determine the question type
        question_type = test_master_data.get(test.test_name, "Unknown")
        skill_type = test_master_skill.get(test.test_name, "Unknown")

        # Update the test count for the specific question type
        if question_type not in grouped_data[student_id]['test_breakdown']:
            grouped_data[student_id]['test_breakdown'][question_type] = 0
        grouped_data[student_id]['test_breakdown'][question_type] += 1

        if skill_type not in grouped_data[student_id]['test_skill']:
            grouped_data[student_id]['test_skill'][skill_type] = 0
        grouped_data[student_id]['test_skill'][skill_type] += 1

        # Increment the total test count
        grouped_data[student_id]['total_tests_taken'] += 1

    # Prepare the response data
    response_data = []
    for student_id, student_data in grouped_data.items():
        # Calculate average
        total_assigned = student_data['total_assigned_tests']
        total_taken = student_data['total_tests_taken']
        average = (total_taken / total_assigned) * 100 if total_assigned > 0 else 0

        response_data.append({
            'student_name': student_data['student_name'],
            'reg_no': student_data['registration_number'],
            'year': student_data['year'],
            'department': student_data['department'],
            'total_tests_taken': total_taken,
            'test_assigned':total_assigned,
            'test_breakdown': student_data['test_breakdown'],  # Breakdown by question type
            'test_skills':student_data['test_skill'],
            'average': round(average, 2)  # Include calculated average with two decimal points
        })

    return Response(response_data)
@api_view(['GET'])
@cache_page(60 * 60) 
def get_candidateoverall_testReports(request):
    from_date = request.GET.get('from_date')
    to_date = request.GET.get('to_date')
    student_id = request.GET.get('student_id')
    college_id = request.GET.get('college_id')

    if not student_id:
        return Response({"error": "student_id is required."}, status=400)

    # Parse dates
    try:
        if from_date:
            from_date = datetime.strptime(from_date, '%Y-%m-%d')
        if to_date:
            to_date = datetime.strptime(to_date, '%Y-%m-%d')
    except ValueError:
        return Response({"error": "Invalid date format. Use YYYY-MM-DD."}, status=400)

    # Build filters
    filters = {
        "deleted": 0,
        "is_active": True,
        "student_id": student_id
    }
    if from_date:
        filters["dtm_end__date__gte"] = from_date.date()
    if to_date:
        filters["dtm_end__date__lte"] = to_date.date()
    if college_id:
        filters["college_id"] = college_id

    # Fetch test type mappings once
    test_master_qs = test_master.objects.values('test_name', 'question_type_id__question_type', 'skill_type_id__skill_type')
    test_type_lookup = {
        tm['test_name']: {
            'question_type': tm['question_type_id__question_type'] or "Unknown",
            'skill_type': tm['skill_type_id__skill_type'] or "Unknown"
        } for tm in test_master_qs
    }

    # Assigned test counts per test name
    assigned_counts_qs = tests_candidates_map.objects.filter(deleted=0).exclude(created_by='Student').values('test_name').annotate(total=Count('id'))
    assigned_counts_dict = {item['test_name']: item['total'] for item in assigned_counts_qs}

    # Filtered test records for the student
    tests_qs = tests_candidates_map.objects.select_related(
        'student_id', 'college_id', 'department_id'
    ).filter(**filters)

    student_data = {}
    for test in tests_qs:
        sid = test.student_id.id
        if sid not in student_data:
            student_data[sid] = {
                'student_id': sid,
                'student_name': test.student_id.students_name,
                'registration_number': test.student_id.registration_number,
                'year': test.year,
                'college_name': test.college_id.college if test.college_id else None,
                'department': test.department_id.department if test.department_id else None,
                'total_tests_taken': 0,
                'question_type_counts': {},
                'skill_type_counts': {},
                'question_type_assigned': {},
                'skill_type_assigned': {}
            }

        test_info = test_type_lookup.get(test.test_name, {'question_type': 'Unknown', 'skill_type': 'Unknown'})
        question_type = test_info['question_type']
        skill_type = test_info['skill_type']
        assigned = assigned_counts_dict.get(test.test_name, 0)

        # Question Type Counts
        qt_counts = student_data[sid]['question_type_counts']
        qt_assigned = student_data[sid]['question_type_assigned']
        qt_counts[question_type] = qt_counts.get(question_type, 0) + 1
        qt_assigned[question_type] = assigned

        # Skill Type Counts
        st_counts = student_data[sid]['skill_type_counts']
        st_assigned = student_data[sid]['skill_type_assigned']
        st_counts[skill_type] = st_counts.get(skill_type, 0) + 1
        st_assigned[skill_type] = assigned

        student_data[sid]['total_tests_taken'] += 1

    # Get total assigned tests per student
    assigned_total_qs = tests_candidates_map.objects.filter(
        deleted=0
    ).values('student_id').annotate(total_assigned=Count('id'))
    assigned_total_dict = {item['student_id']: item['total_assigned'] for item in assigned_total_qs}

    # Build response
    response_data = []
    for sid, data in student_data.items():
        total_taken = data['total_tests_taken']
        total_assigned = assigned_total_dict.get(sid, 0)
        overall_avg = round((total_taken / total_assigned) * 100, 2) if total_assigned > 0 else 0

        # Feedback
        if overall_avg > 85:
            feedback = "Excellent"
        elif overall_avg > 60:
            feedback = "Good"
        elif overall_avg > 45:
            feedback = "Need to Focus"
        elif overall_avg > 30:
            feedback = "Need Improvement"
        else:
            feedback = "Very Poor"

        # Combine dynamic test stats
        dynamic_data = {}

        for qtype, count in data['question_type_counts'].items():
            assigned = data['question_type_assigned'].get(qtype, 0)
            avg = round(min((count / max(assigned, 1)) * 100, 100), 2) if assigned > 0 else 0
            dynamic_data[f"Total {qtype} Tests Taken"] = count
            dynamic_data[f"{qtype} Average"] = avg

        for stype, count in data['skill_type_counts'].items():
            assigned = data['skill_type_assigned'].get(stype, 0)
            avg = round(min((count / max(assigned, 1)) * 100, 100), 2) if assigned > 0 else 0
            dynamic_data[f"Total {stype} Tests Taken"] = count
            dynamic_data[f"{stype} Average"] = avg

        response_data.append({
            'student_id': sid,
            'student_name': data['student_name'],
            'reg_no': data['registration_number'],
            'year': data['year'],
            'department': data['department'],
            'total_tests_taken': total_taken,
            'college_name': data['college_name'],
            'overall_average': overall_avg,
            'feedback': feedback,
            **dynamic_data
        })

    return Response(response_data)
@api_view(['GET'])
@cache_page(60 * 60) 
def get_all_testReports(request):
    print("API Called: get_all_testReports")

    # Extract parameters
    from_date = request.GET.get('from_date')
    to_date = request.GET.get('to_date')
    student_id = request.GET.get('student_id')
    college_id = request.GET.get('college_id')

    # Validate mandatory `student_id`
    if not student_id:
        return Response({"error": "Student ID is mandatory"}, status=400)

    # Validate and parse dates
    try:
        if from_date:
            from_date = datetime.strptime(from_date, '%Y-%m-%d')
        if to_date:
            to_date = datetime.strptime(to_date, '%Y-%m-%d')
    except ValueError:
        return Response({"error": "Invalid date format. Use YYYY-MM-DD."}, status=400)

    # Apply filters
    filters = {"deleted": 0, "is_active": True, "student_id": student_id}
    if from_date:
        filters["dtm_end__date__gte"] = from_date.date()
    if to_date:
        filters["dtm_end__date__lte"] = to_date.date()
    if college_id:
        filters["student_id__college_id"] = college_id

    # Fetch test records with selective fields
    tests_candidates = (
        tests_candidates_map.objects.filter(**filters)
        .exclude(created_by='Student') 
        .select_related('student_id', 'student_id__college_id')
        .only(
            'student_id__students_name',
            'student_id__registration_number',
            'student_id__college_id__college',
            'test_name',
            'dtm_end',
            'avg_mark'
        )
    )

    if not tests_candidates.exists():
        return Response({"message": "No test reports found"}, status=404)

    # Fetch test_master details in a single query
    test_master_details = {
        test["test_name"]: {
            "skill_type": test["skill_type_id__skill_type"] or "Unknown",
            "question_type": test["question_type_id__question_type"] or "Unknown"
        }
        for test in test_master.objects.values(
            "test_name", "skill_type_id__skill_type", "question_type_id__question_type"
        )
    }

    # Prepare response
    response_data = []
    for test in tests_candidates:
        student = test.student_id

        test_info = test_master_details.get(
            test.test_name, {"skill_type": "Unknown", "question_type": "Unknown"}
        )

        response_data.append({
            "student_name": student.students_name,
            "college_name": student.college_id.college if student.college_id else None,
            "registration_number": student.registration_number,
            "test_name": test.test_name,
            "skill_type": test_info["skill_type"],
            "question_type": test_info["question_type"],
            "dtm_end": test.dtm_end.strftime('%Y-%m-%d') if test.dtm_end else None,
            "avg_mark": test.avg_mark or 0,
            "feedback": (
                "Excellent" if (test.avg_mark or 0) > 85 else
                "Good" if (test.avg_mark or 0) > 60 else
                "Need to Focus" if (test.avg_mark or 0) > 45 else
                "Need Improvement" if (test.avg_mark or 0) > 30 else
                "Very Poor"
            ),
        })

    return Response(response_data)


def get_unique_students(request):
    # Get the college_id from the request (assumes it's passed as a query parameter)
    college_id = request.GET.get('college_id')

    if not college_id:
        return JsonResponse({'error': 'college_id is required'}, status=400)

    try:
        # Query distinct student IDs, names, and registration numbers for the specific college
        students = candidate_master.objects.filter(college_id=college_id,deleted=0).values('id', 'students_name', 'registration_number').distinct()

        # Prepare data to be returned in the dropdown format
        student_data = [{'student_id': student['id'], 'students_name': student['students_name'], 'registration_number': student['registration_number']} for student in students]

        return JsonResponse(student_data, safe=False)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


from datetime import datetime

#_____________________________________selvi newly added_____________________________________#
       

class GetCompanyEmailView(APIView):
    def get(self, request):
        test_name = request.query_params.get('test_name')
        
        if not test_name:
            return Response({"error": "test_name parameter is required"}, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            test_instance = test_master.objects.get(test_name=test_name,deleted=0)
            print(f"Retrieved test_instance: {test_instance}")
            print(f"Company Name: {test_instance.company_name}")
            
            return Response({
                "company_email": test_instance.company_email,
                "company_name": test_instance.company_name,
                "round_of_interview": test_instance.round_of_interview,
                "student_ids": test_instance.student_ids,
            }, status=status.HTTP_200_OK)
        except test_master.DoesNotExist:
            return Response({"error": "Test not found"}, status=status.HTTP_404_NOT_FOUND)


class UpdateCompanyEmailView(APIView):
    def put(self, request):
        print("Received PUT request to update company email.")

        # Retrieve `test_name`, `company_email`, and `excel_file` from the request
        test_name = request.query_params.get('test_name')
        company_email = request.data.get('company_email')
        company_name = request.data.get('company_name')
        excel_file = request.FILES.get('excel_file')
        round_of_interview = request.data.get('round_of_interview')
        print(f"Extracted test_name: {test_name}")
        print(f"Extracted company_email: {company_email}")
        print(f"Excel file provided: {'Yes' if excel_file else 'No'}")
        print(f"Extracted round_of_interview: {round_of_interview}")
        # Check for missing parameters
        if not test_name:
            print("Error: test_name parameter is missing.")
            return Response({"error": "test_name parameter is required"}, status=status.HTTP_400_BAD_REQUEST)
        if not company_email:
            print("Error: company_email is missing.")
            return Response({"error": "company_email is required"}, status=status.HTTP_400_BAD_REQUEST)
        if not round_of_interview:
            print("Error: round_of_interview is missing.")
            return Response({"error": "round_of_interview is required"}, status=status.HTTP_400_BAD_REQUEST)

        if not excel_file:
            print("Error: Excel file is missing.")
            return Response({"error": "Excel file is required"}, status=status.HTTP_400_BAD_REQUEST)

        # Validate and update test instance
        try:
            test_instance = test_master.objects.get(test_name=test_name,deleted=0)
            print(f"Found test instance for test_name: {test_name}")
        except test_master.DoesNotExist:
            print(f"Error: Test instance not found for test_name: {test_name}")
            return Response({"error": "Test not found"}, status=status.HTTP_404_NOT_FOUND)

        # Serialize and update company email
        serializer = TestMasterEmailUpdateSerializer(test_instance, data={"company_email": company_email,"company_name":company_name,"round_of_interview": round_of_interview},  partial=True)
        if serializer.is_valid():
            print("Serializer is valid. Updating company email.")
            serializer.save()
            print("Company email updated successfully.")

            # Prepare to send email with Excel file attached
            email = EmailMessage(
                subject="Test Results",
                body="Please find attached the test results.",
                from_email=settings.DEFAULT_FROM_EMAIL,  # Using default from email
                to=[company_email]
            )
            print("Created email message.")

            email.attach(excel_file.name, excel_file.read(), 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
            print(f"Attached Excel file: {excel_file.name}")

            email.send()
            print("Email sent successfully to:", company_email)

            return Response({"success": "Company email updated and file sent successfully"}, status=status.HTTP_200_OK)
        
        # Print serializer errors if validation fails
        print("Error: Serializer validation failed. Errors:", serializer.errors)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@api_view(['GET'])
def get_test_reports_placementofficer(request):
    # Get filter parameters from the request
    test_name = request.GET.get('test_name')
    college_id = request.GET.get('college_id')
    department_id = request.GET.get('department_id')
    year = request.GET.get('year')

    # Start with filtering out deleted reports
   # reports = test_reports.objects.filter(deleted=0)
    # Filter reports where deleted=0 and join with test_master to ensure is_company=False
    reports = test_reports.objects.filter(deleted=0, test_name__in=test_master.objects.filter(is_company=False).values('test_name'))

    # Apply additional filters if provided
    if test_name:
        reports = reports.filter(test_name=test_name)
    if college_id:
        reports = reports.filter(college_id=college_id)
    if department_id:
        reports = reports.filter(department_id=department_id)
    if year:
        reports = reports.filter(year=year)

    # Subquery to fetch dtm_start and dtm_end from tests_candidates_map based on test_name
    test_candidate_map = tests_candidates_map.objects.filter(
        test_name=OuterRef('test_name'),deleted=0
    ).values('dtm_start', 'dtm_end')

    dtm_start_subquery = Subquery(test_candidate_map.values('dtm_start')[:1])
    dtm_end_subquery = Subquery(test_candidate_map.values('dtm_end')[:1])

    # Annotate the reports with dtm_start and dtm_end
    reports = reports.annotate(
        dtm_start=dtm_start_subquery,
        dtm_end=dtm_end_subquery
    )

    # Prepare data based on grouping conditions
    if test_name and not (college_id or department_id or year):
        grouped_reports = reports.values('test_name', 'dtm_start', 'dtm_end').annotate(total_students=Sum('students_count'))

        data = [
            {
                'test_name': report['test_name'],
                'college_name': 'All',
                'department_name': 'All',
                'year': 'All',
                'total_students': report['total_students'],
                'dtm_start': report['dtm_start'],
                'dtm_end': report['dtm_end']
            } 
            for report in grouped_reports
        ]
    elif college_id and not (department_id or year):
        grouped_reports = reports.values('test_name', 'college_id', 'college_id__college', 'dtm_start', 'dtm_end').annotate(total_students=Sum('students_count'))

        data = [
            {
                'test_name': report['test_name'],
                'college_name': report['college_id__college'],
                'department_name': 'All',
                'year': 'All',
                'total_students': report['total_students'],
                'dtm_start': report['dtm_start'],
                'dtm_end': report['dtm_end']
            }
            for report in grouped_reports
        ]
    else:
        grouped_reports = reports.values(
            'test_name',
            'college_id', 'college_id__college',
            'department_id', 'department_id__department',
            'year',
            'dtm_start',
            'dtm_end'
        ).annotate(total_students=Sum('students_count'))

        data = [
            {
                'test_name': report['test_name'],
                'college_name': report['college_id__college'] if college_id else 'All',
                'department_name': report['department_id__department'] if department_id else 'All',
                'year': report['year'] if year else 'All',
                'total_students': report['total_students'],
                'dtm_start': report['dtm_start'],
                'dtm_end': report['dtm_end']
            }
            for report in grouped_reports
        ]

    # Log the grouped report for debugging
    # logger.error(f'Grouped Reports: {grouped_reports}')

    # Return the serialized data
    return Response(data)


class UpdateStudentRoundView(APIView):
    def post(self, request):
        student_ids = request.data.get('student_ids')
        round_of_interview = request.data.get('round_of_interview')

        if not student_ids or not round_of_interview:
            return Response({"error": "Student IDs and round of interview are required"}, status=status.HTTP_400_BAD_REQUEST)

        # Update the students' round of interview
        try:
            students = test_master.objects.filter(id__in=student_ids,deleted=0)
            students.update(round_of_interview=round_of_interview)
            return Response({"success": "Student rounds updated successfully"}, status=status.HTTP_200_OK)
        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_400_BAD_REQUEST)


class UpdateTestRoundView(APIView):
    def put(self, request):
        # Step 1: Extract test_name from query parameters
        test_name = request.query_params.get('test_name')
        print(f"Received test_name: {test_name}")
        
        if not test_name:
            return Response({"error": "test_name parameter is required"}, status=status.HTTP_400_BAD_REQUEST)

        # Step 2: Retrieve the test_master instance based on test_name
        try:
            test_instance = test_master.objects.get(test_name=test_name)
            print(f"Test instance found: {test_instance}")
        except test_master.DoesNotExist:
            print("Test not found")
            return Response({"error": "Test not found"}, status=status.HTTP_404_NOT_FOUND)

        # Step 3: Extract fields from the request data
        student_ids = request.data.get('student_ids')
        round_of_interview = request.data.get('round_of_interview')
        company_name = request.data.get('company_name')
        
        print(f"Received student_ids: {student_ids}")
        print(f"Received round_of_interview: {round_of_interview}")
        print(f"Received company_name: {company_name}")

        # Validate mandatory fields
        if not student_ids:
            return Response({"error": "student_ids are required"}, status=status.HTTP_400_BAD_REQUEST)
        if not round_of_interview:
            return Response({"error": "round_of_interview is required"}, status=status.HTTP_400_BAD_REQUEST)
        if not company_name:
            return Response({"error": "company_name is required"}, status=status.HTTP_400_BAD_REQUEST)

        # Step 4: Convert student_ids to list if they are passed as JSON string
        if isinstance(student_ids, str):
            try:
                student_ids = json.loads(student_ids)
                print(f"Parsed student_ids: {student_ids}")
            except json.JSONDecodeError:
                print("Invalid JSON format for student_ids")
                return Response({"error": "Invalid JSON format for student_ids"}, status=status.HTTP_400_BAD_REQUEST)

        # Step 5: Update test_master instance using serializer
        update_data = {
            "student_ids": student_ids,
            "round_of_interview": round_of_interview,
            "company_name": company_name,
        }
        serializer = TestroundUpdateSerializer(test_instance, data=update_data, partial=True)
        
        if serializer.is_valid():
            serializer.save()
            print("Serializer saved successfully")
        else:
            print(f"Serializer errors: {serializer.errors}")
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        # Step 6: Update round_of_interview in eligible_student_list for matching entries
        print("Updating eligible_student_list...")
        eligible_students = eligible_student_list.objects.filter(
            students_id__in=student_ids,
            job_id__company_name=company_name,
            is_eligible=True
        )

        for student in eligible_students:
            student.round_of_interview = round_of_interview
            student.save()
            print(f"Updated student {student.students_id} with round_of_interview {round_of_interview}")

        # Step 7: Return success response
        print("Test round and related fields updated successfully")
        return Response({"success": "Test round and related fields updated successfully"}, status=status.HTTP_200_OK)

from django.db import transaction


def get_college_instance(college_name, college_group=None):
    """
    Retrieve the college instance based on college name and optionally college_group.
    If multiple entries exist for the same college name, require college_group.
    """
    colleges = college_master.objects.filter(college=college_name,deleted=0)
    
    if colleges.count() > 1:
        # Multiple entries found, require college_group
        if college_group:
            college = colleges.filter(college_group=college_group).first()
            if college:
                return college
            else:
                raise ValueError(f"College group '{college_group}' not found for college '{college_name}'.")
        else:
            raise ValueError(f"Multiple groups found for college '{college_name}'. Please specify a college group.")
    elif colleges.exists():
        # Only one entry found, return it
        return colleges.first()
    else:
        raise ValueError(f"College '{college_name}' not found.")

def update_in_memory_data(user_name, row, current_date_time):
    """
    Updates login and candidate records based on user_name and data from row.
    """
    try:
        # Get the college instance from college and optional college_group
        college_instance = None
        if 'college_id' in row and pd.notna(row['college_id']):
            college = row['college_id']
            college_group = row['college_group'] if 'college_group' in row and pd.notna(row['college_group']) else None
            college_instance = get_college_instance(college, college_group)

        if college_instance:
            print(f"Fetched college instance: {college_instance.college} with id {college_instance.id}")
        else:
            print("No valid college instance found!")

        # Retrieve and update login model data
        login_obj = login.objects.filter(user_name=user_name,deleted=0).first()
        if login_obj:
            if 'password' in row and pd.notna(row['password']):
                login_obj.password = row['password']  # Note: hash password in production
            if college_instance:
                login_obj.college = college_instance  # Update the college field correctly
                print(f"Updating login college for user '{user_name}' to college_id '{college_instance.id}'")
            login_obj.role = 'Student'

        # Retrieve and update candidate model data
        candidate_obj = candidate_master.objects.filter(user_name=user_name,deleted=0).first()
        if candidate_obj:
            if college_instance:
                candidate_obj.college = college_instance  # Update the college field
                print(f"Updating candidate college for user '{user_name}' to college_id '{college_instance.id}'")
            candidate_obj.batch_no = row['batch_no'] if 'batch_no' in row and pd.notna(row['batch_no']) else candidate_obj.batch_no
            candidate_obj.is_database = False
            candidate_obj.dtm_upload = current_date_time

        # Wrap in transaction.atomic() to ensure all operations are saved together
        with transaction.atomic():
            if login_obj:
                login_obj.save()  # Save updated login record
                print(f"Saved updated login for user '{user_name}'")
            
            if candidate_obj:
                candidate_obj.save()  # Save updated candidate record
                print(f"Saved updated candidate for user '{user_name}'")

        print(f"Successfully updated data for user '{user_name}'")

    except ValueError as ve:
        print(f"Error updating data for user '{user_name}': {str(ve)}")
    except Exception as e:
        print(f"Unexpected error updating data for user '{user_name}': {str(e)}")



class ExcelUpdateView_Candidateuser(APIView):
    def post(self, request, format=None):
        print("Starting Excel Update Process...")
        
        # Initialize current date and time using timezone-aware method
        current_date_time = timezone.now()
        print('current_date_time:', current_date_time)
        
        # Check if file is present in the request
        if 'file' not in request.FILES:
            print("Error: No file uploaded.")
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)
        
        file = request.FILES['file']
        
        # Check if file is in Excel format
        if not file.name.endswith('.xlsx'):
            print("Error: File is not in Excel format.")
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            df = pd.read_excel(file)
            print("File read successfully.")
        except Exception as e:
            print(f"Error reading file: {str(e)}")
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)
        
        # Check required columns
        if 'user_name' not in df.columns or df['user_name'].isnull().any():
            print("Error: 'user_name' column is missing or contains null values.")
            return Response({'error': "'user_name' column is required and cannot contain null values."}, status=status.HTTP_400_BAD_REQUEST)

        # Process each row and update records
        update_results = []
        for index, row in df.iterrows():
            user_name = row['user_name']
            update_status = update_in_memory_data(user_name, row, current_date_time)
            update_results.append({
                'user_name': user_name,
                'updated': update_status
            })

        # Filter results for successful and failed updates
        successful_updates = [result['user_name'] for result in update_results if result['updated']]
        failed_updates = [result['user_name'] for result in update_results if not result['updated']]

        print("Excel Update Process completed.")
        return Response({
            'successful_updates': successful_updates,
            'failed_updates': failed_updates
        }, status=status.HTTP_200_OK)



class ExcelupdateImport_userCollege(APIView):
    def post(self, request, format=None):
        print("Starting Excel Import Process...")

        # Expected column order
        expected_columns = ['user_name', 'password', 'batch_no']

        # Fetch college_id from query parameters
        college_id = request.query_params.get('college_id', None)
        if college_id is None:
            print("Error: 'college_id' query parameter is missing.")
            return Response({'error': "'college_id' query parameter is required"}, status=status.HTTP_400_BAD_REQUEST)

        try:
            # Ensure the college_id corresponds to an existing college_master instance
            college_instance = get_object_or_404(college_master, pk=college_id)
        except Exception as e:
            print(f"Error: {str(e)}")
            return Response({'error': 'Invalid college_id or college does not exist'}, status=status.HTTP_400_BAD_REQUEST)

        # Check if file is present in the request
        if 'file' not in request.FILES:
            print("Error: No file uploaded.")
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']

        # Check if file is in Excel format
        if not file.name.endswith('.xlsx'):
            print("Error: File is not in Excel format.")
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            # Read the Excel file into a DataFrame
            df = pd.read_excel(file)
            print("File read successfully.")
        except Exception as e:
            print(f"Error reading file: {str(e)}")
            return Response({'error': f"Error reading file: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)

        # Validate columns
        if list(df.columns) != expected_columns:
            print(f"Invalid column format. Expected: {expected_columns}, Provided: {list(df.columns)}")
            return Response({
                'error': 'Invalid column format.',
                'expected_columns': expected_columns,
                'provided_columns': list(df.columns)
            }, status=status.HTTP_400_BAD_REQUEST)

        # Reorder columns (if necessary)
        df = df[expected_columns]
        print("Columns validated and reordered successfully.")

        # Prepare current date and time
        current_date_time = timezone.now()

        # Track updated and newly created records
        updated_logins = []
        updated_candidates = []
        new_logins = []
        new_candidates = []

        # Start transaction block
        try:
            with transaction.atomic():
                for index, row in df.iterrows():
                    user_name = row['user_name']
                    password = row['password']
                    batch_no = row['batch_no']

                    # Update or Create login entry
                    login_instance, created = login.objects.update_or_create(
                        user_name=user_name,
                        defaults={
                            'password': password,
                            'college_id': college_instance,  # Pass the instance, not the id
                            'role': 'Student'
                        }
                    )
                    if created:
                        new_logins.append(user_name)
                        print(f"New login created: {user_name}")
                    else:
                        updated_logins.append(user_name)
                        print(f"Login updated: {user_name}")

                    # Update or Create candidate entry
                    candidate_instance, created = candidate_master.objects.update_or_create(
                        user_name=user_name,
                        defaults={
                            'batch_no': batch_no,
                            'college_id': college_instance,  # Pass the instance, not the id
                            'is_database': False,
                            'dtm_upload': current_date_time
                        }
                    )
                    if created:
                        new_candidates.append(user_name)
                        print(f"New candidate created: {user_name}")
                    else:
                        updated_candidates.append(user_name)
                        print(f"Candidate updated: {user_name}")

        except Exception as e:
            print(f"Transaction failed: {str(e)}")
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Return success response
        print("Import and update process completed successfully.")
        return Response({
            'message': "Import process completed successfully.",
            'new_logins': new_logins,
            'updated_logins': updated_logins,
            'new_candidates': new_candidates,
            'updated_candidates': updated_candidates
        }, status=status.HTTP_200_OK)
class TestAssignviewBatch(APIView):
    def post(self, request, format=None):
        print("‚úÖ [TestAssignviewBatch] Received POST request")
        print("üì• Raw request data:", request.data)
        test_name = request.data.get('test_name')
        test_type_id = request.data.get('test_type_id')
        question_type_id = request.data.get('question_type_id')
        created_by = request.data.get('created_by', 'System')
        skill_type_id = request.data.get('skill_type_id')
        company_name = request.data.get('company_name')
        company_email = request.data.get('company_email')

        if not all([test_name, test_type_id, question_type_id]):
            return Response({'error': 'Missing fields for test_master'}, status=status.HTTP_400_BAD_REQUEST)

        # ‚úÖ Get test_type instance
        try:
            test_type_instance = test_type.objects.get(id=test_type_id, deleted=0)
        except test_type.DoesNotExist:
            return Response({'error': 'Invalid test_type_id'}, status=status.HTTP_400_BAD_REQUEST)

        # ‚úÖ Detect company type
        is_company = test_type_instance.test_type_categories == "Mock/Interview"

        # ‚úÖ Get related objects (question_type & skill_type)
        try:
            question_type_instance = question_type.objects.get(id=question_type_id, deleted=0)
        except question_type.DoesNotExist:
            return Response({'error': 'Invalid question_type_id'}, status=status.HTTP_400_BAD_REQUEST)

        skill_type_instance = None
        if skill_type_id:
            try:
                skill_type_instance = skill_type.objects.get(id=skill_type_id, deleted=0)
            except skill_type.DoesNotExist:
                return Response({'error': 'Invalid skill_type_id'}, status=status.HTTP_400_BAD_REQUEST)

        # ‚úÖ Create/Update test_master
        test_master_instance, created = test_master.objects.update_or_create(
            test_name=test_name,
            defaults={
                'test_type_id': test_type_instance,     # üëà instance, not raw ID
                'question_type_id': question_type_instance,
                'skill_type_id': skill_type_instance,
                'is_company': is_company,
                'company_name': company_name,
                'company_email': company_email,
                'created_by': created_by,
            }
        )

        # üéØ Get students
        students = candidate_master.objects.filter(is_database=True, deleted=0)

        if request.data.get('college_id'):
            students = students.filter(college_id__in=request.data.get('college_id'))

        if request.data.get('department_id'):
            students = students.filter(department_id__in=request.data.get('department_id'))

        if request.data.get('year'):
            students = students.filter(year__in=request.data.get('year'))

        if request.data.get('batch_no'):
            students = students.filter(batch_no__in=request.data.get('batch_no'))

        if not students.exists():
            return Response({'error': 'No students match the provided criteria.'}, status=status.HTTP_404_NOT_FOUND)

        data = []
        updated_candidates = []
        current_date_and_time = datetime.now()

        for student in students:
            if not student.department_id or not student.college_id:
                continue

            # ‚úÖ Check duplicate (student_id + test_name)
            existing_map = tests_candidates_map.objects.filter(
                student_id=student.id,
                test_name=test_name
            ).first()

            if existing_map:
                # Update existing record if needed
                existing_map.dtm_start = request.data.get('dtm_start')
                existing_map.dtm_end = request.data.get('dtm_end')
                existing_map.duration = request.data.get('duration')
                existing_map.duration_type = request.data.get('duration_type')
                existing_map.rules_id = request.data.get('rules_id')
                existing_map.need_candidate_info = request.data.get('need_candidate_info')
                existing_map.is_camera_on = request.data.get('is_camera_on')
                existing_map.save(update_fields=[
                    'dtm_start', 'dtm_end', 'duration', 'duration_type',
                    'rules_id', 'need_candidate_info', 'is_camera_on'
                ])
                data.append({"updated": existing_map.id})
                continue

            # ‚úÖ Otherwise create new
            test_candidate_data = {
                'test_name': test_name,
                'question_id': request.data.get('question_id'),
                'student_id': student.id,
                'college_id': student.college_id.id,
                'department_id': student.department_id.id,
                'dtm_start': request.data.get('dtm_start'),
                'dtm_end': request.data.get('dtm_end'),
                'dtm_start1': request.data.get('dtm_start'),
                'dtm_end1': request.data.get('dtm_end'),
                'is_camera_on': request.data.get('is_camera_on'),
                'duration': request.data.get('duration'),
                'duration_type': request.data.get('duration_type'),
                'year': student.year,
                'rules_id': request.data.get('rules_id'),
                'need_candidate_info': request.data.get('need_candidate_info'),
                'dtm_created': timezone.now(),
                'created_by': created_by
            }
            # print("üßæ test_candidate_dathhhha:", test_candidate_data)


            serializer = testcandidatemapSerializers(data=test_candidate_data)
            if serializer.is_valid():
                serializer.save()
                data.append(serializer.data)

                # Update student if needed
                if student.need_candidate_info is None and request.data.get('need_candidate_info') is True:
                    student.need_candidate_info = True
                    student.save(update_fields=['need_candidate_info'])
                    updated_candidates.append(student.id)
            else:
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        return Response({"test_master": test_master_instance.id, "candidates": data}, status=status.HTTP_200_OK)


@api_view(['GET'])
def get_distinct_dtm_uploads_cc(request):
    try:
        college_id = request.GET.get('college_id')
        college_group_id = request.GET.get('college_group_id')
        batch_no = request.GET.get('batch_no')

        print('college_id: ', college_id)
        print('college_group_id: ', college_group_id)
        print('batch_no: ', batch_no)

        # Filter the candidate_master table based on college_id and is_database = False
        query = candidate_master.objects.filter(is_database=False,deleted=0)

        if college_id:
            query = query.filter(college_id__in=college_id.split(','))

        # if college_group_id:
        #     query = query.filter(college_id__in=college_group_id.split(','))

        if batch_no:
            query = query.filter(batch_no=batch_no)

        distinct_dtm_uploads = (
            query.order_by('-dtm_upload')
            .values_list('dtm_upload', flat=True)
            .distinct()
        )

        # Return the distinct dtm_upload values
        return Response({
            'distinct_dtm_uploads': list(distinct_dtm_uploads)
        }, status=status.HTTP_200_OK)

    except Exception as e:
        # Handle any errors
        return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)


#--------------Test Assign--------------#

@api_view(['GET'])
def get_college_group_by_college(request):
    clg_name = request.query_params.get('college_name')
    print('clg_name: ', clg_name)

    # Validate the college name input
    if not clg_name:
        return Response({'error': 'College name is required.'}, status=status.HTTP_400_BAD_REQUEST)

    # Fetch the id and college_group for the given college name, ensuring college_group is not null or empty
    college_groups = college_master.objects.filter(
        college=clg_name,
        college_group__isnull=False,deleted=0
    ).exclude(college_group='').values('id', 'college_group')

    # If no data is found, return a meaningful response
    if not college_groups.exists():
        return Response({'message': f'No groups found for college "{clg_name}".'}, status=status.HTTP_404_NOT_FOUND)

    # Return the valid college groups
    return Response(list(college_groups), status=status.HTTP_200_OK)
@api_view(['GET'])
def get_candidate_batches(request):
    # Retrieve query parameters
    college_names = request.query_params.getlist('colleges', [])
    college_ids = request.query_params.getlist('college_id', [])

    # Log the received parameters for debugging
    print('college_ids:', college_ids)
    print('college_names:', college_names)

    # Initialize the queryset
    queryset = candidate_master.objects.filter(batch_no__isnull=False, college_id__college__in=college_names, is_database=True,deleted=0)

    if college_ids:
        queryset = queryset.filter(college_id__in=college_ids)

    # Get distinct batch numbers
    batch_numbers = queryset.values('batch_no').distinct()

    # Return the result as a list of dictionaries
    return Response(list(batch_numbers))

@api_view(['GET'])
def get_department_info_test(request):
    college_ids = request.query_params.getlist('college_id')  # Retrieve college_ids from query parameters
    print('college_ids Dept checking..: ', college_ids)

    if not college_ids:
        return Response({"error": "No college_ids provided"}, status=status.HTTP_400_BAD_REQUEST)
    
    try:
        # Debug: Print what we are querying
        print(f"Filtering for college_ids: {college_ids}")

        results = candidate_master.objects.filter(
            college_id__college__in=college_ids,
            department_id__isnull=False,deleted=0
        ).values(
            'department_id__id',
            'department_id__department'
        ).distinct()

        print(f"Query Results: {list(results)}")  # Debugging

        return Response(results, status=status.HTTP_200_OK)

    except Exception as e:
        print(f"Error: {str(e)}")  # Debugging
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

@api_view(['GET'])
def get_department_info_test_cum(request):
    college_ids = request.query_params.getlist('college_id')  # Retrieve college_ids from query parameters
    print('college_ids Dept checking..: ', college_ids)

    if not college_ids:
        return Response({"error": "No college_ids provided"}, status=status.HTTP_400_BAD_REQUEST)
    
    try:
        # Debug: Print what we are querying
        print(f"Filtering for college_ids: {college_ids}")

        results = candidate_master.objects.filter(
            college_id__id__in=college_ids,
            department_id__isnull=False,deleted=0
        ).values(
            'department_id__id',
            'department_id__department'
        ).distinct()

        print(f"Query Results: {list(results)}")  # Debugging

        return Response(results, status=status.HTTP_200_OK)

    except Exception as e:
        print(f"Error: {str(e)}")  # Debugging
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_distinct_dtm_uploads_test(request):
    try:
        college_ids = request.query_params.getlist('college_id') 
        # Filter the candidate_master table based on college_id and is_database = False
        distinct_dtm_uploads = candidate_master.objects.filter(
            Q(college_id__college__in=college_ids) & Q(is_database=False) & Q(deleted=0)
        ).order_by('-dtm_upload').values_list('dtm_upload', flat=True).distinct()

        # Return the distinct dtm_upload values
        return Response({
            'distinct_dtm_uploads': list(distinct_dtm_uploads)
        }, status=status.HTTP_200_OK)

    except Exception as e:
        # Handle any errors
        return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)




#_________________________________27-11-24 corporate________________________________#

@csrf_exempt
def add_company(request):
    if request.method == 'POST':
        form = CompanyForm(request.POST, request.FILES)

        if form.is_valid():
            user_name = form.cleaned_data.get('user_name')
            email_id = form.cleaned_data.get('email_id')
            password = form.cleaned_data.get('password')
            uploaded_logo = request.FILES.get('company_logo')
            college_ids = form.cleaned_data.get('college_id')  # ManyToManyField

            # Ensure user_name is unique in company_login
            if company_login.objects.filter(user_name=user_name,deleted=0).exists():
                return render(request, 'add_company.html', {
                    'form': form,
                    'error': 'User name must be unique'
                })

            # Mandatory fields validation
            if not form.cleaned_data.get('company_name') or not password:
                return render(request, 'add_company.html', {
                    'form': form,
                    'error': 'Company name and password are mandatory'
                })

            try:
                with transaction.atomic():
                    # Save company object without committing
                    company = form.save(commit=False)

                    # If you're storing binary logo instead of ImageField
                    if uploaded_logo:
                        company.company_logo = uploaded_logo.read()  # Binary field
                        # If using ImageField in model, just do: company.company_logo = uploaded_logo

                    company.save()

                    # Save ManyToMany relationship
                    if college_ids:
                        company.college_id.set(college_ids)  # Proper way for ManyToManyField

                    # Create login entry
                    login.objects.create(
                        email_id=email_id,
                        user_name=user_name,
                        password=password,
                        role='Corporate'
                    )

                return render(request, 'add_company.html', {
                    'form': CompanyForm(),
                    'success': 'Company and login created successfully'
                })

            except Exception as e:
                return render(request, 'add_company.html', {
                    'form': form,
                    'error': f'Error creating records: {str(e)}'
                })
        else:
            return render(request, 'add_company.html', {
                'form': form,
                'error': 'Invalid form data'
            })

    else:  # GET request
        form = CompanyForm()
        return render(request, 'add_company.html', {'form': form})

@csrf_exempt
def update_company(request, company_id):
    print("Received request to update company with ID:", company_id)
    
    # Fetch the company instance or return a 404 error if not found
    company = get_object_or_404(company_login, id=company_id)
    print("Fetched company instance:", company)

    if request.method == 'POST':  # For update
        print("Processing POST request for company update")
        form = CompanyForm(request.POST, request.FILES, instance=company)
        print("Form initialized with data:", form.data)

        if form.is_valid():
            print("Form is valid. Proceeding with update.")
            try:
                with transaction.atomic():
                    print("Starting transaction.")
                    updated_company = form.save(commit=False)

                    # Handle updating the company_logo
                    uploaded_logo = request.FILES.get('company_logo')
                    if uploaded_logo:
                        print("Uploaded logo detected. Updating logo.")
                        updated_company.company_logo = uploaded_logo.read()
                    else:
                        print("No new logo uploaded.")

                    # Save the updated company_login instance
                    updated_company.save()
                    print("Updated company instance saved:", updated_company)

                    # Update the related college_id field
                    college_ids = form.cleaned_data.get('college_id')
                    if college_ids:
                        print("Updating related college IDs:", college_ids)
                        updated_company.college_id.set(college_ids)
                    else:
                        print("No college IDs provided. Clearing related colleges.")
                        updated_company.college_id.clear()

                    # Update the related login entry
                    user_name = form.cleaned_data.get('user_name')
                    email_id = form.cleaned_data.get('email_id')
                    password = form.cleaned_data.get('password')  # Retrieve the password from the form
                    print("Retrieved user_name:", user_name, "email_id:", email_id, "password:", password)

                    # Find the related login entry
                    login_entry = get_object_or_404(login, user_name=company.user_name)
                    print("Fetched related login entry:", login_entry)

                    # Update login details
                    login_entry.user_name = user_name
                    login_entry.email_id = email_id

                    # Only update the password if a new one is provided
                    if password:
                        print("New password provided. Updating password.")
                        login_entry.password = password
                    else:
                        print("No new password provided. Retaining existing password.")

                    login_entry.save()
                    print("Updated login entry saved:", login_entry)

                    return JsonResponse({'success': 'Company and login updated successfully'}, status=200)

            except Exception as e:
                print("Error during update transaction:", str(e))
                return JsonResponse({'error': f'Error updating company: {str(e)}'}, status=500)

        else:
            print("Form is invalid. Errors:", form.errors)
            return JsonResponse({'error': 'Invalid form data', 'form_errors': form.errors}, status=400)

    else:  # Render the form for a GET request
        print("Rendering form for GET request.")
        form = CompanyForm(instance=company)
        return render(request, 'update_company.html', {'form': form, 'company': company})

@api_view(['GET'])
def get_companies(request):
    # Query all companies with their data
    companies = company_login.objects.filter(deleted=0).prefetch_related('college_id').values(
        'id',
        'company_name',
        'company_profile',
        'user_name',
        'email_id',
        'mobile_no',
        'password',
        'company_logo',  # Fetch the binary data for the logo
    ).order_by('-id')

    # Prepare the data with Base64 encoding for logos
    company_data = []
    for company in companies:
        # Fetch the colleges associated with the company
        company_instance = company_login.objects.get(id=company['id'])
        colleges = company_instance.college_id.values('id', 'college')

        company_logo = None
        if company['company_logo']:
            company_logo = base64.b64encode(company['company_logo']).decode('utf-8')
        
        company_data.append({
            'id': company['id'],
            'company_name': company['company_name'],
            'company_profile': company['company_profile'],
            'user_name': company['user_name'],
            'password':company['password'],
            'email_id': company['email_id'],
            'mobile_no': company['mobile_no'],
            'company_logo': company_logo,
            'colleges': list(colleges),  # Add college details
        })

    return JsonResponse(company_data, safe=False)


@api_view(['PUT', 'PATCH'])
def delete_corporate(request, pk):
    
    try:
        print("Entering Function..")
        corporate=company_login.objects.get(id=pk)

        print("corporate: ",corporate)
    except company_login.DoesNotExist:
        return JsonResponse("tests not found", status=404)

    corporate.deleted = 1
    corporate.save()
 
    print("content: ",corporate)

    return JsonResponse("corporate 'deleted' field updated successfully", safe=False)
@api_view(['GET'])
def get_group_test_name_corporate(request, college_ids): 
    try:
        college_id_list = list(map(int, college_ids.split(',')))
       
        relevant_tests = test_master.objects.filter( 
            deleted=0,
            test_type_id__test_type_categories='Mock/Interview'  # Filter by test_type_categories in the test_master table
        ).values_list('test_name', flat=True)
        tests_candidates = (
            tests_candidates_map.objects.filter(
                deleted=0, 
                college_id__in=college_id_list, 
                test_name__in=relevant_tests
            )
            .values(
                'test_name', 
             
                'dtm_start', 
                'dtm_end', 
                'dtm_created'
            )
            # Count total students (assigned to the test)
            .annotate(student_count=Count('student_id'))
            # Count active students (where is_active=True)
            .annotate(active_student_count=Count('student_id', filter=Q(is_active=True)))
            .order_by(
                Case(
                    When(dtm_created__isnull=True, then=1),
                    default=0,
                    output_field=DateTimeField()
                ),
                '-dtm_created'
            )
        )
            
        test_candidate_map_data = []
        for testing in tests_candidates:
            test_name = testing['test_name']
            test_master_entry = test_master.objects.filter(test_name=test_name,deleted=0).first()

            # If the test master entry exists, fetch the related test_type_categories
            if test_master_entry:
                test_type_categories = test_master_entry.test_type_id.test_type_categories
            else:
                test_type_categories = None  # If no matching entry found, set it to None
            
            test_candidate_map_data.append({
                'test_name': test_name,
                # 'question_id': testing['question_id'],
                'test_type': test_type_categories,  # Add test_type_categories here
                # 'question_paper_name': testing['question_id__question_paper_name'],
                'dtm_start': django_format_date(localtime(testing['dtm_start']), 'd-m-Y h:i A'),
                'dtm_end': django_format_date(localtime(testing['dtm_end']), 'd-m-Y h:i A'),
                'student_count': testing['student_count'],  # Total students assigned to the test
                'active_student_count': testing['active_student_count'],  # Active students (is_active=True)
                'dtm_created': testing['dtm_created']
            })

        return Response(test_candidate_map_data)
    except Exception as e:
       # print("An error occurred:", str(e))
        return Response({"error": str(e)}, status=400)
   



@api_view(['GET'])
def get_tests_Reports_corporate_Candidates(request, college_ids, test_name):
    # Split the college_ids string by commas and convert it into a list of integers
    college_ids_list = list(map(int, college_ids.split(',')))
    print("Parsed college_id_list:", college_ids_list)

    # Fetch related data using select_related for efficiency
    tests_candidates = tests_candidates_map.objects.filter(
        deleted=0,
        college_id__in=college_ids_list,  # Filter by multiple college_ids
        test_name=test_name
    ).select_related(
        'rules_id', 
        'department_id', 
        'question_id', 
        'student_id', 
        'college_id'
    ).values(
        'id',
        'test_name',
        'college_id__college',
        'department_id__department',
        'question_id__question_paper_name',
        'student_id__id',
        'student_id__students_name',
        'student_id__user_name',
        'student_id__email_id',
        'student_id__mobile_number',
        'student_id__gender',
        'student_id__registration_number',
        'rules_id__rule_name',
        'rules_id__instruction',
        'dtm_start',
        'dtm_end',
        'attempt_count',
        'is_camera_on',
        'is_active',
        'duration',
        'duration_type',
        'year',
        'need_candidate_info',
        'total_score',
        'avg_mark'
    )

    # Convert the QuerySet to a list of dictionaries
    test_candidate_map_data = []
    for testing in tests_candidates:
        dtm_start_formatted = django_format_date(localtime(testing['dtm_start']), 'd-m-Y h:i A')
        dtm_end_formatted = django_format_date(localtime(testing['dtm_end']), 'd-m-Y h:i A')

        test_candidate_map_data.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
            'college_id': testing['college_id__college'],
            'department_id': testing['department_id__department'],
            'question_id': testing['question_id__question_paper_name'],
            'student_id': testing['student_id__id'],
            'registration_number': testing['student_id__registration_number'],
            'email_id': testing['student_id__email_id'],
            'mobile_number': testing['student_id__mobile_number'],
            'gender': testing['student_id__gender'],
            'student_name': testing['student_id__students_name'],
            'user_name': testing['student_id__user_name'],
            'dtm_start': dtm_start_formatted,
            'dtm_end': dtm_end_formatted,
            'attempt_count': testing['attempt_count'],
            'is_camera_on': testing['is_camera_on'],
            'is_active': testing['is_active'],
            'duration': testing['duration'],
            'duration_type': testing['duration_type'],
            'year': testing['year'],
            'rules': testing['rules_id__rule_name'],
            'instruction': testing['rules_id__instruction'],
            'need_candidate_info': testing['need_candidate_info'],
            'total_score': testing['total_score'],
            'avg_mark': testing['avg_mark']
        })

    return Response(test_candidate_map_data)


@api_view(['GET'])
def get_candidate_all_corporate_id(request, college):
    try:
        # Split the college string into a list of integers
        college_ids_list = list(map(int, college.split(',')))
        
        # Filter candidates by the list of college_ids
        candidatelist = candidate_master.objects.filter(
            deleted=0, 
            college_id__in=college_ids_list  # Filter by multiple college_ids
        ).select_related(
            'college_id', 
            'department_id'
        ).values(
            'id', 
            'college_id',
            'college_id__college',  # Get college name
            'students_name', 
            'user_name', 
            'registration_number', 
            'gender',
            'email_id', 
            'mobile_number', 
            'year', 
            'cgpa', 
            'department_id', 
            'department_id__department',  # Get department name
            'marks_10th',
            'marks_12th', 
            'marks_semester_wise', 
            'history_of_arrears', 
            'standing_arrears',
            'number_of_offers', 
            'text', 
            'it_of_offers', 
            'core_of_offers', 
            'skill_id',
        )

        # Convert the queryset to a list of dictionaries
        candidate_data = list(candidatelist)

        return Response(candidate_data)
    
    except Exception as e:
        return Response({'error': str(e)}, status=500)

@api_view(['GET'])
def get_tests_Reports_corporate_Candidates(request, college_ids, test_name):
    # Split the comma-separated college_ids string into a list
    college_ids_list = college_ids.split(',')

    # Fetch related data using select_related for efficiency
    tests_candidates = tests_candidates_map.objects.filter(
        deleted=0,
        college_id__in=college_ids_list,  # Allow filtering by multiple college IDs
        test_name=test_name
    ).select_related(
        'rules_id', 
        'department_id', 
        'question_id', 
        'student_id', 
        'college_id'
    ).values(
        'id',
        'test_name',
        'college_id__college',
        'department_id__department',
        'question_id__question_paper_name',
        'student_id__id',
        'student_id__students_name',
        'student_id__user_name',
        'student_id__email_id',
        'student_id__mobile_number',
        'student_id__gender',
        'student_id__registration_number',
        'rules_id__rule_name',
        'rules_id__instruction',
        'dtm_start',
        'dtm_end',
        'attempt_count',
        'is_camera_on',
        'is_active',
        'duration',
        'duration_type',
        'year',
        'need_candidate_info',
        'total_score',
        'avg_mark'
    )

    # Convert the QuerySet to a list of dictionaries
    test_candidate_map_data = []
    for testing in tests_candidates:
        dtm_start_formatted = django_format_date(localtime(testing['dtm_start']), 'd-m-Y h:i A')
        dtm_end_formatted = django_format_date(localtime(testing['dtm_end']), 'd-m-Y h:i A')
        
        test_candidate_map_data.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
            'college_id': testing['college_id__college'],
            'department_id': testing['department_id__department'],
            'question_id': testing['question_id__question_paper_name'],
            'student_id': testing['student_id__id'],
            'registration_number': testing['student_id__registration_number'],
            'email_id': testing['student_id__email_id'],
            'mobile_number': testing['student_id__mobile_number'],
            'gender': testing['student_id__gender'],
            'student_name': testing['student_id__students_name'],
            'user_name': testing['student_id__user_name'],
            'dtm_start': dtm_start_formatted,
            'dtm_end': dtm_end_formatted,
            'attempt_count': testing['attempt_count'],
            'is_camera_on': testing['is_camera_on'],
            'is_active': testing['is_active'],
            'duration': testing['duration'],
            'duration_type': testing['duration_type'],
            'year': testing['year'],
            'rules': testing['rules_id__rule_name'],
            'instruction': testing['rules_id__instruction'],
            'need_candidate_info': testing['need_candidate_info'],
            'total_score': testing['total_score'],
            'avg_mark': testing['avg_mark']
        })

    return Response(test_candidate_map_data)

    
class CollegeListViewTesTId(generics.ListAPIView):
    serializer_class = collegeSerializers

    def get_queryset(self):
        # Extract college_ids from the URL
        college_ids = self.kwargs.get('college_ids', None)
        
        # Filter by deleted field and college_ids if provided
        queryset = college_master.objects.filter(deleted=0)
        
        if college_ids:
            # Split the comma-separated IDs into a list
            ids = [int(id.strip()) for id in college_ids.split(',')]
            queryset = queryset.filter(id__in=ids)
        
        # Use distinct values for both 'id' and 'college'
        queryset = queryset.values('id', 'college').distinct()
        return queryset
    

@api_view(['GET'])
def get_jobId(request, id=None):
    # Filter job offers by ID if provided, or get all if not
    if id:
        job_data = job_offers.objects.filter(id=id, deleted=0).prefetch_related(
            'college_id', 'department_id', 'skill_id'
        ).values(
            'id',
            'company_name',
            'post_name',
            'job_type',
            'company_profile',
            'college_id__college',
            'department_id__id',  # Get department ID
            'department_id__department',  # Get department name
            'skill_id__id',
            'skill_id__skill_name',
            'intern_fulltime',
            'on_off_campus',
            'marks_10th',
            'marks_12th',
            'cgpa',
            'gender',
            'year',
            'interview_date',
            'history_of_arrears',
            'standing_arrears',
            'location',
            'no_of_offers'
        )
    else:
        job_data = job_offers.objects.filter(deleted=0).prefetch_related(
            'college_id', 'department_id', 'skill_id'
        ).values(
            'id',
            'company_name',
            'post_name',
            'job_type',
            'company_profile',
            'college_id__college',
            'department_id__id',
            'department_id__department',
            'skill_id__id',
            'skill_id__skill_name',
            'intern_fulltime',
            'on_off_campus',
            'marks_10th',
            'marks_12th',
            'cgpa',
            'gender',
            'year',
            'interview_date',
            'history_of_arrears',
            'standing_arrears',
            'location',
            'no_of_offers'
        )

    # Group jobs by ID and aggregate related fields
    job_dict = defaultdict(lambda: {
        'id': None,
        'company_name': None,
        'post_name': None,
        'job_type': None,
        'company_profile': None,
        'colleges': set(),
        'departments': [],
        'skills': [],
        'intern_fulltime': None,
        'on_off_campus': None,
        'marks_10th': None,
        'marks_12th': None,
        'cgpa': None,
        'gender': None,
        'year': None,
        'interview_date': None,
        'history_of_arrears': None,
        'standing_arrears': None,
        'location': None,
        'no_of_offers': None
    })

    for entry in job_data:
        job = job_dict[entry['id']]
        job.update(entry)

        # Add colleges
        if entry.get('college_id__college'):
            job['colleges'].add(entry['college_id__college'])

        # Add departments as a list of dictionaries
        if entry.get('department_id__id') and entry.get('department_id__department'):
            department = {
                "department_id": entry['department_id__id'],
                "department_name": entry['department_id__department']
            }
            if department not in job['departments']:
                job['departments'].append(department)


        # Add departments as a list of dictionaries
        if entry.get('skill_id__id') and entry.get('skill_id__skill_name'):
            skill = {
                "skill_id": entry['skill_id__id'],
                "skill_name": entry['skill_id__skill_name']
            }
            if skill not in job['skills']:
                job['skills'].append(skill)


    # Convert sets to lists for serialization
    job_list = [
        {
            **job,
            'id': job['id'],
            'colleges': list(job['colleges']) if job['colleges'] else None,
        }
        for job in job_dict.values()
    ]

    return Response(job_list)
    
   

#-------------------------------------------------------#



@api_view(['GET'])
def get_candidate_batches_cor(request):
    # Extract parameters
    college_ids = request.query_params.getlist('college_id', [])
    dept_ids = request.query_params.getlist('department_id', [])
    year = request.query_params.get('year', None)
    college_names = request.query_params.getlist('college_name', [])

    # Base query
    batch_name_query = eligible_student_list.objects.filter(
        batch_name__isnull=False,deleted=0
    )

    # Apply filters
    if college_names:
        batch_name_query = batch_name_query.filter(
            students_id__college_id__college__in=college_names
        )

    if college_ids:
        batch_name_query = batch_name_query.filter(
            students_id__college_id__in=college_ids
        )

    if dept_ids:
        batch_name_query = batch_name_query.filter(
            students_id__department_id__in=dept_ids
        )

    if year:
        batch_name_query = batch_name_query.filter(
            students_id__year=year
        )

    # Return results
    return Response(batch_name_query.values('batch_name').distinct())
@api_view(['GET'])
def getting_folder_name(request):
    test_type = request.query_params.get('test_type')
    topic = request.query_params.get('topic')
    subtopic = request.query_params.get('subtopic')  # optional
    remarks = request.query_params.get('category')   # ‚úÖ use category as remarks


    # ‚úÖ print incoming values
    print("üì• API Called: /api/get-folder-name/")
    print("  test_type:", test_type)
    print("  topic:", topic)
    print("  subtopic:", subtopic)
    print("  remarks(category):", remarks)

    # ‚úÖ now remarks is also required
    if not test_type or not topic or not remarks:
        return Response(
            {"error": "Fields 'test_type', 'topic' and 'remarks(category)' are required."},
            status=status.HTTP_400_BAD_REQUEST
        )

    try:
        filters = {
            "test_type__iexact": test_type.strip(),
            "topic__iexact": topic.strip(),
            "remarks__iexact": remarks.strip(),  # ‚úÖ mandatory filter
            "deleted": 0  
        }

        if subtopic:
            filters["sub_topic__iexact"] = subtopic.strip()

        print("üîç Applied filters:", filters)  # ‚úÖ debug

        folder_names = (
            question_paper_master.objects
            .filter(**filters)
            .values_list("folder_name", flat=True)
            .distinct()
        )

        unique_folder_names = [name for name in folder_names if name]

        print("üì§ Found folder names:", unique_folder_names)  # ‚úÖ debug

        return Response({"folder_names": unique_folder_names}, status=status.HTTP_200_OK)

    except Exception as e:
        print("‚ùå Error in getting_folder_name:", str(e))  # ‚úÖ debug
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_questions_by_folder(request):
    # Get folder_name and test_type from query parameters
    folder_name = request.query_params.get('folder_name')
    test_type = request.query_params.get('test_type')
    topic = request.query_params.get('topic')
    subtopic = request.query_params.get('subtopic')
    remarks = request.query_params.get('category')
    # print("remarks for question paper select",remarks)

    if not folder_name:
        return Response({"error": "folder_name is required"}, status=status.HTTP_400_BAD_REQUEST)

    try:
        # Query the question_paper_master for matching records
        question_papers = question_paper_master.objects.filter(
            folder_name=folder_name,
            test_type=test_type,
            topic=topic,
            sub_topic=subtopic,
            deleted=0,
            remarks=remarks,
        )

        response_data = []
        for paper in question_papers:
            # Fetch questions related to the current question paper
            questions = question_master.objects.filter(question_name_id=paper.id, deleted=0)

            question_list = []
            for q in questions:
                # Prepare question data
                question_data = {
                    "id": q.id,
                    "question_text": q.question_text,
                    "question_image_data": base64.b64encode(q.question_image_data).decode('utf-8') if q.question_image_data else None
                }
                question_list.append(question_data)

            # Append the question paper with its questions to the response
            response_data.append({
                "id": paper.id,
                "question_paper_name": paper.question_paper_name,
                "questions": question_list
            })

        return Response(response_data, status=status.HTTP_200_OK)

    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_non_null_trainers_usernames(request):
    """
    API view to fetch all user_name entries from trainer_master where user_name is not null.
    """
    try:
        # Query to fetch user_name where it is not null
        usernames = trainer_master.objects.filter(user_name__isnull=False,deleted=0).values_list('user_name', flat=True)
        
        # Convert queryset to a list
        usernames_list = list(usernames)
        
        # Return the response
        return Response({'usernames': usernames_list}, status=200)
    except Exception as e:
        return Response({'error': str(e)}, status=500)




class TestAssignviewcorporateBatch(APIView):
    def post(self, request, format=None):
        print('request.data: ', request.data)

        test_name = request.data.get('test_name')
        test_type_id = request.data.get('test_type_id')
        question_type_id = request.data.get('question_type_id')
        skill_type_id = request.data.get('skill_type_id')
        company_name = request.data.get('company_name')  # Add company_name field
        company_email = request.data.get('company_email')  

        if not all([test_name, test_type_id, question_type_id]):
            return Response({'error': 'Missing fields for test_master'}, status=status.HTTP_400_BAD_REQUEST)

        # Check test_type validity and set is_company flag
        try:
            test_type_instance = test_type.objects.get(id=test_type_id,deleted=0)
            print('test_type_instance: ', test_type_instance)

            is_company = test_type_instance.test_type_categories == "Mock/Interview"
            print('is_company: ', is_company)
        except test_type.DoesNotExist:
            return Response({'error': 'Invalid test_type_id'}, status=status.HTTP_400_BAD_REQUEST)

        # Prepare test_master data
        test_master_data = {
            'test_name': test_name,
            'test_type_id': test_type_id,
            'question_type_id': question_type_id,
            'skill_type_id': skill_type_id,
            'is_company': is_company,
            'company_name': company_name,
            'company_email': company_email
        }
        print('test_master_data: ', test_master_data)
        
        test_master_serializer = testsSerializersAdd(data=test_master_data)
        if not test_master_serializer.is_valid():
            return Response(test_master_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        batch_no = request.data.get('batch_no', [])
        print('batch_no: ', batch_no)

        if not batch_no:
            return Response({'error': 'college_name, department_id, and year are required fields.'}, status=status.HTTP_400_BAD_REQUEST)

        # Filter eligible_student_list based on batch_no
        eligible = eligible_student_list.objects.filter(batch_name__in=batch_no,deleted=0)
        print('eligible: ', eligible)

        # Extract students_id from eligible list and ensure uniqueness
        eligible_student_ids = eligible.values_list('students_id', flat=True).distinct()
        print('eligible_student_ids: ', eligible_student_ids)
        
        # Filter candidate_master using the eligible students_id and is_database=True
        students = candidate_master.objects.filter(id__in=eligible_student_ids, is_database=True,deleted=0)
        print('students: ', students)
       
        # Get list of questions
        question_ids = request.data.get('question_ids', [])
        if not question_ids:
            return Response({'error': 'question_ids field is required.'}, status=status.HTTP_400_BAD_REQUEST)

        shuffle(question_ids)  # Shuffle questions for randomness
        current_date_and_time = datetime.now()
        data = []
        updated_candidates = []

        # Assign one question per student
        for i, student in enumerate(students):
            print('student: ', student)
            assigned_question_id = question_ids[i % len(question_ids)]  # Assign question in round-robin fashion

            test_candidate_data = {
                'test_name': test_name,
                'question_id': assigned_question_id,
                'student_id': student.id,
                'college_id': [college.id for college in student.college_id.all()],

               # 'college_id': student.college_id.id,
                'department_id': student.department_id.id,
                'dtm_start': request.data.get('dtm_start'),
                'dtm_end': request.data.get('dtm_end'),
                'is_camera_on': request.data.get('is_camera_on'),
                'duration': request.data.get('duration'),
                'duration_type': request.data.get('duration_type'),
                'year': student.year,
                'rules_id': request.data.get('rules_id'),
                'need_candidate_info': request.data.get('need_candidate_info'),
                'dtm_created': current_date_and_time
            }

            print('test_candidate_data: ', test_candidate_data)

            serializer = testcandidatemapSerializers(data=test_candidate_data)

            if not serializer.is_valid():
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

            with transaction.atomic():  # Use transaction to ensure atomicity
                test_master_serializer.save()
                serializer.save()
                data.append(serializer.data)

                # Update candidate if needed
                if student.need_candidate_info is None and request.data.get('need_candidate_info') is True:
                    student.need_candidate_info = request.data.get('need_candidate_info')
                    student.save(update_fields=['need_candidate_info'])
                    updated_candidates.append(student.id)

        return Response({'data': data, 'updated_candidates': updated_candidates}, status=status.HTTP_201_CREATED)


class ExcelImportView_Questions_COR_CODE(APIView):
    def post(self, request, format=None):
        print('Request Data: ', request.data)
        
        # Extract multiple question paper names and files
        question_paper_names = request.data.getlist('question_paper_name', [])
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        files = request.FILES.getlist('file')

        # Validation for required fields
        if not all([question_paper_names, files, duration_of_test, topic, sub_topic, no_of_questions, upload_type, test_type]):
            return Response({'error': 'Missing fields or files'}, status=status.HTTP_400_BAD_REQUEST)

        # Ensure the number of files matches the number of question paper names
        if len(files) != len(question_paper_names):
            return Response({'error': 'Mismatch between question paper names and files'}, status=status.HTTP_400_BAD_REQUEST)

        responses = []
        for question_paper_name, file in zip(question_paper_names, files):
            question_paper_data = {
                'question_paper_name': question_paper_name,
                'duration_of_test': duration_of_test,
                'topic': topic,
                'sub_topic': sub_topic,
                'no_of_questions': no_of_questions,
                'upload_type': upload_type,
                'test_type': test_type
            }

            print('Question Paper Data: ', question_paper_data)

            question_paper_serializer = questionsPaperSerializer(data=question_paper_data)

            if question_paper_serializer.is_valid():
                question_paper_instance = question_paper_serializer.save()
                print('question_paper_instance: ', question_paper_instance)
                question_paper_id = question_paper_instance.id

                # Append question paper details to the response
                responses.append({
                    'question_paper_name': question_paper_name,
                    'id': question_paper_id,
                    'status': 'Uploaded successfully'
                })
            else:
                return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

            print('response1: ', responses)
            # Process the file based on file extension
            try:
                if file.name.endswith('.xlsx'):
                    df = pd.read_excel(file)
                    print('DataFrame contents:')
                    print(df.head())
                    
                    # Map Excel columns to the expected format
                    header_mapping = {
                        'Questions**': 'question_text',
                        'Answer**': 'answer',
                        'Mark**': 'mark',
                        'Explain Answer**': 'explain_answer',
                        'Input Format': 'input_format'
                    }
                    missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
                    if missing_columns:
                        return Response({'error': f'Missing columns in Excel file: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

                    df.rename(columns=header_mapping, inplace=True)

                    mandatory_columns = [
                        'question_text',
                        'answer',
                        'mark',
                        'explain_answer'
                    ]

                    empty_columns = [col for col in mandatory_columns if df[col].isnull().any()]

                    if empty_columns:
                        error_message = f'Mandatory columns have null values: {", ".join(empty_columns)}'
                        return Response({'error': error_message}, status=status.HTTP_400_BAD_REQUEST)

                    # Convert DataFrame to records and associate with the newly created question_paper_master
                    records = df.to_dict(orient='records')

                    for record in records:
                        record['question_name_id'] = question_paper_id
                        for key in record:
                            if isinstance(record[key], str):
                                record[key] = record[key].strip()

                    # Serialize and save the records
                    serializer = questionsSerializerCodeImport(data=records, many=True)
                    print("Serializer: ", serializer)

                    if serializer.is_valid():
                        print("Before Saving..")
                        serializer.save()
                        print("After Saving..")
                      #  return Response(serializer.data, status=status.HTTP_201_CREATED)
                    else:
                        print("Serializer Errors: ", serializer.errors)
                        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

                elif file.name.endswith('.docx'):
                    # Word document processing logic
                    print(f"Processing DOCX file: {file.name}")
                    
                    text, images_binary = extract_text_and_images_from_docx(file)
                    data = create_json_structures(text, images_binary)

                    
                    for ques in data["questions"]:
                        print('ques: ', ques)

                        if 'question' in ques:
                            # Debugging: Print the data being processed
                            question_text = ques['question']
                            input_format = ques.get('input_format', '')
                            answers = ques.get('answers', [])
                            marks = ques.get('marks', '0')
                            explain_answer = ques.get('explanation', '')
                            question_image_data = ques.get('question_image_data', '')

                            print(f"Processing question: {question_text}")
                            print(f"Input format: {input_format}")
                            print(f"Answers: {answers}")
                            print(f"Marks: {marks}")
                            print(f"Explanation: {explain_answer}")

                            # Remove brackets from explanation if present
                            if explain_answer.startswith('[') and explain_answer.endswith(']'):
                                explain_answer = explain_answer[1:-1]

                            print(f"Image data: {question_image_data}")

                            try:
                                marks = int(marks) if marks else 0  # Convert to int, set 0 if empty
                            except ValueError:
                                print("Invalid mark value, setting to 0")
                                marks = 0

                            print(f"Marks (after conversion): {marks}")

                            try:
                                # Save to temporary table
                                temp_question = question_master_temp.objects.create(
                                    question_name_id=question_paper_instance,
                                    question_text=question_text,
                                    question_image_data=base64.b64decode(question_image_data) if question_image_data else None,
                                    input_format=input_format,
                                    answer=', '.join(answers),
                                    mark=marks,
                                    explain_answer=explain_answer
                                )

                                print(f"Temp question saved: {temp_question}")

                                # Move to main table
                                main_question = question_master.objects.create(
                                    question_name_id=temp_question.question_name_id,
                                    question_text=temp_question.question_text,
                                    question_image_data=temp_question.question_image_data,
                                    input_format=temp_question.input_format,
                                    answer=temp_question.answer,
                                    mark=temp_question.mark,
                                    explain_answer=temp_question.explain_answer
                                )

                                print(f"Main question saved: {main_question}")

                                # Optionally delete the temporary question
                                temp_question.delete()

                            except Exception as e:
                                print(f"Error saving question: {e}")
                                return HttpResponse(f"Error saving or moving question: {e}")

                    print("All questions processed and saved successfully.")

            except Exception as e:
                return Response({'error': f"Error processing file {file.name}: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)
        print('Responses: ', responses)
        return Response({'result': responses}, status=status.HTTP_201_CREATED)



#------------------test report pdf generated----------------------------#


@api_view(['GET'])
def candidate_details(request):
    candidate_id = request.GET.get('candidate_id')  # Fetching the ID from request parameters
    try:
        candidate = candidate_master.objects.filter(id=candidate_id).annotate(
            college_name=F('college_id__college'),
            college_group=F('college_id__college_group')
        ).values('students_name', 'college_name', 'college_group').first()

        if candidate:
            return Response(candidate, status=status.HTTP_200_OK)
        else:
            return Response({"error": "Candidate not found"}, status=status.HTTP_404_NOT_FOUND)
    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


from datetime import timedelta

@api_view(['GET'])
def test_details(request):
    test_name = request.GET.get('test_name')
    student_id = request.GET.get('student_id')

    try:
        # Total Score
        total_score = question_master.objects.filter(
            question_name_id__id__in=tests_candidates_map.objects.filter(
                test_name=test_name,deleted=0
                ).exclude(created_by='Student')  # ‚úÖ Exclude Student
            .values('question_id')
        ).aggregate(total_score=Sum('mark'))['total_score'] or 0

        # Your Score
        your_score = tests_candidates_answers.objects.filter(
            test_name=test_name, student_id=student_id,deleted=0
        ).aggregate(your_score=Sum('result'))['your_score'] or 0

        # Total Questions and Attended Questions
        total_questions = question_master.objects.filter(
            question_name_id__id__in=tests_candidates_map.objects.filter(test_name=test_name,deleted=0).values('question_id')
        ).count()

        attended_questions = tests_candidates_answers.objects.filter(
            test_name=test_name, student_id=student_id,deleted=0
        ).count()

        # Time Taken
        time_data = tests_candidates_answers.objects.filter(
            test_name=test_name, student_id=student_id,deleted=0
        ).order_by('-dtm_end').values('dtm_start', 'dtm_end').first()

        if time_data and time_data['dtm_start'] and time_data['dtm_end']:
            time_taken = time_data['dtm_end'] - time_data['dtm_start']
        else:
            time_taken = timedelta()

        # Test Invite Time
        invite_time = tests_candidates_map.objects.filter(
            test_name=test_name, student_id=student_id
        ).values('dtm_start').first()

        # Test Start Time and End Time
        test_times = tests_candidates_answers.objects.filter(
            test_name=test_name, student_id=student_id
        ).values('dtm_start', 'dtm_end').first()

        response_data = {
            "total_score": total_score,
            "your_score": your_score,
            "total_questions": total_questions,
            "attended_questions": attended_questions,
            "time_taken": str(time_taken),
            "test_invite_time": invite_time['dtm_start'] if invite_time else None,
            "test_start_time": test_times['dtm_start'] if test_times else None,
            "test_end_time": test_times['dtm_end'] if test_times else None
        }

        return Response(response_data, status=status.HTTP_200_OK)

    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


from django.db import models 

@api_view(['GET'])
def get_test_results_score(request):
    test_name = request.GET.get('test_name')
    student_id = request.GET.get('student_id')

    if not test_name or not student_id:
        return Response({"error": "test_name and student_id are required parameters."}, status=400)

    try:
        # Subquery to check if a question was answered by the student
        answered_questions = tests_candidates_answers.objects.filter(
            test_name=test_name,
            student_id=student_id,
            question_id=OuterRef('id'),
            deleted=0
        ).exclude(created_by='Student') \
        .values('result')
        

        # Query all questions from question_master for the test
        results = question_master.objects.filter(
            question_name_id__in=tests_candidates_map.objects.filter(
                test_name=test_name, student_id=student_id,deleted=0
            ).values_list('question_id', flat=True)
        ).annotate(
            status=Case(
                When(id__in=tests_candidates_answers.objects.filter(
                    test_name=test_name, student_id=student_id,deleted=0
                ).values_list('question_id', flat=True), then=Value('Accepted')),
                default=Value('Rejected'),
                output_field=models.CharField()
            ),
            question_mark=F('mark'),  # Renamed annotation field
            your_score=Subquery(answered_questions, output_field=models.IntegerField()),
            test_type=F('question_name_id__test_type'),
            annotated_question_text=F('question_text')  # Renamed annotation field
        ).values('annotated_question_text', 'test_type', 'status', 'question_mark', 'your_score')

        return Response({"results": list(results)})

    except Exception as e:
        return Response({"error": str(e)}, status=500)



@api_view(['GET'])
def get_test_question_details(request):
    test_name = request.GET.get('test_name')
    student_id = request.GET.get('student_id')
    question_paper_id = request.GET.get('question_paper_id')

    if not test_name or not student_id or not question_paper_id:
        return Response({"error": "test_name, student_id, and question_paper_id are required parameters."}, status=400)

    try:
        # Query to fetch question details with corresponding answers
        results = tests_candidates_answers.objects.filter(
            test_name=test_name,
            student_id=student_id,
            question_id__in=question_master.objects.filter(
                question_name_id=question_paper_id,deleted=0
            ).values_list('id', flat=True)
        ).annotate(
            question_text=F('question_id__question_text'),
            correct_answer=F('question_id__answer'),
            question_mark=F('question_id__mark'),
            sample_code=F('question_id__explain_answer'),
            input_format=F('question_id__input_format'),
            submitted_code=F('compile_code_editor'),
            output=F('answer'),
            your_score=F('result')
        ).values(
            'question_text', 'correct_answer', 'question_mark', 'sample_code', 'input_format', 
            'submitted_code', 'output', 'your_score'
        )

        return Response({"results": list(results)})

    except Exception as e:
        return Response({"error": str(e)}, status=500)



@api_view(['GET'])
def get_skill_type(request):
    test_name = request.GET.get('test_name')
    student_id = request.GET.get('student_id')

    if not test_name:
        return Response({"error": "test_name is a required parameter."}, status=400)

    try:
        # Fetching test_name data from tests_candidates_map
        test_data = tests_candidates_map.objects.filter(
            test_name=test_name, student_id=student_id,deleted=0
        ).values_list('test_name', flat=True).first()

        if not test_data:
            return Response({"error": "No matching test data found for the given test_name and student_id."}, status=404)

        # Query to fetch skill type
        skill_type = test_master.objects.filter(
            test_name=test_data,deleted=0
        ).values_list('skill_type_id__skill_type', flat=True).first()

        if skill_type:
            return Response({"skill_type": skill_type})
        else:
            return Response({"error": "Test not found or no skill type available."}, status=404)

    except Exception as e:
        return Response({"error": str(e)}, status=500)






@api_view(['GET'])
def get_completed_reports_corporate(request):
    # Get filter parameters from the request
    test_name = request.GET.get('test_name')
    college_ids = request.GET.get('college_id')
    department_id = request.GET.get('department_id')
    year = request.GET.get('year')

    # Start with filtering out deleted reports
    reports = tests_candidates_map.objects.filter(deleted=0, is_active=True)

    # Apply additional filters if provided
    if test_name:
        reports = reports.filter(test_name=test_name)

    # Adjust filters for 'All' case
    if college_ids and college_ids != 'All':
        reports = reports.filter(college_id__college=college_ids)
    
    if department_id and department_id != 'All':
        reports = reports.filter(department_id__department=department_id)
    
    if year and year != 'All':
        reports = reports.filter(year=year)

    # Fetch related data using select_related for efficiency
    tests_candidates = reports.select_related(
        'rules_id', 
        'department_id', 
        'question_id', 
        'student_id', 
        'college_id'
    ).values(
        'id',
        'test_name',
        'college_id__college',
        'department_id__department',
        'question_id__id',
        'question_id__question_paper_name',
        'student_id__id',
        'student_id__students_name',
        'student_id__user_name',
        'student_id__email_id',
        'student_id__mobile_number',
        'student_id__gender',
        'student_id__registration_number',
        'rules_id__rule_name',
        'rules_id__instruction',
        'dtm_start',
        'dtm_end',
        'attempt_count',
        'is_camera_on',
        'is_active',
        'duration',
        'duration_type',
        'year',
        'need_candidate_info',
        'total_score',
        'avg_mark',
        'capture_duration'
    )
    
    # Format the datetime fields
    test_candidate_map_data = []
    for testing in tests_candidates:
        dtm_start_formatted = django_format_date(localtime(testing['dtm_start']), 'd-m-Y h:i A')
        dtm_end_formatted = django_format_date(localtime(testing['dtm_end']), 'd-m-Y h:i A')

        test_candidate_map_data.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
            'college_id': testing['college_id__college'],
            'department_id': testing['department_id__department'],
            'question_id_id': testing['question_id__id'],
            'question_id': testing['question_id__question_paper_name'],
            'student_id': testing['student_id__id'],
            'registration_number': testing['student_id__registration_number'],
            'email_id': testing['student_id__email_id'],
            'mobile_number': testing['student_id__mobile_number'],
            'gender': testing['student_id__gender'],
            'student_name': testing['student_id__students_name'],
            'user_name': testing['student_id__user_name'],
            'dtm_start': dtm_start_formatted,
            'dtm_end': dtm_end_formatted,
            'attempt_count': testing['attempt_count'],
            'is_camera_on': testing['is_camera_on'],
            'is_active': testing['is_active'],
            'duration': testing['duration'],
            'duration_type': testing['duration_type'],
            'year': testing['year'],
            'rules': testing['rules_id__rule_name'],
            'instruction': testing['rules_id__instruction'],
            'need_candidate_info': testing['need_candidate_info'],
            'total_score': testing['total_score'],
            'avg_mark': testing['avg_mark'],
            'capture_duration': testing['capture_duration']
        })

    return Response(test_candidate_map_data)


#-----------------------------------20-12-2024------------------------------#



from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
@csrf_exempt
def get_invoice_details(request):
    if request.method == 'GET':
        try:
            # Filter query parameters
            invoice_no = request.GET.get('invoice_no')
            trainer_username = request.GET.get('trainer_username')
            college_id = request.GET.get('college_id')

            # Base queryset
            query = invoice_form.objects.filter(deleted=0)

            # Apply filters conditionally
            if invoice_no:
                query = query.filter(invoice_no=invoice_no)
            if trainer_username:
                query = query.filter(trainer_id__user_name__iexact=trainer_username)  # Case-insensitive match
            if college_id:
                query = query.filter(college_id=college_id)

            # Prepare response data
            data = list(query.values(
                'id',
                'payment_status',
                'schedule_date',
                'invoice_no',
                'college_id',
                'college_id__college',
                'trainer_id',
                'trainer_id__user_name',
                'trainer_id__pan_number',  # Include trainer's PAN number
                'trainer_id__address',     # Include trainer's address
                'trainer_id__city',        # Include trainer's city
                'trainer_id__bank_name',   # Include trainer's bank name
                'trainer_id__branch_name', # Include trainer's branch name
                'trainer_id__account_no',  # Include trainer's account number
                'trainer_id__ifsc_code',  # Include trainer's IFSC code
                'trainer_id__pan_number', # Include trainer's PAN number (if not already included)
                'misc_expenses',
                'travel_expenses',
                'food_allowance',
                'misc_expenses_type',
               'is_tds_deduct',
                'dtm_start',
                'dtm_end',
                'overall_feedback',
                'travel_amount',
                'print_amount',
                'food_amount',
                'travel_days',
                'print_days',
                'food_days',
                'training_amount',
                'training_days'
            ))

            # Return the response
            return JsonResponse({'success': True, 'data': data}, status=200)

        except Exception as e:
            return JsonResponse({'success': False, 'error': str(e)}, status=500)

    return JsonResponse({'success': False, 'error': 'Invalid request method'}, status=400)

@api_view(['GET'])
def Trainer_course_content_viewpopup(request):
    user_name = request.query_params.get('user_name')
    current_date_time = timezone.now()  # Use timezone-aware datetime

    # Calculate the start of yesterday
    start_of_yesterday = current_date_time - timedelta(days=1)
    start_of_yesterday = start_of_yesterday.replace(hour=0, minute=0, second=0, microsecond=0)

    # Print the user_name and current time
    print(f"Received user_name: {user_name}")
    print(f"Current DateTime: {current_date_time}")
    print(f"Start of Yesterday: {start_of_yesterday}")

    if not user_name:
        print("Error: user_name is missing")
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        # Fetch trainer
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id
        print(f"Trainer found: ID={trainer_id}, Name={trainer.trainer_name}")

        # Fetch course schedules, include today and future dates
        course_schedules = course_schedule.objects.filter(
            deleted=0,
            trainer_id=trainer_id,
            dtm_start_trainer__lte=current_date_time,
            dtm_end_trainer__gte=start_of_yesterday
        ).exclude(status='Completed')  # Exclude "Completed" records

        # Identify missing trainer reports (yesterday or earlier)
        missing_reports = course_schedule.objects.filter(
            deleted=0,
            trainer_id=trainer_id,
            dtm_end_trainer__lt=start_of_yesterday,  # Before yesterday
            status__isnull=True  # Status is null
        )

        # If there are missing reports, notify the frontend
        if missing_reports.exists():
            print(f"Missing reports found: {missing_reports.count()}")
            return Response({
                'popup': True,
                'message': "You have not submitted the Trainer‚Äôs report for the last session. Your payment will not be processed until the report is submitted.",
            }, status=status.HTTP_200_OK)

        # Include today's and future schedules if previous statuses are completed
        valid_course_schedules = course_schedule.objects.filter(
            deleted=0,
            trainer_id=trainer_id,
            dtm_start_trainer__lte=current_date_time,
            dtm_end_trainer__gte=start_of_yesterday,
            status='Completed'  # Only include records with completed status
        ).select_related('topic_id')

        # Print the number of course schedules found
        print(f"Valid course schedules found: {valid_course_schedules.count()}")

        # Use list comprehension to create unique data dictionary
        unique_data = {
            (cs.topic_id.topic, cs.topic_id.sub_topic, cs.topic_id.content_url, cs.topic_id.actual_content, cs.dtm_start_trainer, cs.dtm_end_trainer): {
                'id': cs.id,
                'topic': cs.topic_id.topic,
                'sub_topic': cs.topic_id.sub_topic,
                'Content_URL': cs.topic_id.content_url,
                'Actual_Content': cs.topic_id.actual_content,
                'Start_Date': cs.dtm_start_trainer,
                'End_Date': cs.dtm_end_trainer,
            }
            for cs in valid_course_schedules
        }

        # Print unique data before conversion to list
        print(f"Unique data extracted: {unique_data}")

        data = list(unique_data.values())

        # Print the final data being returned
        print(f"Data to be returned: {data}")

        return Response(data, status=status.HTTP_200_OK)
    except Exception as e:
        # Print error message for debugging
        print(f"Error occurred: {str(e)}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['POST'])
def update_invoice(request):
    try:
        print("Received request data for update:", request.data)
        print("Received is_tds_deduct:", request.data.get('is_tds_deduct'))

        # Get the invoice_no to identify the invoice
        invoice_no = request.data.get('invoice_no')
        if not invoice_no:
            return JsonResponse({"error": "Invoice number is required for update."}, status=status.HTTP_400_BAD_REQUEST)

        # Fetch the existing invoice
        try:
            invoice = invoice_form.objects.get(invoice_no=invoice_no)
            print("Invoice found for update:", invoice)
        except invoice_form.DoesNotExist:
            return JsonResponse({"error": "Invoice not found."}, status=status.HTTP_404_NOT_FOUND)

        # Update foreign keys (college_id and trainer_id)
        college_id = request.data.get('college_id')
        trainer_id = request.data.get('trainer_id')

        if college_id:
            try:
                invoice.college_id = college_master.objects.get(id=college_id,deleted=0)
                print("Updated college_id:", invoice.college_id)
            except college_master.DoesNotExist:
                return JsonResponse({"error": "College not found."}, status=status.HTTP_404_NOT_FOUND)

        if trainer_id:
            try:
                invoice.trainer_id = trainer_master.objects.get(id=trainer_id,deleted=0)
                print("Updated trainer_id:", invoice.trainer_id)
            except trainer_master.DoesNotExist:
                return JsonResponse({"error": "Trainer not found."}, status=status.HTTP_404_NOT_FOUND)

        # Update other fields
        invoice.overall_feedback = request.data.get('overall_feedback', invoice.overall_feedback)
        invoice.misc_expenses_type = request.data.get('misc_expenses_type', invoice.misc_expenses_type)
        invoice.travel_amount = request.data.get('travel_amount', invoice.travel_amount)
        invoice.print_amount = request.data.get('print_amount', invoice.print_amount)
        invoice.food_amount = request.data.get('food_amount', invoice.food_amount)
        invoice.travel_days = request.data.get('travel_days', invoice.travel_days)
        is_tds_deduct_value = request.data.get('is_tds_deduct', invoice.is_tds_deduct)

        # Strip any whitespace and handle string-to-boolean conversion
        if isinstance(is_tds_deduct_value, str):
            is_tds_deduct_value = is_tds_deduct_value.strip().lower()  # Remove extra spaces and normalize case
            if is_tds_deduct_value == 'true':
                invoice.is_tds_deduct = True
            elif is_tds_deduct_value == 'false':
                invoice.is_tds_deduct = False
            else:
                return JsonResponse(
                    {"error": "Invalid value for is_tds_deduct. Must be 'true' or 'false'."},
                    status=status.HTTP_400_BAD_REQUEST
                )
        elif isinstance(is_tds_deduct_value, bool):
            invoice.is_tds_deduct = is_tds_deduct_value

        # Handle file updates if new files are uploaded
        if request.FILES.get('misc_expenses'):
            print("Misc Expenses File Uploaded:", request.FILES['misc_expenses'])
            invoice.misc_expenses = request.FILES['misc_expenses']
            invoice.misc_expenses_text = extract_text_from_file(invoice.misc_expenses)
            print("Updated misc_expenses file.")

        if request.FILES.get('travel_expenses'):
            print("Travel Expenses File Uploaded:", request.FILES['travel_expenses'])
            invoice.travel_expenses = request.FILES['travel_expenses']
            invoice.travel_expenses_text = extract_text_from_file(invoice.travel_expenses)
            print("Updated travel_expenses file.")

        if request.FILES.get('food_allowance'):
            print("Food Allowance File Uploaded:", request.FILES['food_allowance'])
            invoice.food_allowance = request.FILES['food_allowance']
            invoice.food_allowance_text = extract_text_from_file(invoice.food_allowance)
            print("Updated food_allowance file.")

        # Recalculate training_amount and food_amount if necessary
        if 'college_id' in request.data or 'trainer_id' in request.data:
            print("Recalculating training amount and food amount...")
            completed_schedule_qs = course_schedule.objects.filter(
                trainer_id=invoice.trainer_id,
                college_id=invoice.college_id,
                status="Completed"
            )
            training_days_qs = completed_schedule_qs.values('dtm_of_training').distinct()
            training_days_count = len(training_days_qs)

            trainer_payment_qs = completed_schedule_qs.values_list('trainer_payment', flat=True).distinct()
            trainer_payment = float(trainer_payment_qs.first() or 0)

            training_amount = training_days_count * trainer_payment
            # Calculate food_amount based on `food` column
            food_column_values = completed_schedule_qs.values_list('food', flat=True).distinct()
            if "By Campus" in food_column_values:
                food_rate_per_day = 100
                food_amount = training_days_count * food_rate_per_day
            elif "By College" in food_column_values:
                food_amount = 0
            else:
                food_amount = 0  # Default to 0 if no valid value is found


            # Update amounts
            invoice.training_days = training_days_count
            invoice.training_amount = training_amount
            invoice.food_amount = food_amount

            print(f"Recalculated training_amount: {training_amount}, food_amount: {food_amount}")

        # Save the updated invoice
        invoice.save()
        print("misc_expenses file:", invoice.misc_expenses)
        print("travel_expenses file:", invoice.travel_expenses)
        print("food_allowance file:", invoice.food_allowance)

        print("Invoice updated successfully!")

        # Return success response
        return JsonResponse({
            "message": "Invoice updated successfully!",
            "invoice_no": invoice.invoice_no,
            "training_days": invoice.training_days,
            "training_amount": invoice.training_amount,
            "food_amount": invoice.food_amount,
            "is_tds_deduct": invoice.is_tds_deduct  # Include updated field in response
        }, status=status.HTTP_200_OK)

    except Exception as e:
        print("Error occurred while updating invoice:", str(e))
        return JsonResponse({"error": f"Failed to update invoice: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)


@api_view(['GET'])
def get_invoice_with_schedule(request):
    try:
        # Retrieve filters from request parameters
        college_id = request.GET.get('college_id')
        trainer_name = request.GET.get('trainer_name')

        # Validate the filters
        if not college_id or not trainer_name:
            return JsonResponse({"error": "Both college_id and trainer_name are required."}, status=status.HTTP_400_BAD_REQUEST)

        # Fetch the trainer object
        try:
            trainer = trainer_master.objects.get(user_name=trainer_name,deleted=0)
        except trainer_master.DoesNotExist:
            return JsonResponse({"error": "Trainer not found."}, status=status.HTTP_404_NOT_FOUND)

        # Filter the course_schedule table based on college_id and trainer
        course_schedule_qs = course_schedule.objects.filter(
            college_id=college_id,
            trainer_id=trainer.id,deleted=0
        ).order_by('dtm_of_training')  # Optional: Order by training date for consistent output

        if not course_schedule_qs.exists():
            return JsonResponse({"error": "No course schedules found for the given filters."}, status=status.HTTP_404_NOT_FOUND)

        # Prepare combined data with unique dates
        result = []
        unique_dates = set()  # To track unique training dates

        for schedule in course_schedule_qs:
            if schedule.dtm_of_training in unique_dates:
                continue  # Skip duplicate training dates
            
            # Mark date as processed
            unique_dates.add(schedule.dtm_of_training)

            # Get associated invoice (if exists)
            invoice = invoice_form.objects.filter(
                college_id=college_id,
                trainer_id=trainer.id,
                deleted=0,
                training_days=schedule.dtm_of_training
            ).first()

            result.append({
                "schedule_id": schedule.id,
                "dtm_of_training": schedule.dtm_of_training,
                "status": schedule.status,
                "food": schedule.food,
                "travel": schedule.travel,
                "trainer_payment": schedule.trainer_payment,
                "training_days": invoice.training_days if invoice else None,
                "training_amount": invoice.training_amount if invoice else None,
                "food_amount": invoice.food_amount if invoice else None,
            })

        # Return the combined data
        return JsonResponse({"data": result}, status=status.HTTP_200_OK, safe=False)

    except Exception as e:
        print("Error occurred while fetching invoice details:", str(e))
        return JsonResponse({"error": f"Failed to fetch details: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)

@api_view(['PUT', 'PATCH'])
def delete_invoice_form(request, pk):
   # ##logger.debug('Entering delete_skill_type function with id: %s', pk)
    try:
        invoice = invoice_form.objects.get(id=pk)
      #  ##logger.debug('Skill type found: %s', invoice)
    except invoice_form.DoesNotExist:
        logger.error('invoice with id %s not found', pk)
        return JsonResponse("Skill type not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    invoice.deleted = 1
    invoice.save()
   # ##logger.debug('Skill type marked as deleted: %s', skilltype)

    return JsonResponse("invoice 'deleted' field updated successfully", safe=False)

@api_view(['POST'])
def update_ccinvoice(request):
    try:
        print("Received request data for update:", request.data)
        print("Received is_tds_deduct:", request.data.get('is_tds_deduct'))

        # Get the invoice_no to identify the invoice
        invoice_no = request.data.get('invoice_no')
        if not invoice_no:
            return JsonResponse({"error": "Invoice number is required for update."}, status=status.HTTP_400_BAD_REQUEST)

        # Fetch the existing invoice
        try:
            invoice = invoice_form.objects.get(invoice_no=invoice_no,deleted=0)
            print("Invoice found for update:", invoice)
        except invoice_form.DoesNotExist:
            return JsonResponse({"error": "Invoice not found."}, status=status.HTTP_404_NOT_FOUND)

        # Update foreign keys (college_id and trainer_id)
        college_id = request.data.get('college_id')
        trainer_id = request.data.get('trainer_id')

        if college_id:
            try:
                invoice.college_id = college_master.objects.get(id=college_id,deleted=0)
                print("Updated college_id:", invoice.college_id)
            except college_master.DoesNotExist:
                return JsonResponse({"error": "College not found."}, status=status.HTTP_404_NOT_FOUND)

        if trainer_id:
            try:
                invoice.trainer_id = trainer_master.objects.get(id=trainer_id,deleted=0)
                print("Updated trainer_id:", invoice.trainer_id)
            except trainer_master.DoesNotExist:
                return JsonResponse({"error": "Trainer not found."}, status=status.HTTP_404_NOT_FOUND)

        # Update other fields
        invoice.overall_feedback = request.data.get('overall_feedback', invoice.overall_feedback)
        invoice.misc_expenses_type = request.data.get('misc_expenses_type', invoice.misc_expenses_type)
                # Normalize and handle is_tds_deduct field
        is_tds_deduct_value = request.data.get('is_tds_deduct', invoice.is_tds_deduct)

        # Strip any whitespace and handle string-to-boolean conversion
        if isinstance(is_tds_deduct_value, str):
            is_tds_deduct_value = is_tds_deduct_value.strip().lower()  # Remove extra spaces and normalize case
            if is_tds_deduct_value == 'true':
                invoice.is_tds_deduct = True
            elif is_tds_deduct_value == 'false':
                invoice.is_tds_deduct = False
            else:
                return JsonResponse(
                    {"error": "Invalid value for is_tds_deduct. Must be 'true' or 'false'."},
                    status=status.HTTP_400_BAD_REQUEST
                )
        elif isinstance(is_tds_deduct_value, bool):
            invoice.is_tds_deduct = is_tds_deduct_value

        # Handle file updates if new files are uploaded
        if request.FILES.get('misc_expenses'):
            print("Misc Expenses File Uploaded:", request.FILES['misc_expenses'])
            invoice.misc_expenses = request.FILES['misc_expenses']
            invoice.misc_expenses_text = extract_text_from_file(invoice.misc_expenses)
            print("Updated misc_expenses file.")

        if request.FILES.get('travel_expenses'):
            print("Travel Expenses File Uploaded:", request.FILES['travel_expenses'])
            invoice.travel_expenses = request.FILES['travel_expenses']
            invoice.travel_expenses_text = extract_text_from_file(invoice.travel_expenses)
            print("Updated travel_expenses file.")

        if request.FILES.get('food_allowance'):
            print("Food Allowance File Uploaded:", request.FILES['food_allowance'])
            invoice.food_allowance = request.FILES['food_allowance']
            invoice.food_allowance_text = extract_text_from_file(invoice.food_allowance)
            print("Updated food_allowance file.")

        # Update training_days, training_amount, food_amount, travel_amount, travel_days if provided explicitly
        if 'training_days' in request.data:
            invoice.training_days = request.data['training_days']
        
        if 'training_amount' in request.data:
            invoice.training_amount = request.data['training_amount']
        
        if 'food_amount' in request.data:
            invoice.food_amount = request.data['food_amount']
        
        if 'travel_amount' in request.data:
            invoice.travel_amount = request.data['travel_amount']
        
        if 'travel_days' in request.data:
            invoice.travel_days = request.data['travel_days']

        # Save the updated invoice
        invoice.save()
        print("misc_expenses file:", invoice.misc_expenses)
        print("travel_expenses file:", invoice.travel_expenses)
        print("food_allowance file:", invoice.food_allowance)

        print("Invoice updated successfully!")

        # Return success response
        return JsonResponse({
            "message": "Invoice updated successfully!",
            "invoice_no": invoice.invoice_no,
            "training_days": invoice.training_days,
            "training_amount": invoice.training_amount,
            "food_amount": invoice.food_amount,
            "is_tds_deduct": invoice.is_tds_deduct  # Include updated field in response
        }, status=status.HTTP_200_OK)

    except Exception as e:
        print("Error occurred while updating invoice:", str(e))
        return JsonResponse({"error": f"Failed to update invoice: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)





@api_view(['GET'])
def get_is_edit(request):
    username = request.GET.get('user_name')
    
    if not username:
        return Response(
            {"error": "user_name parameter is required."},
            status=status.HTTP_400_BAD_REQUEST
        )
    
    # Fetch the `is_edit` value for the given `user_name`
    trainer = trainer_master.objects.filter(user_name=username,deleted=0).values('is_edit').first()
    
    if trainer:
        return Response({"is_edit": trainer['is_edit']}, status=status.HTTP_200_OK)
    else:
        return Response(
            {"error": "Trainer not found with the given user_name."},
            status=status.HTTP_404_NOT_FOUND
        )




@api_view(['GET'])
def get_college_ids_from_company(request):
    # Get the 'user_name' from the request
    user_name = request.GET.get('user_name')
    
    if not user_name:
        return Response({"error": "user_name parameter is required"}, status=400)

    try:
        # Fetch the company_login object by user_name
        company = company_login.objects.filter(user_name=user_name,deleted=0).first()
        if not company:
            return Response({"error": "No company found for the given user_name"}, status=404)
        
        # Fetch all related college_id values
        college_ids = company.college_id.values_list('id', flat=True)
        
        # Return the college IDs as a list in the response
        return Response({"college_ids": list(college_ids)}, status=200)
    except Exception as e:
        return Response({"error": str(e)}, status=500)



@api_view(['GET'])
def get_distinct_test_data_cor(request):
    # Parse `college_id` query parameter as a list
    college_id_raw = request.GET.get('college_id', '')
    print('college id: ', college_id_raw)
    try:
        # Safely parse the string into a Python list
        college_id_list = [int(id.strip()) for id in college_id_raw.strip('[]').split(',') if id.strip()]
    except ValueError:
        return Response({"error": "Invalid college_id format"}, status=400)

    # Fetch distinct test_name
    distinct_test_names = tests_candidates_map.objects.filter(college_id__in=college_id_list,deleted=0).values('test_name').distinct()

    # Fetch distinct college_id and related college_name
    distinct_colleges = tests_candidates_map.objects.filter(deleted=0).select_related('college_id').values(
        'college_id', 'college_id__college').distinct()

    # Fetch distinct department_id and related department_name, excluding null values
    distinct_departments = tests_candidates_map.objects.filter(deleted=0).select_related('department_id').values(
        'department_id', 'department_id__department').exclude(department_id__isnull=True).distinct()

    # Fetch distinct years, excluding null values
    distinct_years = tests_candidates_map.objects.filter(deleted=0).values('year').exclude(year__isnull=True).distinct()

    # Create response data
    data = {
        "distinct_test_names": list(distinct_test_names),
        "distinct_colleges": [{"college_id": item["college_id"], "college_name": item["college_id__college"]} for item in distinct_colleges],
        "distinct_departments": [{"department_id": item["department_id"], "department_name": item["department_id__department"]} for item in distinct_departments],
        "distinct_years": list(distinct_years)
    }

    return Response(data)

#-------------------------24-01-2025------------------------#

@api_view(['GET'])
def get_login_by_username(request):
    try:
        username = request.GET.get('user_name')
        passw = request.GET.get('password')

        if not username or not passw:
            return Response({'error': 'Username and password are required'}, status=400)

        # Case-insensitive matching for username and exact match for password
        login_data = login.objects.filter(
            Q(user_name__iexact=username) & Q(password=passw)& Q(deleted=0)
        ).select_related('college_id').values(
            'id',
            'email_id',
            'user_name',
            'password',
            'role',
            'college_id__id',
            'college_id__college'
        )

        if not login_data.exists():
            return Response({'error': 'Invalid username or password'}, status=404)

        # Format the data for response
        formatted_login_data = [
            {
                'id': entry['id'],
                'email_id': entry['email_id'],
                'user_name': entry['user_name'],
                'password': entry['password'],
                'role': entry['role'],
                'college_id': entry['college_id__id'],
                'college_name': entry['college_id__college']
            }
            for entry in login_data
        ]

        return Response(formatted_login_data)

    except Exception as e:
        logger.error(f'Error occurred in get_login_by_username function: {e}')
        return Response({'error': 'An error occurred'}, status=500)


#---------------------------------25-01-2025----------------------------#


class Round(Func):
    function = 'ROUND'
    template = '%(function)s(%(expressions)s, 2)'


@api_view(['GET'])
def get_active_tests_by_department(request):
    try:
        # Query with grouping by department_id and ordering by dtm_start
        data = (
            tests_candidates_map.objects.filter(is_active=True,deleted=0)
            .values(
                'department_id', 
                'department_id__department', 
                'college_id__college',
                'year',
                'test_name',
                'dtm_start'  # Include dtm_start in values
            )
            .annotate(
                avg_mark=Round(Avg('avg_mark')),
                total_students=Count('student_id', distinct=True)
            )
            .order_by('college_id')  # Order by dtm_start in ascending order
        )

        return Response({'success': True, 'data': list(data)}, status=200)

    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)

@api_view(['GET'])
def get_batch_wise_data(request):
    try:
        # Query with grouping by batch_no and aggregating data
        data = (
            tests_candidates_map.objects.filter(
                is_active=True,deleted=0,
                student_id__batch_no__isnull=False,  # Exclude null batch_no
            )
            .exclude(student_id__batch_no='')  # Exclude empty batch_no
            .values(
                'student_id__batch_no',  # Group by batch_no
                'test_name',
                'student_id__students_name',
                'student_id__user_name',
                'college_id__college',
                'department_id__department',
                'dtm_start',
                'dtm_end',
                'year',
                'avg_mark',
            )
            .annotate(
                total_students=Count('student_id', distinct=True),
                average_mark=Avg('avg_mark'),  # Calculate average marks
            )
            .order_by('student_id__batch_no')  # Sort by batch_no
        )

        return Response({'success': True, 'data': list(data)}, status=200)

    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)




@api_view(['GET'])
def get_tests_by_username(request):
    try:
        # Get the username from query parameters
        user_name = request.query_params.get('user_name')
        if not user_name:
            return Response({'success': False, 'error': 'user_name parameter is required'}, status=400)

        # Query the database
        data = (
            tests_candidates_map.objects.filter(is_active=True, student_id__user_name=user_name,deleted=0)
            .values(
                'test_name',
                'student_id__students_name',
                'student_id__user_name',
                'college_id__college',
                'department_id__department',
                'dtm_start',
                'dtm_end',
                'is_active',
                'year',
                'avg_mark',
            )
        )

        return Response({'success': True, 'data': list(data)}, status=200)

    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)


#----------------------------27-01-2025-----------------------#




@api_view(['GET'])
def get_batch_by_college_id(request):
    # Retrieve parameters from the request
    college_id = request.GET.get('college_id')
    is_db = request.GET.get('is_database')  # Get as string from query params

    if not college_id:
        return JsonResponse({"error": "college_id is required"}, status=400)

    try:
        # Base queryset filtering by college_id and excluding null batch_no
        queryset = candidate_master.objects.filter(college_id=college_id,deleted=0).exclude(batch_no__isnull=True)

        # Handle optional is_database filter
        if is_db is not None:  # Check if is_database is provided
            if is_db.lower() in ["true", "1"]:  # Convert string input to boolean
                queryset = queryset.filter(is_database=True)
            elif is_db.lower() in ["false", "0"]:
                queryset = queryset.filter(is_database=False)

        # Get distinct batch_no values
        batch_numbers = queryset.values_list('batch_no', flat=True).distinct()

        return JsonResponse({"batch_numbers": list(batch_numbers)}, safe=False)
    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500)


@api_view(['PUT'])
def update_test_status(request):
    # Retrieve the test_name and user_name from query parameters
    test_name = request.data.get('test_name')
    user_name = request.data.get('user_name', [])

    if not test_name:
        return Response({"error": "test_name is required"}, status=status.HTTP_400_BAD_REQUEST)

    if not user_name or not isinstance(user_name, list):
        return Response({"error": "user_name must be a list of strings"}, status=status.HTTP_400_BAD_REQUEST)

    try:
        # Find candidates based on user_name
        candidates = candidate_master.objects.filter(user_name__in=user_name,deleted=0)
        if not candidates.exists():
            return Response(
                {"error": f"No candidates found for the given usernames: {user_name}"},
                status=status.HTTP_404_NOT_FOUND
            )

        # Update the records in tests_candidates_map
        updated_count = tests_candidates_map.objects.filter(
            
            test_name=test_name,
            student_id__in=candidates.values_list('id', flat=True)
        ).update(
            is_active=False,
            total_score=None,
            avg_mark=None
        )

        if updated_count == 0:
            return Response(
                {"message": f"No records found for test_name '{test_name}' and the given usernames."},
                status=status.HTTP_404_NOT_FOUND
            )

        return Response(
            {"message": f"Test status updated successfully for test_name '{test_name}' and usernames {user_name}."},
            status=status.HTTP_200_OK
        )
    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



@api_view(['GET'])
def get_candidate_all_college_id(request, college):
    try:
        candidatelist = candidate_master.objects.filter(deleted=0, college_id=college).select_related('college_id', 'department_id').values(
            'id', 
            'college_id',
            'college_id__college',  # Get college name
            'students_name', 
            'user_name', 
            'registration_number', 
            'gender',
            'email_id', 
            'mobile_number', 
            'year', 
            'cgpa', 
            'department_id', 
            'department_id__department',  # Get department name
            'marks_10th',
            'marks_12th', 
            'marks_semester_wise', 
            'history_of_arrears', 
            'standing_arrears',
            'number_of_offers', 
            'text', 
            'it_of_offers', 
            'core_of_offers', 
            'skill_id',
            'batch_no',
            'is_database',
        )
        candidate_data = list(candidatelist)
        return Response(candidate_data)
    except Exception as e:
        return Response({'error': str(e)}, status=500)




@api_view(['GET'])
def get_active_test_reassign(request, test_name):
    # Subquery to fetch the password from the login table where user_name matches
    login_password_subquery = login.objects.filter(
        user_name=OuterRef('student_id__user_name')
    ).values('password')[:1]

    # Fetch related data using select_related for efficiency
    tests_candidates = tests_candidates_map.objects.filter(
        deleted=0,
        test_name=test_name,
        is_active=True
    ).select_related(
        'rules_id',
        'department_id',
        'question_id',
        'student_id',
        'college_id'
    ).annotate(
        login_password=Subquery(login_password_subquery)
    ).values(
        'id',
        'test_name',
        'college_id__college',
        'department_id__department',
        'question_id__question_paper_name',
        'student_id__id',
        'student_id__students_name',
        'student_id__user_name',
        'student_id__email_id',
        'student_id__mobile_number',
        'student_id__gender',
        'student_id__registration_number',
        'rules_id__rule_name',
        'rules_id__instruction',
        'dtm_start',
        'dtm_end',
        'attempt_count',
        'is_camera_on',
        'is_active',
        'duration',
        'duration_type',
        'year',
        'need_candidate_info',
        'total_score',
        'avg_mark',
        'capture_duration',
        'login_password'  # Include the annotated password field
    )

    # Format the datetime fields
    test_candidate_map_data = []
    for testing in tests_candidates:
        dtm_start_formatted = django_format_date(localtime(testing['dtm_start']), 'd-m-Y h:i A')
        dtm_end_formatted = django_format_date(localtime(testing['dtm_end']), 'd-m-Y h:i A')

        test_candidate_map_data.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
            'college_id': testing['college_id__college'],
            'department_id': testing['department_id__department'],
            'question_id': testing['question_id__question_paper_name'],
            'student_id': testing['student_id__id'],
            'registration_number': testing['student_id__registration_number'],
            'email_id': testing['student_id__email_id'],
            'mobile_number': testing['student_id__mobile_number'],
            'gender': testing['student_id__gender'],
            'student_name': testing['student_id__students_name'],
            'user_name': testing['student_id__user_name'],
            'password': testing['login_password'],  # Include the password in the response
            'dtm_start': dtm_start_formatted,
            'dtm_end': dtm_end_formatted,
            'attempt_count': testing['attempt_count'],
            'is_camera_on': testing['is_camera_on'],
            'is_active': testing['is_active'],
            'duration': testing['duration'],
            'duration_type': testing['duration_type'],
            'year': testing['year'],
            'rules': testing['rules_id__rule_name'],
            'instruction': testing['rules_id__instruction'],
            'need_candidate_info': testing['need_candidate_info'],
            'total_score': testing['total_score'],
            'avg_mark': testing['avg_mark'],
            'capture_duration': testing['capture_duration']
        })

    return Response(test_candidate_map_data)

@api_view(['GET'])
def get_candidate_batches_non_db(request):
    # Retrieve query parameters
    college_names = request.query_params.getlist('colleges', [])
    college_ids = request.query_params.getlist('college_id', [])

    # Log the received parameters for debugging
    print('college_ids:', college_ids)
    print('college_names:', college_names)

    # Initialize the queryset
    queryset = candidate_master.objects.filter(batch_no__isnull=False, college_id__college__in=college_names, is_database=False,deleted=0)

    if college_ids:
        queryset = queryset.filter(college_id__in=college_ids)

    # Get distinct batch numbers
    batch_numbers = queryset.values('batch_no').distinct()

    # Return the result as a list of dictionaries
    return Response(list(batch_numbers))






@api_view(['GET'])
def get_candidate_batches_non_db(request):
    # Retrieve query parameters
    college_names = request.query_params.getlist('colleges', [])
    college_ids = request.query_params.getlist('college_id', [])

    # Log the received parameters for debugging
    print('college_ids:', college_ids)
    print('college_names:', college_names)

    # Initialize the queryset
    queryset = candidate_master.objects.filter(batch_no__isnull=False, college_id__college__in=college_names, is_database=False,deleted=0)

    if college_ids:
        queryset = queryset.filter(college_id__in=college_ids)

    # Get distinct batch numbers
    batch_numbers = queryset.values('batch_no').distinct()

    # Return the result as a list of dictionaries
    return Response(list(batch_numbers))




@api_view(['GET'])
def get_screenshots(request):
    try:
        # Get test_candidate_id from the query parameters
        test_candidate_id = request.GET.get('test_candidate_id')
        if not test_candidate_id:
            return JsonResponse({"error": "test_candidate_id is required"}, status=400)
        
        # Query the screenshots for the given test_candidate_id
        screenshots_data = Screenshots.objects.filter(test_candidate_id=test_candidate_id, deleted=0)
        
        # Prepare the response: a list of Base64 encoded screenshots
        screenshots_list = [
            base64.b64encode(screenshot.screenshots).decode('utf-8')
            for screenshot in screenshots_data if screenshot.screenshots
        ]
        
        # Return only the screenshots list
        return JsonResponse(screenshots_list, safe=False, status=200)

    except Exception as e:
        # Handle errors
        return JsonResponse({"error": str(e)}, status=500)




@api_view(['GET'])
def get_departments(request):
    # Query all non-deleted departments
    departments = department_master.objects.all().filter(deleted=0).order_by('-id').values('id', 'department')

    #departments = department_master.objects.filter(deleted=0).values('id', 'department')
    # Convert QuerySet to a list of dictionaries
    department_list = list(departments)
    return Response(department_list)



@api_view(['GET'])
def get_group_test_name_Aptitude_Test(request):
    college_id = request.GET.get('college_id')  
    department_filter = request.GET.get('department')  # Get selected department
    year_filter = request.GET.get('year')  # Get selected year

    # Get test names of 'Aptitude' type
    test_names = test_master.objects.filter(question_type_id__question_type='Aptitude',deleted=0).values_list('test_name', 'skill_type_id')

    # Create a dictionary for mapping test_name to skill_type_id
    skill_types = skill_type.objects.filter(id__in=[test[1] for test in test_names if test[1] is not None],deleted=0).values_list('id', 'skill_type')
    skill_type_mapping = {skill[0]: skill[1] for skill in skill_types}

    # Map test_name to skill_type_id
    test_skill_mapping = {test[0]: skill_type_mapping.get(test[1], None) for test in test_names}

    # Base filters
    filters = {'deleted': 0, 'test_name__in': test_skill_mapping.keys()}
    if college_id:
        filters['college_id'] = college_id  # Apply college filter

    # Aggregate all department and year data into a single row per `test_name`
    base_query = tests_candidates_map.objects.filter(**filters).exclude(created_by='Student').values(
        'test_name',
        'college_id',
        'college_id__college'
    ).annotate(
        student_count=Count('student_id', distinct=True),  # ‚úÖ Aggregate student count
        active_student_count=Count('student_id', filter=Q(is_active=True), distinct=True),  # ‚úÖ Aggregate active student count
        dtm_created=Max('dtm_created'),  # ‚úÖ Get latest creation date
        department_names=Concat(Value(''), 'department_id__department', output_field=CharField()),  # ‚úÖ Concatenate department names
        all_years=Concat(Value(''), 'year', output_field=CharField())  # ‚úÖ Concatenate all years
    ).order_by('-dtm_created')

    # Apply filtering only when department or year is selected
    if department_filter or year_filter:
        filtered_query = tests_candidates_map.objects.filter(**filters)

        if department_filter:
            filtered_query = filtered_query.filter(department_id__department=department_filter)
        if year_filter:
            filtered_query = filtered_query.filter(year=year_filter)

        filtered_query = filtered_query.values(
            'test_name',
            'college_id',
            'college_id__college'
        ).annotate(
            student_count=Count('student_id', distinct=True),  
            active_student_count=Count('student_id', filter=Q(is_active=True), distinct=True),
            dtm_created=Max('dtm_created'),
            department_names=Concat(Value(''), 'department_id__department', output_field=CharField()),
            all_years=Concat(Value(''), 'year', output_field=CharField())
        ).order_by('-dtm_created')

        results = filtered_query
    else:
        results = base_query  # ‚úÖ Default view: one row per test_name

    # Format response data
    test_candidate_map_data = []
    seen_tests = {}

    for testing in results:
        test_name = testing['test_name']

        if test_name not in seen_tests:
            seen_tests[test_name] = {
                'test_name': test_name,
                'student_count': 0,  # ‚úÖ Start from zero to sum properly
                'active_student_count': 0,
                'dtm_created': testing['dtm_created'],
                'college_id': testing['college_id'],
                'college_name': testing['college_id__college'],
                'skill_type': test_skill_mapping.get(test_name),
                'department_name': set(),  # ‚úÖ Store multiple departments
                'year': set()  # ‚úÖ Store multiple years
            }

        # ‚úÖ Aggregate student counts correctly
        seen_tests[test_name]['student_count'] += testing['student_count']
        seen_tests[test_name]['active_student_count'] += testing['active_student_count']
        seen_tests[test_name]['department_name'].add(testing['department_names'])
        seen_tests[test_name]['year'].add(testing['all_years'])

    # Convert sets to comma-separated strings
    for test in seen_tests.values():
        test['department_name'] = ", ".join(test['department_name'])
        test['year'] = ", ".join(test['year'])
        test_candidate_map_data.append(test)

    return Response(test_candidate_map_data)

@api_view(['GET'])
def get_group_test_name_Technical_Test(request):
    college_id = request.GET.get('college_id')
    department_filter = request.GET.get('department')  # Get selected department
    year_filter = request.GET.get('year')  # Get selected year

    # Get test names of 'Technical' type along with skill_type_id
    test_names = test_master.objects.filter(question_type_id__question_type='Technical',deleted=0).values_list('test_name', 'skill_type_id')

    # Create a dictionary for mapping skill_type_id to skill_type
    skill_types = skill_type.objects.filter(id__in=[test[1] for test in test_names if test[1] is not None],deleted=0).values_list('id', 'skill_type')
    skill_type_mapping = {skill[0]: skill[1] for skill in skill_types}

    # Map test_name to skill_type
    test_skill_mapping = {test[0]: skill_type_mapping.get(test[1], None) for test in test_names}

    # Base filters
    filters = {'deleted': 0, 'test_name__in': test_skill_mapping.keys()}
    if college_id:
        filters['college_id'] = college_id  # Apply college filter

    # Base query (Default: Aggregates all departments and years into a single entry per test_name)
    base_query = tests_candidates_map.objects.filter(**filters).exclude(created_by='Student').values(
        'test_name',
        'college_id',
        'college_id__college'
    ).annotate(
        student_count=Count('student_id', distinct=True),  # ‚úÖ Aggregate student count
        active_student_count=Count('student_id', filter=Q(is_active=True), distinct=True),  # ‚úÖ Aggregate active student count
        dtm_created=Max('dtm_created'),  # ‚úÖ Get latest creation date
        department_names=Concat(Value(''), 'department_id__department', output_field=CharField()),  # ‚úÖ Concatenate department names
        all_years=Concat(Value(''), 'year', output_field=CharField())  # ‚úÖ Concatenate all years
    ).order_by('-dtm_created')

    # Apply filtering only when department or year is selected
    if department_filter or year_filter:
        filtered_query = tests_candidates_map.objects.filter(**filters)

        if department_filter:
            filtered_query = filtered_query.filter(department_id__department=department_filter)
        if year_filter:
            filtered_query = filtered_query.filter(year=year_filter)

        filtered_query = filtered_query.values(
            'test_name',
            'college_id',
            'college_id__college'
        ).annotate(
            student_count=Count('student_id', distinct=True),  
            active_student_count=Count('student_id', filter=Q(is_active=True), distinct=True),
            dtm_created=Max('dtm_created'),
            department_names=Concat(Value(''), 'department_id__department', output_field=CharField()),
            all_years=Concat(Value(''), 'year', output_field=CharField())
        ).order_by('-dtm_created')

        results = filtered_query
    else:
        results = base_query  # ‚úÖ Default view: one row per test_name

    # Format response data
    test_candidate_map_data = []
    seen_tests = {}

    for testing in results:
        test_name = testing['test_name']

        if test_name not in seen_tests:
            seen_tests[test_name] = {
                'test_name': test_name,
                'student_count': 0,  # ‚úÖ Start from zero to sum properly
                'active_student_count': 0,
                'dtm_created': testing['dtm_created'],
                'college_id': testing['college_id'],
                'college_name': testing['college_id__college'],
                'skill_type': test_skill_mapping.get(test_name),
                'department_name': set(),  # ‚úÖ Store multiple departments
                'year': set()  # ‚úÖ Store multiple years
            }

        # ‚úÖ Aggregate student counts correctly
        seen_tests[test_name]['student_count'] += testing['student_count']
        seen_tests[test_name]['active_student_count'] += testing['active_student_count']
        seen_tests[test_name]['department_name'].add(testing['department_names'])
        seen_tests[test_name]['year'].add(testing['all_years'])

    # Convert sets to comma-separated strings
    for test in seen_tests.values():
        test['department_name'] = ", ".join(test['department_name'])
        test['year'] = ", ".join(test['year'])
        test_candidate_map_data.append(test)

    return Response(test_candidate_map_data)

@api_view(['GET'])
def Placement_course_content_view(request):
    print("Received API request for Placement")

    college_id = request.query_params.get('college_id')
    question_type = request.query_params.get('question_type', None)
    skill_type = request.query_params.get('skill_type', None)
    current_date_time = timezone.now()

    if not college_id:
        return Response({'error': 'college_id is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        college = get_object_or_404(college_master, id=college_id)

        students = candidate_master.objects.filter(
            college_id=college_id,
            deleted=0
        ).values('id', 'department_id', 'year', 'batch_no')

        if not students:
            return Response({'message': 'No students found for the given college_id'}, status=status.HTTP_404_NOT_FOUND)

        student_ids = [s['id'] for s in students]
        batch_nos = list(set([s['batch_no'] for s in students if s.get('batch_no')]))

        # --------------------------
        # Build base filters
        # --------------------------
        topic_filters = {}
        if question_type:
            topic_filters["topic_id__question_type_id__question_type"] = question_type
            print(f"‚úÖ Filter applied: question_type={question_type}")
        if skill_type:
            topic_filters["topic_id__skill_type_id__skill_type"] = skill_type
            print(f"‚úÖ Filter applied: skill_type={skill_type}")

        topic_data = defaultdict(lambda: {
            'topic': None,
            'sub_topic': None,
            'content_url': None,
            'worksheet_link': None,
            'actual_content': None,
            'start_date': None,
            'end_date': None,
            'departments': set(),
            'years': set(),
            'source': None
        })

        # --------------------------
        # 1. course_schedule
        # --------------------------
        course_schedules = course_schedule.objects.filter(
            deleted=0,
            student_id__in=student_ids,
            dtm_start_student__lte=current_date_time,
            dtm_end_student__gte=current_date_time,
            **topic_filters
        ).select_related('topic_id', 'student_id__department_id')

        print(f"üìö course_schedule found: {course_schedules.count()}")

        for cs in course_schedules:
            topic = cs.topic_id
            if not topic:
                continue

            topic_key = str(topic.id)  # ‚úÖ unique by topic.id

            topic_data[topic_key].update({
                'topic': topic.topic,
                'sub_topic': getattr(topic, "sub_topic", None),
                'content_url': topic.content_url,
                'worksheet_link': topic.worksheet_link,
                'actual_content': topic.actual_content,
                'start_date': cs.dtm_start_student,
                'end_date': cs.dtm_end_student,
                'source': 'course_schedule'
            })

            department_name = cs.student_id.department_id.department if cs.student_id.department_id else "N/A"
            year = cs.student_id.year if cs.student_id.year else "N/A"
            topic_data[topic_key]['departments'].add(department_name)
            topic_data[topic_key]['years'].add(str(year))

        # --------------------------
        # 2. training_schedule
        # --------------------------
        training_records = training_schedule.objects.filter(
            college_id=college_id,
            batch_no__in=batch_nos,
            dtm_start_student__lte=current_date_time,
            dtm_end_student__gte=current_date_time,
            deleted=0,
            **topic_filters
        ).exclude(status="Completed").select_related("topic_id")

        print(f"üèãÔ∏è training_schedule found: {training_records.count()}")

        for ts in training_records:
            topic = ts.topic_id
            if not topic:
                continue

            topic_key = str(topic.id)  # ‚úÖ same key as course

            # Training schedule overrides course data if same topic exists
            topic_data[topic_key].update({
                'topic': topic.topic,
                'sub_topic': getattr(topic, "sub_topic", None),
                'content_url': topic.content_url,
                'worksheet_link': getattr(topic, "worksheet_link", None),
                'actual_content': topic.actual_content,
                'start_date': ts.dtm_start_trainer,
                'end_date': ts.dtm_end_trainer,
                'source': 'training_schedule'
            })

            # Merge departments & years from all students
            for s in students:
                topic_data[topic_key]['departments'].add(
                    s['department_id'] if s['department_id'] else "N/A"
                )
                topic_data[topic_key]['years'].add(str(s['year']) if s['year'] else "N/A")

        # --------------------------
        # Final Response
        # --------------------------
        data = []

        for topic_key, details in topic_data.items():
            data.append({
                'id': topic_key,
                'topic': details['topic'],
                'sub_topic': details['sub_topic'],
                'Content_URL': details['content_url'],
                'worksheet_link': details['worksheet_link'],
                'Actual_Content': details['actual_content'],
                'Start_Date': details['start_date'],
                'End_Date': details['end_date'],
                'college_id': college.id,
                'college_name': college.college,
                'departments': ", ".join(sorted([str(d) for d in details['departments']])),
                'years': ", ".join(
                    sorted([str(y) for y in details['years']], key=lambda x: int(x) if x.isdigit() else 0)
                ),
                'source': details['source']
            })

        print(f"\n‚úÖ Final response ready ‚Äî Total unique topics: {len(data)}")
        return Response(data, status=status.HTTP_200_OK)

    except Exception as e:
        print("‚ùå Exception:", e)
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_course_content_feedback_count(request):
    try:
        search = request.query_params.get('search', '')  
        topic = request.query_params.get('topic', None)
        college_name = request.query_params.get('college_name', None)
        department_name = request.query_params.get('department_name', None)
        trainer_name = request.query_params.get('trainer_name', None)

        # Filters for the query
        filters = {'deleted': 0}
        if topic:
            filters['topic_id__topic'] = topic
        if college_name:
            filters['student_id__college_id__college'] = college_name
        if department_name:
            filters['student_id__department_id__department'] = department_name
        if trainer_name:
            filters['trainer_id__trainer_name'] = trainer_name

        # Fetch and annotate data
        course_content_feedback_data = course_content_feedback.objects.filter(**filters).values(
            'student_id__college_id__college',
            'student_id__department_id__department',
            'topic_id__topic',
            'trainer_id__trainer_name',
            'dtm_session'
        ).annotate(student_count=Count('student_id', distinct=True))

        # Apply search filters
        if search:
            course_content_feedback_data = course_content_feedback_data.filter(
                Q(topic_id__topic__icontains=search) |
                Q(student_id__college_id__college__icontains=search) |
                Q(student_id__department_id__department__icontains=search) |
                Q(trainer_id__trainer_name__icontains=search)
            )

        # Format data for response
        formatted_data = [
            {
                'college_name': content['student_id__college_id__college'],
                'department_name': content['student_id__department_id__department'],
                'topic': content['topic_id__topic'],
                'trainer_name': content['trainer_id__trainer_name'],
                'dtm_session': content['dtm_session'],
                'student_count': content['student_count']
            }
            for content in course_content_feedback_data
        ]

        # Apply pagination
        paginator = CustomPagination()
        paginated_data = paginator.paginate_queryset(formatted_data, request)

        # Fetch unique fields
        unique_topics = course_content_feedback.objects.filter(deleted=0).values_list('topic_id__topic', flat=True).distinct()
        unique_colleges = course_content_feedback.objects.filter(deleted=0).values_list('student_id__college_id__college', flat=True).distinct()
        unique_departments = course_content_feedback.objects.filter(deleted=0).values_list('student_id__department_id__department', flat=True).distinct()
        unique_trainer_usernames = course_content_feedback.objects.filter(deleted=0).values_list('trainer_id__trainer_name', flat=True).distinct()

        # Response
        response_data = {
            'count': paginator.page.paginator.count,
            'next': paginator.get_next_link(),
            'previous': paginator.get_previous_link(),
            'results': paginated_data,
            'unique_topics': list(unique_topics),
            'unique_colleges': list(unique_colleges),
            'unique_departments': list(unique_departments),
            'unique_trainer_usernames': list(unique_trainer_usernames),
        }

        return Response(response_data)

    except Exception as e:
        logger.error(f'Error in get_course_content_feedback function: {e}')
        return Response({'error': str(e)}, status=500)



@api_view(['GET'])
def get_trainers_reportNew(request):
    try:
        trainer_report_data = trainers_report.objects.filter(deleted=0).select_related(
            'course_schedule_id'
        ).values(
            'course_schedule_id__college_id__college',
            'course_schedule_id__department_id__department',
            'course_schedule_id__trainer_id__user_name'
        ).annotate(topic_count=Count('course_schedule_id__topic_id', distinct=True))

        formatted_data = [
            {
                'college_name': report['course_schedule_id__college_id__college'],
                'department_name': report['course_schedule_id__department_id__department'],
                'trainer_name': report['course_schedule_id__trainer_id__user_name'],
                'topic_count': report['topic_count']
            }
            for report in trainer_report_data
        ]

        return Response(formatted_data)
    except Exception as e:
        logger.error(f'Error in get_trainers_report function: {e}')
        return Response({'error': 'An error occurred'}, status=500)

@api_view(['GET'])
def get_trainer_report_status(request):
    try:
        college_name = request.GET.get('college_name')
        department_name = request.GET.get('department_name')
        trainer_name = request.GET.get('trainer_name')

        trainer_status_data = trainers_report.objects.filter(
            deleted=0,
            course_schedule_id__college_id__college=college_name,
            course_schedule_id__department_id__department=department_name,
            course_schedule_id__trainer_id__user_name=trainer_name
        ).select_related('course_schedule_id').values(
            'id',
            'no_of_question_solved',
            'comments',
            'activities_done',
            'status',
            'student_feedback',
            'infrastructure_feedback',
            'remarks',
            'course_schedule_id__college_id__college',
            'course_schedule_id__department_id__department',
            'course_schedule_id__topic_id__topic',
            'course_schedule_id__trainer_id__user_name',
            'course_schedule_id__dtm_of_training',
        )

        formatted_status_data = [
            {
                'report_id': report['id'],
                'no_of_question_solved': report['no_of_question_solved'],
                'comments': report['comments'],
                'activities_done': report['activities_done'],
                'status': report['status'],
                'student_feedback': report['student_feedback'],
                'infrastructure_feedback': report['infrastructure_feedback'],
                'remarks': report['remarks'],
                'college_name': report['course_schedule_id__college_id__college'],
                'department_name': report['course_schedule_id__department_id__department'],
                'topic': report['course_schedule_id__topic_id__topic'],
                'trainer_name': report['course_schedule_id__trainer_id__user_name'],
                'dtm_of_training': report['course_schedule_id__dtm_of_training'],
            }
            for report in trainer_status_data
        ]

        return Response(formatted_status_data)
    except Exception as e:
        logger.error(f'Error in get_trainer_status function: {e}')
        return Response({'error': 'An error occurred'}, status=500)

@api_view(['GET'])
def get_trainers_report(request):
    search = request.query_params.get('search', '')
    topic = request.query_params.get('topic')
    college_name = request.query_params.get('college_name')
    department_name = request.query_params.get('department_name')
    trainer_name = request.query_params.get('trainer_name')

    filters = {'deleted': 0}
    reports = trainers_report.objects.filter(**filters)\
        .select_related('course_schedule_id', 'training_schedule_id')

    # Filtering by topic/college/department
    if topic:
        reports = reports.filter(
            Q(course_schedule_id__topic_id__topic=topic) |
            Q(training_schedule_id__topic_id__topic=topic)
        )
    if college_name:
        reports = reports.filter(
            Q(course_schedule_id__college_id__college=college_name) |
            Q(training_schedule_id__college_id__college=college_name)
        )
    if department_name:
        reports = reports.filter(
            Q(course_schedule_id__department_id__department=department_name)
        )
    if trainer_name:
        # For course_schedule, trainer_ids is a JSON list
        trainer_ids = list(trainer_master.objects.filter(user_name__icontains=trainer_name)
                            .values_list('id', flat=True))
        reports = reports.filter(
            Q(training_schedule_id__trainer_id__user_name__icontains=trainer_name) |
            Q(course_schedule_id__trainer_ids__overlap=trainer_ids)
        )

    if search:
        reports = reports.filter(
            Q(course_schedule_id__topic_id__topic__icontains=search) |
            Q(training_schedule_id__topic_id__topic__icontains=search) |
            Q(course_schedule_id__college_id__college__icontains=search) |
            Q(training_schedule_id__college_id__college__icontains=search) |
            Q(course_schedule_id__department_id__department__icontains=search) |
            Q(course_schedule_id__trainer_ids__icontains=search) |
            Q(training_schedule_id__trainer_id__user_name__icontains=search) |
            Q(status__icontains=search)
        )

    paginator = CustomPagination()
    page = paginator.paginate_queryset(reports, request)

    response_results = []
    for r in page:
        source = r.course_schedule_id or r.training_schedule_id

        # Assemble trainer_names
        trainer_names = []
        if source and getattr(source, 'trainer_ids', None):
            # JSON field
            ids = source.trainer_ids or []
            trainers = trainer_master.objects.filter(id__in=ids)
            trainer_names = [t.user_name for t in trainers]
        elif source and getattr(source, 'trainer_id', None):
            trainer_names = [source.trainer_id.user_name]

        response_results.append({
            'report_id': r.id,
            'no_of_question_solved': r.no_of_question_solved,
            'comments': r.comments,
            'activities_done': r.activities_done,
            'status': r.status,
            'student_feedback': r.student_feedback,
            'infrastructure_feedback': r.infrastructure_feedback,
            'remarks': r.remarks,
            'college_name': source.college_id.college if source and source.college_id else None,
            'department_name': getattr(source, 'department_id', None) and source.department_id.department,
            'year': getattr(source, 'year', None),
            'topic': source.topic_id.topic if source and source.topic_id else None,
            'sub_topic': getattr(source.topic_id, 'sub_topic', None),
            'trainer_name': trainer_names,
            'dtm_of_training': getattr(source, 'dtm_of_training', None),
        })

    # Gather filters data
    def distinct_list(field_lookup):
        return list(trainers_report.objects.filter(deleted=0)
                    .values_list(field_lookup, flat=True).distinct())

    unique_topics = list(set(list(trainers_report.objects.filter(deleted=0)
    .values_list('course_schedule_id__topic_id__topic', flat=True).distinct()) +
    list(trainers_report.objects.filter(deleted=0)
    .values_list('training_schedule_id__topic_id__topic', flat=True).distinct())
    ))

    unique_colleges = list(set(list(trainers_report.objects.filter(deleted=0)
        .values_list('course_schedule_id__college_id__college', flat=True).distinct()) +
        list(trainers_report.objects.filter(deleted=0)
        .values_list('training_schedule_id__college_id__college', flat=True).distinct())
    ))

    unique_departments = list(trainers_report.objects.filter(deleted=0)
        .exclude(course_schedule_id=None)
        .values_list('course_schedule_id__department_id__department', flat=True).distinct()
    )

    
    # Flatten trainer_ids from course_schedule JSON field (list of lists to flat list)
    trainer_json_lists = trainers_report.objects.filter(deleted=0, course_schedule_id__isnull=False) \
        .values_list('course_schedule_id__trainer_ids', flat=True)

    flat_trainer_usernames_from_json = list(chain.from_iterable(filter(None, trainer_json_lists)))

    # Training schedule: normal foreign key field
    trainer_names_from_training_schedule = trainers_report.objects.filter(deleted=0, training_schedule_id__isnull=False) \
        .values_list('training_schedule_id__trainer_id__user_name', flat=True).distinct()

    # Combine and deduplicate
    unique_trainers = list(set(flat_trainer_usernames_from_json + list(trainer_names_from_training_schedule)))


  
    response_data = {
        'count': paginator.page.paginator.count,
        'next': paginator.get_next_link(),
        'previous': paginator.get_previous_link(),
        'results': response_results,
        'unique_topics': list(set(filter(None, unique_topics))),
        'unique_colleges': list(set(filter(None, unique_colleges))),
        'unique_departments': list(filter(None, unique_departments)),
        'unique_trainer_usernames': list(set(unique_trainers)),
    }

    return Response(response_data)

from openpyxl import load_workbook
from openpyxl.chart import BarChart, Reference
from openpyxl.chart.series import Series
from django.http import HttpResponse
from openpyxl.chart import BarChart, PieChart, LineChart
from openpyxl.chart.label import DataLabelList

def get_chart(chart_type, title, x_title=None, y_title=None):
    chart_type = (chart_type or "").lower()
    if chart_type == "pie":
        chart = PieChart()
        chart.title = title
        chart.dataLabels = DataLabelList(showVal=True)  # show values on pie
    elif chart_type == "line":
        chart = LineChart()
        chart.title = title
        if x_title:
            chart.x_axis.title = x_title
        if y_title:
            chart.y_axis.title = y_title
    elif chart_type == "clustered":
        # clustered -> grouped bars
        chart = BarChart()
        chart.grouping = "clustered"
        chart.title = title
        if x_title:
            chart.x_axis.title = x_title
        if y_title:
            chart.y_axis.title = y_title
    else:
        # default to regular bar chart
        chart = BarChart()
        chart.title = title
        if x_title:
            chart.x_axis.title = x_title
        if y_title:
            chart.y_axis.title = y_title

    # sensible size (Excel units)
    chart.width = 20
    chart.height = 10
    return chart

def normalize_mark(value):
    """Return avg_mark on 0-100 scale."""
    try:
        v = float(value) if value is not None else 0.0
    except Exception:
        v = 0.0
    # If DB stored as fraction (0 <= v <= 1), convert to percent
    if 0 <= v <= 1:
        return v * 100.0
    return v

from openpyxl.utils import get_column_letter
from django.utils.text import slugify
@api_view(['GET'])
def get_tests_reports_by_college1(request):
    college_id = request.GET.get('college_id')
    department_ids = request.GET.get('department_id')  # Department filter
    question_types = request.GET.get('question_type') 
    start_date = request.GET.get('start_date')  # Start date filter
    end_date = request.GET.get('end_date')  # End date filter
    chart_type = request.GET.get('chart_type', 'bar')
    years = request.GET.get('year')  # Capture multiple years
    batch_nos = request.GET.get('batch_no')  # Capture multiple batch numbers
    created_by_role = request.GET.get('created_by_role') 
    inactive = request.GET.get('inactive') 
# ‚úÖ Apply year filter

    if not college_id:
        return Response({'error': 'college_id parameter is required'}, status=400)
    
    if start_date:
        start_date = parse_date(start_date)
    if end_date:
        end_date = parse_date(end_date)

    if start_date and end_date:
        if start_date > end_date:
            return Response({'error': 'start_date cannot be greater than end_date'}, status=400)

    # ‚úÖ Apply filters to students (filter by college and department)
   
    department_list = []
    #if department_ids and department_ids.lower() != "all":
       # department_list = [int(dep) for dep in department_ids.split(',') if dep.isdigit()]
   
    if department_ids and department_ids.lower() != "all":
        department_list = [int(dep) for dep in department_ids.split(',') if dep.isdigit()]
    else:
        department_list = []

    
    if years is None or years.lower() == "all":
        year_list = []
    else:
        year_list = [y.strip() for y in years.split(',') if y.strip()]

    if batch_nos is None or batch_nos.lower() == "all":
        batch_list = []
    else:
        batch_list = [b.strip() for b in batch_nos.split(',') if b.strip()]
    if not question_types:
        question_type_list = ["Aptitude", "Technical", "Softskills"]
    else:
        question_type_list = question_types.split(',')

    # ‚úÖ Ensure "All" behaves correctly
    if "All" in question_type_list:
        question_type_list = ["Aptitude", "Technical", "Softskills"]
  #  question_type_list = question_types.split(',') if question_types else []

    # ‚úÖ Apply filters to students (filter by college and department)
    student_filter = Q(deleted=0, college_id=college_id)
    if department_list:
        student_filter &= Q(department_id__in=department_list)
    if year_list:
        student_filter &= Q(year__in=year_list)
    if batch_list:
        student_filter &= Q(batch_no__in=batch_list)

    # Add a subquery to filter tests_candidates_map
    active_tests_filter = tests_candidates_map.objects.filter(
        deleted=0,
        student_id=OuterRef('id'),
        is_active=True
    ).exclude(created_by='Student')
    inactive_students = candidate_master.objects.filter(
        student_filter,deleted=0
    ).exclude(
        Exists(active_tests_filter)
    ).values(
        'students_name', 'registration_number', 'department_id__department', 'year',  'user_name',
        #'email_id', 'mobile_number', 
    )

    # Modify the `all_students` query to include the condition
    all_students = candidate_master.objects.filter(
        student_filter,
        Exists(active_tests_filter)
    ).values(
        'id', 'registration_number', 'students_name', 'user_name', 'department_id__department', 'year',
       # 'email_id', 'mobile_number', 'batch_no'
    )
    if not all_students.exists():
        return Response({'message': 'No students found for the given college'}, status=404)
    
    test_filter = Q()
   
    
    if question_type_list:
        if "All" in question_type_list:
            question_type_list = ["Aptitude", "Technical", "Softskills"]
        test_filter &= Q(question_type_id__question_type__in=question_type_list)

    # Fetch test details
    test_details = test_master.objects.filter(test_filter).values(
        'test_name', 'question_type_id__question_type', 'skill_type_id__skill_type'
    )

    # Create mappings for skill type and question type
    test_skill_map = {
        test['test_name']: test['skill_type_id__skill_type'][0] if test['skill_type_id__skill_type'] else "U"
        for test in test_details
    }
    test_type_map = {
        test['test_name']: test['question_type_id__question_type'] for test in test_details
    }

    # Identify which tests are aptitude vs technical
    aptitude_tests = [
        test['test_name'] for test in test_details
        if test['question_type_id__question_type'] == 'Aptitude'
    ]
    technical_tests = [
        test['test_name'] for test in test_details
        if test['question_type_id__question_type'] == 'Technical'
    ]

    softskill_tests = [
        test['test_name'] for test in test_details
        if test['question_type_id__question_type'] == 'Softskills'
    ]
    

   # print('Softskill tests: ', softskill_tests)
    # ‚úÖ Ensure "All" behaves correctly by only keeping categories with actual test names
    if "All" in question_type_list:
        question_type_list = []
        if aptitude_tests:
            question_type_list.append("Aptitude")
        if technical_tests:
            question_type_list.append("Technical")
        if softskill_tests:
            question_type_list.append("Softskills")

    print("Filtered Question Types After Removing Empty Categories:", question_type_list)  # Debugging


    test_report_filter = Q(deleted=0, college_id=college_id, is_active=True)
    
    
     
    test_report_filter &= Q(test_name__in=[t['test_name'] for t in test_details])


    if department_list:
        test_report_filter &= Q(student_id__department_id__in=department_list)


   # if question_type:
       # test_report_filter &= Q(test_name__in=[t['test_name'] for t in test_details])

    if start_date and end_date:
        test_report_filter &= Q(dtm_start_test__date__range=[start_date, end_date])  # ‚úÖ Apply user-selected date range

    if year_list:
        test_report_filter &= Q(year__in=year_list)  # ‚úÖ Multiple years in test filter
    if batch_list:
        test_report_filter &= Q(student_id__batch_no__in=batch_list)  # ‚úÖ Filter by batch
    if question_type_list:
        test_filter &= Q(question_type_id__question_type__in=question_type_list)  # ‚úÖ Always include default test types

    user_roles = {
        user['user_name']: (user['role'], user['college_id'])
        for user in login.objects.values('user_name', 'role', 'college_id')
    }

    # Check if role filtering is applied correctly
    placement_officer_users = [user for user, role in user_roles.items() if role[0] == "Placement Officer"]
    super_admin_users = [user for user, role in user_roles.items() if role[0] == "Super admin"]

    print("Placement Officer Users:", placement_officer_users)
    print("Super Admin Users:", super_admin_users)

    if created_by_role == "placement_officer":
        test_report_filter &= Q(created_by__in=placement_officer_users)
    elif created_by_role == "super_admin":
        test_report_filter &= Q(created_by__in=super_admin_users)

    test_reports = tests_candidates_map.objects.filter(test_report_filter,deleted=0).values(
        'test_name', 'student_id__id', 'avg_mark', 'capture_duration',
        'dtm_start_test', 'dtm_start', 'dtm_end', 'year',
        'student_id__batch_no', 'created_by'
    ).order_by('dtm_start', 'test_name').exclude(created_by='Student')


    # Debug filtered test reports
    attended_student_ids = set(test['student_id__id'] for test in test_reports)
    #print(f"\nTotal Attended Students in Tests: {len(attended_student_ids)}")
    if not test_reports.exists():
        return Response({'message': 'No test reports found for the given filters'}, status=404)
  
    for test in test_reports:
        pass
        
    technical_data, aptitude_data, test_wise_data, softskill_data = {}, {}, {}, {}

    # Initialize student data
    sorted_students = sorted(
        all_students,
        key=lambda x: x['department_id__department'] or ""
    )

   # for student in all_students:
    for student in sorted_students:
        student_id = student['id']
        student_info = {
            'Candidate': student['students_name'],
             'Reg_No': student['registration_number'] or "N/A",
         
            'Department': student['department_id__department'],
           'Login ID': student['user_name'],
            'year': student['year'],
           
        }
        technical_data[student_id] = student_info.copy()
        aptitude_data[student_id] = student_info.copy()
        softskill_data[student_id] = student_info.copy()

    # Create a lookup for student info
    student_map = {student['id']: student for student in all_students}

    # Process test reports
    for report in test_reports:
        test_name = str(report['test_name'])
        student_id = report['student_id__id']
        avg_mark = float(report['avg_mark']) if report['avg_mark'] else 0.0
        formatted_test_name = f"{test_name}_{test_skill_map.get(test_name, 'U')}"

        # Store aptitude data if it's an aptitude test
        if test_name in aptitude_tests and student_id in aptitude_data:
            aptitude_data[student_id][formatted_test_name] = avg_mark

        # Store technical data if it's a technical test
        if test_name in technical_tests and student_id in technical_data:
            technical_data[student_id][formatted_test_name] = avg_mark

        # Store technical data if it's a technical test
        if test_name in softskill_tests and student_id in softskill_data:
            softskill_data[student_id][formatted_test_name] = avg_mark

        # For the test-wise sheet
        if test_name not in test_wise_data:
            test_wise_data[test_name] = []

        student = student_map.get(student_id, {})
        test_wise_data[test_name].append({
            "Test Name": test_name,
            "College Name": college_master.objects.get(id=college_id).college,
           #  "Batch No": report.get('student_id__batch_no', ''),
            "Department": student.get('department_id__department', ''),
            "Year": report['year'],
            "Student Name": student.get('students_name', ''),
            "User Name": student.get('user_name', ''),
            "Email": student.get('email_id', ''),
            "Mobile": student.get('mobile_number', ''),
            "Registration Number": student.get('registration_number', ''),
            "Average Mark": avg_mark,
            "Capture Duration": report['capture_duration'],
            "Student Start Test": (
                report['dtm_start_test'].strftime('%d-%m-%Y %I:%M %p') if report['dtm_start_test'] else ""
            ),
            "Test Start Time": (
                report['dtm_start'].strftime('%d-%m-%Y %I:%M %p') if report['dtm_start'] else ""
            ),
            "Test End Time": (
                report['dtm_end'].strftime('%d-%m-%Y %I:%M %p') if report['dtm_end'] else ""
            )
        })

     # Step 1: Build assigned test counts per student per category
    # 1Ô∏è‚É£ Build a mapping: test_name ‚Üí question_type (Aptitude / Technical / Softskills)
    test_qtype_map = dict(
        test_master.objects.values_list('test_name', 'question_type_id__question_type')
    )

    # 2Ô∏è‚É£ Get assigned tests (no join here)
    assigned_tests = tests_candidates_map.objects.filter(
        deleted=0,
        student_id__in=[s['id'] for s in all_students]
    ).exclude(created_by='Student').values('student_id', 'test_name')

    # 3Ô∏è‚É£ Count per student per question type
    assigned_counts = {}
    for entry in assigned_tests:
        sid = entry['student_id']
        qtype = test_qtype_map.get(entry['test_name'])  # look up from mapping
        if sid not in assigned_counts:
            assigned_counts[sid] = {"Aptitude": 0, "Technical": 0, "Softskills": 0}
        if qtype in assigned_counts[sid]:
            assigned_counts[sid][qtype] += 1

    # 4Ô∏è‚É£ Compute averages (safe divide)
    for student_id in aptitude_data.keys():
        # Attended scores
        apti_scores = [
            val for key, val in aptitude_data[student_id].items()
            if isinstance(val, (int, float))
        ]
        tech_scores = [
            val for key, val in technical_data[student_id].items()
            if isinstance(val, (int, float))
        ]
        soft_scores = [
            val for key, val in softskill_data[student_id].items()
            if isinstance(val, (int, float))
        ]

        # Denominators
        assigned_apti = assigned_counts.get(student_id, {}).get("Aptitude", 0)
        assigned_tech = assigned_counts.get(student_id, {}).get("Technical", 0)
        assigned_soft = assigned_counts.get(student_id, {}).get("Softskills", 0)

        # Compute safe averages
        aptitude_data[student_id]['Total_Aptitude_Avg'] = (
            round(sum(apti_scores) / assigned_apti) if assigned_apti > 0 else 0
        )
        technical_data[student_id]['Total_Technical_Avg'] = (
            round(sum(tech_scores) / assigned_tech) if assigned_tech > 0 else 0
        )
        softskill_data[student_id]['Total_Softskills_Avg'] = (
            round(sum(soft_scores) / assigned_soft) if assigned_soft > 0 else 0
        )

    # Build a combined "top_students" list with Category
    # (This actually includes all students, not just "top" by rank)
    all_students_with_cat = []
    for student_id, student_info in aptitude_data.items():
        total_apt = aptitude_data[student_id]['Total_Aptitude_Avg']
        total_tech = technical_data[student_id]['Total_Technical_Avg']
        total_soft = softskill_data[student_id]['Total_Softskills_Avg']
        # Calculate total_avg based on question_type
        
        
       # if question_type == 'Aptitude':
       #     total_avg = total_apt
       # elif question_type == 'Technical':
       #     total_avg = total_tech
       # elif question_type == 'SoftSkills':
       #     total_avg = total_soft
       # else:
       # #    total_avg = (total_apt + total_tech + total_soft) / 2
       #      # Calculate total_avg dynamically
       #     if total_soft > 0:  # Softskills present ‚Üí divide by 3
       #         total_avg = (total_apt + total_tech + total_soft) / 3
       #     else:
       #         # No softskills ‚Üí divide by 2 even if one is 0
       #         total_avg = (total_apt + total_tech) / 2
        #total_avg = round(total_avg)
        # Determine selected question types
        selected_question_types = question_type_list  # Already a list from request

        # Calculate total_avg based on selected question types
        scores_to_avg = []

        if "Aptitude" in selected_question_types:
            scores_to_avg.append(total_apt)
        if "Technical" in selected_question_types:
            scores_to_avg.append(total_tech)
        if "Softskills" in selected_question_types:
            scores_to_avg.append(total_soft)

        # Compute total_avg safely
        total_avg = round(sum(scores_to_avg) / len(scores_to_avg)) if scores_to_avg else 0

        # Assign category
        if total_apt >= 70 and total_tech >= 70:
            category = "A"
        elif (
            (total_apt >= 50 and total_tech >= 50) or
            (total_apt >= 50 and total_tech >= 70) or
            (total_apt >= 70 and total_tech >= 50) 
            
        ):
            category = "B"
        elif (
           (total_apt >= 30 and total_tech >= 30) or
           (total_apt >= 30 and total_tech >= 50) or
           (total_apt >= 50 and total_tech >= 30) 
            
        ):
             category = "C"

        else:
            total_apt < 30 and total_tech < 30

            category = "D"

        all_students_with_cat.append({
             'Candidate': student_info['Candidate'],
             'Reg_No': student_info['Reg_No'],
            'Department': student_info['Department'],
            'Year': student_info['year'],
              'Total_Aptitude_Avg': total_apt,
            'Total_Technical_Avg': total_tech,
            'Total_Softskills_Avg': total_soft,
            'Total_Avg': total_avg,
            'Category': category
        })

    # Group scores by skill type
    tech_skill_scores = {}
    for test_name, score in technical_data[student_id].items():
        if isinstance(score, (int, float)):
            skill = test_skill_map.get(test_name, "Unknown")
            tech_skill_scores.setdefault(skill, []).append(score)

    # Compute total technical average
    flat_tech_scores = [s for scores in tech_skill_scores.values() for s in scores]
    technical_data[student_id]['Total_Technical_Avg'] = round(
        sum(flat_tech_scores) / len(flat_tech_scores)
    ) if flat_tech_scores else 0

    # Store skill-wise averages
    for skill, scores in tech_skill_scores.items():
        technical_data[student_id][f"Technical_{skill}_Avg"] = round(sum(scores) / len(scores))
    # For aptitude_data[student_id]
    apt_skill_scores = {}
    for test_name, score in aptitude_data[student_id].items():
        if isinstance(score, (int, float)):
            skill = test_skill_map.get(test_name, "Unknown")
            apt_skill_scores.setdefault(skill, []).append(score)

    flat_apt_scores = [s for scores in apt_skill_scores.values() for s in scores]
    aptitude_data[student_id]['Total_Aptitude_Avg'] = round(
        sum(flat_apt_scores) / len(flat_apt_scores)
    ) if flat_apt_scores else 0

    # Store skill-wise
    for skill, scores in apt_skill_scores.items():
        aptitude_data[student_id][f"Aptitude_{skill}_Avg"] = round(sum(scores) / len(scores))

    # Sort all students by Total_Avg in descending order
    all_students_with_cat_sorted = sorted(
        all_students_with_cat,
       # key=lambda x: x['Department']
        key=lambda x: x['Total_Avg'],  # Sort by Total_Avg
        reverse=True                  # Descending order
    )
    def deduplicate_by_regno(data_list, key='Reg_No'):
        """Return a list of dicts with unique registration numbers."""
        seen = set()
        unique_list = []
        for student in data_list:
            reg_no = str(student.get(key, '')).strip()
            if reg_no and reg_no not in seen:
                seen.add(reg_no)
                unique_list.append(student)
        return unique_list

    # Filter only Category A students
    # Filter only Category A and B students
    category_a_students = [student for student in all_students_with_cat_sorted if student['Category'] == "A"]
    category_b_students = [student for student in all_students_with_cat_sorted if student['Category'] == "B"]

    total_students = len(all_students_with_cat_sorted)
    top_25_percent_count = max(1, int(total_students * 0.25))  # At least 1 student

    # If Category A students are enough, take only from Category A
    if len(category_a_students) >= top_25_percent_count:
        top_students_filtered = category_a_students[:top_25_percent_count]
    else:
        # If Category A doesn't have enough students, fill the remaining slots with Category B students
        remaining_count = top_25_percent_count - len(category_a_students)
        top_students_filtered = category_a_students + category_b_students[:remaining_count]

    # ‚úÖ Convert Top Students Data into DataFrame
    top_students_df = pd.DataFrame(top_students_filtered)
    aptitude_df = pd.DataFrame.from_dict(aptitude_data, orient='index')
    technical_df = pd.DataFrame.from_dict(technical_data, orient='index')
    softskill_df = pd.DataFrame.from_dict(softskill_data, orient='index')
    
    if aptitude_df.empty:
        aptitude_df = pd.DataFrame([{"Message": "No aptitude data available"}])

    if technical_df.empty:
        technical_df = pd.DataFrame([{"Message": "No technical data available"}])

    if softskill_df.empty:
        softskill_df = pd.DataFrame([{"Message": "No soft skills data available"}])

        
    top_students_df = pd.DataFrame(top_students_filtered)
    category_performance_map = {
        "A": "Creamy",
        "B": "Good",
        "C": "Average",
        "D": "Need Care"
    }

    # Add performance analysis column
    for student in all_students_with_cat_sorted:
        student["Performance Analysis"] = category_performance_map.get(student["Category"], "Unknown")

    if student_id in attended_student_ids:
        if test_name in aptitude_tests:
            aptitude_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
        if test_name in technical_tests:
            technical_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
        if test_name in softskill_tests:
            softskill_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
    for report in test_reports:
            test_name = str(report['test_name'])
            student_id = report['student_id__id']
            avg_mark = float(report['avg_mark']) if report['avg_mark'] else 0.0
            formatted_test_name = f"{test_name}_{test_skill_map.get(test_name, 'U')}"

            # ‚úÖ Store in appropriate category **only if student attended**
            if student_id in attended_student_ids:
                if test_name in aptitude_tests:
                    aptitude_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
                if test_name in technical_tests:
                    technical_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
                if test_name in softskill_tests:
                    softskill_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})

        # ‚úÖ Step 5: Remove students with no test records
    def filter_empty_students(data):
        """Remove students who have no test scores (all zeros)."""
        return {k: v for k, v in data.items() if any(isinstance(val, (int, float)) and val > 0 for val in v.values())}

    aptitude_data = filter_empty_students(aptitude_data)
    technical_data = filter_empty_students(technical_data)
    softskill_data = filter_empty_students(softskill_data)

        # ‚úÖ Debug: Print attended student IDs and ensure proper type
    attended_student_ids_str = set(str(student_id) for student_id in attended_student_ids)

     # ‚úÖ Step 2: Filter students for the Growth Report
    attended_students_data = [
        student for student in all_students_with_cat_sorted 
        if str(student['Reg_No']).strip().upper() in attended_student_ids_str
    ]
   # ‚úÖ Step 3: Convert to DataFrame for Growth Report
    growth_report_df = pd.DataFrame(attended_students_data)
    if growth_report_df.empty:
        growth_report_df = pd.DataFrame([{"Message": "No Growth Report Data Available"}])
    
    if not top_students_filtered:
        top_students_df = pd.DataFrame([{"Message": "No Top 100 Students Available"}])
    else:
        top_students_df = pd.DataFrame(top_students_filtered)

    top_students_df = pd.DataFrame(deduplicate_by_regno(top_students_filtered))
   

    growth_report_df = pd.DataFrame(deduplicate_by_regno(all_students_with_cat_sorted))
   
    buffer = BytesIO()
    
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            def deduplicate_df_by_regno(df, reg_col='Reg_No'):
                """Keep only the first occurrence of each Reg_No."""
                return df.drop_duplicates(subset=[reg_col])

            # ------------------- Cumulative Aptitude -------------------
            if aptitude_data:
                aptitude_df = pd.DataFrame.from_dict(aptitude_data, orient='index')
                aptitude_df = deduplicate_df_by_regno(aptitude_df, 'Reg_No')  # Deduplicate

                base_cols = ['Candidate', 'Reg_No', 'Department', 'Login ID', 'year']
                test_cols = [col for col in aptitude_df.columns if col not in base_cols + ['Total_Aptitude_Avg']]
                final_cols = base_cols + test_cols + ['Total_Aptitude_Avg']
                aptitude_df = aptitude_df[final_cols]

                aptitude_df.to_excel(writer, sheet_name="Cumulative Aptitude", index=False)

            # ------------------- Cumulative Technical -------------------
            if technical_data:
                technical_df = pd.DataFrame.from_dict(technical_data, orient='index')
                technical_df = deduplicate_df_by_regno(technical_df, 'Reg_No')  # Deduplicate

                base_cols = ['Candidate', 'Reg_No', 'Department', 'Login ID', 'year']
                test_cols = [col for col in technical_df.columns if col not in base_cols + ['Total_Technical_Avg']]
                final_cols = base_cols + test_cols + ['Total_Technical_Avg']
                technical_df = technical_df[final_cols]

                technical_df.to_excel(writer, sheet_name="Cumulative Technical", index=False)

            # ------------------- Cumulative Softskills -------------------
            if softskill_data:
                softskill_df = pd.DataFrame.from_dict(softskill_data, orient='index')
                softskill_df = deduplicate_df_by_regno(softskill_df, 'Reg_No')  # Deduplicate

                base_cols = ['Candidate', 'Reg_No', 'Department', 'Login ID', 'year']
                test_cols = [col for col in softskill_df.columns if col not in base_cols + ['Total_Softskills_Avg']]
                final_cols = base_cols + test_cols + ['Total_Softskills_Avg']
                softskill_df = softskill_df[final_cols]

                softskill_df.to_excel(writer, sheet_name="Cumulative Softskills", index=False)

            top_students_df.to_excel(writer, sheet_name="Top 100", index=False)
            # Assume growth_report_df already has 'Total_Aptitude_Avg' and 'Total_Technical_Avg'
            
            # Step 1: Deduplicate and prepare growth report
            growth_report_df = pd.DataFrame(deduplicate_by_regno(all_students_with_cat_sorted))


            # Step 6: Write to Excel
            growth_report_df.to_excel(writer, sheet_name="Overall Report", index=False)

                    
            if inactive == "true":
                if not inactive_students.exists():
                    return Response({'message': 'No inactive students found'}, status=404)

                # Convert queryset to DataFrame
                df = pd.DataFrame(list(inactive_students))

                # Write to the existing Excel file in buffer
                df.to_excel(writer, sheet_name="Inactive Sheet", index=False)

        # ‚úÖ Step 7: Remove empty cumulative sheets from the workbook
    wb = load_workbook(buffer)
    if "Cumulative Aptitude" in wb.sheetnames and not aptitude_data:
        wb.remove(wb["Cumulative Aptitude"])
    if "Cumulative Technical" in wb.sheetnames and not technical_data:
        wb.remove(wb["Cumulative Technical"])
    if "Cumulative Softskills" in wb.sheetnames and not softskill_data:
        wb.remove(wb["Cumulative Softskills"])
        
    buffer.seek(0)

    # 2) Load the workbook to add the chart sheets
    wb = load_workbook(buffer)

    # ----------------------------------------------------------------------------
    # APTITUDE REPORT (Quants, Logical, Verbal, Problem Solving, Logical Handling)
    # ----------------------------------------------------------------------------
   # Ensure we only create sheets for question types that actually have tests
    print("‚ñ∂ Starting Aptitude Report Generation")

    valid_question_types = {
        "Aptitude": bool(aptitude_tests),
        "Technical": bool(technical_tests),
        "Softskills": bool(softskill_tests),
    }

    # If "All" is selected, filter out question types that have no tests
    if "All" in question_type_list:
        print("üîç 'All' selected in question_type_list. Filtering valid question types with tests.")
        question_type_list = [qtype for qtype, has_tests in valid_question_types.items() if has_tests]
        print(f"‚úÖ Filtered question types: {question_type_list}")

    def is_all_zero(df, exclude_columns=[]):
        """ Returns True if all numeric values in DataFrame (excluding specified columns) are 0 """
        df_numeric = df.drop(columns=exclude_columns, errors='ignore')  # Drop non-numeric columns
        return (df_numeric.select_dtypes(include=['number']) == 0).all().all()  # Check all numeric values

    # Now create only relevant sheets
    if "Aptitude" in question_type_list and aptitude_tests:
        print("üß† Aptitude tests found. Processing aptitude data...")
        
        aptitude_df_copy = aptitude_df.copy()
        
        print("‚ûï Creating category columns...")
        aptitude_df_copy["Quants"] = aptitude_df_copy.filter(regex="(?i)quants|quantitative", axis=1).sum(axis=1)
        aptitude_df_copy["Logical"] = aptitude_df_copy.filter(regex="(?i)logical(?!.*handling)", axis=1).sum(axis=1)
        aptitude_df_copy["Verbal"] = aptitude_df_copy.filter(regex="(?i)verbal", axis=1).sum(axis=1)
     
        print("üìä Grouping and averaging by Department...")
        apti_grouped = aptitude_df_copy.groupby("Department", as_index=False)[
            ["Quants", "Logical", "Verbal",  "Total_Aptitude_Avg"]
        ].mean().round(0)

        print("‚úÖ Grouped Aptitude Data:\n", apti_grouped)

        # Check before adding sheet
        if not is_all_zero(apti_grouped, exclude_columns=["Department"]):
            print("‚úÖ Valid aptitude data found. Creating 'Aptitude Report' sheet.")
            ws_apt = wb.create_sheet("Aptitude Report")
            ws_apt.append(["Department", "Quants", "Logical", "Verbal",  "Total_Aptitude_Avg"])
            
            for _, row in apti_grouped.iterrows():
                ws_apt.append([
                    row["Department"], row["Quants"], row["Logical"], row["Verbal"],
                    row["Total_Aptitude_Avg"]
                ])

            print("üìà Preparing chart for Aptitude Report...")
            # after writing header row + data rows to ws_apt:
            dept_count = len(apti_grouped)

            # department names for x-axis
            dept_ref = Reference(ws_apt, min_col=1, min_row=2, max_row=dept_count + 1)

            # all numeric columns including header row for titles
            data_ref = Reference(ws_apt, min_col=2, max_col=4, min_row=1, max_row=dept_count + 1)

            chart_apti = get_chart(chart_type, title="Aptitude Performance", x_title="Department", y_title="Scores")
            chart_apti.add_data(data_ref, titles_from_data=True)
            chart_apti.set_categories(dept_ref)
            ws_apt.add_chart(chart_apti, "H2")

            print("‚úÖ 'Aptitude Report' sheet and chart created successfully.")
        else:
            print("‚õî Skipping Aptitude Report - All data is zero or empty.")

    else:
        print("‚ö†Ô∏è Aptitude not in question_type_list or no tests found.")


    if "Technical" in question_type_list and technical_tests:
        technical_df_copy = technical_df.copy()
        technical_df_copy["C"] = technical_df_copy.filter(regex="(?i)\\bC\\b", axis=1).sum(axis=1)
        technical_df_copy["C++"] = technical_df_copy.filter(regex="(?i)c\+\+", axis=1).sum(axis=1)
        technical_df_copy["Python"] = technical_df_copy.filter(regex="(?i)python", axis=1).sum(axis=1)
        technical_df_copy["JAVA"] = technical_df_copy.filter(regex="(?i)java", axis=1).sum(axis=1)
        technical_df_copy["All Languages"] = technical_df_copy.filter(regex="(?i)all.?languages", axis=1).sum(axis=1)

        tech_grouped = technical_df_copy.groupby("Department", as_index=False)[
            ["C", "C++", "Python", "JAVA", "All Languages", "Total_Technical_Avg"]
        ].mean().round(0)
        
        # ‚úÖ Check before adding sheet
        if not is_all_zero(tech_grouped, exclude_columns=["Department"]):
            ws_tech = wb.create_sheet("Technical Report")
            ws_tech.append(["Department", "C", "C++", "Python", "JAVA", "All Languages", "Total_Technical_Avg"])
            for _, row in tech_grouped.iterrows():
                ws_tech.append([row["Department"], row["C"], row["C++"], row["Python"], row["JAVA"], row["All Languages"], row["Total_Technical_Avg"]])
            dept_ref = Reference(ws_tech, min_col=1, min_row=2, max_row=len(tech_grouped) + 1)
            data_ref = Reference(ws_tech, min_col=2, max_col=6, min_row=1, max_row=len(tech_grouped) + 1)

            # Create chart
            chart_tech = get_chart(chart_type, title="Technical Performance", x_title="Department", y_title="Scores")
            chart_tech.add_data(data_ref, titles_from_data=True)
            chart_tech.set_categories(dept_ref)
            ws_tech.add_chart(chart_tech, "H2")
        else:
            print("Skipping Technical Report - No valid data")

    # ‚úÖ Only create "SoftSkills Report" if it has non-zero values
    if "Softskills" in question_type_list:
        if softskill_tests:  # Ensure we have soft skills tests
            softskill_df_copy = softskill_df.copy()
            softskill_df_copy["Communication"] = softskill_df_copy.filter(regex="(?i)communication", axis=1).sum(axis=1)
            softskill_df_copy["Teamwork"] = softskill_df_copy.filter(regex="(?i)teamwork", axis=1).sum(axis=1)
            softskill_df_copy["Leadership"] = softskill_df_copy.filter(regex="(?i)leadership", axis=1).sum(axis=1)

            softskill_grouped = softskill_df_copy.groupby("Department", as_index=False)[
                ["Communication", "Teamwork", "Leadership", "Total_Softskills_Avg"]
            ].mean().round(0)
            
            # ‚úÖ Check if all values are zero before creating the sheet
            if not is_all_zero(softskill_grouped, exclude_columns=["Department"]):
                ws_soft = wb.create_sheet("SoftSkills Report")
                ws_soft.append(["Department", "Communication", "Teamwork", "Leadership", "Total_Softskills_Avg"])
                for _, row in softskill_grouped.iterrows():
                    ws_soft.append([row["Department"], row["Communication"], row["Teamwork"], row["Leadership"], row["Total_Softskills_Avg"]])
                dept_ref = Reference(ws_soft, min_col=1, min_row=2, max_row=len(softskill_grouped) + 1)
                data_ref = Reference(ws_soft, min_col=2, max_col=4, min_row=1, max_row=len(softskill_grouped) + 1)

                # Create chart
                chart_soft = get_chart(chart_type, title="Soft Skills Performance", x_title="Department", y_title="Scores")
                chart_soft.add_data(data_ref, titles_from_data=True)
                chart_soft.set_categories(dept_ref)
                ws_soft.add_chart(chart_soft, "H2")
            else:
                print("Skipping SoftSkills Report - No valid data")

        # ‚úÖ Remove "Aptitude Report" if no aptitude tests exist
        if "Aptitude Report" in wb.sheetnames and not aptitude_tests:
            wb.remove(wb["Aptitude Report"])

        # ‚úÖ Remove "Technical Report" if no technical tests exist
        if "Technical Report" in wb.sheetnames and not technical_tests:
            wb.remove(wb["Technical Report"])

        # ‚úÖ Remove "Softskills Report" if no soft skills tests exist
        if "SoftSkills Report" in wb.sheetnames and not softskill_tests:
            wb.remove(wb["SoftSkills Report"])

        # --------------------------------------------------------------------------
        # CATEGORY REPORT (Department-wise count of A/B/C students)
        # --------------------------------------------------------------------------
        # all_students_with_cat has all students + assigned categories
        df_category = pd.DataFrame(all_students_with_cat)

        # Group by Department and Category to get the number of students
        group_cat = df_category.groupby(["Department", "Category"]).size().reset_index(name="Count")

        # Pivot so each department is a row, each Category is a column (A, B, C)
        cat_pivot = group_cat.pivot(index="Department", columns="Category", values="Count").fillna(0)
        print("pivot",cat_pivot)

        for col in ["A", "B", "C", "D"]:
            if col not in cat_pivot.columns:
                cat_pivot[col] = 0

        ws_cat = wb.create_sheet("Category Report")
        ws_cat.append(["Department", "A", "B", "C", "D"])

        for dept in cat_pivot.index:
            ws_cat.append([dept,
                        cat_pivot.loc[dept].get("A", 0),
                        cat_pivot.loc[dept].get("B", 0),
                        cat_pivot.loc[dept].get("C", 0),
                        cat_pivot.loc[dept].get("D", 0)])

        dept_count_cat = len(cat_pivot.index)

        chart_cat = get_chart(chart_type, title="Category Distribution by Department",
                            x_title="Department", y_title="Number of Students")

                # after writing aptitude data to ws_apt
        dept_ref = Reference(ws_apt, min_col=1, min_row=2, max_row=len(apti_grouped)+1)
        # ‚úÖ Create charts only if corresponding sheet exists
        if "Aptitude Report" in wb.sheetnames:
            ws_apt = wb["Aptitude Report"]
            dept_ref = Reference(ws_apt, min_col=1, min_row=2, max_row=len(apti_grouped)+1)
            if (chart_type or "").lower() == "pie":
                pie_data = Reference(ws_apt, min_col=5, max_col=5, min_row=2, max_row=len(apti_grouped)+1)
                pie_labels = dept_ref
                chart_apti = get_chart("pie", title="Average Aptitude per Department")
                chart_apti.add_data(pie_data, titles_from_data=False)
                chart_apti.set_categories(pie_labels)
                ws_apt.add_chart(chart_apti, "H2")
            else:
                data_ref = Reference(ws_apt, min_col=2, max_col=4, min_row=1, max_row=len(apti_grouped)+1)
                chart_apti = get_chart(chart_type, title="Aptitude Performance",
                                    x_title="Department", y_title="Scores")
                chart_apti.add_data(data_ref, titles_from_data=True)
                chart_apti.set_categories(dept_ref)
                ws_apt.add_chart(chart_apti, "H2")

        if "Technical Report" in wb.sheetnames:
            ws_tech = wb["Technical Report"]
            dept_ref = Reference(ws_tech, min_col=1, min_row=2, max_row=len(tech_grouped)+1)
            if (chart_type or "").lower() == "pie":
                pie_data = Reference(ws_tech, min_col=7, max_col=7, min_row=2, max_row=len(tech_grouped)+1)
                pie_labels = dept_ref
                chart_tech = get_chart("pie", title="Average Technical per Department")
                chart_tech.add_data(pie_data, titles_from_data=False)
                chart_tech.set_categories(pie_labels)
                ws_tech.add_chart(chart_tech, "H2")
            else:
                data_ref = Reference(ws_tech, min_col=2, max_col=6, min_row=1, max_row=len(tech_grouped)+1)
                chart_tech = get_chart(chart_type, title="Technical Performance",
                                    x_title="Department", y_title="Scores")
                chart_tech.add_data(data_ref, titles_from_data=True)
                chart_tech.set_categories(dept_ref)
                ws_tech.add_chart(chart_tech, "H2")

        if "SoftSkills Report" in wb.sheetnames:
            ws_soft = wb["SoftSkills Report"]
            dept_ref = Reference(ws_soft, min_col=1, min_row=2, max_row=len(softskill_grouped)+1)
            if (chart_type or "").lower() == "pie":
                pie_data = Reference(ws_soft, min_col=5, max_col=5, min_row=2, max_row=len(softskill_grouped)+1)
                pie_labels = dept_ref
                chart_soft = get_chart("pie", title="Average Softskills per Department")
                chart_soft.add_data(pie_data, titles_from_data=False)
                chart_soft.set_categories(pie_labels)
                ws_soft.add_chart(chart_soft, "H2")
            else:
                data_ref = Reference(ws_soft, min_col=2, max_col=4, min_row=1, max_row=len(softskill_grouped)+1)
                chart_soft = get_chart(chart_type, title="Soft Skills Performance",
                                    x_title="Department", y_title="Scores")
                chart_soft.add_data(data_ref, titles_from_data=True)
                chart_soft.set_categories(dept_ref)
                ws_soft.add_chart(chart_soft, "H2")

        if (chart_type or "").lower() == "pie":
            # total across all departments ‚Äì only D column
            pie_data = Reference(ws_cat, min_col=5, max_col=5,  # 'D' column
                                min_row=2, max_row=dept_count+1)
            pie_labels = dept_ref  # departments
            chart_cat = get_chart("pie", title="Category D per Department")
            chart_cat.add_data(pie_data, titles_from_data=False)
            chart_cat.set_categories(pie_labels)
            ws_cat.add_chart(chart_cat, "G2")

        else:
            # bar/clustered ‚Äì only include nonzero columns
            # find which category columns have at least one nonzero
            nonzero_cols = []
            for idx, cat in enumerate(["A","B","C","D"], start=2):
                values = [ws_cat.cell(row=r, column=idx).value for r in range(2, dept_count+2)]
                if any(v not in (0, None) for v in values):
                    nonzero_cols.append(idx)
            if not nonzero_cols:
                nonzero_cols = [5]  # at least D

            min_col = min(nonzero_cols)
            max_col = max(nonzero_cols)
            data_ref = Reference(ws_cat, min_col=min_col, max_col=max_col,
                                min_row=1, max_row=dept_count+1)
            chart_cat = get_chart(chart_type, title="Category Distribution by Department",
                                x_title="Department", y_title="Counts")
            chart_cat.add_data(data_ref, titles_from_data=True)
            chart_cat.set_categories(dept_ref)
            ws_cat.add_chart(chart_cat, "G2")
  
    for sheet_name in ["Cumulative Aptitude", "Cumulative Technical", "Cumulative Softskills"]:
        if sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            for col in ws.columns:
                max_length = 0
                col_letter = get_column_letter(col[0].column)  # column index to letter
                for cell in col:
                    try:
                        if cell.value:
                            max_length = max(max_length, len(str(cell.value)))
                    except:
                        pass
                adjusted_width = max_length + 5  # padding
                ws.column_dimensions[col_letter].width = adjusted_width
    try:
        college_name = college_master.objects.get(id=college_id).college
    except college_master.DoesNotExist:
        college_name = 'College'

    safe_name = slugify(college_name)
    filename = f"{safe_name}_report.xlsx"

    final_buffer = BytesIO()
    try:
        wb.save(final_buffer)
    except Exception:
        from openpyxl import Workbook
        wb = Workbook()
        ws = wb.active
        ws.title = "Error"
        ws.append(["No valid data found or workbook was not initialized."])
        wb.save(final_buffer)

    final_buffer.seek(0)

    response = HttpResponse(
        final_buffer.getvalue(),
        content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )
    response['Content-Disposition'] = f'attachment; filename="{filename}"'
    response['Access-Control-Expose-Headers'] = 'Content-Disposition'

    return response

@api_view(['GET'])
def college_master_list(request):
    colleges = (
        college_master.objects
        .filter(deleted=0)  # ‚úÖ Only include non-deleted records
        .annotate(
            college_group_concat=Case(
                When(college_group__isnull=True, then=F('college')),
                When(college_group="", then=F('college')),
                default=Concat(
                    F('college'),
                    Value('-'),
                    F('college_group'),
                    output_field=CharField()
                ),
                output_field=CharField()
            )
        )
        .values('id', 'college_group_concat')
    )

    return Response(list(colleges))


import openpyxl

from openpyxl.chart import BarChart, Reference
from openpyxl.chart.series import DataPoint


def get_student_skill_percentage_download_excel(request): 
    username = request.GET.get('username')
    start_date = request.GET.get('start_date')
    categories = request.GET.get('categories')

    dtm_start_date = timezone.make_aware(timezone.datetime.strptime(start_date, '%Y-%m-%d'))

    student = candidate_master.objects.get(user_name=username,deleted=0)

    # Fetch scores for Quants, Logical, and Verbal
    def get_total_score(skill):
        tests = test_master.objects.filter(
            question_type_id__question_type='Aptitude',
            skill_type_id__skill_type=skill
        )
        # if categories:
        #     tests = tests.filter(test_type_id__test_type_categories=categories)

        test_names = tests.values_list('test_name', flat=True)
        test_candidates = tests_candidates_map.objects.filter(
            student_id=student,deleted=0,
            test_name__in=test_names
        )
        if start_date:
            test_candidates = test_candidates.filter(dtm_start__date=dtm_start_date)

        return test_candidates.aggregate(avg_mark=Sum('avg_mark'))['avg_mark'] or 0

    quants_score = get_total_score('Quants')
    logical_score = get_total_score('Logical')
    verbal_score = get_total_score('Verbal')

    # Prepare the percentages data
    percentages = {
        'Quants': quants_score,
        'Logical': logical_score,
        'Verbal': verbal_score,
    }

    # Create an Excel file
    workbook = openpyxl.Workbook()
    sheet = workbook.active
    sheet.title = 'Skill Percentages'

    # Add header row
    sheet.append(['Skill', 'Percentage'])

    # Add data rows
    for skill, score in percentages.items():
        sheet.append([skill, score])

    
    # Create a bar chart
    chart = BarChart()
    data = Reference(sheet, min_col=2, min_row=1, max_row=4, max_col=2)
    categories = Reference(sheet, min_col=1, min_row=2, max_row=4)
    chart.add_data(data, titles_from_data=True)
    chart.set_categories(categories)
    chart.title = 'Skill Percentages'
    chart.x_axis.title = 'Skills'
    chart.y_axis.title = 'Percentage'

    # Customize Y-axis scale for intervals of 10
    chart.y_axis.majorUnit = 10  # Set interval between tick marks to 10
    chart.y_axis.scaling.min = 0  # Set starting value for Y-axis
    chart.y_axis.scaling.max = 100  # Set ending value for Y-axis (adjust based on your data range)

    # Set bar colors
    colors = ['FF0000', '00FF00', '0000FF']  # Red, Green, Blue (hex color codes)
    for i, color in enumerate(colors):
        if i < len(chart.series[0].data_points):
            data_point = DataPoint(idx=i)
            data_point.graphicalProperties.solidFill = color  # Apply color to the bar
            chart.series[0].data_points.append(data_point)

    # Add the chart to the sheet
    sheet.add_chart(chart, "E5")

    # Save the Excel file to a response
    response = HttpResponse(content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    response['Content-Disposition'] = 'attachment; filename="student_skill_percentages.xlsx"'
    workbook.save(response)

    return response




@api_view(['GET'])
def get_content_master_subTopic_topic(request):
    # if not topic_name:
    #     return Response({'error': 'Topic name is required.'}, status=status.HTTP_400_BAD_REQUEST)

    # Fetch the id and sub_topic based on the topic name
    topics = content_master.objects.values('id', 'topic')
   # if not topics.exists():
        #return Response({'error': f'No topics found for the given topic name'}, status=status.HTTP_404_NOT_FOUND)

    return Response(list(topics), status=status.HTTP_200_OK)


from django.utils import timezone
from datetime import datetime


@api_view(['POST']) 
def update_test_candidates_status(request):
    try:
        test_name = request.data.get('test_name')
        student_ids = request.data.get('student_ids', [])

        print(f"Received test_name: {test_name}")
        print(f"Received student_ids: {student_ids}")

        if not test_name:
            return Response({"error": "test_name is required"}, status=400)

        if not student_ids or not isinstance(student_ids, list):
            return Response({"error": "A list of student_ids is required"}, status=400)

        # Get today's date range from 6 AM to 11 PM
        today_str = timezone.localtime().strftime('%Y-%m-%d')
        dtm_start = timezone.make_aware(datetime.strptime(f"{today_str} 06:00:00", "%Y-%m-%d %H:%M:%S"))
        dtm_end = timezone.make_aware(datetime.strptime(f"{today_str} 23:00:00", "%Y-%m-%d %H:%M:%S"))

        print(f"Start Time (6 AM): {dtm_start}")
        print(f"End Time (11 PM): {dtm_end}")

        # Get existing test-candidate map records
        existing_records = tests_candidates_map.objects.filter(
            test_name=test_name, student_id__in=student_ids,deleted=0
        )

        if not existing_records.exists():
            print("No matching records found.")
            return Response({"error": "No records found for the given test_name and student_ids"}, status=404)

        # ‚ùå Delete previous answers for this test_name and student_ids
        deleted_answers_count, _ = tests_candidates_answers.objects.filter(
            test_name=test_name,
            student_id__in=student_ids,deleted=0
        ).delete()
        print(f"Deleted {deleted_answers_count} answer(s) from tests_candidates_answers.")

        # ‚úÖ Update test-candidate map records
        updated_count = 0
        for record in existing_records:
            record.is_active = False
            record.status = "reassigned"
            record.is_reassigned = True
            record.total_score = 0
            record.avg_mark = 0
            record.assign_count = (record.assign_count or 0) + 1
            record.save()
            updated_count += 1

        print(f"Updated {updated_count} records.")
        return Response({
            "message": f"{updated_count} record(s) updated successfully",
            "answers_deleted": deleted_answers_count
        }, status=200)

    except Exception as e:
        print(f"Error: {str(e)}")
        return Response({"error": "An internal error occurred", "details": str(e)}, status=500)

def download_get_technical_test_reports_stu(request):
    username = request.GET.get('username')
    start_date = request.GET.get('start_date')
    categories = request.GET.get('categories')

    # Parse the start date
    dtm_start_date = timezone.datetime.strptime(start_date, '%Y-%m-%d').date()

    # Get the student object
    student = candidate_master.objects.get(user_name=username)

    # Filter MCQ Tests
    mcq_tests = test_master.objects.filter(
        question_type_id__question_type='Technical',
        test_type_id__test_type='MCQ Test',deleted=0
    )
    if categories:
        mcq_tests = mcq_tests.filter(test_type_id__test_type_categories=categories)

    mcq_tests = mcq_tests.values_list('test_name', flat=True)
    mcq_test_candidates = tests_candidates_map.objects.filter(
        student_id=student,
        test_name__in=mcq_tests,deleted=0
    )
    if start_date:
        mcq_test_candidates = mcq_test_candidates.filter(dtm_start__date=dtm_start_date)
    mcq_total_score = mcq_test_candidates.aggregate(avg_mark=Sum('avg_mark'))['avg_mark'] or 0

    # Filter Coding Tests
    coding_tests = test_master.objects.filter(
        question_type_id__question_type='Technical',
        test_type_id__test_type='Coding Test',deleted=0
    )
    if categories:
        coding_tests = coding_tests.filter(test_type_id__test_type_categories=categories)

    coding_tests = coding_tests.values_list('test_name', flat=True)
    coding_test_candidates = tests_candidates_map.objects.filter(
        student_id=student,
        test_name__in=coding_tests,deleted=0
    )
    if start_date:
        coding_test_candidates = coding_test_candidates.filter(dtm_start__date=dtm_start_date)
    coding_total_score = coding_test_candidates.aggregate(avg_mark=Sum('avg_mark'))['avg_mark'] or 0

    # Construct the response data
    percentages = {
        'MCQ': mcq_total_score,
        'Coding': coding_total_score
    }

    # Create an Excel file
    workbook = openpyxl.Workbook()
    sheet = workbook.active
    sheet.title = 'Technical report'

    # Add header row
    sheet.append(['Skill', 'Percentage'])

    # Add data rows
    for skill, score in percentages.items():
        sheet.append([skill, score])

    # Create a bar chart
    chart = BarChart()
    data = Reference(sheet, min_col=2, min_row=1, max_row=3, max_col=2)  # Adjusted max_row based on your data
    categories = Reference(sheet, min_col=1, min_row=2, max_row=3)  # Adjusted to match the rows
    chart.add_data(data, titles_from_data=True)
    chart.set_categories(categories)
    chart.title = 'Technical report'
    chart.x_axis.title = 'Skills'
    chart.y_axis.title = 'Percentage'

    # Customize Y-axis scale for intervals of 10
    chart.y_axis.majorUnit = 10  # Set interval between tick marks to 10
    chart.y_axis.scaling.min = 0  # Set starting value for Y-axis
    chart.y_axis.scaling.max = 100  # Set ending value for Y-axis (adjust based on your data range)

    # Set bar colors
    colors = ['FF0000', '00FF00']  # Red, Green
    for i, color in enumerate(colors):
        if i < len(chart.series[0].data_points):
            data_point = DataPoint(idx=i)
            data_point.graphicalProperties.solidFill = color  # Apply color to the bar
            chart.series[0].data_points.append(data_point)

    # Add the chart to the sheet
    sheet.add_chart(chart, "E5")
    
    # Save the Excel file to a response
    response = HttpResponse(content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    response['Content-Disposition'] = 'attachment; filename="student_skill_percentages.xlsx"'
    workbook.save(response)
    
    return response


#__________________________________________28-02-2025______________________#

@api_view(['GET'])
def get_announcements_cc_po(request):
    try:
        # Step 1: Get the role and college_id from query parameters
        role = request.GET.get('role')
        collegeId = request.GET.get('college_id')
        username = request.GET.get('username')

        # Step 2: Fetch all active and non-deleted announcements
        announcements = comman_announcement.objects.filter(deleted=0)

        # Step 3: Apply filtering based on role
        if role == 'Training admin':
            admin_login_ids = login.objects.filter(role__in=['Training admin', 'Super admin'],deleted=0).values_list('id', flat=True)
            announcements = announcements.filter(login_id__in=admin_login_ids)

        elif role == 'Placement admin':
            # Step 4: Filter based on college_id if provided
            if collegeId:
                admin_login_ids = login.objects.filter(role__in=['Placement admin', 'Super admin'], college_id=collegeId,deleted=0).values_list('id', flat=True)
            else:
                admin_login_ids = login.objects.filter(role__in=['Placement admin', 'Super admin'],deleted=0).values_list('id', flat=True)
            
            announcements = announcements.filter(login_id__in=admin_login_ids)

        # Step 3: Apply filtering based on role
        if role == 'Placement Officer':
            print('PO if condition......')
            admin_login_ids = login.objects.filter(role__in=['Placement Officer'], college_id=collegeId, user_name=username,deleted=0).values_list('id', flat=True)
            announcements = announcements.filter(login_id__in=admin_login_ids)


        # Step 5: Prepare the response data
        unique_announcements = defaultdict(lambda: None)

        for announcement in announcements:
            if announcement.announcement_image:
                image_base64 = base64.b64encode(announcement.announcement_image).decode('utf-8')
            else:
                image_base64 = None  # Handle case where image is not present

            if announcement.announcement not in unique_announcements:
                unique_announcements[announcement.announcement] = {
                    'announcement': announcement.announcement,
                    'announcement_image': image_base64
                }

        # Step 6: Fetch job offers and include them in the response
        job_offers_data = job_offers.objects.filter(announcement__isnull=False, college_id=collegeId,deleted=0)  # Add any necessary filtering if needed

        for job in job_offers_data:
            unique_announcements[job.announcement] = {
                'announcement': job.announcement,
                'company_name': job.company_name,
                'post_name': job.post_name,
                'job_type': job.job_type,
                'intern_fulltime': job.intern_fulltime,
                'post_name_description': job.post_name_description,
                'announcement_image': None  # Assuming there's no image for job offers, adjust as necessary
            }

        response_data = list(unique_announcements.values())

        return JsonResponse(response_data, safe=False, status=200)

    except comman_announcement.DoesNotExist:
        return JsonResponse({'error': 'No announcements found'}, status=404)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)

@api_view(['GET'])
@cache_page(60 * 60) 
def get_student_test_summary(request):
    """Optimized function to get total assigned and attended tests for a student."""
    student_id = request.GET.get('student_id')

    # Validate mandatory `student_id`
    if not student_id:
        return Response({"error": "The student_id field is required."}, status=400)

    from_date = request.GET.get('from_date')
    to_date = request.GET.get('to_date')
    college_id = request.GET.get('college_id')
    search_query = request.GET.get('search', '')

    # Validate and parse dates
    try:
        if from_date:
            from_date = datetime.strptime(from_date, '%Y-%m-%d').date()
        if to_date:
            to_date = datetime.strptime(to_date, '%Y-%m-%d').date()
    except ValueError:
        return Response({"error": "Invalid date format. Use YYYY-MM-DD."}, status=400)

    # Build filters
    filters = Q(student_id=student_id, deleted=False)
    if from_date and to_date:
        filters &= Q(dtm_end__date__range=(from_date, to_date))
    elif from_date:
        filters &= Q(dtm_end__date__gte=from_date)
    elif to_date:
        filters &= Q(dtm_end__date__lte=to_date)

    if college_id:
        filters &= Q(student_id__college_id=college_id)
    if search_query:
        filters &= Q(student_id__students_name__icontains=search_query) | Q(student_id__registration_number__icontains=search_query)

    # Query assigned and attended tests
    assigned_tests = tests_candidates_map.objects.filter(filters).values('student_id').annotate(
        total_assigned=Count('test_name', distinct=True)
    )
    attended_tests = tests_candidates_map.objects.filter(filters & Q(is_active=True)).values('student_id').annotate(
        total_attended=Count('id')
    )

    assigned_tests_dict = {item['student_id']: item['total_assigned'] for item in assigned_tests}
    attended_tests_dict = {item['student_id']: item['total_attended'] for item in attended_tests}

    # Fetch student details
    students = candidate_master.objects.filter(id=student_id).select_related(
        'college_id', 'department_id'
    ).values(
        'id', 'students_name', 'registration_number', 'college_id__college', 'department_id__department', 'year'
    )

    # Prepare response
    response_data = [
        {
            'student_id': student['id'],
            'student_name': student['students_name'],
            'registration_number': student['registration_number'],
            'college_name': student['college_id__college'],
            'department': student['department_id__department'],
            'year': student['year'],
            'total_assigned_tests': assigned_tests_dict.get(student['id'], 0),
            'total_attended_tests': attended_tests_dict.get(student['id'], 0),
        }
        for student in students
    ]

    return Response(response_data)


@api_view(['GET'])
def get_test_reports_cor(request):
    # Get filter parameters from the request
    test_name = request.GET.get('test_name', "").strip()
    college_id = request.GET.getlist('college_id[]') 
    department_id = request.GET.get('department_id', "").strip()
    year = request.GET.get('year', "").strip()

    print('Request.GET:', request.GET)

    print('college_id1: ', college_id)


    # Base query for test reports
    reports = test_reports.objects.filter(deleted=0)

    # Apply filters if parameters are provided
    if test_name:
        reports = reports.filter(test_name=test_name)
    if college_id:
        reports = reports.filter(college_id__in=college_id)
    if department_id:
        reports = reports.filter(department_id=department_id)
    if year:
        reports = reports.filter(year=year)

    # Subquery for fetching `dtm_start` and `dtm_end`
    test_candidate_map = tests_candidates_map.objects.filter(
        test_name=OuterRef('test_name')
    ).values('dtm_start', 'dtm_end')

    reports = reports.annotate(
        dtm_start=Subquery(test_candidate_map.values('dtm_start')[:1]),
        dtm_end=Subquery(test_candidate_map.values('dtm_end')[:1]),
    )

    # Prepare data based on conditions
    if test_name and not (college_id or department_id or year):
        grouped_reports = reports.values('test_name', 'dtm_start', 'dtm_end').annotate(
            total_students=Sum('students_count')
        )
        data = [
            {
                'test_name': report['test_name'],
                'college_name': 'All',
                'department_name': 'All',
                'year': 'All',
                'total_students': report['total_students'],
                'dtm_start': report['dtm_start'],
                'dtm_end': report['dtm_end'],
            }
            for report in grouped_reports
        ]
    elif college_id and not (department_id or year):
        grouped_reports = reports.values(
            'test_name', 'college_id', 'college_id__college', 'dtm_start', 'dtm_end'
        ).annotate(total_students=Sum('students_count'))
        data = [
            {
                'test_name': report['test_name'],
                'college_name': report['college_id__college'],
                'department_name': 'All',
                'year': 'All',
                'total_students': report['total_students'],
                'dtm_start': report['dtm_start'],
                'dtm_end': report['dtm_end'],
            }
            for report in grouped_reports
        ]
    elif college_id and test_name == "" and department_id == "" and year in ['1', '2', '3', '4']:
        grouped_reports = reports.values(
            'test_name', 'college_id', 'college_id__college', 'year', 'dtm_start', 'dtm_end'
        ).annotate(total_students=Sum('students_count')).distinct()
        data = [
            {
                'test_name': report['test_name'],
                'college_name': report['college_id__college'],
                'department_name': 'All',
                'year': report['year'],
                'total_students': report['total_students'],
                'dtm_start': report['dtm_start'],
                'dtm_end': report['dtm_end'],
            }
            for report in grouped_reports
        ]
    elif college_id and test_name and (department_id == "" or department_id is None) and year in ['1', '2', '3', '4']:
        grouped_reports = reports.values(
            'test_name', 'college_id', 'college_id__college', 'year', 'dtm_start', 'dtm_end'
        ).annotate(total_students=Sum('students_count')).distinct()
        data = [
            {
                'test_name': report['test_name'],
                'college_name': report['college_id__college'],
                'department_name': 'All',
                'year': report['year'],
                'total_students': report['total_students'],
                'dtm_start': report['dtm_start'],
                'dtm_end': report['dtm_end'],
            }
            for report in grouped_reports
        ]
    else:
        grouped_reports = reports.values(
            'test_name', 'college_id', 'college_id__college', 
            'department_id', 'department_id__department', 
            'year', 'dtm_start', 'dtm_end'
        ).annotate(total_students=Sum('students_count'))
        data = [
            {
                'test_name': report['test_name'],
                'college_name': report['college_id__college'] if college_id else 'All',
                'department_name': report['department_id__department'] if department_id else 'All',
                'year': report['year'] if year else 'All',
                'total_students': report['total_students'],
                'dtm_start': report['dtm_start'],
                'dtm_end': report['dtm_end'],
            }
            for report in grouped_reports
        ]

    # Return the serialized data
    return Response(data)

def get_batch_numbers(request, college_id):
    batch_numbers = candidate_master.objects.filter(college_id=college_id,deleted=0).values_list('batch_no', flat=True).distinct()
    return JsonResponse({'batch_numbers': list(batch_numbers)})


class jobcreateAPIViewNew(generics.CreateAPIView):
    queryset = job_offers.objects.all()
    serializer_class = jobSerializer

    def perform_create(self, serializer):
        print("üöÄ API Endpoint Triggered: perform_create")

        try:
            # Before saving, check if the serializer is valid
            if not serializer.is_valid():
                print(f"‚ùå Serializer validation failed: {serializer.errors}")
                return
            
            print("‚úÖ Serializer is valid. Proceeding to save job instance.")

            # Save job instance
            job_instance = serializer.save()

            print(f"‚úÖ Job instance created: {job_instance}")

            # Many-to-Many fields need to be assigned separately
            department_data = self.request.data.get('department_id', [])
            college_data = self.request.data.get('college_id', [])
            
            if department_data:
                job_instance.department_id.set(department_data)
                print(f"‚úÖ Department IDs assigned: {department_data}")

            if college_data:
                job_instance.college_id.set(college_data)
                print(f"‚úÖ College IDs assigned: {college_data}")

            # Now create eligible students for this job
            self.create_eligible_students(job_instance)

        except Exception as e:
            print(f"‚ùå Error in creating job: {e}")
            print(f"‚ùå Serializer errors: {serializer.errors}")

    def create_eligible_students(self, job_instance):
        try:
            print(f"üîç Creating eligible students for job ID: {job_instance.id}")

            # Step 1: Fetch all students based on college_id
            all_students = candidate_master.objects.filter(college_id__in=job_instance.college_id.all(), deleted=0)
            print(f"üéì Total students fetched: {all_students.count()}")

            if not all_students.exists():
                print("‚ùå No students found for the given college.")
                return

            existing_students_ids = eligible_student_list.objects.filter(job_id=job_instance.id).values_list('students_id', flat=True)
            
            ineligible_students = [
                {
                    'students_id': student.id,
                    'announcement': '',
                    'job_id': job_instance.id,
                    'round_of_interview': 'Interview Date',
                    'is_eligible': False
                }
                for student in all_students if student.id not in existing_students_ids
            ]

            # Bulk create ineligible students only if there are new students to add
            if ineligible_students:
                ineligible_serializer = eligible_studentSerializer(data=ineligible_students, many=True)
                if ineligible_serializer.is_valid():
                    ineligible_serializer.save()
                    print(f"‚úÖ Ineligible students saved successfully.")
                else:
                    print(f"‚ùå Ineligible student data is not valid: {ineligible_serializer.errors}")
            else:
                print(f"‚ÑπÔ∏è No new ineligible students to save.")

            # Step 3: Filter eligible candidates based on job criteria
            eligible_candidates = self.filter_candidates(job_instance)
            print(f"‚úÖ Filtered eligible candidates: {len(eligible_candidates)}")

            # Step 4: Update the is_eligible field to True for eligible students
            if eligible_candidates:
                eligible_student_list.objects.filter(job_id=job_instance.id, students_id__in=[candidate.id for candidate in eligible_candidates]).update(is_eligible=True)
                print(f"‚úÖ Eligible students updated successfully.")
            else:
                print(f"‚ùå No eligible students found for the job.")

        except Exception as e:
            print(f'‚ùå Exception in create_eligible_students: {str(e)}')
    @staticmethod
    def safe_int(value):
        """Convert value to int if possible, otherwise return None"""
        try:
            return int(value) if value is not None and value != "" else None
        except ValueError:
            return None

    def filter_candidates(self, job):
        print(f"üîç Filtering candidates for job ID: {job.id}")

        department_ids = list(job.department_id.values_list('id', flat=True))  # ManyToManyField fix
        print(f"üìå department_ids: {department_ids}")

        filters = Q(deleted=0)

        if department_ids:
            filters &= Q(department_id__in=department_ids)
            print(f"‚úÖ Filtering candidates with department_id in {department_ids}")

        # ‚úÖ Convert CharFields to Integer Before Filtering
        history_of_arrears_int = self.safe_int(job.history_of_arrears)
        standing_arrears_int = self.safe_int(job.standing_arrears)
        marks_10th_int = self.safe_int(job.marks_10th)
        marks_12th_int = self.safe_int(job.marks_12th)
        cgpa_int = self.safe_int(job.cgpa)
        no_of_offers_int = self.safe_int(job.no_of_offers)

        # ‚úÖ Use Converted Integers in Filters
        criteria = {
            'college_id__in': list(job.college_id.values_list('id', flat=True)),  # ManyToManyField fix
            'year': job.year,
            'marks_10th__gte': marks_10th_int,
            'marks_12th__gte': marks_12th_int,
            'cgpa__gte': cgpa_int,
            'history_of_arrears__lte': history_of_arrears_int,
            'standing_arrears__lte': standing_arrears_int
        }

        print(f"üìä Filter Criteria (Converted to Ints where needed): {criteria}")

        # Apply filters dynamically
        for field, value in criteria.items():
            if value is not None:
                filters &= Q(**{field: value})
                print(f"‚úÖ Applied filter: {field} = {value}")

        if no_of_offers_int is not None:
            filters &= Q(number_of_offers__lte=no_of_offers_int)
            print(f"‚úÖ Filtering candidates with number_of_offers <= {no_of_offers_int}")

        # Handle gender separately
        if job.gender:
            gender = job.gender.lower()
            print(f"üßë Gender filter applied: {gender}")
            if gender in ['male', 'female']:
                filters &= Q(gender__iexact=gender)
            elif gender == 'both':
                filters &= Q(gender__in=['Male', 'Female'])
                print(f"‚úÖ Filtering both male and female candidates.")

        print("üìå Final Filters:", filters)

        candidates = candidate_master.objects.filter(filters)
        print(f"‚úÖ Final count of eligible candidates: {candidates.count()}")

        return candidates

class TestAssignviewBatch_Placement(APIView):
    print("hi")
    def post(self, request, format=None):

        test_name = request.data.get('test_name')
        test_type_id = request.data.get('test_type_id')
        question_type_id = request.data.get('question_type_id')
        skill_type_id = request.data.get('skill_type_id')
        company_name = request.data.get('company_name')  # Add company_name field
        company_email = request.data.get('company_email')  
        created_by = request.data.get('created_by', 'System')
        if not all([test_name, test_type_id, question_type_id]):
            return Response({'error': 'Missing fields for test_master'}, status=status.HTTP_400_BAD_REQUEST)

        is_company = False
        try:
            # Attempt to retrieve the test_type and set is_company accordingly
            print('Attempting to retrieve test_type with ID:', test_type_id)
            test_type_instance = test_type.objects.get(id=test_type_id,deleted=0)
            print('Retrieved test_type_instance:', test_type_instance)

            # Check if the test is company-specific
            if test_type_instance.test_type_categories == "Mock/Interview":
                is_company = True
                print('is_company set to True for company-specific test')
            else:
                print('is_company remains False as test is not company-specific')
                
        except test_type.DoesNotExist:
            print('Error: Invalid test_type_id - test_type with this ID does not exist')
            return Response({'error': 'Invalid test_type_id'}, status=status.HTTP_400_BAD_REQUEST)
        test_master_data = {
            'test_name': test_name,
            'test_type_id': test_type_id,
            'question_type_id': question_type_id,
            'skill_type_id': skill_type_id,
            'is_company':is_company
        }
        
        if company_name:
            test_master_data['company_name'] = company_name
        if company_email:
            test_master_data['company_email'] = company_email

        test_master_serializer = testsSerializersAdd(data=test_master_data)
        
        if not test_master_serializer.is_valid():
            print(f"Test master serializer errors: {test_master_serializer.errors}")
            return Response(test_master_serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        

        college_id = request.data.get('college_id')
        college_group_id = request.data.get('college_group_id', [])
        batch_no = request.data.get('batch_no', [])
        department_id = request.data.get('department_id', [])
        year = request.data.get('year', [])
        print('Year Passing..', year)

        print("Response data******!: ", year, college_id, department_id)

        students = candidate_master.objects.filter(is_database=True)

        if college_id:
            students = students.filter(college_id=college_id)

        if department_id:
            students = students.filter(department_id__in=department_id)

        if year:
            students = students.filter(year__in=year)

        if batch_no:
            students = students.filter(batch_no__in=batch_no)

        if not students.exists():
            return Response({'error': 'No students match the provided criteria.'}, status=status.HTTP_404_NOT_FOUND)



        print("Students: ", students)
        data = []
        updated_candidates = []  # To store IDs of updated candidates

        current_date_and_time = datetime.now()  # Get the current date and time

        for student in students:
            print("Student id: ", student.id)
            test_candidate_data = {
                'test_name': request.data.get('test_name'),  # Assuming 'test_name' is provided in the request
                'question_id': request.data.get('question_id'),  # Assuming 'question_id' is provided in the request
                'student_id': student.id,
                'college_id': student.college_id.id,  # Use student.college_id.id for pk
                'department_id': student.department_id.id,  # Use student.department_id.id for pk
                'dtm_start': request.data.get('dtm_start'),
                'dtm_end': request.data.get('dtm_end'),
                'dtm_start1': request.data.get('dtm_start'),  # Store same value as dtm_start
                'dtm_end1': request.data.get('dtm_end'), 
                'is_camera_on': request.data.get('is_camera_on'),
                'duration': request.data.get('duration'),
                'duration_type': request.data.get('duration_type'),
                'year': student.year,
                'rules_id': request.data.get('rules_id'),
                'need_candidate_info': request.data.get('need_candidate_info'),
                'dtm_created': current_date_and_time ,
                  'created_by': created_by # Add current date and time
            }

            serializer = testcandidatemapSerializers(data=test_candidate_data)
            
            print("Serializer: ", serializer)

            if not serializer.is_valid():
                print(f"serializer errors: {serializer.errors}")
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        


            with transaction.atomic():  # Use transaction to ensure atomicity
                test_master_serializer.save()
                print('Test master saved Successfully')
                serializer.save()
                data.append(serializer.data)
                print("Data.append: ", data)

                # Check and update candidate_master if needed
                if student.need_candidate_info is None and request.data.get('need_candidate_info') is True:
                    student.need_candidate_info = request.data.get('need_candidate_info')
                    student.save(update_fields=['need_candidate_info'])
                    updated_candidates.append(student.id)
        
        print("Data: ", data)
        return Response(data, status=status.HTTP_201_CREATED)

from datetime import timedelta
@api_view(['POST'])
def update_test_candidates_status_reassign(request):
    try:
        test_name = request.data.get('test_name', '').strip()
        student_id = request.data.get('student_id')

        print(f"Received test_name: '{test_name}'")  # Debugging
        print(f"Received student_id: {student_id}")  # Debugging

        if not test_name:
            return Response({"error": "test_name is required"}, status=400)

        if not student_id:
            return Response({"error": "student_id is required"}, status=400)
        
       # dtm_end = timezone.now() + timedelta(days=2)  # Set dtm_end to 48 hours from now

        # Debugging: Check if test_name exists in the database
        existing_tests = tests_candidates_map.objects.filter(test_name=test_name,deleted=0)
        print(f"Matching test_name count: {existing_tests.count()}")

        # Correct query: Use `.filter(student_id__id=student_id)`
        record = tests_candidates_map.objects.filter(
            test_name=test_name, student_id__id=student_id,deleted=0
        ).first()

        if not record:
            print(f"No matching record found for test_name: '{test_name}' and student_id: {student_id}")
            return Response({
                "error": f"No record found for test_name '{test_name}' and student_id '{student_id}'"
            }, status=404)

        # Check if total_score is 0 and capture_duration is 3 min or less
        if is_duration_below_3_min(record.capture_duration):
            record.is_active = False
           # record.dtm_end = dtm_end 
            record.is_reassigned=True
            record.status = "reassigned"
            record.total_score = 0  # Set total_score to 0
            record.avg_mark = 0  
            if record.assign_count is None:
                record.assign_count = 1  # Initialize if None
            else:
                record.assign_count += 1  # Increment by 1
    
            record.save()

            print(f"‚úÖ Updated record for student_id {student_id}.")  # Debugging
            return Response({"message": "Record updated successfully"}, status=200)

        return Response({"message": "No update required"}, status=200)

    except Exception as e:
        print(f"üî• Error: {str(e)}")  # Debugging
        return Response({"error": "An internal error occurred", "details": str(e)}, status=500)


def is_duration_below_3_min(duration_str):
    """Convert 'X min Y sec' to total seconds and check if it's <= 180 seconds (3 min)."""
    match = re.match(r'(\d+)\s*min\s*(\d+)?\s*sec?', duration_str)
    
    if match:
        minutes = int(match.group(1)) if match.group(1) else 0
        seconds = int(match.group(2)) if match.group(2) else 0
        total_seconds = (minutes * 60) + seconds
        return total_seconds <= 180  # 3 minutes
    return False
			




@api_view(['GET'])
def update_question_text(request):
    """
    API endpoint to update question_text in question_master.
    Example request: /api/update_question_text?id=1&question_text=New+Text
    """
    # Retrieve query parameters
    question_id = request.GET.get('id')  # Get question ID
    new_question_text = request.GET.get('question_text')  # Get new question text
    
    if not question_id or not new_question_text:
        return Response(
            {"error": "Both 'id' and 'question_text' query parameters are required."},
            status=400,
        )

    # Fetch the question_master object or return 404
    question = get_object_or_404(question_master, id=question_id)

    # Update the question_text field
    question.question_text = new_question_text
    question.save()  # Save the updated model to the database

    return Response(
        {"message": f"Question ID {question_id} updated successfully.", "updated_text": question.question_text},
        status=200,
    )

@csrf_exempt
def update_test_entries(request):
    try:
        if request.method == "POST":
            data = json.loads(request.body.decode("utf-8"))
            test_names = data.get("test_name", [])  # Expecting a list
            created_by = data.get("created_by")  # Directly use the provided value

        elif request.method == "GET":
            test_names = request.GET.getlist("test_name")
            created_by = request.GET.get("created_by")

        else:
            return JsonResponse({"error": "Invalid request method"}, status=400)

        # Debugging logs
        print(f"‚úÖ Received test_name: {test_names}, created_by: {created_by}")

        # Ensure test_names is not empty
        if not test_names:
            return JsonResponse({"error": "test_name is required"}, status=400)

        # Check if test_name exists in the database before updating
        existing_tests = tests_candidates_map.objects.filter(test_name__in=test_names,deleted=0).values_list("test_name", flat=True)
        if not existing_tests:
            print("‚ùå No matching test_name found in the database")
            return JsonResponse({"error": "No matching test entries found"}, status=404)

        print(f"üîç Matching test_names in DB: {list(existing_tests)}")

        # Perform update query
        updated_count = tests_candidates_map.objects.filter(test_name__in=test_names).update(
            dtm_created=now(),
            created_by=created_by
        )

        print(f"‚úÖ Updated {updated_count} entries successfully")

        # Debugging: Print raw SQL executed
        print("üõ† Executed SQL Query:")
        with connection.cursor() as cursor:
            cursor.execute("SELECT test_name, created_by FROM tests_candidates_map WHERE test_name = ANY(%s)", [test_names])
            rows = cursor.fetchall()
            for row in rows:
                print(row)

        return JsonResponse({"message": f"Updated {updated_count} entries successfully"})

    except json.JSONDecodeError:
        return JsonResponse({"error": "Invalid JSON format"}, status=400)

    except Exception as e:
        print(f"‚ùå Unexpected Error: {str(e)}")
        return JsonResponse({"error": str(e)}, status=500)

def _generate_cache_key_for_filter(params):
    """Generate a unique cache key from request query parameters."""
    key_string = json.dumps(params, sort_keys=True)
    return "database_candidate_filter_" + hashlib.md5(key_string.encode()).hexdigest()

  # Caches for 1 hour at view level
@api_view(['GET'])
def get_database_candidate_filter(request):
    try:
        college_name = request.GET.get('college_name', '')
        batch_no = request.GET.get('batch_no', '')
        department = request.GET.get('department', '')
        year = request.GET.get('year', '')

        # Generate unique cache key from query parameters
        cache_key = _generate_cache_key_for_filter({
            'college_name': college_name,
            'batch_no': batch_no,
            'department': department,
            'year': year
        })

        cached_data = cache.get(cache_key)
        if cached_data:
            logger.info(f"[CACHE HIT] {cache_key}")
            return Response(cached_data)

        logger.info(f"[CACHE MISS] {cache_key}")

        queryset = candidate_master.objects.filter(
            deleted=0, is_database=True
        ).select_related('college_id', 'department_id')

        if college_name:
            queryset = queryset.filter(college_id__college=college_name)

        if not batch_no and not department and not year:
            # ‚úÖ include college_id here too
            grouped_data = queryset.values(
                'college_id',
                'college_id__college',
                'college_id__college_group'
            ).annotate(
                user_count=Count('id'),
                batch_no=models.Value("All", output_field=models.CharField()),
                department_id__department=models.Value("All", output_field=models.CharField()),
                year=models.Value("All", output_field=models.CharField())
            ).order_by('college_id__college')
        else:
            if batch_no and batch_no != "All":
                queryset = queryset.filter(batch_no=batch_no)
            if department and department != "All":
                queryset = queryset.filter(department_id__department=department)
            if year and year != "All":
                queryset = queryset.filter(year=year)

            grouped_data = queryset.values(
                'college_id',
                'college_id__college',
                'college_id__college_group',
                'batch_no',
                'department_id__department',
                'year'
            ).annotate(
                user_count=Count('id')
            ).order_by('college_id__college', 'batch_no', 'department_id__department', 'year')

        response_data = list(grouped_data)

        # Cache the response data manually
        cache.set(cache_key, response_data, timeout=300)

        return Response(response_data)

    except Exception as e:
        print(traceback.format_exc())
        return Response({'error': str(e)}, status=500)

def _generate_cache_key_for_nondb_filter(params):
    """Generate a unique cache key for non-database filter request."""
    key_string = json.dumps(params, sort_keys=True)
    return "nondatabase_candidate_filter_" + hashlib.md5(key_string.encode()).hexdigest()

  # Cache the view for 1 hour
@api_view(['GET'])
def get_Nondatabase_candidate_filter(request):
    try:
        college_name = request.GET.get('college_name', '')
        batch_no = request.GET.get('batch_no', 'All')

        # Generate cache key
        cache_key = _generate_cache_key_for_nondb_filter({
            'college_name': college_name,
            'batch_no': batch_no
        })

        # Try fetching from cache
        cached_data = cache.get(cache_key)
        if cached_data:
            logger.info(f"[CACHE HIT] {cache_key}")
            return Response(cached_data)

        logger.info(f"[CACHE MISS] {cache_key}")

        # Base query
        queryset = candidate_master.objects.filter(deleted=0, is_database=False)

        # Apply filters
        if college_name:
            queryset = queryset.filter(college_id__college=college_name)
        if batch_no != 'All':
            queryset = queryset.filter(batch_no=batch_no)

        # Aggregate grouped data (add college_id)
        grouped_data = queryset.values(
            'college_id',
            'college_id__college',
            'college_id__college_group'
        ).annotate(
            user_count=Count('id'),
            batch_no=models.Value(batch_no, output_field=models.CharField()),
            dtm_upload=Max('dtm_upload')
        ).order_by('college_id__college')

        # Format for response
        response_data = [
            {
                "college_id": data["college_id"],   # ‚úÖ Added
                "college_id__college": data["college_id__college"],
                "college_id__college_group": data["college_id__college_group"],
                "batch_no": data["batch_no"],
                "dtm_upload": data["dtm_upload"].strftime('%Y-%m-%d %H:%M:%S') if data["dtm_upload"] else None,
                "user_count": data["user_count"]
            }
            for data in grouped_data
        ]

        # Set cache
        cache.set(cache_key, response_data, timeout=300)  # Cache for 5 min

        return Response(response_data)

    except Exception as e:
        logger.error(traceback.format_exc())
        return Response({'error': str(e)}, status=500)


@api_view(['GET'])
def get_candidate_batches_clg_id(request):
    # Retrieve query parameters
    college_ids = request.query_params.getlist('college_id[]', [])
    
    # Log for debugging
    print('Received college_ids:', college_ids)

    if not college_ids:
        return Response({"error": "No college IDs provided"}, status=400)

    # Query the database
    queryset = candidate_master.objects.filter(
        batch_no__isnull=False, is_database=True, college_id__in=college_ids
    )
    
    # Get distinct batch numbers
    batch_numbers = queryset.values('batch_no').distinct()

    # Return the result
    return Response(list(batch_numbers))


@api_view(['GET'])
def get_candidate_batches_clg_id_NDB(request):
    # Retrieve query parameters
    college_ids = request.query_params.getlist('college_id[]', [])
    
    # Log for debugging
    print('Received college_ids:', college_ids)

    if not college_ids:
        return Response({"error": "No college IDs provided"}, status=400)

    # Query the database
    queryset = candidate_master.objects.filter(
        batch_no__isnull=False, is_database=False, college_id__in=college_ids
    )
    
    # Get distinct batch numbers
    batch_numbers = queryset.values('batch_no').distinct()

    # Return the result
    return Response(list(batch_numbers))
													

#------------------------------17-03-2025------------------------------------#


class ExcelImportView_Questions_PO(APIView):
    def post(self, request, format=None):
        print('Request Data: ', request.data)
        
        # Extract multiple question paper names and files
        question_paper_names = request.data.getlist('question_paper_name', [])
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        files = request.FILES.getlist('file')
        folder_name = request.data.get('folder_name')

        # Validation for required fields
        if not all([question_paper_names, files, duration_of_test, topic, sub_topic, no_of_questions, upload_type, test_type]):
            return Response({'error': 'Missing fields or files'}, status=status.HTTP_400_BAD_REQUEST)

        # Ensure the number of files matches the number of question paper names
        if len(files) != len(question_paper_names):
            return Response({'error': 'Mismatch between question paper names and files'}, status=status.HTTP_400_BAD_REQUEST)

        responses = []
        for question_paper_name, file in zip(question_paper_names, files):
            question_paper_data = {
                'question_paper_name': question_paper_name,
                'duration_of_test': duration_of_test,
                'topic': topic,
                'sub_topic': sub_topic,
                'no_of_questions': no_of_questions,
                'upload_type': upload_type,
                'test_type': test_type,
                'folder_name': folder_name,

            }

            print('Question Paper Data: ', question_paper_data)

            question_paper_serializer = questionsPaperSerializer(data=question_paper_data)

            if question_paper_serializer.is_valid():
                question_paper_instance = question_paper_serializer.save()
                print('question_paper_instance: ', question_paper_instance)
                question_paper_id = question_paper_instance.id

                # Append question paper details to the response
                responses.append({
                    'question_paper_name': question_paper_name,
                    'id': question_paper_id,
                    'status': 'Uploaded successfully'
                })
            else:
                return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

            # Process the file based on file extension
            try:
                if file.name.endswith('.xlsx'):
                    # Excel processing logic
                    df = pd.read_excel(file)
                    df.columns = [col.strip() for col in df.columns]
       

                    # Rename and validate columns
                    df.rename(columns={
                        'Questions**': 'question_text',
                        'Option A': 'option_a',
                        'Option B': 'option_b',
                        'Option C': 'option_c',
                        'Option D': 'option_d',
                        'Answer**': 'answer',
                        'Mark**': 'mark',
                        'Explain Answer': 'explain_answer',
                        'Difficulty Level': 'difficulty_level',
                        
                    }, inplace=True)

                    mandatory_columns = ['question_text', 'answer', 'mark']
                    for col in mandatory_columns:
                        if col not in df.columns or df[col].isnull().any():
                            return Response({'error': f"Missing or invalid data in column '{col}' for file {file.name}"}, status=status.HTTP_400_BAD_REQUEST)

                    records = df.fillna('').to_dict(orient='records')
                    for record in records:
                        record['question_name_id'] = question_paper_id

                    # Save questions
                    serializer = questionsSerializerImport(data=records, many=True)
                    if serializer.is_valid():
                        serializer.save()
                       #  responses.append({'question_paper_name': question_paper_name, 'status': 'Uploaded successfully'})
                    else:
                        return Response({'error': f"Error saving questions for {file.name}"}, status=status.HTTP_400_BAD_REQUEST)

                elif file.name.endswith('.docx'):
                    # Word document processing logic
                    print(f"Processing DOCX file: {file.name}")
                    
                    # Get the directory of the current script
                    current_dir = os.path.dirname(os.path.abspath(__file__))
                    output_json_path = os.path.join(current_dir, '../words/output.json')
                    output_unmatched_lines_path = os.path.join(current_dir, '../words/unmatched_lines.docx')

                    text, images_binary = extract_text_and_images_from_docx_mcq(file)

                    # Create JSON structure from extracted data
                    data = create_json_structure(text, images_binary)

                    # Save JSON and unmatched lines to respective files
                    with open(output_json_path, 'w') as json_file:
                        json.dump(data, json_file, indent=4)
                    
                    
                    print(f"Saving unmatched lines to DOCX file: {output_unmatched_lines_path}")

                    # Process questions extracted from DOCX file
                    for ques in data["questions"]:
                        question_text = ques.get('question_text', '')
                        question_image_data = ques.get('question_image_data', '')
                        answer = ques.get('answer', '')
                        marks = ques.get('marks', 0)
                        negative_mark = ques.get('negative_marks', 0)
                        explain_answer = ques.get('explanation', '')

                        if ques['options']:
                            print("Extracting options...")
                            options_a = ques['options'].get('a', ['', False])
                            options_b = ques['options'].get('b', ['', False])
                            options_c = ques['options'].get('c', ['', False])
                            options_d = ques['options'].get('d', ['', False])

                            option_a_image_data = options_a[0] if options_a[1] else ''
                            option_a = options_a[0] if not options_a[1] else ''

                            option_b_image_data = options_b[0] if options_b[1] else ''
                            option_b = options_b[0] if not options_b[1] else ''

                            option_c_image_data = options_c[0] if options_c[1] else ''
                            option_c = options_c[0] if not options_c[1] else ''

                            option_d_image_data = options_d[0] if options_d[1] else ''
                            option_d = options_d[0] if not options_d[1] else ''

                            print(f"Options extracted: A: {option_a}, B: {option_b}, C: {option_c}, D: {option_d}")
                        else:
                            print(f"Warning: No options found for question: {question_text}")

                        # Create and save question instance
                        question = question_master(
                            question_name_id=question_paper_instance,
                            question_text=question_text or '',
                            question_image_data=decode_base64_image(question_image_data) if question_image_data else None,
                            option_a_image_data=decode_base64_image(option_a_image_data) if option_a_image_data else None,
                            option_b_image_data=decode_base64_image(option_b_image_data) if option_b_image_data else None,
                            option_c_image_data=decode_base64_image(option_c_image_data) if option_c_image_data else None,
                            option_d_image_data=decode_base64_image(option_d_image_data) if option_d_image_data else None,
                            input_format="",
                            option_a=option_a or '',
                            option_b=option_b or '',
                            option_c=option_c or '',
                            option_d=option_d or '',
                            answer=answer or '',
                            negative_mark=negative_mark or 0,
                            mark=marks or 0,
                            explain_answer=explain_answer or ''
                        )
                        question.save()
                        print(f"Saved question: {question.id}")

                    print("All questions processed and saved successfully.")

            except Exception as e:
                return Response({'error': f"Error processing file {file.name}: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)

        return Response({'result': responses}, status=status.HTTP_201_CREATED)


class ExcelImportView_Questions_PO_CODE(APIView):
    def post(self, request, format=None):
        print('Request Data: ', request.data)
        
        # Extract multiple question paper names and files
        question_paper_names = request.data.getlist('question_paper_name', [])
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        files = request.FILES.getlist('file')
        folder_name = request.data.get('folder_name')

        # Validation for required fields
        if not all([question_paper_names, files, duration_of_test, topic, sub_topic, no_of_questions, upload_type, test_type]):
            return Response({'error': 'Missing fields or files'}, status=status.HTTP_400_BAD_REQUEST)

        # Ensure the number of files matches the number of question paper names
        if len(files) != len(question_paper_names):
            return Response({'error': 'Mismatch between question paper names and files'}, status=status.HTTP_400_BAD_REQUEST)

        responses = []
        for question_paper_name, file in zip(question_paper_names, files):
            question_paper_data = {
                'question_paper_name': question_paper_name,
                'duration_of_test': duration_of_test,
                'topic': topic,
                'sub_topic': sub_topic,
                'no_of_questions': no_of_questions,
                'upload_type': upload_type,
                'test_type': test_type,
                'folder_name': folder_name,
            }

            print('Question Paper Data: ', question_paper_data)

            question_paper_serializer = questionsPaperSerializer(data=question_paper_data)

            if question_paper_serializer.is_valid():
                question_paper_instance = question_paper_serializer.save()
                print('question_paper_instance: ', question_paper_instance)
                question_paper_id = question_paper_instance.id

                # Append question paper details to the response
                responses.append({
                    'question_paper_name': question_paper_name,
                    'id': question_paper_id,
                    'status': 'Uploaded successfully'
                })
            else:
                return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

            print('response1: ', responses)
            # Process the file based on file extension
            try:
                if file.name.endswith('.xlsx'):
                    df = pd.read_excel(file)
                    print('DataFrame contents:')
                    print(df.head())
                    
                    # Map Excel columns to the expected format
                    header_mapping = {
                        'Questions**': 'question_text',
                        'Answer**': 'answer',
                        'Mark**': 'mark',
                        'Explain Answer**': 'explain_answer',
                        'Input Format': 'input_format',
                        'Difficulty Level': 'difficulty_level',
                    }
                    missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
                    if missing_columns:
                        return Response({'error': f'Missing columns in Excel file: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

                    df.rename(columns=header_mapping, inplace=True)

                    mandatory_columns = [
                        'question_text',
                        'answer',
                        'mark',
                        'explain_answer'
                    ]

                    empty_columns = [col for col in mandatory_columns if df[col].isnull().any()]

                    if empty_columns:
                        error_message = f'Mandatory columns have null values: {", ".join(empty_columns)}'
                        return Response({'error': error_message}, status=status.HTTP_400_BAD_REQUEST)

                    # Convert DataFrame to records and associate with the newly created question_paper_master
                    records = df.to_dict(orient='records')

                    for record in records:
                        record['question_name_id'] = question_paper_id
                        for key in record:
                            if isinstance(record[key], str):
                                record[key] = record[key].strip()

                    # Serialize and save the records
                    serializer = questionsSerializerCodeImport(data=records, many=True)
                    print("Serializer: ", serializer)

                    if serializer.is_valid():
                        print("Before Saving..")
                        serializer.save()
                        print("After Saving..")
                      #  return Response(serializer.data, status=status.HTTP_201_CREATED)
                    else:
                        print("Serializer Errors: ", serializer.errors)
                        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

                elif file.name.endswith('.docx'):
                    # Word document processing logic
                    print(f"Processing DOCX file: {file.name}")
                    
                    text, images_binary = extract_text_and_images_from_docx(file)
                    data = create_json_structures(text, images_binary)

                    
                    for ques in data["questions"]:
                        print('ques: ', ques)

                        if 'question' in ques:
                            # Debugging: Print the data being processed
                            question_text = ques['question']
                            input_format = ques.get('input_format', '')
                            answers = ques.get('answers', [])
                            marks = ques.get('marks', '0')
                            explain_answer = ques.get('explanation', '')
                            question_image_data = ques.get('question_image_data', '')

                            print(f"Processing question: {question_text}")
                            print(f"Input format: {input_format}")
                            print(f"Answers: {answers}")
                            print(f"Marks: {marks}")
                            print(f"Explanation: {explain_answer}")

                            # Remove brackets from explanation if present
                            if explain_answer.startswith('[') and explain_answer.endswith(']'):
                                explain_answer = explain_answer[1:-1]

                            print(f"Image data: {question_image_data}")

                            try:
                                marks = int(marks) if marks else 0  # Convert to int, set 0 if empty
                            except ValueError:
                                print("Invalid mark value, setting to 0")
                                marks = 0

                            print(f"Marks (after conversion): {marks}")

                            try:
                                # Save to temporary table
                                temp_question = question_master_temp.objects.create(
                                    question_name_id=question_paper_instance,
                                    question_text=question_text,
                                    question_image_data=base64.b64decode(question_image_data) if question_image_data else None,
                                    input_format=input_format,
                                    answer=', '.join(answers),
                                    mark=marks,
                                    explain_answer=explain_answer
                                )

                                print(f"Temp question saved: {temp_question}")

                                # Move to main table
                                main_question = question_master.objects.create(
                                    question_name_id=temp_question.question_name_id,
                                    question_text=temp_question.question_text,
                                    question_image_data=temp_question.question_image_data,
                                    input_format=temp_question.input_format,
                                    answer=temp_question.answer,
                                    mark=temp_question.mark,
                                    explain_answer=temp_question.explain_answer
                                )

                                print(f"Main question saved: {main_question}")

                                # Optionally delete the temporary question
                                temp_question.delete()

                            except Exception as e:
                                print(f"Error saving question: {e}")
                                return HttpResponse(f"Error saving or moving question: {e}")

                    print("All questions processed and saved successfully.")

            except Exception as e:
                return Response({'error': f"Error processing file {file.name}: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)
        print('Responses: ', responses)
        return Response({'result': responses}, status=status.HTTP_201_CREATED)


def job_offer_view(request, job_id):
    """
    API View to fetch job offer details by job_id.
    """
    # Fetch the job offer object
    job_offer = get_object_or_404(job_offers, id=job_id)

    # Convert ManyToMany fields to lists
    job_data = {
        "id": job_offer.id,
        "company_name": job_offer.company_name,
        "company_profile": job_offer.company_profile,
        "post_name": job_offer.post_name,
        "post_name_description": job_offer.post_name_description,
        "announcement": job_offer.announcement,
        "intern_fulltime": job_offer.intern_fulltime,
        "job_type": job_offer.job_type,
        "on_off_campus": job_offer.on_off_campus,
        "cgpa": job_offer.cgpa,
        "marks_10th": job_offer.marks_10th,
        "marks_12th": job_offer.marks_12th,
        "gender": job_offer.gender,
        "history_of_arrears": job_offer.history_of_arrears,
        "standing_arrears": job_offer.standing_arrears,
        "interview_date": job_offer.interview_date,
        "year": job_offer.year,
        "location": job_offer.location,
        "no_of_offers": job_offer.no_of_offers,
        "packages": job_offer.packages,
        "colleges": list(job_offer.college_id.values_list("college", flat=True)),  
        "departments": list(job_offer.department_id.values_list("department", flat=True)),  
        "skills": list(job_offer.skill_id.values_list("skill_name", flat=True)),  
    }

    return JsonResponse(job_data)


from collections import defaultdict
from datetime import datetime
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.chart import BarChart, Reference

@api_view(['GET'])
def get_monthly_performance_by_college(request):
    """
    Generates Excel report:
    1. Student-wise Month-wise table
    2. Category Distribution chart per month (no summary table)
    3. Skill-Based Report sheet with chart
    """
    # --- Extract Filters ---
    college_id = request.GET.get('college_id')
    department_ids = request.GET.get('department_id')
    years = request.GET.get('year')
    report_year = request.GET.get('report_year')
    batch_nos = request.GET.get('batch_no')

    if not college_id:
        return HttpResponse({'error': 'college_id parameter is required'}, status=400)

    department_list = [int(dep) for dep in department_ids.split(',')] if department_ids else []
    student_year_list = years.split(',') if years else []
    batch_list = batch_nos.split(',') if batch_nos else []

    # --- Students ---
    student_filter = Q(deleted=0, college_id=college_id)
    if department_list:
        student_filter &= Q(department_id__in=department_list)
    if student_year_list:
        student_filter &= Q(year__in=student_year_list)
    if batch_list:
        student_filter &= Q(batch_no__in=batch_list)

    all_students = candidate_master.objects.filter(student_filter).values(
        'id', 'registration_number', 'students_name', 'year', 'batch_no'
    ).order_by('registration_number').distinct('registration_number')

    if not all_students.exists():
        return HttpResponse({'message': 'No students found for the given filters'}, status=404)

    student_ids = [s['id'] for s in all_students]

    # --- Test Reports ---
    test_report_filter = Q(deleted=0, college_id=college_id, is_active=True, student_id__in=student_ids)
    if department_list:
        test_report_filter &= Q(student_id__department_id__in=department_list)
    if report_year:
        test_report_filter &= Q(dtm_start__year=report_year)

    test_master_qs = test_master.objects.filter(test_name=OuterRef('test_name'))

    test_reports = tests_candidates_map.objects.filter(test_report_filter).annotate(
        test_type_name=Subquery(test_master_qs.values('test_type_id__test_type')[:1]),
        skill_type_name=Subquery(test_master_qs.values('skill_type_id__skill_type')[:1]),
        question_type_name=Subquery(test_master_qs.values('question_type_id__question_type')[:1]),
    ).values(
        'student_id',
        'dtm_start',
        'avg_mark',
        'skill_type_name'
    )

    if not test_reports.exists():
        return HttpResponse({'message': 'No test reports found for the given filters'}, status=404)

    # --- Months order ---
    months_set = set()
    for report in test_reports:
        if report['dtm_start']:
            months_set.add(report['dtm_start'].strftime("%B%Y"))
    months_order = sorted(list(months_set), key=lambda x: pd.to_datetime(x, format="%B%Y"))

    # --- Student Monthly Categories ---
    monthly_scores = defaultdict(lambda: defaultdict(list))
    student_monthly_category = defaultdict(dict)
    for report in test_reports:
        if report['dtm_start']:
            month_year = report['dtm_start'].strftime("%B%Y")
            avg_mark = float(report['avg_mark']) if report['avg_mark'] else 0.0
            monthly_scores[report['student_id']][month_year].append(avg_mark)

    for student_id, month_scores in monthly_scores.items():
        for month, scores in month_scores.items():
            avg_score = sum(scores) / len(scores)
            if avg_score >= 70:
                category = "Creamy"
            elif avg_score >= 50:
                category = "Good"
            elif avg_score >= 30:
                category = "Average"
            else:
                category = "Need to Focus"
            student_monthly_category[student_id][month] = category

    # --- Build Student Table ---
    report_data = []
    for student in all_students:
        student_id = student['id']
        student_info = {
            "Student Name": student['students_name'],
            "Reg No": student['registration_number'],
            "Year": student['year'],
        }
        for month in months_order:
            student_info[month] = student_monthly_category.get(student_id, {}).get(month, "-")
        report_data.append(student_info)

    df_monthly_report = pd.DataFrame(report_data)

    # --- Category Counts for Chart ---
    categories = ["Creamy", "Good", "Average", "Need to Focus"]
    category_summary = defaultdict(lambda: defaultdict(int))
    for student_id, month_data in student_monthly_category.items():
        for month, category in month_data.items():
            category_summary[month][category] += 1

    # --- Skill Scores ---
    skill_scores = defaultdict(lambda: defaultdict(list))
    for report in test_reports:
        skill = report['skill_type_name']
        if skill and report['dtm_start']:
            month_year = report['dtm_start'].strftime("%B%Y")
            avg_mark = float(report['avg_mark']) if report['avg_mark'] else 0.0
            skill_scores[skill][month_year].append(avg_mark)

    # --- Excel Workbook ---
    buffer = BytesIO()
    wb = Workbook()
    ws1 = wb.active
    ws1.title = "Month-Wise Performance"

    # Write Student Table
    for r in dataframe_to_rows(df_monthly_report, index=False, header=True):
        ws1.append(r)

    # Create Category Chart (right side)
    chart = BarChart()
    chart.type = "col"
    chart.title = "Category Distribution per Month"
    chart.y_axis.title = "Number of Students"
    chart.x_axis.title = "Months"

    # Prepare data for chart in hidden columns after last table column
    max_col = ws1.max_column
    for col_idx, category in enumerate(categories, start=max_col + 2):
        ws1.cell(row=1, column=col_idx, value=category)
        for row_idx, month in enumerate(months_order, start=2):
            ws1.cell(row=row_idx, column=col_idx, value=category_summary[month].get(category, 0))

    data = Reference(ws1, min_col=max_col + 2, min_row=1, max_col=max_col + 1 + len(categories), max_row=1 + len(months_order))
    cats = Reference(ws1, min_col=1, min_row=2, max_row=1 + len(months_order))
    chart.add_data(data, titles_from_data=True)
    chart.set_categories(cats)
    chart.height = 8
    chart.width = 15
    start_row_for_chart = 12  # chart will start after 10 rows
    ws1.add_chart(chart, f"{chr(65 + max_col + 3)}{start_row_for_chart}") # place to the right

    # --- Skill Based Report Sheet ---
    ws2 = wb.create_sheet(title="Skill Based Report")
    skill_list = list(skill_scores.keys())
    for idx, skill in enumerate(skill_list, start=2):
        ws2.cell(row=idx, column=1, value=skill)
    for col_idx, month in enumerate(months_order, start=2):
        ws2.cell(row=1, column=col_idx, value=month)
        for row_idx, skill in enumerate(skill_list, start=2):
            scores = skill_scores[skill].get(month, [])
            ws2.cell(row=row_idx, column=col_idx, value=round(sum(scores)/len(scores), 0) if scores else 0)

    skill_chart = BarChart()
    skill_chart.title = "Skill Based Report"
    skill_chart.y_axis.title = "Avg %"
    skill_chart.x_axis.title = "Skills"
    data = Reference(ws2, min_col=2, min_row=1, max_col=1 + len(months_order), max_row=1 + len(skill_list))
    cats = Reference(ws2, min_col=1, min_row=2, max_row=1 + len(skill_list))
    skill_chart.add_data(data, titles_from_data=True)
    skill_chart.set_categories(cats)
    skill_chart.height = 12
    skill_chart.width = 20
    ws2.add_chart(skill_chart, f"G10")  # Chart will start after 9 rows


    # --- Save Workbook ---
    # --- Fetch College Name ---
    college_obj = college_master.objects.filter(id=college_id).first()
    college_name = college_obj.college if college_obj else "College"
    college_name_clean = "".join(c for c in college_name if c.isalnum())
   
    

    # --- Save Workbook and Set Filename ---
    wb.save(buffer)
    buffer.seek(0)
    filename = f"{college_name_clean}_Monthly_Performance_Report.xlsx"
    response = HttpResponse(
        buffer.read(),
        content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )
    response['Content-Disposition'] = f'attachment; filename={filename}'
    response['Access-Control-Expose-Headers'] = 'Content-Disposition'

    return response


class ExcelImportView_Questionsphysico(APIView):
    def post(self, request, format=None):
        print("‚úÖ Received API Request for Excel Import")  # Debugging

        # Extract and validate question paper details
        question_paper_name = request.data.get('question_paper_name')
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        folder_name = request.data.get('folder_name')
        remarks = request.data.get('remarks')
        print("remarks",remarks)

        print(f"üìå Received Data: {request.data}")  # Debugging
        
        if not all([question_paper_name, duration_of_test, topic, sub_topic, no_of_questions, upload_type, test_type]):
            print("‚ùå Missing fields in question paper details")
            return Response({'error': 'Missing fields for question_paper_master'}, status=status.HTTP_400_BAD_REQUEST)

        question_paper_data = {
            'question_paper_name': question_paper_name,
            'duration_of_test': duration_of_test,
            'topic': topic,
            'sub_topic': sub_topic,
            'no_of_questions': no_of_questions,
            'upload_type': upload_type,
            'test_type': test_type,
            'folder_name': folder_name,
            'remarks':remarks,
        }

        print(f"üìù Creating Question Paper with Data: {question_paper_data}")  # Debugging

        question_paper_serializer = questionsPaperSerializer(data=question_paper_data)
        if question_paper_serializer.is_valid():
            question_paper_instance = question_paper_serializer.save()
            question_paper_id = question_paper_instance.id
            print(f"‚úÖ Question Paper Created with ID: {question_paper_id}")
        else:
            print("‚ùå Question Paper Creation Failed:", question_paper_serializer.errors)
            return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        # File Validation
        if 'file' not in request.FILES:
            print("‚ùå No file uploaded")
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']
        print(f"üìÇ File received: {file.name}")

        if not file.name.endswith('.xlsx'):
            print("‚ùå Uploaded file is not in Excel format")
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        # Read Excel File
        try:
            df = pd.read_excel(file)
            df.columns = [col.strip() for col in df.columns]
       
            print("üìä Successfully Read Excel File")
        except Exception as e:
            print(f"‚ùå Error reading Excel file: {e}")
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Map Excel headers to expected column names
        header_mapping = {
            'Sections':'sections',
            'Questions**': 'question_text',

            'Option A': 'option_a',
            'Option B': 'option_b',
            'Option C': 'option_c',
            'Option D': 'option_d',
            'Option E': 'option_e',
            'Mark Type**': 'mark_method',
            'Difficulty Level': 'difficulty_level',
        }

        missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
        if missing_columns:
            print(f"‚ùå Missing columns in Excel: {', '.join(missing_columns)}")
            return Response({'error': f'Missing columns in Excel: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

        df.rename(columns=header_mapping, inplace=True)
        print(f"üîÑ Renamed Excel Columns: {list(df.columns)}")

        # Validate Required Columns
        mandatory_columns = ['question_text', 'mark_method','difficulty_level']
        error_messages = []

        # Check for empty values in mandatory columns
        for col in mandatory_columns:
            missing_values = df[df[col].isnull()]
            if not missing_values.empty:
                for index in missing_values.index:
                    error_messages.append(f"‚ùå Row {index + 1}: Column '{col}' is empty.")

        # Validate `mark_method` column
        allowed_mark_methods = {'A-E', 'E-A'}
        for index, row in df.iterrows():
            mark_method = str(row.get('mark_method', '')).strip().upper()
            if mark_method not in allowed_mark_methods:
                error_messages.append(f"‚ùå Row {index + 1}: Invalid mark method '{mark_method}'. Must be 'A-E' or 'E-A'.")

        if error_messages:
            print("‚ùå Validation Errors in Excel Data:", error_messages)
            return Response({'error': ' '.join(error_messages)}, status=status.HTTP_400_BAD_REQUEST)

        # Convert DataFrame to JSON Records
        records = df.fillna('').to_dict(orient='records')
        for record in records:
            record['question_name_id'] = question_paper_id
            for key in record:
                if isinstance(record[key], str):
                    record[key] = record[key].strip()

        print(f"‚úÖ Prepared {len(records)} Records for Import")  # Debugging

        # Serialize and Save Questions
        serializer = questionsSerializerImportPhysico(data=records, many=True)
        if serializer.is_valid():
            serializer.save()
            print("‚úÖ Questions Imported Successfully")
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            detailed_errors = []
            for idx, error_dict in enumerate(serializer.errors):
                for field, errors in error_dict.items():
                    if isinstance(errors, list):
                        for error in errors:
                            detailed_errors.append(f"‚ùå Row {idx + 1}, Column '{field}': {error}")

            print("‚ùå Serialization Errors:", detailed_errors)
            return Response({'error': detailed_errors}, status=status.HTTP_400_BAD_REQUEST)





def generate_sample_excel():
    """
    Generates a sample Excel file for question uploads with a dropdown in the 'Mark Type**' column.
    Returns: A BytesIO object containing the Excel file.
    """
    # Sample data with a few initial rows
    data = {
        "Questions**": ["What is the capital of France?", "Which number is even?"],
        "Option A": ["Paris", "One"],
        "Option B": ["Berlin", "Two"],
        "Option C": ["Madrid", "Three"],
        "Option D": ["Rome", "Four"],
        "Option E": ["Lisbon", "Five"],
        "Mark Type**": ["A-E", "E-A"],  # Dropdown column
    }

    df = pd.DataFrame(data)

    # Create an Excel file in memory
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="Sample Questions")

        workbook = writer.book
        worksheet = writer.sheets["Sample Questions"]

        # Define the dropdown options
        dropdown_options = ["A-E", "E-A"]

        # ‚úÖ Apply dropdown validation for **all rows** (G2:G1000)
        dropdown_range = "G2:G1000"  
        worksheet.data_validation(dropdown_range, {
            "validate": "list",
            "source": dropdown_options,
            "input_message": "Choose A-E or E-A",
            "error_message": "Invalid selection, please choose A-E or E-A",
        })

    output.seek(0)  # Move the cursor back to the start
    return output

from django.http import HttpResponse
def download_sample_excel(request):
    """
    Django view to allow users to download a sample Excel file.
    """
    sample_file = generate_sample_excel()
    
    response = HttpResponse(
        sample_file.read(),
        content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    response["Content-Disposition"] = 'attachment; filename="Sample_Questions.xlsx"'
    
    return response

@api_view(['PUT', 'PATCH'])
def delete_job(request, pk):
    ##logger.info(f"Attempting to mark Content with id {pk} as deleted")
    try:
        print("Entering Function..")
        content=job_offers.objects.get(id=pk)

        print("content: ",content)
    except job_offers.DoesNotExist:
        return JsonResponse("tests not found", status=404)

    # Update the 'deleted' field to 1 instead of deleting the object
    content.deleted = 1
    content.save()

    ##logger.info(f"Marked Content with id {pk} as deleted successfully")

    print("content: ",content)

    return JsonResponse("job 'deleted' field updated successfully", safe=False)

class ExcelImportView_Questions_Code_testcase(APIView):
    
    def post(self, request, format=None):
        print("Received request for Excel import")
        # Extract data for the question_paper_master
        question_paper_name = request.data.get('question_paper_name')
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        folder_name = request.data.get('folder_name')
        is_testcase= request.data.get('is_testcase')
        remarks = request.data.get('remarks')
        created_by = request.data.get('created_by')


        print("remarks",created_by)
        print("Extracted data:", {
            "question_paper_name": question_paper_name,
            "duration_of_test": duration_of_test,
            "topic": topic,
            "sub_topic": sub_topic,
            "no_of_questions": no_of_questions,
            "upload_type": upload_type,
            "test_type": test_type,
            "folder_name": folder_name,
            "is_testcase": is_testcase
        })

        # Validate required fields
        if not all([question_paper_name, duration_of_test, topic, sub_topic, no_of_questions, upload_type, folder_name,is_testcase]):
            return Response({'error': 'Missing fields for question_paper_master'}, status=status.HTTP_400_BAD_REQUEST)
        print("Error: Missing fields in question_paper_master")
        # Create a new question_paper_master entry
        question_paper_data = {
            'question_paper_name': question_paper_name,
            'duration_of_test': duration_of_test,
            'topic': topic,
            'sub_topic': sub_topic,
            'no_of_questions': no_of_questions,
            'upload_type': upload_type,
            'test_type': test_type,
            'folder_name': folder_name,
            'is_testcase':is_testcase,
            'remarks':remarks,
            'created_by':created_by,
        }

        question_paper_serializer = questionsPaperSerializer(data=question_paper_data)
        if question_paper_serializer.is_valid():
            question_paper_instance = question_paper_serializer.save()
            question_paper_id = question_paper_instance.id
            print("Question paper saved successfully with ID:", question_paper_id)
        else:
            print("Error in question paper serializer:", question_paper_serializer.errors)
            return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        # Process the uploaded file
        if 'file' not in request.FILES:
            print("Error: No file uploaded")
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']

        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
            df.columns = [col.strip() for col in df.columns]

           
            print('DataFrame contents:')
            print(df.head())
        except Exception as e:
            print("Error reading Excel file:", str(e))
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Map Excel columns to the expected format
        header_mapping = {
            'Questions**': 'question_text',
            #'Answer**': 'answer',
            'TestCase1**':'test_case1',
            'TestCase2**':'test_case2',
            'TestCase3**':'test_case3',
            'Mark**': 'mark',
            'Explain Answer**': 'explain_answer',
            'Input Format': 'input_format',
            'Difficulty Level': 'difficulty_level',
        }
        missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
        if missing_columns:
            print("Error: Missing columns in Excel file:", missing_columns)
            return Response({'error': f'Missing columns in Excel file: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

        df.rename(columns=header_mapping, inplace=True)

        mandatory_columns = [
            'question_text',
           # 'answer',
           'test_case1',
           'test_case2',
           'test_case3',
            'mark',
            'explain_answer',
            'difficulty_level'
        ]

        empty_columns = [col for col in mandatory_columns if df[col].isnull().any()]

        if empty_columns:
            print("Error: Mandatory columns have null values:", empty_columns)
            error_message = f'Mandatory columns have null values: {", ".join(empty_columns)}'
            return Response({'error': error_message}, status=status.HTTP_400_BAD_REQUEST)

        # Convert DataFrame to records and associate with the newly created question_paper_master
        records = df.to_dict(orient='records')
        print("Converted DataFrame to records")
        
        if sub_topic == "All Languages":
            if 'explain_answer' in df.columns:
                invalid_rows = df[~df['explain_answer'].astype(str).str.contains("code:", case=False, na=False)]
                if not invalid_rows.empty:
                    error_rows = invalid_rows.index.tolist()
                    return Response({
                        'error': f"Explain Answer must include 'code:' for All-Languages in rows: {', '.join(str(i + 2) for i in error_rows)}"
                    }, status=status.HTTP_400_BAD_REQUEST)
            else:
                return Response({'error': 'Missing column: Explain Answer** (needed for All-Languages)'}, status=status.HTTP_400_BAD_REQUEST)
        
        for record in records:
            record['question_name_id'] = question_paper_id
            for key in record:
                if isinstance(record[key], str):
                    record[key] = record[key].strip()

        # Serialize and save the records
        serializer = questionsSerializerCodeImport(data=records, many=True)
        print("Serializer: ", serializer)

        if serializer.is_valid():
            print("Before Saving..")
            serializer.save()
            print("After Saving..")
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            print("Serializer Errors: ", serializer.errors)
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

class ExcelImportView_Questions_Code_Placetestcase(APIView):
    def post(self, request, format=None):
        # Extract data for the question_paper_master
        question_paper_name = request.data.get('question_paper_name')
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        created_by = request.data.get('created_by')
        folder_name = request.data.get('folder_name')
        is_testcase = request.data.get('is_testcase')
        remarks = request.data.get('remarks')
        print("remarks",remarks)

        # Validate required fields
        if not all([question_paper_name, duration_of_test, topic, sub_topic, no_of_questions, upload_type, folder_name,is_testcase]):
            return Response({'error': 'Missing fields for question_paper_master'}, status=status.HTTP_400_BAD_REQUEST)

        # Create a new question_paper_master entry
        question_paper_data = {
            'question_paper_name': question_paper_name,
            'duration_of_test': duration_of_test,
            'topic': topic,
            'sub_topic': sub_topic,
            'no_of_questions': no_of_questions,
            'upload_type': upload_type,
            'test_type': test_type,
            'created_by': created_by,
            'folder_name': folder_name,
            'is_testcase':is_testcase,
            'remarks':remarks,
        }

        question_paper_serializer = questionsPaperSerializer_Place(data=question_paper_data)
        if question_paper_serializer.is_valid():
            question_paper_instance = question_paper_serializer.save()
            question_paper_id = question_paper_instance.id
        else:
            return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        # Process the uploaded file
        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']

        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
            df.columns = [col.strip() for col in df.columns]
       
            print('DataFrame contents:')
            print(df.head())
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Map Excel columns to the expected format
        header_mapping = {
            'Questions**': 'question_text',
            'TestCase1**':'test_case1',
            'TestCase2**':'test_case2',
            'TestCase3**':'test_case3',
           # 'Answer': 'answer',
            'Mark**': 'mark',
            'Explain Answer**': 'explain_answer',
            'Input Format': 'input_format',
            'Difficulty Level': 'difficulty_level',
        }
        missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
        if missing_columns:
            return Response({'error': f'Missing columns in Excel file: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

        df.rename(columns=header_mapping, inplace=True)

        mandatory_columns = [
            'question_text',
            'test_case1',
            'test_case2',
            'test_case3',
            'mark',
            'explain_answer',
            'difficulty_level'
        ]

        empty_columns = [col for col in mandatory_columns if df[col].isnull().any()]

        if empty_columns:
            error_message = f'Mandatory columns have null values: {", ".join(empty_columns)}'
            return Response({'error': error_message}, status=status.HTTP_400_BAD_REQUEST)

        # Convert DataFrame to records and associate with the newly created question_paper_master
        
        
        if sub_topic == "All Languages":
            if 'explain_answer' in df.columns:
                invalid_rows = df[~df['explain_answer'].astype(str).str.contains("code:", case=False, na=False)]
                if not invalid_rows.empty:
                    error_rows = invalid_rows.index.tolist()
                    return Response({
                        'error': f"Explain Answer must include 'code:' for All-Languages in rows: {', '.join(str(i + 2) for i in error_rows)}"
                    }, status=status.HTTP_400_BAD_REQUEST)
            else:
                return Response({'error': 'Missing column: Explain Answer** (needed for All-Languages)'}, status=status.HTTP_400_BAD_REQUEST)
        
        
        records = df.to_dict(orient='records')

        for record in records:
            record['question_name_id'] = question_paper_id
            for key in record:
                if isinstance(record[key], str):
                    record[key] = record[key].strip()

        # Serialize and save the records
        serializer = questionsSerializerCodeImport(data=records, many=True)
        print("Serializer: ", serializer)

        if serializer.is_valid():
            print("Before Saving..")
            serializer.save()
            print("After Saving..")
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            print("Serializer Errors: ", serializer.errors)
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class ExcelImportView_Questions_Code(APIView):
    def post(self, request, format=None):
        # Extract data for the question_paper_master
        question_paper_name = request.data.get('question_paper_name')
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        folder_name = request.data.get('folder_name')
        is_testcase= request.data.get('is_testcase')
        remarks = request.data.get('remarks')
        created_by = request.data.get('created_by')

        print("remarksjj",remarks,created_by)

        # Validate required fields
        if not all([question_paper_name, duration_of_test, topic, sub_topic, no_of_questions, upload_type, folder_name,is_testcase]):
            return Response({'error': 'Missing fields for question_paper_master'}, status=status.HTTP_400_BAD_REQUEST)

        # Create a new question_paper_master entry
        question_paper_data = {
            'question_paper_name': question_paper_name,
            'duration_of_test': duration_of_test,
            'topic': topic,
            'sub_topic': sub_topic,
            'no_of_questions': no_of_questions,
            'upload_type': upload_type,
            'test_type': test_type,
            'folder_name': folder_name,
            'is_testcase':is_testcase,
            'remarks':remarks,
            'created_by':created_by,
        }

        question_paper_serializer = questionsPaperSerializer(data=question_paper_data)
        if question_paper_serializer.is_valid():
            question_paper_instance = question_paper_serializer.save()
            question_paper_id = question_paper_instance.id
        else:
            return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        # Process the uploaded file
        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']

        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
            df.columns = [col.strip() for col in df.columns]
       
            print('DataFrame contents:')
            print(df.head())
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Map Excel columns to the expected format
        header_mapping = {
            'Questions**': 'question_text',
            'Answer**': 'answer',
            'Mark**': 'mark',
            'Explain Answer**': 'explain_answer',
            'Input Format': 'input_format',
            'Difficulty Level': 'difficulty_level',

        }
        missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
        if missing_columns:
            return Response({'error': f'Missing columns in Excel file: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

        df.rename(columns=header_mapping, inplace=True)

        mandatory_columns = [
            'question_text',
            'answer',
            'mark',
            'explain_answer',
            'difficulty_level'
        ]

        empty_columns = [col for col in mandatory_columns if df[col].isnull().any()]

        if empty_columns:
            error_message = f'Mandatory columns have null values: {", ".join(empty_columns)}'
            return Response({'error': error_message}, status=status.HTTP_400_BAD_REQUEST)

        
        # This check is AFTER renaming columns to ensure 'explain_answer' exists
        if sub_topic == "All Languages":
            if 'explain_answer' in df.columns:
                invalid_rows = df[~df['explain_answer'].astype(str).str.contains("code:", case=False, na=False)]
                if not invalid_rows.empty:
                    error_rows = invalid_rows.index.tolist()
                    return Response({
                        'error': f"Explain Answer must include 'code:' for All-Languages in rows: {', '.join(str(i + 2) for i in error_rows)}"
                    }, status=status.HTTP_400_BAD_REQUEST)
            else:
                return Response({'error': 'Missing column: Explain Answer** (needed for All-Languages)'}, status=status.HTTP_400_BAD_REQUEST)

        
        # Convert DataFrame to records and associate with the newly created question_paper_master
        records = df.to_dict(orient='records')

        for record in records:
            record['question_name_id'] = question_paper_id
            for key in record:
                if isinstance(record[key], str):
                    record[key] = record[key].strip()

        # Serialize and save the records
        serializer = questionsSerializerCodeImport(data=records, many=True)
        print("Serializer: ", serializer)

        if serializer.is_valid():
            print("Before Saving..")
            serializer.save()
            print("After Saving..")
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            print("Serializer Errors: ", serializer.errors)
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class ExcelImportView_Questions_Code_place(APIView):
    def post(self, request, format=None):
        # Extract data for the question_paper_master
        question_paper_name = request.data.get('question_paper_name')
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        created_by = request.data.get('created_by')
        folder_name = request.data.get('folder_name')
        is_testcase=request.data.get('is_testcase')
        remarks = request.data.get('remarks')
        print("remarks",remarks)

        # Validate required fields
        if not all([question_paper_name, duration_of_test, topic, sub_topic, no_of_questions, upload_type, folder_name,is_testcase]):
            return Response({'error': 'Missing fields for question_paper_master'}, status=status.HTTP_400_BAD_REQUEST)

        # Create a new question_paper_master entry
        question_paper_data = {
            'question_paper_name': question_paper_name,
            'duration_of_test': duration_of_test,
            'topic': topic,
            'sub_topic': sub_topic,
            'no_of_questions': no_of_questions,
            'upload_type': upload_type,
            'test_type': test_type,
            'created_by': created_by,
            'folder_name': folder_name,
            'is_testcase':is_testcase,
            'remarks':remarks,
            
        }

        question_paper_serializer = questionsPaperSerializer_Place(data=question_paper_data)
        if question_paper_serializer.is_valid():
            question_paper_instance = question_paper_serializer.save()
            question_paper_id = question_paper_instance.id
        else:
            return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        # Process the uploaded file
        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']

        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
            df.columns = [col.strip() for col in df.columns]
       
            print('DataFrame contents:')
            print(df.head())
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Map Excel columns to the expected format
        header_mapping = {
            'Questions**': 'question_text',
            
            'Answer**': 'answer',
            'Mark**': 'mark',
            'Explain Answer**': 'explain_answer',
            'Input Format': 'input_format',
            'Difficulty Level': 'difficulty_level',
        }
        missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
        if missing_columns:
            return Response({'error': f'Missing columns in Excel file: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

        df.rename(columns=header_mapping, inplace=True)

        mandatory_columns = [
            'question_text',
            'answer',
            'mark',
            'explain_answer',
            'difficulty_level'
        ]

        empty_columns = [col for col in mandatory_columns if df[col].isnull().any()]

        if empty_columns:
            error_message = f'Mandatory columns have null values: {", ".join(empty_columns)}'
            return Response({'error': error_message}, status=status.HTTP_400_BAD_REQUEST)

        # Convert DataFrame to records and associate with the newly created question_paper_master
        
        
        if sub_topic == "All Languages":
            if 'explain_answer' in df.columns:
                invalid_rows = df[~df['explain_answer'].astype(str).str.contains("code:", case=False, na=False)]
                if not invalid_rows.empty:
                    error_rows = invalid_rows.index.tolist()
                    return Response({
                        'error': f"Explain Answer must include 'code:' for All-Languages in rows: {', '.join(str(i + 2) for i in error_rows)}"
                    }, status=status.HTTP_400_BAD_REQUEST)
            else:
                return Response({'error': 'Missing column: Explain Answer** (needed for All-Languages)'}, status=status.HTTP_400_BAD_REQUEST)
        
        
        records = df.to_dict(orient='records')

        for record in records:
            record['question_name_id'] = question_paper_id
            for key in record:
                if isinstance(record[key], str):
                    record[key] = record[key].strip()

        # Serialize and save the records
        serializer = questionsSerializerCodeImport(data=records, many=True)
        print("Serializer: ", serializer)

        if serializer.is_valid():
            print("Before Saving..")
            serializer.save()
            print("After Saving..")
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            print("Serializer Errors: ", serializer.errors)
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@api_view(['GET'])
def get_department_info_test_cc(request):
    # Retrieve query parameters
    college_ids = request.query_params.getlist('college_id[]', [])
    
    if not college_ids:
        return Response({"error": "No college_ids provided"}, status=status.HTTP_400_BAD_REQUEST)
    
    try:
        # Debug: Print what we are querying
        print(f"Filtering for college_ids: {college_ids}")

        results = candidate_master.objects.filter(
            college_id__in=college_ids,
            department_id__isnull=False,deleted=0
        ).values(
            'department_id__id',
            'department_id__department'
        ).distinct()

        print(f"Query Results: {list(results)}")  # Debugging

        return Response(results, status=status.HTTP_200_OK)

    except Exception as e:
        print(f"Error: {str(e)}")  # Debugging
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


from collections import defaultdict
@api_view(['GET'])
def get_group_test_TestReport(request):
    # Extract filters from request
    college_id = request.GET.get('college_id')
    department_filter = request.GET.get('department')  
    year_filter = request.GET.get('year')  
    test_name_filter = request.GET.get('test_name')  
    from_date = request.GET.get('From_date')
    to_date = request.GET.get('To_date')
    is_all_departments = not department_filter or department_filter.lower() == 'all'
 
    is_all_years = not year_filter or year_filter.lower() == 'all'

    # Parse filters
    department_list = list(map(int, department_filter.split(','))) if department_filter and department_filter.lower() != 'all' else []
    year_list = list(map(int, year_filter.split(','))) if year_filter and year_filter.lower() != 'all' else []

    is_all_departments = not department_list
    is_all_years = not year_list

    filters = {'deleted': 0}
    if college_id:
        filters['college_id'] = college_id
    if department_list:
        filters['department_id__in'] = department_list
    if year_list:
        filters['year__in'] = year_list
    if test_name_filter:
        filters['test_name'] = test_name_filter
    if from_date:
        from_date = datetime.strptime(from_date, "%Y-%m-%d")
        filters['dtm_start__gte'] = from_date.replace(hour=0, minute=0, second=0)
    if to_date:
        to_date = datetime.strptime(to_date, "%Y-%m-%d")
        filters['dtm_start__lte'] = to_date.replace(hour=23, minute=59, second=59)

    # Query database
    raw_query = tests_candidates_map.objects.filter(
        **filters
    ).exclude(
         created_by='Student'  # ‚úÖ Exclude students
    ).values(
        'test_name',
        'college_id',
        'college_id__college',
        'department_id',
        'department_id__department',
        'dtm_end',
        'dtm_start',
         'year'
    ).annotate(
        student_count=Count('student_id', distinct=True),
        active_student_count=Count('student_id', filter=Q(is_active=True), distinct=True),
        dtm_created=Max('dtm_created'),
        department_names=Concat(Value(''), 'department_id__department', output_field=CharField()),
        all_years=Concat(Value(''), 'year', output_field=CharField())
       

    ).order_by('-dtm_created')


    # Group data by test_name
    grouped_data = defaultdict(lambda: {
        'student_count': 0,
        'active_student_count': 0,
        'dtm_created': None,
        'dtm_start': None,
        'dtm_end': None,
        'college_id': None,
        'college_name': None,
        'department_id': None,
        'department_name': set(),
        'year': set(),
    })

    for item in raw_query:
        test_name = item['test_name']
        group = grouped_data[test_name]
        group['test_name'] = test_name
        group['dtm_created'] = item['dtm_created']
        group['dtm_start'] = item['dtm_start']
        group['dtm_end'] = item['dtm_end']
        group['college_id'] = item['college_id']
        group['college_name'] = item['college_id__college']
        group['department_id'] = item['department_id']
        group['student_count'] += item['student_count']
        group['active_student_count'] += item['active_student_count']
        group['department_name'].add(item['department_names'])
        if is_all_years:
            group['year'].add(item['all_years'])  # all years will be added
        else:
            group['year'].add(str(item['year']))  # only filtered years will be added

        print("Item year (all_years):", item.get('all_years'))

    # Prepare final grouped data
    grouped_data_list = [
         {
            **group,
            'department_name': "All" if is_all_departments else ", ".join(group['department_name']),
             'year': ", ".join(group['year']) if group['year'] else "All"

          
        }
        for group in grouped_data.values()
    ]

    # Apply pagination
    paginator = CustomPagination()
    paginated_data = paginator.paginate_queryset(grouped_data_list, request)

    return paginator.get_paginated_response(paginated_data)


from django.db.models import Count, F, Q, Value, DateField
from django.db.models.functions import TruncDate, Cast
from itertools import chain

@api_view(['GET'])
def get_grouped_schedule(request):
    try:
        search = request.query_params.get('search', '')
        topic = request.query_params.get('topic')
        college = request.query_params.get('college')

        # Base filters
        cs_filters = {'deleted': 0}
        ts_filters = {'deleted': 0}

        if topic:
            cs_filters['topic_id__topic'] = topic
            ts_filters['topic_id__topic'] = topic

        if college:
            cs_filters['college_id__college'] = college
            ts_filters['college_id__college'] = college

        if search:
            search_filter = (
                Q(topic_id__topic__icontains=search) |
                Q(college_id__college__icontains=search)
            )
        else:
            search_filter = Q()

        # =========================
        # üîπ course_schedule block
        # =========================
        cs_data = (
            course_schedule.objects.filter(**cs_filters)
            .filter(search_filter)
            .values('topic_id', 'college_id', 'dtm_of_training', 'dtm_created')
            .annotate(
                topic=F('topic_id__topic'),
                college=F('college_id__college'),
                training_date=TruncDate('dtm_of_training'),
                creation_date=F('dtm_created'),
                student_count=Count('student_id'),  # FK
                source=Value('course', output_field=models.CharField())
            )
        )

        # =========================
        # üîπ training_schedule block
        # =========================
        ts_data = (
            training_schedule.objects.filter(**ts_filters)
            .filter(search_filter)
            .annotate(
                topic=F('topic_id__topic'),
                college=F('college_id__college'),
                training_date=TruncDate('dtm_of_training'),
                creation_date=F('dtm_start_trainer'),
                student_count=Func(
                    F('student_ids'),
                    function='jsonb_array_length',
                    output_field=IntegerField()
                ),
               # student_count=Cast(models.functions.Length('student_ids'), output_field=models.IntegerField()),
                source=Value('training', output_field=models.CharField())
            )
            .values('topic_id', 'college_id', 'training_date', 'creation_date', 'topic', 'college', 'student_count', 'source')
        )

        # =========================
        # üîÑ Combine Both
        # =========================
        combined_data = list(chain(cs_data, ts_data))

        # =========================
        # üìä Group by topic, college, date
        # =========================
        from collections import defaultdict
        grouped = defaultdict(lambda: {
            "topic_id": None,
            "topic": None,
            "college_id": None,
            "college": None,
            "training_date": None,
            "creation_date": None,
            "count": 0,
            "source": None
        })

        for item in combined_data:
            key = (item['topic_id'], item['college_id'], item['training_date'])
            group = grouped[key]
            group['topic_id'] = item['topic_id']
            group['topic'] = item['topic']
            group['college_id'] = item['college_id']
            group['college'] = item['college']
            group['training_date'] = item['training_date'].strftime('%Y-%m-%d') if item['training_date'] else None
            group['creation_date'] = item['creation_date'].strftime('%Y-%m-%d %H:%M:%S') if item['creation_date'] else None
            group['count'] += item['student_count'] or 0
            group['source'] = item['source']

        grouped_list = list(grouped.values())

        # Sort by creation date
        grouped_list.sort(key=lambda x: x['creation_date'], reverse=True)

        # Paginate
        paginator = CustomPagination()
        paginated_data = paginator.paginate_queryset(grouped_list, request)

        # Unique filters
        unique_topics = set(
            list(course_schedule.objects.filter(deleted=0).values_list('topic_id__topic', flat=True)) +
            list(training_schedule.objects.filter(deleted=0).values_list('topic_id__topic', flat=True))
        )

        unique_colleges = set(
            list(course_schedule.objects.filter(deleted=0).values_list('college_id__college', flat=True)) +
            list(training_schedule.objects.filter(deleted=0).values_list('college_id__college', flat=True))
        )

        response_data = {
            'count': paginator.page.paginator.count,
            'next': paginator.get_next_link(),
            'previous': paginator.get_previous_link(),
            'results': paginated_data,
            'unique_topics': list(unique_topics),
            'unique_colleges': list(unique_colleges)
        }

        return Response(response_data)

    except Exception as e:
        print(f"‚ùå Error in get_grouped_schedule: {e}")
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_departments_test_report(request):
    # Extract optional query parameters
    college_id = request.query_params.get('college_id')
    test_name = request.query_params.get('test_name')
    year = request.query_params.get('year')
    
    # Base queryset
    queryset = tests_candidates_map.objects.filter(is_active=True, deleted=0).values('department_id', 'department_id__department')

    # Apply filters if present
    if college_id:
        queryset = queryset.filter(college_id=college_id)
    if test_name:
        queryset = queryset.filter(test_name=test_name)
    if year:
        queryset = queryset.filter(year=year)
    
    # Remove duplicates
    queryset = queryset.distinct()
    
    # Return the response
    return Response(queryset)



@api_view(['GET'])
def get_colleges_test_report(request):
    # Extract optional query parameters
    department_id = request.query_params.get('department_id')
    test_name = request.query_params.get('test_name')
    year = request.query_params.get('year')
    
    # Base queryset
    queryset = tests_candidates_map.objects.filter(is_active=True, deleted=0).values('college_id', 'college_id__college')

    # Apply filters if present
    if department_id:
        queryset = queryset.filter(department_id=department_id)
    if test_name:
        queryset = queryset.filter(test_name=test_name)
    if year:
        queryset = queryset.filter(year=year)
    
    # Remove duplicates
    queryset = queryset.distinct()
    
    # Return the response
    return Response(queryset)


@api_view(['GET'])
def get_test_name_test_report(request):
    # Extract optional query parameters
    college_id = request.query_params.get('college_id')
    department_id = request.query_params.get('department_id')
    year = request.query_params.get('year')
    
    # Base queryset
    queryset = tests_candidates_map.objects.filter(
        is_active=True,
        deleted=0
    ).exclude(created_by='Student') \
    .values('test_name')

    # Apply filters if present
    if college_id:
        queryset = queryset.filter(college_id=college_id)
    if department_id:
        queryset = queryset.filter(department_id=department_id)
    if year:
        queryset = queryset.filter(year=year)
    
    # Remove duplicates
    queryset = queryset.distinct()
    
    # Return the response
    return Response(queryset)

@api_view(['GET'])
def get_departments_by_college(request):
    """
    Fetch department_id and department_id__department from candidate_master.
    Optionally filter by college_id.
    """
    college_id = request.query_params.get('college_id', None)

    # Query to get department_id and department name
    query = candidate_master.objects.filter(deleted=0, department_id__isnull=False)  # Assuming 'deleted=0' filters active records
    if college_id:
        query = query.filter(college_id=college_id)
    
    # Annotate department name from the related department_master
    query = query.values(
        'department_id',
        department=F('department_id__department')
    ).distinct()

    # Restructure data for the response
    department_list = [
        {'id': item['department_id'], 'department': item['department']} for item in query
    ]

    # Return the response
    return Response(department_list)

@api_view(['GET'])
def get_student_queriesold(request):
    try:
        college_id = request.GET.get('college_id')

        candidate_ids = candidate_master.objects.filter(deleted=0).values_list('id', flat=True)
        
        if college_id:
            candidate_ids = candidate_master.objects.filter(deleted=0, college_id=college_id).values_list('id', flat=True)

        student_queries = student_request.objects.filter(student_id__in=candidate_ids, status='Pending',deleted=0)

        serializer = StudentRequestSerializer(student_queries, many=True)
        return Response(serializer.data)
    except candidate_master.DoesNotExist:
        return Response({'error': 'College not found'}, status=404)

from rest_framework.decorators import api_view
from rest_framework.response import Response
from django.db.models import F

@api_view(['GET'])
def get_student_queries(request):
    try:
        college_id = request.GET.get('college_id')
        print("üìå Received college_id:", college_id)

        # Step 1: Get candidate IDs
        candidate_qs = candidate_master.objects.filter(deleted=0)
        if college_id:
            candidate_qs = candidate_qs.filter(college_id=college_id)
        candidate_ids = candidate_qs.values_list('id', flat=True)
        print(f"üìå Candidate IDs for college {college_id}:", list(candidate_ids))

        combined_data = []

        # Step 2: Original student requests
        student_queries = student_request.objects.filter(
            student_id__in=candidate_ids,
            status='Pending',
            deleted=0
        )
        print("üìå Pending student_requests count:", student_queries.count())

        for sr in student_queries:
            combined_data.append({
                'id': sr.id,
                'student_id': sr.student_id.id,
                'student_name': sr.student_id.students_name,
                'student_query': sr.student_query,
                'status': sr.status,
                'is_query_type': sr.is_query_type,
                'dtm_request': sr.dtm_request
            })

        # Step 3: Requested tests (as Reassign queries)
        test_requests = tests_candidates_map.objects.filter(
            student_id__in=candidate_ids,
            status='Requested',
            deleted=0
        ).select_related('student_id')  # to get student details

        for tr in test_requests:
            # Get the start date from test_master
            test_info = test_master.objects.filter(test_name=tr.test_name).first()
            dtm_start_test = getattr(test_info, 'dtm_start_test', None)

            combined_data.append({
                'id': None,  # No actual student_request ID
                'student_id': tr.student_id.id,
                'student_name': tr.student_id.students_name,
                'student_query': f"Requested to Reassign for {tr.test_name}",
                'status': tr.status,
                'is_query_type': 'Reassign',
                'dtm_request': dtm_start_test
            })

        print("üìå Combined student queries + test requests:", combined_data)
        return Response(combined_data)

    except candidate_master.DoesNotExist:
        print("‚ùå College not found")
        return Response({'error': 'College not found'}, status=404)
    except Exception as e:
        print("‚ùå Exception occurred:", str(e))
        return Response({'error': str(e)}, status=500)


@api_view(['GET']) 
def get_group_test_name_DepartmentReports(request):
    print("--- API Request Received ---")
    
    college_id = request.GET.get('college_id')  
    department_filter = request.GET.get('department')  
    year_filter = request.GET.get('year')  
    test_name_filter = request.GET.get('test_name')  
    from_date = request.GET.get('from_date')  
    to_date = request.GET.get('to_date')  
    
    print(f"Received parameters: college_id={college_id}, department={department_filter}, year={year_filter}, test_name={test_name_filter}, from_date={from_date}, to_date={to_date}")
    
    date_filters = {}
    if from_date:
        date_filters['dtm_start__gte'] = datetime.strptime(from_date, '%Y-%m-%d')
    if to_date:
        date_filters['dtm_start__lte'] = datetime.strptime(to_date, '%Y-%m-%d')
    
    department_list = [int(dep) for dep in department_filter.split(',') if dep.strip().isdigit()] if department_filter else None
    year_list = [int(year) for year in year_filter.split(',') if year.strip().isdigit()] if year_filter else None
    
    test_name = test_name_filter.strip() if test_name_filter else None
    print("Filtered test_name:", repr(test_name))
    
    filters = {'deleted': 0, **date_filters}
    
    if test_name:
        filters['test_name__iexact'] = test_name  
    if college_id:
        filters['college_id'] = college_id  
    if department_list:
        filters['department_id__in'] = department_list  
    if year_list:
        filters['year__in'] = year_list  
    
    print("Filters applied:", filters)
    
    results = tests_candidates_map.objects.filter(**filters).exclude(created_by='Student').values(
        'test_name',
        'college_id__college',
        'department_id__department',
        'year',
        'student_id__students_name',
        'student_id__registration_number',
        'avg_mark'
    ).annotate(
        dtm_created=Max('dtm_created')
    ).order_by('-dtm_created')
    
    print(f"Query returned {len(results)} results.")
    
    test_candidate_map_data = []
    
    for testing in results:
        skill_type = None
        question_type = None
        
        test_master_entry = test_master.objects.filter(test_name=testing['test_name'],deleted=0).first()
        if test_master_entry:
            skill_type = test_master_entry.skill_type_id.skill_type if test_master_entry.skill_type_id else None
            question_type = test_master_entry.question_type_id.question_type if test_master_entry.question_type_id else None
        
        test_candidate_map_data.append({
            'test_name': testing['test_name'],
            'college_name': testing['college_id__college'],
            'department_name': testing['department_id__department'],
            'year': testing['year'],
            'student_name': testing['student_id__students_name'],
            'rg_no': testing['student_id__registration_number'],
            'avg_mark': testing['avg_mark'],
            'dtm_created': testing['dtm_created'],
            'skill_type': skill_type,
            'question_type': question_type,
        })
    
    print("Final response data:", test_candidate_map_data)
    
    return Response(test_candidate_map_data)

@api_view(['GET'])
def get_test_by_name(request):
    test_name = request.GET.get('test_name')
    if not test_name:
        return Response({'error': 'test_name parameter is required'}, status=400)
    
    tests = test_master.objects.filter(test_name=test_name,deleted=0).values(
        'test_name',
        'test_type_id__test_type',
        'test_type_id__test_type_categories',
        'skill_type_id__skill_type',
        'question_type_id__question_type'
    )
    
    if not tests.exists():
        return Response({'message': 'No tests found'}, status=404)
    
    return Response({'data': list(tests)})

@csrf_exempt
@cache_page(60 * 10)  # Cache view for 10 minutes
def get_questions_IO_filter_mcq_psychometry(request, question_id):
    cache_key = f'question_data_mcq_{question_id}'
    logger.error("Cache Key: %s", cache_key)

    question_data = cache.get(cache_key)
    
    if question_data:
        logger.error(f'Cache hit for key: {cache_key}')
        return JsonResponse(question_data, safe=False)

    logger.error(f'Cache miss for key (DB): {cache_key}')

    questionset = question_master.objects.filter(
        deleted=0,
        question_name_id=question_id
    ).select_related('question_name_id').values(
        'id',
        'question_name_id__id',
        'question_name_id__question_paper_name',
        'question_text',
        'question_image_data',
        'option_a_image_data',
        'option_b_image_data',
        'option_c_image_data',
        'option_d_image_data',
        'option_e_image_data',
        'option_a',
        'option_b',
        'option_c',
        'option_d',
        'option_e',
        'sections',
        'mark_method',
        'explain_answer',
       # 'answer',
       # 'input_format'
    )

    question_data = [
        {
            'id': q['id'],
            'question_name_id': q['question_name_id__id'],
            'question_paper_name': q['question_name_id__question_paper_name'],
            'question_text': q['question_text'],
            'question_image_data': encode_image(q['question_image_data']),
            'option_a_image_data': encode_image(q['option_a_image_data']),
            'option_b_image_data': encode_image(q['option_b_image_data']),
            'option_c_image_data': encode_image(q['option_c_image_data']),
            'option_d_image_data': encode_image(q['option_d_image_data']),
            'option_e_image_data': encode_image(q['option_e_image_data']),
            'option_a': q['option_a'],
            'option_b': q['option_b'],
            'option_c': q['option_c'],
            'option_d': q['option_d'],
            'option_e': q['option_e'],
            'sections': q['sections'],
            'mark_method': q['mark_method'],
            'explain_answer': q['explain_answer'],
           # 'answer': q['answer'],
            #'input_format': q['input_format'],
        }
        for q in questionset
    ]

    random.shuffle(question_data)
    cache.set(cache_key, question_data, timeout=600)

    return JsonResponse(question_data, safe=False)


@api_view(['GET'])
def get_YEAR_by_college(request):
    """
    Fetch distinct year values from candidate_master.
    Optionally filter by college_id.
    """
    college_id = request.query_params.get('college_id', None)

    # Base query with non-null year and active records
    query = candidate_master.objects.filter(deleted=0, year__isnull=False)

    if college_id:
        query = query.filter(college_id=college_id)

    # Get distinct year values
    query = query.values('year').distinct()

    # Format the response
    year_list = [{'year': item['year']} for item in query]

    return Response(year_list)


#-------------------------------------------------------------3

import ast
from bs4 import BeautifulSoup
import re

def compare_python_code(expected, student_code):
    score = 0
    student_code = student_code.lower()
    if "input(" in student_code:
        score += 0.3
    if "+" in student_code:
        score += 0.3
    if "print(" in student_code:
        score += 0.4
    return min(score, 1.0)  # Total score out of 1


from difflib import SequenceMatcher

def compare_html_structure(html1, html2):
    soup1 = BeautifulSoup(html1, 'html.parser')
    soup2 = BeautifulSoup(html2, 'html.parser')

    # Get prettified versions for structural similarity comparison
    pretty_html1 = soup1.prettify()
    pretty_html2 = soup2.prettify()

    # Compute similarity using SequenceMatcher
    similarity = SequenceMatcher(None, pretty_html1, pretty_html2).ratio()
    return similarity

def tokenize_code(code):
    # Remove comments and split by tokens (operators, words, etc.)
    code = re.sub(r'//.*|/\*[\s\S]*?\*/', '', code)  # remove comments
    return re.findall(r'[A-Za-z_][A-Za-z0-9_]*|[{}()\[\];=+*/<>-]', code)

def token_similarity(code1, code2):
    tokens1 = set(tokenize_code(code1))
    tokens2 = set(tokenize_code(code2))
    if not tokens1 or not tokens2:
        return 0
    intersection = len(tokens1 & tokens2)
    union = len(tokens1 | tokens2)
    return (intersection / union) * 100

def compare_mysql_code(expected_code: str, submitted_code: str) -> float:
    # Normalize & remove extra whitespace and semicolons
    def normalize(sql):
        return ' '.join(sql.replace(';', '').lower().split())

    expected = normalize(expected_code)
    submitted = normalize(submitted_code)

    if expected == submitted:
        return 1.0
    elif expected in submitted or submitted in expected:
        return 0.7
    else:
        return 0.4  # Partial score if somewhat similar

def compare_mysql_output(expected_output: str, actual_output: str) -> float:
    import difflib
    expected_lines = expected_output.strip().splitlines()
    actual_lines = actual_output.strip().splitlines()

    sm = difflib.SequenceMatcher(None, expected_lines, actual_lines)
    return sm.ratio()  # Returns a score between 0 and 1




@csrf_exempt
@api_view(['POST'])
def test_candidates_answer_view_Submit_Com(request, format=None):
    import json, re
    print('\n========= Incoming Request =========')
    print('Request.Data:', request.data)
    print('====================================\n')

    try:
        stu_id = request.data.get('student_id')
        ques_id = request.data.get('question_id')
        test_name = request.data.get('test_name')
        code = request.data.get('code', '')
        output = (request.data.get('output') or '').strip()
        explain_ans = (request.data.get('explain_answer') or '').strip()
        question_mark = float(request.data.get('mark', 0))
        question_answer = (request.data.get('answer') or '').strip()
        skill_type_language = request.data.get('skill_type', '')
        p_type = (request.data.get('p_type') or '').lower()
        test_case_results = request.data.get('test_case_results', [])
        is_test_case = request.data.get('is_test_case', False)

        print(f"Student ID: {stu_id}, Question ID: {ques_id}, Lang: {p_type}, Skill: {skill_type_language}")
        print(f"Output: {output}")
        print(f"Expected Answer: {question_answer}")
        print(f"Explain Answer: {explain_ans[:100]}...")  # limit output

        # --- fetch the related question instance ---
        try:
            question_instance = question_master.objects.get(id=ques_id)
            print('‚úÖ Question instance fetched successfully.')
        except question_master.DoesNotExist:
            print(f'‚ùå Question with id {ques_id} not found.')
            return Response({'error': f'Question with id {ques_id} not found'}, status=400)

        result = 0  # Default score

        # --- helper ---
        def extract_code_block(explain_ans, p_type):
            print(f"Extracting code block for {p_type}...")
            p_type_code_start_pattern = re.compile(rf"Code:\s*{p_type}", re.IGNORECASE)
            p_type_code_end = "Code:"
            code_start_match = p_type_code_start_pattern.search(explain_ans)
            if code_start_match:
                code_start_idx = code_start_match.start()
                code_end_idx = explain_ans.find(p_type_code_end, code_start_idx + len(code_start_match.group()))
                if code_end_idx != -1:
                    return explain_ans[code_start_idx:code_end_idx].strip()
                else:
                    return explain_ans[code_start_idx:].strip()
            print("‚ö†Ô∏è No code block found.")
            return ""

        extracted_code = ''
        syntax_score = 0
        test_case_score = 0

        # ---------------- TEST CASE SECTION ----------------
        if is_test_case:
            print('üß™ Test Case Based Evaluation Started')
            if test_case_results:
                passing_tests = sum(
                    1 for case in test_case_results if case["status"] == "Pass" and case["expected"] == case["output"]
                )
                test_case_score = (passing_tests / len(test_case_results)) * (0.40 * question_mark)
            print('Test Case Score:', test_case_score)

            extracted_code = extract_code_block(explain_ans, p_type) if skill_type_language == 'All Languages' else explain_ans
            print('Extracted Code:', extracted_code[:120])

            if p_type == 'python':
                syntax_similarity = compare_python_code(extracted_code, code)
                print('Python Syntax Similarity:', syntax_similarity)
                syntax_score = syntax_similarity * (0.60 * question_mark)
                if "input(" not in code:
                    syntax_score *= 0.5
                result = round(syntax_score)
            elif p_type == 'html':
                syntax_similarity = compare_html_structure(extracted_code, code)
                syntax_score = syntax_similarity * question_mark
            elif p_type in ['c', 'cpp', 'java', 'csharp', 'vlsi', 'angularjs', 'nodejs', 'springboot', 'matlab','php','jquery']:
                similarity = token_similarity(extracted_code, code)
                print('Token Similarity:', similarity)
                syntax_score = (similarity / 100) * (0.60 * question_mark)
                result = round(syntax_score + test_case_score)
            elif p_type == 'mysql':
                code_similarity = compare_mysql_code(extracted_code, code)
                output_similarity = compare_mysql_output(question_answer, output)
                syntax_score = code_similarity * (0.60 * question_mark)
                output_score = output_similarity * (0.40 * question_mark)
                result = round(syntax_score + output_score)
            else:
                result = min(round(test_case_score + syntax_score), question_mark)

            print(f"‚úÖ Test Case Result => Syntax: {syntax_score}, TestCase: {test_case_score}, Final: {result}")

        # ---------------- NON-TEST CASE SECTION ----------------
        else:
            print('üíª Normal (Non-Test Case) Evaluation Started')
            has_errors = 'error' in output.lower() or 'exception' in output.lower()
            extracted_code = extract_code_block(explain_ans, p_type) if skill_type_language == 'All Languages' else explain_ans
            print('Extracted Code:', extracted_code[:120])

            # ‚úÖ Normalize and compare outputs (fix for MATLAB, Node, PHP)
            def normalize(txt):
                return re.sub(r'\s+', ' ', txt.strip().lower())

            if normalize(question_answer) in normalize(output):
                print("‚úÖ Output Matched with Expected Answer!")
                result = question_mark
            else:
                print("‚ö†Ô∏è Output did not match, fallback to syntax comparison.")
                if p_type == 'python':
                    syntax_similarity = compare_python_code(extracted_code, code)
                    syntax_score = syntax_similarity * (0.60 * question_mark)
                    result = max(result, round(syntax_score))
                elif p_type == 'html':
                    syntax_similarity = compare_html_structure(extracted_code, code)
                    syntax_score = syntax_similarity * question_mark
                    result = round(syntax_score)
                elif p_type in ['c', 'cpp', 'java', 'csharp', 'vlsi', 'angularjs', 'nodejs', 'springboot', 'matlab','php','jquery']:
                    similarity = token_similarity(extracted_code, code)
                    print('Token Similarity:', similarity)
                    syntax_score = ((similarity / 100) * question_mark)
                    result = round(syntax_score)
                elif p_type == 'mysql':
                    code_similarity = compare_mysql_code(extracted_code, code)
                    output_similarity = compare_mysql_output(question_answer, output)
                    result = round((code_similarity * 0.6 + output_similarity * 0.4) * question_mark)
                else:
                    result = round(syntax_score)

                if has_errors:
                    result = max(result - 1, 0)

        print('‚úÖ Final Computed Result:', result)

        # ---------------- Save to DB ----------------
        test_candidate_answer_data = {
            'test_name': test_name,
            'question_id': ques_id,
            'student_id': stu_id,
            'answer': json.dumps(test_case_results) if is_test_case else output,
            'compile_code_editor': code,
            'result': result,
            'dtm_start': request.data.get('dtm_start'),
            'dtm_end': request.data.get('dtm_end'),
        }

        print('Saving to DB:', test_candidate_answer_data)

        existing_record = tests_candidates_answers.objects.filter(
            test_name=test_name,
            question_id=question_instance,
            student_id_id=stu_id
        ).first()

        if existing_record:
            for key, value in test_candidate_answer_data.items():
                if key == 'question_id':
                    value = question_master.objects.get(id=value)
                elif key == 'student_id':
                    value = candidate_master.objects.get(id=value)
                setattr(existing_record, key, value)
            existing_record.save()
            print('‚úÖ Existing record updated.')
            serializer = tests_candidates_answerSerializer(existing_record)
            return Response(serializer.data, status=200)
        else:
            serializer = tests_candidates_answerSerializer(data=test_candidate_answer_data)
            if serializer.is_valid():
                serializer.save()
                print('‚úÖ New record created.')
                return Response(serializer.data, status=201)
            else:
                print('‚ùå Validation Errors:', serializer.errors)
                return Response({'errors': serializer.errors, 'data_sent': test_candidate_answer_data}, status=400)

    except Exception as e:
        print(f"üî• Exception Occurred: {str(e)}")
        import traceback
        traceback.print_exc()
        return Response({'error': str(e)}, status=500)


@csrf_exempt
@api_view(['POST'])
def test_candidates_answer_view_Submit_Com_practice(request, format=None):
    print("=== API CALL: test_candidates_answer_view_Submit_Com_practice ===")
    print("Request Data:", request.data)

    try:
        # --- Extract Input Fields ---
        stu_id = request.data.get('student_id')
        ques_id = request.data.get('question_id')
        code = request.data.get('code', '')
        output = request.data.get('output', '')
        explain_ans = request.data.get('explain_answer', '')
        question_mark = float(request.data.get('mark', 0))
        question_answer = request.data.get('answer', '')
        skill_type_language = request.data.get('skill_type', '')
        p_type = request.data.get('p_type', '').lower()
        test_case_results = request.data.get('test_case_results', [])
        is_test_case = request.data.get('is_test_case', False)

        print(f"Student ID: {stu_id}")
        print(f"Question ID: {ques_id}")
        print(f"Language Type: {p_type}")
        print(f"Skill Type Language: {skill_type_language}")
        print(f"Is Test Case: {is_test_case}")
        print(f"Marks: {question_mark}")
        print(f"Explain Answer: {explain_ans[:100]}...")  # show first 100 chars
        print(f"Code Submitted: {code[:100]}...")  # show first 100 chars
        print(f"Output Received: {output}")

        result = 0.0
        syntax_score = 0.0
        test_case_score = 0.0

        # --- Function: Extract Code Block ---
        def extract_code_block(explain_text, language_type):
            print(f"Extracting code block for type: {language_type}")
            try:
                pattern = re.compile(rf"Code:\s*{language_type}", re.IGNORECASE)
                code_start = pattern.search(explain_text)
                if not code_start:
                    print("No matching 'Code:' section found.")
                    return ""
                start_idx = code_start.end()
                next_code_idx = explain_text.find("Code:", start_idx)
                code_snippet = explain_text[start_idx:next_code_idx].strip() if next_code_idx != -1 else explain_text[start_idx:].strip()
                print(f"Extracted code block length: {len(code_snippet)}")
                return code_snippet
            except Exception as e:
                print(f"Error extracting code block: {str(e)}")
                return ""

        # --- Test Case Based Evaluation ---
        if is_test_case:
            print("Processing in Test Case Mode...")

            if test_case_results and isinstance(test_case_results, list):
                passing_tests = sum(
                    1 for case in test_case_results
                    if case.get("status") == "Pass" and case.get("expected") == case.get("output")
                )
                total_cases = len(test_case_results)
                test_case_score = (passing_tests / total_cases) * (0.40 * question_mark)
                print(f"Passing Tests: {passing_tests}/{total_cases} -> Test Case Score: {test_case_score}")
            else:
                print("No valid test case results found.")

            extracted_code = (
                extract_code_block(explain_ans, p_type)
                if skill_type_language == 'All Languages'
                else explain_ans
            )

            # Syntax-based Scoring
            if p_type == 'python':
                syntax_similarity = compare_python_code(extracted_code, code)
                syntax_score = syntax_similarity * (0.60 * question_mark)
                if "input(" not in code:
                    syntax_score *= 0.5
                print(f"Python Syntax Similarity: {syntax_similarity}, Syntax Score: {syntax_score}")

            elif p_type == 'html':
                syntax_similarity = compare_html_structure(extracted_code, code)
                syntax_score = syntax_similarity * question_mark
                print(f"HTML Similarity: {syntax_similarity}, Syntax Score: {syntax_score}")

            elif p_type in ['c', 'cpp', 'java', 'csharp', 'vlsi', 'angularjs', 'nodejs', 'springboot', 'matlab', 'php','jquery']:
                similarity = token_similarity(extracted_code, code)
                syntax_score = (similarity / 100) * (0.60 * question_mark)
                print(f"Token Similarity: {similarity}, Syntax Score: {syntax_score}")

            elif p_type == 'mysql':
                code_similarity = compare_mysql_code(extracted_code, code)
                output_similarity = compare_mysql_output(question_answer, output)
                syntax_score = code_similarity * (0.60 * question_mark)
                test_case_score = output_similarity * (0.40 * question_mark)
                print(f"MySQL Code Sim: {code_similarity}, Output Sim: {output_similarity}, Scores: Syntax={syntax_score}, TestCase={test_case_score}")

            result = round(test_case_score + syntax_score)
            if p_type != 'mysql':
                result = min(result, question_mark)

            print(f"Final Computed Result (Test Case Mode): {result}")

        # --- Non-Test-Case Evaluation ---
        else:
            print("Processing in Non-Test-Case Mode...")
            has_errors = 'error' in output.lower() or 'exception' in output.lower()

            extracted_code = (
                extract_code_block(explain_ans, p_type)
                if skill_type_language == 'All Languages'
                else explain_ans
            )

            if question_answer.strip() == output.strip():
                print("Exact output match found.")
                result = question_mark
            else:
                if p_type == 'python':
                    syntax_similarity = compare_python_code(extracted_code, code)
                    syntax_score = syntax_similarity * (0.60 * question_mark)
                elif p_type == 'html':
                    syntax_similarity = compare_html_structure(extracted_code, code)
                    syntax_score = syntax_similarity * question_mark
                elif p_type in ['c', 'cpp', 'java', 'csharp', 'vlsi', 'angularjs', 'nodejs', 'springboot', 'matlab', 'php','jquery']:
                    similarity = token_similarity(extracted_code, code)
                    syntax_score = (similarity / 100) * question_mark
                elif p_type == 'mysql':
                    code_similarity = compare_mysql_code(extracted_code, code)
                    output_similarity = compare_mysql_output(question_answer, output)
                    syntax_score = code_similarity * (0.60 * question_mark)
                    output_score = output_similarity * (0.40 * question_mark)
                    result = round(syntax_score + output_score)

                if p_type != 'mysql':
                    result = min(round(syntax_score), question_mark)

                if has_errors:
                    print("Error detected in output, reducing score by 1.")
                    result = max(round(result - 1), 0)

            print(f"Final Computed Result (Non-Test-Case Mode): {result}")

        # Ensure non-negative result
        result = max(result, 0)
        print("Final Result after validation:", result)

        # --- Prepare Data to Save ---
        test_candidate_answer_data = {
            'test_name': request.data.get('test_name'),
            'question_id': ques_id,
            'student_id': stu_id,
            'answer': json.dumps(test_case_results) if is_test_case else output,
            'compile_code_editor': code,
            'result': result,
            'dtm_start': request.data.get('dtm_start'),
            'dtm_end': request.data.get('dtm_end'),
        }
        print("Data ready for serializer:", test_candidate_answer_data)

        # --- Save using Serializer ---
        serializer = tests_candidates_answerSerializer(data=test_candidate_answer_data)
        if serializer.is_valid():
            serializer.save()
            print("‚úÖ Data saved successfully!")
            return Response(serializer.data, status=201)
        else:
            print("‚ùå Validation failed:", serializer.errors)
            return Response({'errors': serializer.errors, 'data_sent': test_candidate_answer_data}, status=400)

    except Exception as e:
        print(f"üî• Exception Occurred: {str(e)}")
        return Response({'error': str(e)}, status=500)

from itertools import groupby  # ‚úÖ Import this
from operator import itemgetter

@api_view(['GET'])
def get_skill_types_grouped(request):
    try:
        # Fetch only necessary fields
        skills = skill_type.objects.filter(
            deleted=0,
            question_type_id__isnull=False, question_type_id__deleted=0 
            
        ).values(
            question_type=F('question_type_id__question_type'),
            skill=F('skill_type')
        ).order_by('question_type')

        # Group by question_type
        grouped_data = {
            key: [item['skill'] for item in group]
            for key, group in groupby(skills, key=itemgetter('question_type'))
        }

        return Response(grouped_data, status=status.HTTP_200_OK)

    except Exception as e:
        return Response(
            {"error": str(e)},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

import urllib.parse

@csrf_exempt
def send_whatsapp_to_students(request, job_id, round_of_interview):
    try:
        print(f"Step 1: Fetching students for WhatsApp - Job ID: {job_id}, Round: {round_of_interview}")
        logger.info(f"Step 1: Fetching students for WhatsApp - Job ID: {job_id}, Round: {round_of_interview}")

        # Fetch eligible students
        eligible_students = eligible_student_list.objects.filter(
            job_id_id=job_id,
            round_of_interview=round_of_interview,deleted=0
        )

        if not eligible_students.exists():
            print("Step 2: No eligible students found.")
            logger.warning("Step 2: No eligible students found.")
            return JsonResponse({"error": "No eligible students found for WhatsApp messaging"}, status=404)

        print(f"Step 2: Found {eligible_students.count()} eligible students.")
        logger.info(f"Step 2: Found {eligible_students.count()} eligible students.")

        # Twilio client
      #  client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)

        # Prepare WhatsApp message template
        template = "Hello {name}. For further details check the job posting in CC Portal login of your {company}. All The Best."

        print("Step 3: Sending WhatsApp messages to each student...")
        logger.info("Step 3: Sending WhatsApp messages to each student...")

        sent_messages = []
        for idx, student in enumerate(eligible_students, start=1):
            student_obj = student.students_id
            student_name = student_obj.students_name
            phone_number = f"whatsapp:+91{student_obj.mobile_number}"
            company = getattr(student.job_id, 'company_name', 'Your Company')

            message = template.format(name=student_name, company=company)

            try:
                # Send WhatsApp message
                message_sent = client.messages.create(
                    body=message,
                    #from_=TWILIO_WHATSAPP_NUMBER,
                    to=phone_number
                )

                sent_messages.append({
                    "name": student_name,
                    "phone": student_obj.mobile_number,
                    "company": company,
                    "message_sid": message_sent.sid
                })

                print(f"  - Student {idx}: {student_name} | Phone: {phone_number} | Message Sent.")
                logger.info(f"  - Student {idx}: {student_name} | Phone: {phone_number} | Message Sent.")

            except Exception as e:
                print(f"  - Student {idx}: {student_name} | Phone: {phone_number} | Failed: {e}")
                logger.error(f"  - Student {idx}: {student_name} | Phone: {phone_number} | Failed: {e}")

        print("Step 4: WhatsApp messages sent successfully.")
        logger.info("Step 4: WhatsApp messages sent successfully.")

        return JsonResponse({
            "message": "WhatsApp messages sent successfully",
            "sent_messages": sent_messages
        }, status=200)

    except Exception as e:
        logger.error(f"Error sending WhatsApp messages: {e}")
        print(f"Error occurred: {e}")
        return JsonResponse({"error": str(e)}, status=500)


@api_view(['PUT'])
def update_totalScore_and_avgMark_test_candidate_map(request, pk=None):
    try:
        # Fetch the test candidate by primary key (id)
        total_score_update = tests_candidates_map.objects.get(id=pk)

        # Get total_score and avg_mark from the request data
        total_score = request.data.get('total_score')
        avg_mark = request.data.get('avg_mark')

        if total_score is None or avg_mark is None:
            return JsonResponse("Total score and average mark are required", status=400)

        # Prepare updated data
        update_data = {
            'total_score': total_score,
            'avg_mark': avg_mark
        }

        # Use serializer to validate and save the data
        serializer = testcandidatemapSerializers(instance=total_score_update, data=update_data, partial=True)

        if serializer.is_valid():
            serializer.save()
            print('Total score and avg mark updated')
            return JsonResponse("Total score and Average mark updated successfully", safe=False)
        
        return JsonResponse("Failed to update total score and average mark", status=400)
    
    except tests_candidates_map.DoesNotExist:
        return JsonResponse("Test candidate not found", status=404)

@api_view(['GET'])
def get_view_results_po(request):
    college_id = request.GET.get('college_id')  # optional
    test_name = request.GET.get('test_name')  # required

    if not test_name:
        return Response({'error': 'test_name is required'}, status=400)

    filters = {
        'deleted': 0,
        'test_name': test_name
    }
    if college_id:
        filters['college_id'] = college_id

    # Fetch related data using select_related for efficiency
    tests_candidates = tests_candidates_map.objects.filter(
        **filters
    ).select_related(
        'rules_id', 
        'department_id', 
        'question_id', 
        'student_id', 
        'college_id'
    ).values(
        'id',
        'test_name',
         'college_id__id',
        'college_id__college',
        'department_id__department',
        'student_id__id',
        'student_id__students_name',
        'student_id__user_name',
        'student_id__email_id',
        'student_id__mobile_number',
        'student_id__registration_number',
        'dtm_start_test',
        'dtm_start',
        'dtm_end',
        'capture_duration',
        'is_active',
        'year',
        'avg_mark',
        'is_reassigned',
        'attempt_count'
    )

    # Format the result
    test_candidate_map_data = []
    for testing in tests_candidates:
        dtm_start_formatted = django_format_date(localtime(testing['dtm_start']), 'd-m-Y h:i A')
        dtm_end_formatted = django_format_date(localtime(testing['dtm_end']), 'd-m-Y h:i A')
        dtm_startT_formatted = django_format_date(localtime(testing['dtm_start_test']), 'd-m-Y h:i A')
      
        test_candidate_map_data.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
             'collegeId': testing['college_id__id'],
            'college_id': testing['college_id__college'],
            'department_id': testing['department_id__department'],
            'student_id': testing['student_id__id'],
            'registration_number': testing['student_id__registration_number'],
            'email_id': testing['student_id__email_id'],
            'mobile_number': testing['student_id__mobile_number'],
            'student_name': testing['student_id__students_name'],
            'user_name': testing['student_id__user_name'],
            'dtm_start': dtm_start_formatted,
            'dtm_start_test': dtm_startT_formatted,
            'dtm_end': dtm_end_formatted,
            'capture_duration': testing['capture_duration'],
            'is_active': testing['is_active'],
            'year': testing['year'],
            'avg_mark': testing['avg_mark'],
            'is_reassigned': testing['is_reassigned'],
            'attempt_count': testing['attempt_count']
        })

    return Response(test_candidate_map_data)



@api_view(['GET'])
def get_colleges(request):
    try:
        # Base query
        queryset = college_master.objects.filter(deleted=0).order_by('-id').values(
            'id',
            'college',
            'college_logo',
            'college_code',
            'college_group',
        )

        # Prepare paginated data with logo encoding
        college_data = [
            {
                'id': college['id'],
                'college': college['college'],
                'college_code': college['college_code'],
                'college_group': college['college_group'],
                'college_logo': base64.b64encode(college['college_logo']).decode('utf-8')
                                if college['college_logo'] else None
            }
            for college in queryset
        ]

        return Response(college_data)

    except Exception as e:
        return Response({'error': str(e)}, status=500)


@api_view(['GET'])
def get_candidate_mcq(request):
    try:
        # Extract `user_name` from request parameters
        user_name = request.GET.get('user_name', None)
        
        if not user_name:
            return Response({'error': 'user_name parameter is required'}, status=400)
        
        # Fetch the student ID for the given user_name
        candidate = candidate_master.objects.filter(
            deleted=0,
            user_name=user_name
        ).values('id').first()
        
        if not candidate:
            return Response({'error': 'Candidate not found'}, status=404)
        
        student_id = candidate['id']
        
        # Return the fetched student ID
        return Response({'student_id': student_id})
    except Exception as e:
        return Response({'error': str(e)}, status=500)

from django.db.models import FloatField
from django.db.models.functions import Coalesce, Round
from django.db.models import Case, When, Value, Avg, F, Count, Q


@api_view(['GET'])
def get_dept_clg_report_po(request):
    """
    API view to fetch distinct department_id and department name for a given college_id.
    Ensures college_id is mandatory.
    """
    try:
        # Extract college_id from query parameters
        college_id = request.query_params.get('college_id')

        print('request.college_id: ', college_id)
        
        # Validate that college_id is provided
        if not college_id:
            return Response({"error": "college_id is a mandatory field."}, status=400)
        
        # Fetch departments filtered by college_id and deleted=0
        departments = (
            tests_candidates_map.objects.filter(
                college_id=college_id,
                deleted=0
            )
            .values('department_id', 'department_id__department')
            .distinct()
        )

        # Convert the queryset to a list and filter out incomplete data
        response_data = [
            dept for dept in departments 
            if dept['department_id'] and dept['department_id__department']
        ]

        return Response({"departments": response_data}, status=200)

    except Exception as e:
        return Response({"error": str(e)}, status=400)



@api_view(['GET'])
def get_test_name_dept_report_po(request):
    """
    API view to fetch test names based on filters: college_id (mandatory), department_id, and year.
    Parameters are passed in the request body.
    """
    try:
        # Get filter parameters from the request body
        college_id = request.query_params.get('college_id')
        department_id = request.query_params.get('department_id')
        year = request.query_params.get('year')

        # Validate mandatory field
        if not college_id:
            return Response({"error": "college_id is a mandatory field."}, status=400)

        # Build the filter criteria
        filters = {'deleted': 0, 'college_id': college_id}
        if department_id:
            filters['department_id'] = department_id
        if year:
            filters['year'] = year
        
        # Fetch the data based on filters
        test_names = tests_candidates_map.objects.filter(**filters).exclude(created_by='Student').values_list('test_name', flat=True).distinct()
        
        # Transform queryset to a list
        response_data = list(test_names)
        return Response({"test_names": response_data}, status=200)
    except Exception as e:
        return Response({"error": str(e)}, status=400)

from django.db.models import Avg, Count, Case, When, Value, F, Q, FloatField
from django.db.models.functions import Coalesce, Round


@api_view(['GET'])
def get_student_feedback_report(request):
    college_id = request.GET.get('college_id')
    department_id = request.GET.get('department_id')
    year = request.GET.get('year')
    search = request.query_params.get('search', '')

    print("üìå Request Params:", {"college_id": college_id, "department_id": department_id, "year": year, "search": search})
    college_id = int(college_id) if college_id else None

    if not college_id:
        return Response({"error": "college_id is required"}, status=400)

    # Base query: only active tests
    qs = tests_candidates_map.objects.filter(
        deleted=0,
        college_id=college_id,
        is_active=True
    ).exclude(created_by='Student')

    if department_id:
        qs = qs.filter(department_id=department_id)
    if year:
        qs = qs.filter(year=year)

    print(f"üìå Total active tests found: {qs.count()}")

    # Fetch all student aggregates
    students_agg = qs.values(
        "student_id",
        "student_id__students_name",
        "student_id__registration_number"
    ).annotate(
        total_aptitude_score=Sum('avg_mark', filter=Q(test_name__in=test_master.objects.filter(question_type_id__question_type="Aptitude").values_list('test_name', flat=True))),
        total_technical_score=Sum('avg_mark', filter=Q(test_name__in=test_master.objects.filter(question_type_id__question_type="Technical").values_list('test_name', flat=True))),
        total_softskill_score=Sum('avg_mark', filter=Q(test_name__in=test_master.objects.filter(question_type_id__question_type="SoftSkill").values_list('test_name', flat=True))),
        aptitude_tests_count=Count('id', filter=Q(test_name__in=test_master.objects.filter(question_type_id__question_type="Aptitude").values_list('test_name', flat=True))),
        technical_tests_count=Count('id', filter=Q(test_name__in=test_master.objects.filter(question_type_id__question_type="Technical").values_list('test_name', flat=True))),
        softskill_tests_count=Count('id', filter=Q(test_name__in=test_master.objects.filter(question_type_id__question_type="SoftSkill").values_list('test_name', flat=True))),
    )

    print(f"üìå Aggregated students count: {students_agg.count()}")

    # Build final list with safe division
    final_data = []
    for s in students_agg:
        print("\n--- Student:", s['student_id__students_name'], "| Reg:", s['student_id__registration_number'])
        print("Raw Aggregates:", s)

        # Safe division
        aptitude_avg = s['total_aptitude_score'] / s['aptitude_tests_count'] if s['aptitude_tests_count'] else 0
        technical_avg = s['total_technical_score'] / s['technical_tests_count'] if s['technical_tests_count'] else 0
        softskills_avg = s['total_softskill_score'] / s['softskill_tests_count'] if s['softskill_tests_count'] else 0

        print("Calculated averages:", {"aptitude_avg": aptitude_avg, "technical_avg": technical_avg, "softskills_avg": softskills_avg})

                # Collect non-zero averages
        # Include 0s for aptitude/technical if no score
        averages = []

        # Always include aptitude and technical (even if avg=0) if that category exists
        if s['aptitude_tests_count'] is not None:  # always include
            averages.append(aptitude_avg)
        if s['technical_tests_count'] is not None:
            averages.append(technical_avg)
        # Only include softskills if present
        if s['softskill_tests_count']:
            averages.append(softskills_avg)

        # Dynamic divisor
        divisor = len(averages)
        overall_avg = round(sum(averages) / divisor) if divisor else 0

        # Total tests taken (all categories)
        total_tests_taken = s['aptitude_tests_count'] + s['technical_tests_count'] + s['softskill_tests_count']
        print("Total tests taken:", total_tests_taken)

        # Feedback mapping
        if overall_avg > 85:
            feedback = "Excellent"
        elif overall_avg > 60:
            feedback = "Good"
        elif overall_avg > 45:
            feedback = "Need to Focus"
        elif overall_avg > 30:
            feedback = "Need Improvement"
        else:
            feedback = "Very Poor"

        print("Overall average:", overall_avg, "| Feedback:", feedback)

        # Append result
        final_data.append({
            "student_id": s['student_id'],
            "students_name": s['student_id__students_name'],
            "registration_number": s['student_id__registration_number'],
            "total_tests_taken": total_tests_taken,  # <-- Added
            "aptitude_avg": round(aptitude_avg),
            "technical_avg": round(technical_avg),
            "softskills_avg": round(softskills_avg),
            "overall_avg": overall_avg,
            "feedback": feedback,
        })

    # Apply search filter
    if search:
        final_data = [
            f for f in final_data
            if search.lower() in f['student_name'].lower() or search.lower() in str(f['registration_number'])
        ]
        print(f"üìå After search filter: {len(final_data)} students")

    # Pagination
    paginator = CustomPagination()
    paginated_data = paginator.paginate_queryset(final_data, request)
    print(f"üìå Paginated results: {len(paginated_data)}")
    return paginator.get_paginated_response(paginated_data)


from django.core.paginator import Paginator, EmptyPage, PageNotAnInteger


@api_view(['GET'])
def get_indi_departmentReport_po(request):
    test_name = request.GET.get('test_name')
    college_id = request.GET.get('college_id')
    department_id = request.GET.get('department_id')
    year = request.GET.get('year')
    search_query = request.GET.get('search', '')  # optional search text
    page = request.GET.get('page', 1)
    page_size = request.GET.get('page_size', 10)

    if not test_name:
        return Response({'error': 'test_name is required'}, status=400)

    # Filter base
    filters = {
        'deleted': 0,
        'test_name': test_name,
        'is_active': True, 
    }
    if college_id:
        filters['college_id'] = college_id
    if department_id:
        filters['department_id'] = department_id
    if year:
        filters['year'] = year

    queryset = tests_candidates_map.objects.filter(**filters).exclude(created_by='Student') 

    # Search filter on related student fields
    if search_query:
        queryset = queryset.filter(
            Q(student_id__students_name__icontains=search_query) |
            Q(student_id__user_name__icontains=search_query) |
            Q(student_id__registration_number__icontains=search_query)
        )

    # Optimized fetching of related data
    queryset = queryset.select_related(
        'department_id', 'student_id', 'college_id'
    ).values(
        'id',
        'test_name',
        'college_id__college',
        'department_id__department',
        'student_id__id',
        'student_id__students_name',
        'student_id__user_name',
       
        'student_id__registration_number',

        'dtm_start_test',
       
        'capture_duration',
        'is_active',
        'year',
        'avg_mark',
       
    )

    # Pagination
    paginator = Paginator(queryset, page_size)
    try:
        paged_data = paginator.page(page)
    except PageNotAnInteger:
        paged_data = paginator.page(1)
    except EmptyPage:
        paged_data = []

    results = []
    for item in paged_data:
        results.append({
            'id': item['id'],
            'test_name': item['test_name'],
            'college_id': item['college_id__college'],
            'department_id': item['department_id__department'],
             'registration_number': item['student_id__registration_number'],
                'student_name': item['student_id__students_name'],
            'user_name': item['student_id__user_name'],
             'dtm_start_test': django_format_date(localtime(item['dtm_start_test']), 'd-m-Y h:i A'),
            'capture_duration': item['capture_duration'],
            'is_active': item['is_active'],
            'year': item['year'],
            'avg_mark': item['avg_mark'],
          
        })

    return Response({
        'count': paginator.count,
        'total_pages': paginator.num_pages,
        'current_page': int(page),
        'results': results
    })


class ExcelImportView_Questions_COR(APIView):
    def post(self, request, format=None):
        print('Request Data: ', request.data)
        
        # Extract multiple question paper names and files
        question_paper_names = request.data.getlist('question_paper_name', [])
        duration_of_test = request.data.get('duration_of_test')
        topic = request.data.get('topic')
        sub_topic = request.data.get('sub_topic')
        no_of_questions = request.data.get('no_of_questions')
        upload_type = request.data.get('upload_type')
        test_type = request.data.get('test_type')
        files = request.FILES.getlist('file')

           # Build a list of the always‚Äêrequired values
        required_values = [
            question_paper_names,
            duration_of_test,
            topic,
            no_of_questions,
            upload_type,
            test_type,
        ]

        # Only require sub_topic if topic is NOT Softskills
        if topic != 'Softskills':
            required_values.append(sub_topic)

        if not all(required_values):
            return Response(
                {'error': 'Missing fields for question_paper_master'},
                status=status.HTTP_400_BAD_REQUEST
            )       # Ensure the number of files matches the number of question paper names
        if len(files) != len(question_paper_names):
            return Response({'error': 'Mismatch between question paper names and files'}, status=status.HTTP_400_BAD_REQUEST)

        responses = []
        for question_paper_name, file in zip(question_paper_names, files):
            question_paper_data = {
                'question_paper_name': question_paper_name,
                'duration_of_test': duration_of_test,
                'topic': topic,
                'sub_topic': sub_topic,
                'no_of_questions': no_of_questions,
                'upload_type': upload_type,
                'test_type': test_type
            }

            print('Question Paper Data: ', question_paper_data)

            question_paper_serializer = questionsPaperSerializer(data=question_paper_data)

            if question_paper_serializer.is_valid():
                question_paper_instance = question_paper_serializer.save()
                print('question_paper_instance: ', question_paper_instance)
                question_paper_id = question_paper_instance.id

                # Append question paper details to the response
                responses.append({
                    'question_paper_name': question_paper_name,
                    'id': question_paper_id,
                    'status': 'Uploaded successfully'
                })
            else:
                return Response(question_paper_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

            # Process the file based on file extension
            try:
                if file.name.endswith('.xlsx'):

                    if topic == 'Psychometry':

                        df = pd.read_excel(file)
                        print("üìä Successfully Read Excel File")
                    
                        
                        # Map Excel headers to expected column names
                        header_mapping = {
                            'Sections':'sections',
                            'Questions**': 'question_text',

                            'Option A': 'option_a',
                            'Option B': 'option_b',
                            'Option C': 'option_c',
                            'Option D': 'option_d',
                            'Option E': 'option_e',
                            'Mark Type**': 'mark_method',
                        }

                        missing_columns = [col for col in header_mapping.keys() if col not in df.columns]
                        if missing_columns:
                            print(f"‚ùå Missing columns in Excel: {', '.join(missing_columns)}")
                            return Response({'error': f'Missing columns in Excel: {", ".join(missing_columns)}'}, status=status.HTTP_400_BAD_REQUEST)

                        df.rename(columns=header_mapping, inplace=True)
                        print(f"üîÑ Renamed Excel Columns: {list(df.columns)}")

                        # Validate Required Columns
                        mandatory_columns = ['question_text', 'mark_method']
                        error_messages = []

                        # Check for empty values in mandatory columns
                        for col in mandatory_columns:
                            missing_values = df[df[col].isnull()]
                            if not missing_values.empty:
                                for index in missing_values.index:
                                    error_messages.append(f"‚ùå Row {index + 1}: Column '{col}' is empty.")

                        # Validate `mark_method` column
                        allowed_mark_methods = {'A-E', 'E-A'}
                        for index, row in df.iterrows():
                            mark_method = str(row.get('mark_method', '')).strip().upper()
                            if mark_method not in allowed_mark_methods:
                                error_messages.append(f"‚ùå Row {index + 1}: Invalid mark method '{mark_method}'. Must be 'A-E' or 'E-A'.")

                        if error_messages:
                            print("‚ùå Validation Errors in Excel Data:", error_messages)
                            return Response({'error': ' '.join(error_messages)}, status=status.HTTP_400_BAD_REQUEST)

                        # Convert DataFrame to JSON Records
                        records = df.fillna('').to_dict(orient='records')
                        for record in records:
                            record['question_name_id'] = question_paper_id
                            for key in record:
                                if isinstance(record[key], str):
                                    record[key] = record[key].strip()

                        print(f"‚úÖ Prepared {len(records)} Records for Import")  # Debugging

                        # Serialize and Save Questions
                        serializer = questionsSerializerImportPhysico(data=records, many=True)
                        if serializer.is_valid():
                            serializer.save()
                            print("‚úÖ Questions Imported Successfully")
                           # return Response(serializer.data, status=status.HTTP_201_CREATED)
                        else:
                            detailed_errors = []
                            for idx, error_dict in enumerate(serializer.errors):
                                for field, errors in error_dict.items():
                                    if isinstance(errors, list):
                                        for error in errors:
                                            detailed_errors.append(f"‚ùå Row {idx + 1}, Column '{field}': {error}")

                            print("‚ùå Serialization Errors:", detailed_errors)
                            return Response({'error': detailed_errors}, status=status.HTTP_400_BAD_REQUEST)


                    else:

                        # Excel processing logic
                        df = pd.read_excel(file)

                        # Rename and validate columns
                        df.rename(columns={
                            'Questions**': 'question_text',
                            'Option A': 'option_a',
                            'Option B': 'option_b',
                            'Option C': 'option_c',
                            'Option D': 'option_d',
                            'Answer**': 'answer',
                            'Mark**': 'mark',
                            'Explain Answer': 'explain_answer',
                        }, inplace=True)

                        mandatory_columns = ['question_text', 'answer', 'mark']
                        for col in mandatory_columns:
                            if col not in df.columns or df[col].isnull().any():
                                return Response({'error': f"Missing or invalid data in column '{col}' for file {file.name}"}, status=status.HTTP_400_BAD_REQUEST)

                        records = df.fillna('').to_dict(orient='records')
                        for record in records:
                            record['question_name_id'] = question_paper_id

                        # Save questions
                        serializer = questionsSerializerImport(data=records, many=True)
                        if serializer.is_valid():
                            serializer.save()
                           #  responses.append({'question_paper_name': question_paper_name, 'status': 'Uploaded successfully'})
                        else:
                            return Response({'error': f"Error saving questions for {file.name}"}, status=status.HTTP_400_BAD_REQUEST)

                elif file.name.endswith('.docx'):
                    # Word document processing logic
                    print(f"Processing DOCX file: {file.name}")
                    
                    # Get the directory of the current script
                    current_dir = os.path.dirname(os.path.abspath(__file__))
                    output_json_path = os.path.join(current_dir, '../words/output.json')
                    output_unmatched_lines_path = os.path.join(current_dir, '../words/unmatched_lines.docx')

                    text, images_binary = extract_text_and_images_from_docx_mcq(file)

                    # Create JSON structure from extracted data
                    data = create_json_structure(text, images_binary)

                    # Save JSON and unmatched lines to respective files
                    with open(output_json_path, 'w') as json_file:
                        json.dump(data, json_file, indent=4)
                    
                    
                    print(f"Saving unmatched lines to DOCX file: {output_unmatched_lines_path}")

                    # Process questions extracted from DOCX file
                    for ques in data["questions"]:
                        question_text = ques.get('question_text', '')
                        question_image_data = ques.get('question_image_data', '')
                        answer = ques.get('answer', '')
                        marks = ques.get('marks', 0)
                        negative_mark = ques.get('negative_marks', 0)
                        explain_answer = ques.get('explanation', '')

                        if ques['options']:
                            print("Extracting options...")
                            options_a = ques['options'].get('a', ['', False])
                            options_b = ques['options'].get('b', ['', False])
                            options_c = ques['options'].get('c', ['', False])
                            options_d = ques['options'].get('d', ['', False])

                            option_a_image_data = options_a[0] if options_a[1] else ''
                            option_a = options_a[0] if not options_a[1] else ''

                            option_b_image_data = options_b[0] if options_b[1] else ''
                            option_b = options_b[0] if not options_b[1] else ''

                            option_c_image_data = options_c[0] if options_c[1] else ''
                            option_c = options_c[0] if not options_c[1] else ''

                            option_d_image_data = options_d[0] if options_d[1] else ''
                            option_d = options_d[0] if not options_d[1] else ''

                            print(f"Options extracted: A: {option_a}, B: {option_b}, C: {option_c}, D: {option_d}")
                        else:
                            print(f"Warning: No options found for question: {question_text}")

                        # Create and save question instance
                        question = question_master(
                            question_name_id=question_paper_instance,
                            question_text=question_text or '',
                            question_image_data=decode_base64_image(question_image_data) if question_image_data else None,
                            option_a_image_data=decode_base64_image(option_a_image_data) if option_a_image_data else None,
                            option_b_image_data=decode_base64_image(option_b_image_data) if option_b_image_data else None,
                            option_c_image_data=decode_base64_image(option_c_image_data) if option_c_image_data else None,
                            option_d_image_data=decode_base64_image(option_d_image_data) if option_d_image_data else None,
                            input_format="",
                            option_a=option_a or '',
                            option_b=option_b or '',
                            option_c=option_c or '',
                            option_d=option_d or '',
                            answer=answer or '',
                            negative_mark=negative_mark or 0,
                            mark=marks or 0,
                            explain_answer=explain_answer or ''
                        )
                        question.save()
                        print(f"Saved question: {question.id}")

                    print("All questions processed and saved successfully.")

            except Exception as e:
                return Response({'error': f"Error processing file {file.name}: {str(e)}"}, status=status.HTTP_400_BAD_REQUEST)

        return Response({'result': responses}, status=status.HTTP_201_CREATED)


from django.http import JsonResponse
from django.db.models import Q

def get_test_candidates_count_companyspecific(request):
    try:
        # Get query parameters from the request
        college_id = request.GET.get('college_id')

        # Get the question type instance for 'CompanySpecific'
        question_type_instance = question_type.objects.filter(
             question_type__in=['Mock/Interview', 'CompanySpecific'], deleted=0
        ).first()

        if not question_type_instance:
            return JsonResponse({'error': 'Question type not found'}, status=404)

        # Build base queryset for candidate test names
        if college_id:
            candidate_test_names = tests_candidates_map.objects.filter(
                deleted=0, college_id=college_id
            ).exclude(created_by='Student').values_list('test_name', flat=True).distinct()
        else:
            candidate_test_names = tests_candidates_map.objects.filter(
                deleted=0
            ).values_list('test_name', flat=True).distinct()

        print("üéØ Candidate test names (distinct):", list(candidate_test_names))

        # Filter test_master for unique tests
        # Either question_type is CompanySpecific OR test_type_categories is CompanySpecific/Mock/Interview
        test_master_data = test_master.objects.filter(
            deleted=0,
            test_name__in=candidate_test_names
        ).filter(
            Q(question_type_id=question_type_instance.id) |
            Q(test_type_id__test_type_categories__in=['CompanySpecific', 'Mock/Interview'])
        ).distinct()

        print("üéØ Matching test_master entries (ID, Name):",
              list(test_master_data.values_list('id', 'test_name')))

        # Count unique test names
        count = test_master_data.values('test_name').distinct().count()
        print("üéØ Final unique test count:", count)

        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


def get_test_candidates_count_communication(request):
    try:
        # Get query parameters from the request
        college_id = request.GET.get('college_id')

        # Get the question type instance (for 'Aptitude')
        question_type_instance = question_type.objects.filter(question_type='Softskills', deleted=0).first()

        if not question_type_instance:
            return JsonResponse({'error': 'Question type not found'}, status=404)

        # Base query: Get test names from app_test_master and filter by question_type_id
        if college_id:
            # Filter test names based on college_id if provided
            test_master_data = test_master.objects.filter(
                question_type_id=question_type_instance.id,
                deleted=0,
                test_name__in=tests_candidates_map.objects.filter(deleted=0, college_id=college_id).exclude(created_by='Student').values_list('test_name', flat=True)
            )
        else:
            # No college_id provided, filter without it
            test_master_data = test_master.objects.filter(
                question_type_id=question_type_instance.id,
                deleted=0,
                test_name__in=tests_candidates_map.objects.filter(deleted=0).values_list('test_name', flat=True)
            )

        # Get the count of the records
        count = test_master_data.count()

        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)

from django.http import JsonResponse

def get_cmpy_test_stu(request):
    try:
        username = request.GET.get('username')
        if not username:
            return JsonResponse({'error': 'Username required'}, status=400)

        print("username:", username)

        # Get CompanySpecific question type
        qt = question_type.objects.filter(
            question_type__iexact="Mock/Interview",
            deleted=0
        ).first()
        if not qt:
            return JsonResponse({'error': 'Question type not found'}, status=404)

        print("question_type_id:", qt.id)

        # All active tests for the student
        active_tests = tests_candidates_map.objects.select_related('student_id').filter(
            student_id__user_name=username,
            is_active=True
        ).values_list('test_name', flat=True)

        print("Active test names:", list(active_tests))

        # Count tests in test_master with that question type
        count = test_master.objects.filter(
            question_type_id=qt,  # pass instance instead of qt.id
            test_name__in=active_tests
        ).count()

        print("Filtered test count:", count)
        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        print("Error:", str(e))
        return JsonResponse({'error': str(e)}, status=500)


def get_commun_test_stu(request):
    try:
        username = request.GET.get('username')
        if not username:
            return JsonResponse({'error': 'Username required'}, status=400)

        print("username:", username)

        # Get Softskills question type
        qt = question_type.objects.filter(
            question_type__iexact='Softskills',
            deleted=0
        ).first()
        if not qt:
            return JsonResponse({'error': 'Question type not found'}, status=404)

        print("question_type_id:", qt.id)

        active_tests = tests_candidates_map.objects.select_related('student_id').filter(
            student_id__user_name=username,
            is_active=True
        ).values_list('test_name', flat=True)

        print("Active test names:", list(active_tests))

        count = test_master.objects.filter(
            question_type_id=qt,
            test_name__in=active_tests
        ).count()

        print("Filtered test count:", count)
        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        print("Error:", str(e))
        return JsonResponse({'error': str(e)}, status=500)

#__________________________________________________training schedule new_______________#



@api_view(['GET'])
def get_training_schedule_new(request):
    """
    API view to fetch training schedule data based on college name, content topic, and data_extract.
    Handles case-insensitive, punctuation-insensitive, and partial topic matching.
    """
    college_name = request.GET.get('college_name')
    topic_name = request.GET.get('topic_name')
    data_filter = request.GET.get('data_filter')

    logger.info(f"Request URL: {request.build_absolute_uri()}")

    try:
        queryset = training_schedule_temp.objects.filter(deleted=0)

        if college_name:
            queryset = queryset.filter(college_id__college__icontains=college_name)

        if data_filter:
            queryset = queryset.filter(data_extract__icontains=data_filter)

        result = []

        def normalize(text):
            text = text.lower().strip()
            text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
            text = re.sub(r'\s+', ' ', text)     # Replace multiple spaces with one
            if text.endswith('s') and not text.endswith('ss'):
                text = text[:-1]  # crude singularization
            return text

        topic_normalized = normalize(topic_name) if topic_name else None

        for schedule in queryset:
            content_topics = list(schedule.content_id.values_list('topic', flat=True))
            content_ids = list(schedule.content_id.values_list('id', flat=True))

            matched = False

            if topic_normalized:
                logger.info(f"Comparing with input topic: {topic_normalized}")

                for content_topic in content_topics:
                    content_normalized = normalize(content_topic)

                    logger.info(f" -> Comparing '{topic_normalized}' with '{content_normalized}'")

                    if topic_normalized in content_normalized or content_normalized in topic_normalized:
                        logger.info(" ---> MATCH FOUND")
                        matched = True
                        break

                if not matched:
                    logger.info(" ---> NO MATCH. Skipping this schedule.")
                    continue  # Skip if no match

            result.append({
                "college_name": schedule.college_id.college,
                "content_topics": content_topics,
                "content_ids": content_ids,
                "data_extract": schedule.data_extract,
            })

        return Response({"data": result}, status=status.HTTP_200_OK)

    except Exception as e:
        logger.error(f"Error in get_training_schedule_new: {str(e)}")
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

@api_view(['GET'])
def get_distinct_batches(request, college_id):
    # Fetch distinct batch numbers for the given college_id
    distinct_batches = candidate_master.objects.filter(college_id=college_id,deleted=0).values_list('batch_no', flat=True).distinct()
    # Format data for frontend compatibility
    response_data = [{"value": batch, "label": batch} for batch in distinct_batches if batch]
    return Response(response_data)


from .models import training_schedule_temp, training_schedule, trainer_master
from rest_framework.decorators import api_view
from rest_framework.response import Response
from rest_framework.pagination import PageNumberPagination
from django.db.models import Q

@api_view(['GET'])
def get_colleges_clg_training(request):
    try:
        search = request.query_params.get('search', '')

        # Step 1: Base query
        queryset = training_schedule_temp.objects.filter(deleted=0).select_related('college_id').order_by('-id').values(
            'id',
            'college_id__college',
            'college_id__id',
            'department_id',
            'year',
            'no_of_days',
            'topics',
            'no_of_topics',
            'location',
            'batches',
            'trainer_date',
            'no_of_batch',
            'training_name'
        )

        # Step 2: Filter if search is applied
        if search:
            queryset = queryset.filter(
                Q(college_id__college__icontains=search) |
                Q(college_id__college_group__icontains=search)
            )

        # Step 3: Pagination
        paginator = PageNumberPagination()
        paginator.page_size = 10
        paginated_queryset = paginator.paginate_queryset(queryset, request)

        # Step 4: Prepare final data
        schedule_data = []
        for item in paginated_queryset:
            training_id = item['id']

            # Get trainer names from training_schedule based on training_id
            trainer_names = list(
                trainer_master.objects.filter(
                    id__in=training_schedule.objects.filter(training_id=training_id).values_list('trainer_id', flat=True)
                ).values_list('user_name', flat=True)
            )

            schedule_data.append({
                'id': training_id,
                'college': item['college_id__college'],
                'college_id': item.get('college_id__id', ''),
                'department_id': item['department_id'],
                'year': item['year'],
                'no_of_days': item['no_of_days'],
                'topics': item['topics'],
                'no_of_topics': item['no_of_topics'],
                'location': item['location'],
                'batches': item['batches'],
                'trainer_date': item['trainer_date'],
                'no_of_batch': item['no_of_batch'],
                'training_name': item['training_name'],
                'trainers': trainer_names  # ‚úÖ Add trainer names here
            })

        return paginator.get_paginated_response(schedule_data)

    except Exception as e:
        return Response({'error': str(e)}, status=500)

@api_view(['GET'])
def get_batches_by_college_id(request, college_id):
    try:
        college = college_master.objects.get(id=college_id, deleted=0)
        return Response({
            "college": college.college,
            "batches": college.batches
        })
    except college_master.DoesNotExist:
        return Response({"error": "College not found."}, status=status.HTTP_404_NOT_FOUND)



from .forms import TrainerDateForm

@csrf_exempt
def update_trainer_date_view(request, college_id):
    print("‚ñ∂ Request received for college_id:", college_id)
    
    schedule = get_object_or_404(training_schedule_temp, college_id=college_id)
    print("‚úî Found training schedule for college_id:", college_id)

    if request.method == 'POST':
        print("üîÑ POST request received")
        print("üìù Raw POST data:", request.POST)

        form = TrainerDateForm(request.POST)
        if form.is_valid():
            print("‚úÖ Form is valid")
            trainer_date_dict = form.cleaned_data['trainer_date']
            print("üì¶ Parsed trainer_date:", trainer_date_dict)

            schedule.trainer_date = trainer_date_dict
            schedule.save()

            print("üíæ Trainer date saved successfully for college_id:", college_id)
            return HttpResponse("‚úÖ Trainer date updated successfully!")
        else:
            print("‚ùå Form is invalid")
            print("‚ö† Form errors:", form.errors)

    else:
        print("üëÄ GET request received")
        # Preload JSON for display
        existing_data = schedule.trainer_date or {}
        print("üìÑ Existing trainer_date:", existing_data)

        initial_data = {
            'trainer_date': json.dumps(existing_data, indent=2)
        }
        form = TrainerDateForm(initial=initial_data)
        print("üõ† Initialized form with existing data")

    return render(request, 'update_trainer_date.html', {
        'form': form,
        'college_id': college_id
    })



def question_category_counts(request):
    # Step 1: Filter only active, non-deleted questions
    questions = question_master.objects.filter(deleted=0)
    print("Step 1 - Total active, non-deleted questions found:", questions.count())

    if not questions.exists():
        print("No active, non-deleted questions found in question_master.")
    
    # Step 2: Join with question_paper_master using question_name_id foreign key
    data = questions.values(
        'question_name_id__test_type',
        'question_name_id__topic',
        #'question_name_id__sub_topic',
       # 'question_name_id__folder_name',
    ).annotate(
        total=Count('id')
    ).order_by(
        'question_name_id__test_type',
        'question_name_id__topic',
       # 'question_name_id__sub_topic',
        #'question_name_id__folder_name'
    )
    
    print("Step 2 - Grouped data count (with annotate):", len(data))
    if not data:
        print("No grouped data found. Possibly related question_paper_master records missing or fields are null.")

    # Step 3: Format the response
    formatted_data = []
    for item in data:
        print("Processing group:", item)
        formatted_data.append({
            "test_type": item['question_name_id__test_type'],
            "topic": item['question_name_id__topic'],
           # "sub_topic": item['question_name_id__sub_topic'],
           # "folder_name": item['question_name_id__folder_name'],
            "count": item['total']
        })

    print("Final formatted data:", formatted_data)

    return JsonResponse({"status": "success", "data": formatted_data})

from django.db.models import Count
from django.http import JsonResponse
from .models import question_master

def question_topic_counts(request):
    questions = question_master.objects.filter(deleted=0)

    data = questions.values(
        'question_name_id__topic'
    ).annotate(
        total=Count('id')
    ).order_by('question_name_id__topic')

    formatted_data = [
        {"topic": item['question_name_id__topic'], "count": item['total']}
        for item in data
    ]

    return JsonResponse({"status": "success", "data": formatted_data})

from django.db.models import Count
from django.http import JsonResponse
from .models import question_master

def question_topic_counts(request):
    questions = question_master.objects.filter(deleted=0)

    data = questions.values(
        'question_name_id__topic'
    ).annotate(
        total=Count('id')
    ).order_by('question_name_id__topic')

    formatted_data = [
        {"topic": item['question_name_id__topic'], "count": item['total']}
        for item in data
    ]

    return JsonResponse({"status": "success", "data": formatted_data})

def question_subtopic_counts(request):
    questions = question_master.objects.filter(deleted=0)

    data = questions.values(
        'question_name_id__sub_topic'
    ).annotate(
        total=Count('id')
    ).order_by('question_name_id__sub_topic')

    formatted_data = [
        {"sub_topic": item['question_name_id__sub_topic'], "count": item['total']}
        for item in data
    ]

    return JsonResponse({"status": "success", "data": formatted_data})

def question_folder_counts(request):
    questions = question_master.objects.filter(deleted=0)

    data = questions.values(
        'question_name_id__folder_name'
    ).annotate(
        total=Count('id')
    ).order_by('question_name_id__folder_name')

    formatted_data = [
        {"folder_name": item['question_name_id__folder_name'], "count": item['total']}
        for item in data
    ]

    return JsonResponse({"status": "success", "data": formatted_data})

def question_testtype_counts(request):
    questions = question_master.objects.filter(deleted=0)

    data = questions.values(
        'question_name_id__test_type'
    ).annotate(
        total=Count('id')
    ).order_by('question_name_id__test_type')

    formatted_data = [
        {"test_type": item['question_name_id__test_type'], "count": item['total']}
        for item in data
    ]

    return JsonResponse({"status": "success", "data": formatted_data})




@api_view(['GET'])
def get_filtered_trainers(request):
    question_type_id = request.query_params.get('question_type_id')
    skill_type_id = request.query_params.get('skill_type')  # pass skill_type id here

    trainers = trainer_master.objects.filter(deleted=0)

    if question_type_id or skill_type_id:
        if question_type_id and skill_type_id:
            skills = skill_type.objects.filter(id=skill_type_id, question_type_id=question_type_id, deleted=0)
        elif question_type_id:
            skills = skill_type.objects.filter(question_type_id=question_type_id, deleted=0)
        else:  # only skill_type
            skills = skill_type.objects.filter(id=skill_type_id, deleted=0)

        trainers = trainers.filter(skill_id__in=skills).distinct()

    usernames = list(trainers.values_list('user_name', flat=True))
    return Response({"trainer_usernames": usernames})




@api_view(['GET'])
def assign_topics_to_trainescorrect(request):
    import json, re
    from datetime import datetime, timedelta

    try:
        training_id = request.query_params.get('training_id')
        if not training_id:
            return Response({"error": "training_id is required"}, status=400)

        ts = training_schedule_temp.objects.filter(id=training_id).first()
        if not ts:
            return Response({"error": "Training schedule not found"}, status=404)

        college = ts.college_id
        batches = [str(b).strip() for b in (ts.batches or []) if str(b).strip()]
        trainer_dates = ts.trainer_date or {}
        if isinstance(trainer_dates, str):
            trainer_dates = json.loads(trainer_dates)

        batch_skill_map = ts.batch_skill or {}
        if isinstance(batch_skill_map, str):
            batch_skill_map = json.loads(batch_skill_map)

        raw_topics = ts.topics or []
        sorted_date_keys = sorted(trainer_dates.keys())
        sorted_sessions = ["FN", "AN"]

        # --- helpers ---
        def clean_topic(text):
            text = (text or "").lower()
            text = re.sub(r'[&.,]', ' ', text)
            text = re.sub(r'\s+', ' ', text).strip()
            return text

        # flatten topics (as strings to validate existence)
        flat_topics = []
        for entry in raw_topics:
            flat_topics.extend([clean_topic(p) for p in entry.split(',') if p.strip()])

        all_content = content_master.objects.filter(deleted=0)
        all_content_map = {clean_topic(c.topic or ""): c for c in all_content}

        # missing topics check
        missing = [t for t in flat_topics if t not in all_content_map]
        if missing:
            missing_detail = {}
            for raw_entry in raw_topics:
                for part in raw_entry.split(','):
                    cleaned = clean_topic(part)
                    if cleaned in missing:
                        missing_detail.setdefault(cleaned, []).append(part.strip())
            missing_list = []
            for k, v in missing_detail.items():
                missing_list.extend(v)
            return Response({
                "error": f"Missing topics in content_master: {', '.join(set(missing_list))}",
                "missing_topics": list(set(missing_list))
            }, status=400)

        # Build topics_by_skill: skill_id -> list(content_master objects)
        topics_by_skill = {}
        for c in all_content:
            c_topic = clean_topic(c.topic or "")
            if c_topic in flat_topics:
                sid = getattr(c, "skill_type_id_id", None) or getattr(c, "skill_type_id", None)
                if sid is None:
                    continue
                topics_by_skill.setdefault(int(sid), []).append(c)

        # Trainers (ignore skills for assignment)
        trainer_ids = ts.trainer_ids
        if isinstance(trainer_ids, str):
            trainer_ids = json.loads(trainer_ids)
        trainers = list(trainer_master.objects.filter(id__in=trainer_ids or []))
        if not trainers:
            return Response({"error": "No valid trainers found."}, status=400)

        # Must have at least one trainer per batch to avoid double-booking in a session
        if len(trainers) < len(batches):
            return Response({
                "error": "Insufficient trainers to cover all batches without double-booking in a session.",
                "batches": len(batches),
                "available_trainers": len(trainers)
            }, status=400)

        assigned_data = []

        def assign_topic(date_obj, session, batch, trainer, topic):
            dtm_start_trainer = date_obj - timedelta(days=3)
            dtm_end_trainer = date_obj
            dtm_start_student = date_obj
            dtm_end_student = date_obj + timedelta(days=365)

            student_ids = list(candidate_master.objects.filter(
                college_id=college.id if hasattr(college, 'id') else college,
                batch_no=str(batch).strip()
            ).values_list('id', flat=True))

            training_schedule.objects.create(
                training_id=ts,
                college_id=college,
                batch_no=batch,
                topic_id=topic,
                skill_type_id=topic.skill_type_id,
                question_type_id=topic.question_type_id,
                trainer_id=trainer,
                dtm_of_training=date_obj,
                dtm_start_trainer=dtm_start_trainer,
                dtm_end_trainer=dtm_end_trainer,
                dtm_start_student=dtm_start_student,
                dtm_end_student=dtm_end_student,
                student_ids=student_ids,
                session=session
            )

            assigned_data.append({
                "date": date_obj.strftime('%Y-%m-%d'),
                "session": session,
                "batch": batch,
                "trainer": trainer.trainer_name,
                "topic": topic.topic,
                "student_count": len(student_ids)
            })

        # Build skill_topic_queues for rotation (list copy so we can index by position)
        skill_topic_queues = {}
        for sid, tlist in topics_by_skill.items():
            skill_topic_queues[int(sid)] = list(tlist)

        # indices to rotate within each skill
        skill_topic_index = {sid: 0 for sid in skill_topic_queues}

        # Track assigned topics:
        # - per batch globally (so a batch doesn't repeat a topic)
        assigned_topic_ids_per_batch = {batch: set() for batch in batches}

        # - per (date, session) globally (so same topic not used for multiple batches in same date+session)
        used_topic_in_session = {}  # key = (date_str, session) -> set(topic_id)

        # Helper to get next topic for a skill that is not already assigned to this batch or used in this date+session
        def get_next_topic_for_skill(skill_id, date_key, batch):
            """
            Returns a content_master object or None
            """
            queue = skill_topic_queues.get(skill_id, [])
            if not queue:
                return None

            start_idx = skill_topic_index.get(skill_id, 0)
            n = len(queue)
            tried = 0
            while tried < n:
                idx = (start_idx + tried) % n
                candidate = queue[idx]
                cand_id = candidate.id

                # Skip if already assigned to this batch globally
                if cand_id in assigned_topic_ids_per_batch.get(batch, set()):
                    tried += 1
                    continue

                # Skip if used in same date+session across other batches
                used_set = used_topic_in_session.get(date_key, set())
                if cand_id in used_set:
                    tried += 1
                    continue

                # Found valid candidate
                skill_topic_index[skill_id] = (idx + 1) % n  # advance pointer for next rotation
                return candidate

            return None

        # Now iterate dates -> sessions -> batches and pick topics/trainer
        progress = True
        while progress:
            progress = False

            for day_index, day_key in enumerate(sorted_date_keys):
                date_val = trainer_dates[day_key]
                date_obj = datetime.strptime(date_val, "%Y-%m-%d").date()
                date_key_str = date_obj.strftime("%Y-%m-%d")

                for session_index, session in enumerate(sorted_sessions):
                    date_session_key = (date_key_str, session)
                    used_topic_in_session.setdefault(date_session_key, set())

                    for batch_index, batch in enumerate(batches):
                        # Determine the skill(s) for this batch
                        raw_batch_skills = batch_skill_map.get(batch, [])
                        batch_skills = [s["skill_type_id"] if isinstance(s, dict) else s for s in raw_batch_skills]
                        if not batch_skills:
                            continue

                        # Find a skill from which we can get a topic.
                        chosen_topic = None
                        for skill_id_raw in batch_skills:
                            try:
                                skill_id = int(skill_id_raw)
                            except Exception:
                                continue
                            candidate_topic = get_next_topic_for_skill(skill_id, date_session_key, batch)
                            if candidate_topic:
                                chosen_topic = candidate_topic
                                break

                        if not chosen_topic:
                            continue
                        # -------------------------
                        # Trainer selection logic
                        # -------------------------
                        if chosen_topic.question_type_id and chosen_topic.question_type_id.question_type.lower() == "technical":
                            # ‚úÖ Technical ‚Üí trainer must match the skill_type
                            eligible_trainers = [
                                t for t in trainers
                                if t.skill_id.filter(id=chosen_topic.skill_type_id.id).exists()
                            ]
                            if not eligible_trainers:
                                # Skip if no trainer available for this skill
                                continue
                            trainer_idx = (batch_index + day_index + session_index) % len(eligible_trainers)
                            trainer = eligible_trainers[trainer_idx]
                        else:
                            # ‚úÖ Non-technical ‚Üí round robin among all trainers
                            trainer_idx = (batch_index + day_index + session_index) % len(trainers)
                            trainer = trainers[trainer_idx]

                        # Assign topic & trainer
                        assign_topic(date_obj, session, batch, trainer, chosen_topic)

                        # Mark progress & record usage
                        progress = True
                        assigned_topic_ids_per_batch.setdefault(batch, set()).add(chosen_topic.id)
                        used_topic_in_session[date_session_key].add(chosen_topic.id)

        return Response({
            "message": "Trainer & topic assignments created/updated. Topics rotated by skill; trainers rotated ignoring skills.",
            "table": assigned_data
        })

    except Exception as e:
        return Response({"error": str(e)}, status=500)


@api_view(['GET'])
def assign_topics_to_trainers(request):
    import json, re
    from datetime import datetime, timedelta

    try:
        training_id = request.query_params.get('training_id')
        if not training_id:
            return Response({"error": "training_id is required"}, status=400)

        ts = training_schedule_temp.objects.filter(id=training_id).first()
        if not ts:
            return Response({"error": "Training schedule not found"}, status=404)

        college = ts.college_id
        batches = [str(b).strip() for b in (ts.batches or []) if str(b).strip()]
        trainer_dates = ts.trainer_date or {}
        if isinstance(trainer_dates, str):
            trainer_dates = json.loads(trainer_dates)

        batch_skill_map = ts.batch_skill or {}
        if isinstance(batch_skill_map, str):
            batch_skill_map = json.loads(batch_skill_map)

        raw_topics = ts.topics or []
        sorted_date_keys = sorted(trainer_dates.keys())
        sorted_sessions = ["FN", "AN"]

        # --- helpers ---
        def clean_topic(text):
            text = (text or "").lower()
            text = re.sub(r'[&.,]', ' ', text)
            text = re.sub(r'\s+', ' ', text).strip()
            return text

        # flatten topics (as strings to validate existence)
        flat_topics = []
        for entry in raw_topics:
            flat_topics.extend([clean_topic(p) for p in entry.split(',') if p.strip()])

        all_content = content_master.objects.filter(deleted=0)
        all_content_map = {clean_topic(c.topic or ""): c for c in all_content}

        # missing topics check
        missing = [t for t in flat_topics if t not in all_content_map]
        if missing:
            missing_detail = {}
            for raw_entry in raw_topics:
                for part in raw_entry.split(','):
                    cleaned = clean_topic(part)
                    if cleaned in missing:
                        missing_detail.setdefault(cleaned, []).append(part.strip())
            missing_list = []
            for k, v in missing_detail.items():
                missing_list.extend(v)
            return Response({
                "error": f"Missing topics in content_master: {', '.join(set(missing_list))}",
                "missing_topics": list(set(missing_list))
            }, status=400)

        # Build topics_by_skill: skill_id -> list(content_master objects)
        topics_by_skill = {}
        for c in all_content:
            c_topic = clean_topic(c.topic or "")
            if c_topic in flat_topics:
                sid = getattr(c, "skill_type_id_id", None) or getattr(c, "skill_type_id", None)
                if sid is None:
                    continue
                topics_by_skill.setdefault(int(sid), []).append(c)

        # Trainers (ignore skills for assignment)
        trainer_ids = ts.trainer_ids
        if isinstance(trainer_ids, str):
            trainer_ids = json.loads(trainer_ids)
        trainers = list(trainer_master.objects.filter(id__in=trainer_ids or []))
        if not trainers:
            return Response({"error": "No valid trainers found."}, status=400)

        # Must have at least one trainer per batch to avoid double-booking in a session
        if len(trainers) < len(batches):
            return Response({
                "error": "Insufficient trainers to cover all batches without double-booking in a session.",
                "batches": len(batches),
                "available_trainers": len(trainers)
            }, status=400)

        assigned_data = []

        def assign_topic(date_obj, session, batch, trainer, topic):
            dtm_start_trainer = date_obj - timedelta(days=3)
            dtm_end_trainer = date_obj
            dtm_start_student = date_obj
            dtm_end_student = date_obj + timedelta(days=365)

            student_ids = list(candidate_master.objects.filter(
                college_id=college.id if hasattr(college, 'id') else college,
                batch_no=str(batch).strip()
            ).values_list('id', flat=True))

            training_schedule.objects.create(
                training_id=ts,
                college_id=college,
                batch_no=batch,
                topic_id=topic,
                skill_type_id=topic.skill_type_id,
                question_type_id=topic.question_type_id,
                trainer_id=trainer,
                dtm_of_training=date_obj,
                dtm_start_trainer=dtm_start_trainer,
                dtm_end_trainer=dtm_end_trainer,
                dtm_start_student=dtm_start_student,
                dtm_end_student=dtm_end_student,
                student_ids=student_ids,
                session=session
            )

            assigned_data.append({
                "date": date_obj.strftime('%Y-%m-%d'),
                "session": session,
                "batch": batch,
                "trainer": trainer.trainer_name,
                "topic": topic.topic,
                "student_count": len(student_ids)
            })

        # Build skill_topic_queues for rotation (list copy so we can index by position)
        skill_topic_queues = {}
        for sid, tlist in topics_by_skill.items():
            skill_topic_queues[int(sid)] = list(tlist)

        # indices to rotate within each skill
        skill_topic_index = {sid: 0 for sid in skill_topic_queues}

        # Track assigned topics:
        # - per batch globally (so a batch doesn't repeat a topic)
        assigned_topic_ids_per_batch = {batch: set() for batch in batches}

        # - per (date, session) globally (so same topic not used for multiple batches in same date+session)
        used_topic_in_session = {}  # key = (date_str, session) -> set(topic_id)

        # Helper to get next topic for a skill that is not already assigned to this batch or used in this date+session
        def get_next_topic_for_skill(skill_id, date_key, batch):
            """
            Returns a content_master object or None
            """
            queue = skill_topic_queues.get(skill_id, [])
            if not queue:
                return None

            start_idx = skill_topic_index.get(skill_id, 0)
            n = len(queue)
            tried = 0
            while tried < n:
                idx = (start_idx + tried) % n
                candidate = queue[idx]
                cand_id = candidate.id

                # Skip if already assigned to this batch globally
                if cand_id in assigned_topic_ids_per_batch.get(batch, set()):
                    tried += 1
                    continue

                # Skip if used in same date+session across other batches
                used_set = used_topic_in_session.get(date_key, set())
                if cand_id in used_set:
                    tried += 1
                    continue

                # Found valid candidate
                skill_topic_index[skill_id] = (idx + 1) % n  # advance pointer for next rotation
                return candidate

            return None

        # Now iterate dates -> sessions -> batches and pick topics/trainer
        progress = True
        while progress:
            progress = False

            for day_index, day_key in enumerate(sorted_date_keys):
                date_val = trainer_dates[day_key]
                date_obj = datetime.strptime(date_val, "%Y-%m-%d").date()
                date_key_str = date_obj.strftime("%Y-%m-%d")

                for session_index, session in enumerate(sorted_sessions):
                    date_session_key = (date_key_str, session)
                    used_topic_in_session.setdefault(date_session_key, set())

                    for batch_index, batch in enumerate(batches):
                        # Determine the skill(s) for this batch
                        raw_batch_skills = batch_skill_map.get(batch, [])
                        batch_skills = [s["skill_type_id"] if isinstance(s, dict) else s for s in raw_batch_skills]
                        if not batch_skills:
                            continue

                        # Find a skill from which we can get a topic.
                        chosen_topic = None
                        for skill_id_raw in batch_skills:
                            try:
                                skill_id = int(skill_id_raw)
                            except Exception:
                                continue
                            candidate_topic = get_next_topic_for_skill(skill_id, date_session_key, batch)
                            if candidate_topic:
                                chosen_topic = candidate_topic
                                break

                        if not chosen_topic:
                            continue
                        # -------------------------
                        # Trainer selection logic
                        # -------------------------
                        qtype = chosen_topic.question_type_id.question_type.lower() if chosen_topic.question_type_id else ""

                        if qtype == "technical":
                            # ‚úÖ Technical ‚Üí trainer must match the *exact* skill_type
                            eligible_trainers = [
                                t for t in trainers
                                if t.skill_id.filter(id=chosen_topic.skill_type_id.id).exists()
                            ]

                        elif qtype == "aptitude":
                            # ‚úÖ Aptitude ‚Üí trainer must be mapped to ANY aptitude skill_type
                            eligible_trainers = [
                                t for t in trainers
                                if t.skill_id.filter(
                                    question_type_id__question_type__iexact="aptitude"
                                ).exists()
                            ]

                        else:
                            # Fallback ‚Üí allow all trainers
                            eligible_trainers = trainers

                        # Skip if no trainers found
                        if not eligible_trainers:
                            continue

                        # Rotate trainers so that all are used fairly
                        trainer_idx = (batch_index + day_index + session_index) % len(eligible_trainers)
                        trainer = eligible_trainers[trainer_idx]

                        # Assign topic & trainer
                        assign_topic(date_obj, session, batch, trainer, chosen_topic)

                        # Mark progress & record usage
                        progress = True
                        assigned_topic_ids_per_batch.setdefault(batch, set()).add(chosen_topic.id)
                        used_topic_in_session[date_session_key].add(chosen_topic.id)

        return Response({
            "message": "Trainer & topic assignments created/updated. Topics rotated by skill; trainers rotated ignoring skills.",
            "table": assigned_data
        })

    except Exception as e:
        return Response({"error": str(e)}, status=500)

import inflect

p = inflect.engine()

import re

def normalize_topic(text: str) -> str:
    """Normalize topic names for loose comparison (hyphens, spaces, etc. but keep singular/plural same)."""
    if not text:
        return ""

    text = text.lower().strip()

    # Replace special chars with spaces
    text = text.replace("&", " and ").replace("+", " and ")
    text = re.sub(r"[-_/]", " ", text)        # replace hyphen, underscore, slash with space
    text = re.sub(r"[.,]", " ", text)         # remove dots and commas
    text = re.sub(r"\s+", " ", text).strip()  # collapse multiple spaces

    return text


def topics_match(t1: str, t2: str) -> bool:
    """Return True if topics are equivalent under loose normalization."""
    n1 = normalize_topic(t1)
    n2 = normalize_topic(t2)

    # Debug print to see normalization effect
    print(f"üîé Comparing raw=({t1}) vs ({t2}) ‚Üí normalized=({n1}) vs ({n2})")

    # Direct match
    if n1 == n2:
        return True

    # One contained in another
    if n1 in n2 or n2 in n1:
        return True

    return False

@api_view(['GET'])
def schedule_tests_for_students(request):
    try:
        print("\nüì• schedule_tests_for_students API triggered")

        # --- Extract request params ---
        training_id = request.query_params.get('training_id')
        start_time_str = request.query_params.get('start_time')
        end_time_str = request.query_params.get('end_time')
        schedule_day_option = request.query_params.get('schedule_day_option', 'on_day')

        raw_test_type_ids = (
            request.query_params.getlist("test_type_id")
            or request.query_params.get("test_type_id")
        )

        # --- Normalize test_type_ids ---
        if isinstance(raw_test_type_ids, list):
            test_type_ids = []
            for item in raw_test_type_ids:
                if isinstance(item, str):
                    test_type_ids.extend([int(x) for x in item.split(",") if x.strip().isdigit()])
                elif isinstance(item, int):
                    test_type_ids.append(item)
        elif isinstance(raw_test_type_ids, str):
            test_type_ids = [int(x) for x in raw_test_type_ids.split(",") if x.strip().isdigit()]
        else:
            test_type_ids = []

        if not test_type_ids:
            return Response({"error": "At least one test_type_id is required"}, status=400)

        # --- Fetch test_type objects ---
        test_types = list(test_type.objects.filter(id__in=test_type_ids))
        if not test_types:
            return Response({"error": f"No test_type found for IDs {test_type_ids}"}, status=404)

        # --- Validate training_id ---
        if not training_id:
            return Response({"error": "training_id is required"}, status=400)

        # --- Validate times ---
        if not start_time_str or not end_time_str:
            return Response({"error": "start_time and end_time are required"}, status=400)

        try:
            start_time = datetime.strptime(start_time_str.strip(), "%I:%M %p").time() if "AM" in start_time_str.upper() or "PM" in start_time_str.upper() else datetime.strptime(start_time_str.strip(), "%H:%M").time()
            end_time = datetime.strptime(end_time_str.strip(), "%I:%M %p").time() if "AM" in end_time_str.upper() or "PM" in end_time_str.upper() else datetime.strptime(end_time_str.strip(), "%H:%M").time()
        except ValueError:
            return Response({"error": "Invalid time format. Use HH:MM (24-hour) or HH:MM AM/PM."}, status=400)

        # --- Schedule offset ---
        schedule_offsets = {"on_day": 0, "next_day": 1, "two_days_later": 2}
        if schedule_day_option not in schedule_offsets:
            return Response({"error": "Invalid schedule_day_option"}, status=400)

        schedule_offset = schedule_offsets[schedule_day_option]

        # --- Fetch training template ---
        training_temp = training_schedule_temp.objects.filter(id=training_id).first()
        if not training_temp:
            return Response({"error": "Training schedule not found"}, status=404)

        college = training_temp.college_id
        batches = training_temp.batches or []
        year = training_temp.year

        difficulty_map = {1: "Easy", 2: "Intermediate", 3: "Difficulty", 4: "Challenging"}
        difficulty_level = difficulty_map.get(year, "Easy")

        # --- Fetch training schedule entries ---
        training_entries = training_schedule.objects.filter(
            training_id=training_id,
            college_id=college,
            batch_no__in=batches,
            topic_id__isnull=False,
            deleted=0
        ).select_related('topic_id')

        student_topic_batch_map = defaultdict(lambda: defaultdict(lambda: {"date": None, "students": set()}))
        for entry in training_entries:
            topic_obj = entry.topic_id
            if not topic_obj or not topic_obj.topic:
                continue

            topic_clean = normalize_topic(topic_obj.topic.strip())
            batch = entry.batch_no
            date = entry.dtm_of_training
            student_ids = list(candidate_master.objects.filter(batch_no=batch, college_id=college, deleted=0).values_list('id', flat=True))
            if not student_ids:
                continue

            if (student_topic_batch_map[topic_clean][batch]["date"] is None or
                date < student_topic_batch_map[topic_clean][batch]["date"]):
                student_topic_batch_map[topic_clean][batch]["date"] = date
            student_topic_batch_map[topic_clean][batch]["students"].update(student_ids)

        created_count, skipped_count = 0, 0
        missing_topics = []

        for t_obj in test_types:
            test_type_str = t_obj.test_type.strip().lower()

            if test_type_str == "mcq test":
                no_of_question = 25
                duration_of_test = 30

                # --- Only Aptitude topics ---
                aptitude_entries = training_schedule.objects.filter(
                    training_id=training_id,
                    college_id=college,
                    question_type_id__question_type__iexact="Aptitude",
                    deleted=0
                )

                all_qpapers = question_paper_master.objects.filter(
                    deleted=0,
                    topic__iexact="Aptitude"
                )

            elif test_type_str == "coding test":
                no_of_question = 2
                duration_of_test = 40
                is_testcase = request.query_params.get("is_testcase", "no").lower() in ["yes", "true", "1"]

                # --- Only Technical topics ---
                aptitude_entries = training_schedule.objects.filter(
                    training_id=training_id,
                    college_id=college,
                    question_type_id__question_type__iexact="Technical",
                    deleted=0
                )

                all_qpapers = question_paper_master.objects.filter(
                    deleted=0,
                    topic__iexact="Technical",
                    is_testcase=is_testcase
                )

            else:
                continue

            missing_topics = set()   # ‚úÖ use a set to avoid duplicates
            insufficient_questions = []
            topic_question_map = {}

            for entry in aptitude_entries:
                topic_clean = normalize_topic(entry.topic_id.topic)
                print(f"üîç Checking topic: {topic_clean}")

                qp = None
                for qp_obj in all_qpapers:
                    if topics_match(topic_clean, qp_obj.folder_name):
                        qp = qp_obj
                        break

                if not qp:
                    print(f"‚ö†Ô∏è Missing question paper for topic: {topic_clean}")
                    missing_topics.add(topic_clean)
                    continue

                q_ids = list(question_master.objects.filter(
                    question_name_id=qp.id, deleted=0
                ).values_list('id', flat=True))

                print(f"üìå Topic: {topic_clean}, Found QP: {qp.folder_name}, "
                    f"Questions available: {len(q_ids)}")

                if test_type_str == "coding test":
                    if len(q_ids) >= no_of_question:
                        topic_question_map[topic_clean] = {
                            "question_paper": qp,
                            "question_ids": random.sample(q_ids, no_of_question)
                        }
                    else:
                        print(f"‚ùå Insufficient questions for {topic_clean}: "
                            f"{len(q_ids)} available, {no_of_question} required")
                        insufficient_questions.append({
                            "topic": topic_clean,
                            "available_questions": len(q_ids),
                            "required_questions": no_of_question,
                            "question_paper": qp.question_paper_name
                        })
                else:  # mcq
                    topic_question_map[topic_clean] = {
                        "question_paper": qp,
                        "question_ids": random.sample(q_ids, min(len(q_ids), no_of_question))
                    }

            # --- Errors ---
            if test_type_str == "coding test" and insufficient_questions:
                print("üö® Insufficient Questions Summary:", insufficient_questions)
                return Response({
                    "error": "Some coding topics have insufficient questions",
                    "insufficient_questions": insufficient_questions
                }, status=400)

            if missing_topics:
                print("üö® Missing Topics Summary:", list(missing_topics))
                return Response({
                    "error": "Some topics are missing question papers",
                    "missing_topics": list(missing_topics)   # ‚úÖ convert set back to list
                }, status=400)

            # --- Continue with creating tests using topic_question_map ---

            rule = rules.objects.filter(rule_name__iexact=t_obj.test_type).first()

            # --- Create tests ---
            for topic_clean, batches_data in student_topic_batch_map.items():
                data_obj = topic_question_map.get(topic_clean)
                if not data_obj:
                    continue

                qp_obj = data_obj["question_paper"]
                q_ids = data_obj["question_ids"]

                for batch, data in batches_data.items():
                    test_date = data["date"] + timedelta(days=schedule_offset)
                    dtm_start = datetime.combine(test_date, start_time)
                    dtm_end = datetime.combine(test_date, end_time)
                    ts_entry = training_schedule.objects.filter(
                        training_id=training_id,
                        college_id=college,
                        batch_no=batch,
                        topic_id__topic__iexact=topic_clean,
                        deleted=0
                    ).first()
                    if not ts_entry:
                        continue
                    q_type_obj = ts_entry.question_type_id
                    skill_type_obj = ts_entry.skill_type_id  
                    students = candidate_master.objects.filter(id__in=data["students"], deleted=0)
                    for student in students:
                        test_name = f"{college.college_code}_{student.year}Yr_{topic_clean}_{test_date.strftime('%d%m%Y')}_{test_type_str}"
                        if tests_candidates_map.objects.filter(test_name=test_name, student_id=student, question_id=qp_obj, deleted=0).exists():
                            skipped_count += 1
                            continue

                        # --- Save in tests_candidates_map ---
                        tests_candidates_map.objects.create(
                            test_name=test_name,
                            student_id=student,
                            college_id=college,
                            department_id=student.department_id,
                            year=student.year,
                            dtm_start=dtm_start,
                            dtm_end=dtm_end,
                            dtm_start1=dtm_start,
                            dtm_end1=dtm_end,
                            dtm_created=now(),
                            rules_id=rule,
                            is_active=False,
                            need_candidate_info=True,
                            duration_type="QuestionTime",
                            duration=duration_of_test,
                            question_ids=q_ids,
                            no_of_question=no_of_question,
                        )
                        created_count += 1

                        # --- Save in test_master ---
                        test_master.objects.update_or_create(
                            test_name=test_name,
                            defaults={
                                "test_type_id": t_obj,
                                "question_type_id": q_type_obj,
                                "skill_type_id": skill_type_obj
                            }
                        )

        return Response({"message": f"‚úÖ Tests scheduled. Created: {created_count}, Skipped: {skipped_count}"}, status=200)

    except Exception as e:
        traceback.print_exc()
        return Response({"error": str(e)}, status=500)


class UpdateTrainingScheduleFields(APIView):
    def put(self, request, id):
        try:
            training_schedule = get_object_or_404(training_schedule_temp, id=id)
            data = request.data

            print("üîÅ Update Request Data:", data)

            # ‚úÖ Batches
            if 'batches' in data:
                raw_batches = json.loads(data['batches']) if isinstance(data['batches'], str) else data['batches']
                training_schedule.batches = raw_batches
                print("‚úÖ batches updated:", raw_batches)

            # ‚úÖ Department IDs
            if 'department_id' in data:
                department_ids = data['department_id']
                # Save as comma-separated string
                if isinstance(department_ids, list):
                    training_schedule.department_id = ",".join(map(str, department_ids))
                    print("‚úÖ department_id updated:", training_schedule.department_id)

            # ‚úÖ Trainer IDs
            if 'trainer_ids' in data:
                trainer_ids = json.loads(data['trainer_ids']) if isinstance(data['trainer_ids'], str) else data['trainer_ids']
                if isinstance(trainer_ids, list):
                    training_schedule.trainer_ids = ",".join(map(str, trainer_ids))
                    training_schedule.trainer_ids = json.dumps(trainer_ids)

                    print("‚úÖ trainer_ids stored as CSV string:", training_schedule.trainer_ids)

            # ‚úÖ Trainer Names
            if 'trainers' in data:
                trainer_names = json.loads(data['trainers']) if isinstance(data['trainers'], str) else data['trainers']
                training_schedule.trainers = trainer_names
                print("‚úÖ trainers list stored:", trainer_names)

            training_schedule.save()

            return Response({"message": "‚úÖ Training schedule fields updated successfully"}, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"‚ùå Exception during update: {str(e)}")
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


from .serializers import TrainerCreateSerializer,TrainerCreateSerializerNew

@api_view(['POST'])
def add_trainer_login(request):
    serializer = TrainerCreateSerializer(data=request.data)
    if serializer.is_valid():
        serializer.save()
        return Response({"message": "Trainer and login created successfully"}, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
def add_trainer_login_new(request):
    print(request.data)
    serializer = TrainerCreateSerializerNew(data=request.data)
    if serializer.is_valid():
        serializer.save()
        print(traceback.format_exc())
        return Response({"message": "Trainer and login created/updated successfully"}, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

@api_view(['GET'])
def get_trainers_by_skill(request):
    skill_type_ids = request.GET.get('skill_type', None)

    if skill_type_ids:
        try:
            skill_id_list = [int(sid) for sid in skill_type_ids.split(',') if sid.strip().isdigit()]
            print("üëâ Filter by skill IDs:", skill_id_list)

            trainers = trainer_master.objects.filter(skill_id__id__in=skill_id_list,deleted=0).distinct()

            print("‚úÖ Matched trainers:")
            for t in trainers:
                print(f"- {t.user_name} | Skills: {[s.id for s in t.skill_id.all()]}")
        except ValueError:
            return Response({"error": "Invalid skill_type format"}, status=400)
    else:
        trainers = trainer_master.objects.filter(deleted=0)

    trainer_list = [
        {
            "id": trainer.id,  # ‚úÖ Include trainer_id
            "user_name": trainer.user_name,
            "trainer_name": trainer.trainer_name,
            "skill_type": [skill.skill_type for skill in trainer.skill_id.filter(deleted=0)]
        }
        for trainer in trainers
    ]

    return Response(trainer_list)

@api_view(['POST'])
def update_batch_for_students(request):
    batch_no = request.data.get('batch_no')
    college_id = request.data.get('college_id')
    department_id = request.data.get('department_id')
    reg_start = request.data.get('reg_start')
    reg_end = request.data.get('reg_end')

    print("üì• Received Data:")
    print("batch_no:", batch_no)
    print("college_id:", college_id)
    print("department_id:", department_id)
    print("reg_start:", reg_start)
    print("reg_end:", reg_end)

    if not batch_no or not college_id:
        return Response({"error": "batch_no and college_id are required"}, status=400)

    candidates = None

    if department_id:
        candidates = candidate_master.objects.filter(
            college_id=college_id,
            department_id=department_id,deleted=0
        )
        print(f"üîç Found {candidates.count()} candidates for department_id={department_id}")

    elif reg_start and reg_end:
        # Extract numbers from reg_start and reg_end
        start_match = re.search(r'(\d+)', reg_start)
        end_match = re.search(r'(\d+)', reg_end)

        if not start_match or not end_match:
            return Response({"error": "Invalid registration number format."}, status=400)

        start_num = int(start_match.group())
        end_num = int(end_match.group())

        # Optional prefix handling (if any)
        prefix_match = re.match(r'[^\d]+', reg_start)
        prefix = prefix_match.group() if prefix_match else ''

        print(f"üîç Filtering with prefix: '{prefix}', start_num: {start_num}, end_num: {end_num}")

        # Filter candidates starting with prefix (if present)
        candidates_qs = candidate_master.objects.filter(college_id=college_id,deleted=0)
        if prefix:
            candidates_qs = candidates_qs.filter(registration_number__startswith=prefix)

        # Now filter by numeric range
        candidates = [
            c for c in candidates_qs
            if re.search(r'\d+', c.registration_number)
            and start_num <= int(re.search(r'\d+', c.registration_number).group()) <= end_num
        ]

        print(f"üîç Found {len(candidates)} candidates between reg no {reg_start} - {reg_end}")

    else:
        return Response({"error": "Provide either department_id or reg_start and reg_end"}, status=400)

    if not candidates:
        print("‚ö†Ô∏è No candidates matched the filter conditions.")
        return Response({"message": "No candidates found for the given filters."}, status=404)

    # Bulk update
    updated_count = 0
    if isinstance(candidates, list):
        for c in candidates:
            c.batch_no = batch_no
            c.save()
            updated_count += 1
    else:
        updated_count = candidates.update(batch_no=batch_no)

    print(f"‚úÖ Updated batch_no to '{batch_no}' for {updated_count} students.")

    return Response({
        "message": f"Batch number '{batch_no}' updated for {updated_count} students."
    }, status=200)


@api_view(['GET'])
def get_registration_number_range(request):
    college_id = request.GET.get('college_id')

    if not college_id:
        return Response({"error": "college_id is required"}, status=400)

    students = candidate_master.objects.filter(
        college_id=college_id,deleted=0
    ).exclude(
        registration_number__isnull=True
    ).exclude(
        registration_number=''
    )

    if not students.exists():
        return Response({"message": "No students found for the given college_id"}, status=404)

    # Extract numeric part and sort based on it
    def extract_number(reg):
        match = re.search(r'(\d+)$', reg)
        return int(match.group()) if match else -1

    reg_numbers = list(students.values_list('registration_number', flat=True))
    reg_numbers = sorted(reg_numbers, key=extract_number)

    return Response({
        "college_id": college_id,
        "min_registration_number": reg_numbers[0],
        "max_registration_number": reg_numbers[-1]
    })

@api_view(['GET'])
def get_departments_by_batch_and_college(request):
    batch_no_param = request.GET.get('batch_no')  # This will be a CSV string
    college_id = request.GET.get('college_id')

    if not batch_no_param or not college_id:
        return Response({"error": "batch_no and college_id are required"}, status=400)

    # Split the CSV string into a list of batch numbers
    batch_nos = batch_no_param.split(',')

    print("üì• Received batch_nos:", batch_nos)

    department_ids = candidate_master.objects.filter(
        batch_no__in=batch_nos,
        college_id=college_id,
        deleted=0
    ).values_list('department_id', flat=True).distinct()

    departments = department_master.objects.filter(
        id__in=department_ids,
        deleted=0
    ).values('id', 'department')

    print("‚úÖ Departments found:", list(departments))

    return Response({"departments": list(departments)})

@api_view(['GET'])
def get_skill_types_by_question_type(request):
    question_type_id = request.GET.get('question_type_id')

    if not question_type_id:
        return Response({"error": "question_type_id parameter is required"}, status=400)

    try:
        question_type_obj = question_type.objects.filter(id=question_type_id, deleted=0).first()
        if not question_type_obj:
            return Response({"error": "Invalid question_type_id"}, status=404)

        allowed_question_types = ["Aptitude", "Technical", "Softskills"]
        if question_type_obj.question_type not in allowed_question_types:
            return Response([])  # Return empty if not allowed

        # Filter for Aptitude-specific skill types
        if question_type_obj.question_type == "Aptitude":
            allowed_skills = ["Quants", "Logical", "Verbal"]
            skills = skill_type.objects.filter(
                question_type_id=question_type_id,
                skill_type__in=allowed_skills,
                deleted=0
            )
        else:
            # For Technical and Softskills, return all skill types under that question_type
            skills = skill_type.objects.filter(
                question_type_id=question_type_id,
                deleted=0
            )

        serializer = skilltypeSerializer(skills, many=True)
        return Response(serializer.data)

    except Exception as e:
        return Response({"error": str(e)}, status=500)

@api_view(['GET'])
def Trainer_course_content_view(request):
    user_name = request.query_params.get('user_name')
    current_datetime = timezone.now()
    start_of_today = current_datetime.replace(hour=0, minute=0, second=0, microsecond=0)

    if not user_name:
        return Response({'error': 'user_name is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        trainer = get_object_or_404(trainer_master, user_name=user_name)
        trainer_id = trainer.id

        unique_data = {}

        # ------------------------------
        # 1. From course_schedule (trainer_ids is a list)
        # ------------------------------

        # Step 1a: Fetch uncompleted past records
        uncompleted_course_records = course_schedule.objects.filter(
            trainer_ids__contains=[trainer_id],
            deleted=0,
            dtm_end_trainer__lt=start_of_today
        ).exclude(status='Completed')

        # Step 1b: If none, fetch current/future records
        if not uncompleted_course_records.exists():
            uncompleted_course_records = course_schedule.objects.filter(
                trainer_ids__contains=[trainer_id],
                deleted=0,
                dtm_start_trainer__lte=current_datetime,
                dtm_end_trainer__gte=start_of_today
            ).exclude(status='Completed')

        for cs in uncompleted_course_records.select_related('topic_id'):
            t = cs.topic_id
            if not t:
                continue
            key = (t.topic, t.sub_topic, t.content_url, t.worksheet_link, t.actual_content)
            if key not in unique_data:
                unique_data[key] = {
                    'id': cs.id,
                    'source': 'course_schedule',
                    'topic': t.topic,
                    'sub_topic': t.sub_topic,
                    'Content_URL': t.content_url,
                    'worksheet_link': t.worksheet_link,
                    'Actual_Content': t.actual_content,
                    'Start_Date': cs.dtm_start_trainer,
                    'End_Date': cs.dtm_end_trainer,
                    'Status': cs.status
                }

        # ------------------------------
        # 2. From training_schedule (trainer_id is a ForeignKey)
        # ------------------------------
        training_records = training_schedule.objects.filter(
            trainer_id=trainer_id,
            dtm_start_trainer__lte=current_datetime,
            dtm_end_trainer__gte=current_datetime,deleted=0
        ).exclude(status='Completed').select_related('topic_id')

        for ts in training_records:
            t = ts.topic_id
            if not t:
                continue
            key = (t.topic, t.sub_topic, t.content_url, t.worksheet_link, t.actual_content)
            if key not in unique_data:
                unique_data[key] = {
                    'id': ts.id,
                    'source': 'training_schedule',
                    'topic': t.topic,
                    'sub_topic': t.sub_topic,
                    'Content_URL': t.content_url,
                    'worksheet_link': t.worksheet_link,
                    'Actual_Content': t.actual_content,
                    'Start_Date': ts.dtm_start_trainer,
                    'End_Date': ts.dtm_end_trainer,
                    'Status': ts.status
                }
        return Response(list(unique_data.values()), status=status.HTTP_200_OK)

    except Exception as e:
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

@api_view(['GET'])
def get_assessment_test_types(request):
    data = test_type.objects.filter(test_type_categories='PracticeTest',deleted=0)
    result = [
        {
            "id": t.id,
            "label": t.test_type,
            "value": t.id
        }
        for t in data
    ]
    return Response(result)

@api_view(['POST'])
def create_course_content_feedback(request):
    try:
        print("Step 1: Received request data:", request.data)

        training_schedule_id = request.data.get('training_id')  # This is actually training_schedule.id
        student_id = request.data.get('student_id')
        feedback = request.data.get('feedback', '')
        remarks = request.data.get('remarks', '')

        print("Step 2: Extracted training_schedule_id:", training_schedule_id)
        print("Step 3: Extracted student_id:", student_id)

        if not training_schedule_id or not student_id:
            print("Step 4: Missing required fields")
            return Response({'error': 'training_id (training_schedule.id) and student_id are required.'},
                            status=status.HTTP_400_BAD_REQUEST)

        print("Step 5: Fetching training_schedule object by primary key")
        training = get_object_or_404(training_schedule, id=training_schedule_id)
        print("Step 6: Found training_schedule:", training)

        print("Step 6.1: topic_id =", training.topic_id)
        print("Step 6.2: trainer_id =", training.trainer_id)

        if not training.topic_id or not training.trainer_id:
            print("Step 6.3: Missing topic or trainer mapping in training_schedule")
            return Response({'error': 'Training schedule is missing topic or trainer.'},
                            status=status.HTTP_400_BAD_REQUEST)

        print("Step 7: Creating or updating course_content_feedback")
        feedback_obj, created = course_content_feedback.objects.get_or_create(
            student_id_id=student_id,
            training_id_id=training.id,
            topic_id_id=training.topic_id.id,
            trainer_id_id=training.trainer_id.id,
        )

        print("Step 8: Setting feedback and session data")
        feedback_obj.feedback = feedback
        feedback_obj.remarks = remarks  # Ensure remarks is in your model if used
        feedback_obj.dtm_session = getattr(training, 'dtm_of_training', None)
        feedback_obj.save()

        print("Step 9: Saved feedback with ID:", feedback_obj.id)

        stored = course_content_feedback.objects.filter(id=feedback_obj.id).exists()
        print("Step 10: Confirm feedback stored in DB?", stored)

        print("Step 11: Serializing response")
        serializer = courseContentFeedbackSerializer(feedback_obj)

        print("Step 12: Sending response")
        return Response(serializer.data, status=status.HTTP_201_CREATED if created else status.HTTP_200_OK)

    except Exception as e:
        print("Step 13: Exception occurred:", str(e))
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

@api_view(['GET'])
def get_student_id_by_username(request):
    user_name = request.GET.get('user_name')

    if not user_name:
        return Response({'error': 'user_name is required.'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        student = candidate_master.objects.get(user_name=user_name,deleted=0)
        return Response({'student_id': student.id}, status=status.HTTP_200_OK)
    except candidate_master.DoesNotExist:
        return Response({'error': 'Student not found.'}, status=status.HTTP_404_NOT_FOUND)

from .serializers import courseStudentfeedbackSerializer, courseContentFeedbackSerializer

class FeedbackUpdateView(generics.RetrieveUpdateAPIView):
    queryset = course_schedule.objects.filter(deleted=0)
    serializer_class = courseStudentfeedbackSerializer

    def update_feedback_and_create_content(self, instance):
        trainer_ids = instance.trainer_ids if isinstance(instance.trainer_ids, list) else []

        for trainer_id in trainer_ids:
            # Optional: avoid duplicates if necessary
            if not course_content_feedback.objects.filter(
                student_id=instance.student_id,
                topic_id=instance.topic_id,
                trainer_id_id=trainer_id,
                dtm_session=instance.dtm_of_training
            ).exists():
                course_content_feedback.objects.create(
                    student_id=instance.student_id,
                    topic_id=instance.topic_id,
                    trainer_id_id=trainer_id,
                    dtm_session=instance.dtm_of_training,
                    feedback=instance.feedback,
                    training_id=None  # You can set this if you have the value
                )

    def put(self, request, *args, **kwargs):
        response = super().put(request, *args, **kwargs)

        if response.status_code == 200:
            instance = self.get_object()
            self.update_feedback_and_create_content(instance)

        return response

    def patch(self, request, *args, **kwargs):
        response = super().patch(request, *args, **kwargs)

        if response.status_code == 200:
            instance = self.get_object()
            self.update_feedback_and_create_content(instance)

        return response


from collections import defaultdict

@api_view(['GET'])
def get_assigned_topics_by_training_id(request, training_id):
    try:
        assigned_rows = training_schedule.objects.filter(training_id=training_id, deleted=0)

        # Group by session, date, batch, trainer
        session_group = defaultdict(lambda: {
            "date": None,
            "session": None,
            "batch": None,
            "trainer": None,
            "topics": set(),   # üëà use set for uniqueness
            "student_count": 0
        })

        for row in assigned_rows:
            topic_name = row.topic_id.topic if row.topic_id else ""
            key = (
                row.dtm_of_training.strftime('%Y-%m-%d') if row.dtm_of_training else None,
                getattr(row, 'session', None),
                row.batch_no,
                row.trainer_id.trainer_name if row.trainer_id else None,
            )

            session_group[key]["date"] = key[0]
            session_group[key]["session"] = key[1]
            session_group[key]["batch"] = key[2]
            session_group[key]["trainer"] = key[3]
            session_group[key]["topics"].add(topic_name)  # üëà add to set
            session_group[key]["student_count"] += len(row.student_ids or [])

        # Prepare final output
        assigned_data = []
        for group in session_group.values():
            assigned_data.append({
                "date": group["date"],
                "session": group["session"],
                "batch": group["batch"],
                "trainer": group["trainer"],
                # convert set back to list (or string)
                "topics": list(group["topics"]),     
                # "topics": ", ".join(group["topics"]),  # üëâ if you prefer string
                "student_count": group["student_count"]
            })

        return Response({"assigned_data": assigned_data}, status=200)

    except Exception as e:
        return Response({"error": str(e)}, status=500)

from io import BytesIO
import openpyxl
import pdfplumber
from docx import Document

def extract_table_from_excel(file):
    wb = openpyxl.load_workbook(filename=BytesIO(file.read()), data_only=True)
    ws = wb.active  # use first sheet dynamically
    all_topics = []
    topics_col_idx = None

    # Detect "Topics" column
    headers = [str(c).strip().lower() if c else "" for c in [cell.value for cell in ws[1]]]
    for idx, header in enumerate(headers):
        if "topics" in header:
            topics_col_idx = idx
            break

    if topics_col_idx is None:
        return []

    for row in ws.iter_rows(min_row=2, values_only=True):
        topics = row[topics_col_idx]
        if topics:
            topics_list = [t.strip() for t in str(topics).split(',') if t.strip()]
            all_topics.extend(topics_list)

    return list(dict.fromkeys(all_topics))  # unique, keep order


def extract_table_from_docxs(file):
    doc = Document(file)
    all_topics = []
    for table in doc.tables:
        headers = [cell.text.strip().lower() for cell in table.rows[0].cells]
        topics_col_idx = None
        for idx, header in enumerate(headers):
            if "topics" in header:
                topics_col_idx = idx
                break
        if topics_col_idx is None:
            continue

        for row in table.rows[1:]:
            topics = row.cells[topics_col_idx].text.strip()
            if topics:
                topics_list = [t.strip() for t in topics.split(',') if t.strip()]
                all_topics.extend(topics_list)

    return list(dict.fromkeys(all_topics))


def extract_table_from_pdfs(file):
    file.seek(0)
    all_topics = []
    with pdfplumber.open(file) as pdf:
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                headers = [h.strip().lower() if h else "" for h in table[0]]
                topics_col_idx = None
                for idx, header in enumerate(headers):
                    if "topics" in header:
                        topics_col_idx = idx
                        break
                if topics_col_idx is None:
                    continue
                for row in table[1:]:
                    topics = row[topics_col_idx]
                    if topics:
                        topics_list = [t.strip() for t in topics.split(',') if t.strip()]
                        all_topics.extend(topics_list)
    return list(dict.fromkeys(all_topics))


def extract_text_from_txt(file):
    text = file.read().decode("utf-8")
    return [t.strip() for t in text.split(',') if t.strip()]

@csrf_exempt
def add_training_schedule(request):
    if request.method == 'POST':
        print("üîÑ POST request received")
        print("üëâ Raw POST data:", request.POST)
        print("üëâ skill_type:", request.POST.getlist("skill_type"))
        print("üëâ skill_types:", request.POST.getlist("skill_types"))
        print("üëâ question_type:", request.POST.getlist("question_type"))
        print("üëâ question_types:", request.POST.getlist("question_types"))

        college_id = request.POST.get('college_id')
        if not college_id:
            return HttpResponse("college_id is required", status=400)

        # ‚úÖ Validate college
        try:
            college = college_master.objects.get(id=college_id, deleted=0)
            print(f"üè´ College object found: {college}")
        except college_master.DoesNotExist:
            return HttpResponse("Invalid college_id", status=400)

        # ‚úÖ Use temp instance for dynamic form choices
        temp_instance = training_schedule_temp(college_id=college)
        form = TrainingScheduleFormUpdate(request.POST, request.FILES, instance=temp_instance)

        if form.is_valid():
            try:
                training_schedule = form.save(commit=False)
                training_schedule.college_id = college
                training_schedule.batches = form.cleaned_data.get('batches', [])
                training_schedule.trainers = form.cleaned_data.get('trainers', [])

                # ‚úÖ Department & Year
                department_ids = form.cleaned_data.get('department_id') or []
                year = form.cleaned_data.get('year') or []
                training_schedule.department_id = ','.join([str(dept.id) for dept in department_ids])
                training_schedule.year = ','.join([str(y) for y in year])
                # --- Question Types --- 
                qtype_raw = request.POST.get("question_type")  # single JSON string
                qtype_labels = []   # keep name same
                if qtype_raw:
                    try:
                        qtype_data = json.loads(qtype_raw)   # [{'id': 2, 'name': 'Technical'}, ...]
                        qtype_labels = [q['id'] for q in qtype_data if 'id' in q]   # ‚úÖ store only IDs
                    except Exception as e:
                        print("‚ùå Failed to parse question_type:", e)

                training_schedule.question_type = json.dumps(qtype_labels)  # store clean JSON array of IDs


                # --- Skill Types --- 
                stype_raw = request.POST.get("skill_type")
                stype_labels = []
                if stype_raw:
                    try:
                        stype_data = json.loads(stype_raw)
                        stype_labels = [s['id'] for s in stype_data if 'id' in s]   # ‚úÖ store only IDs
                    except Exception as e:
                        print("‚ùå Failed to parse skill_type:", e)

                training_schedule.skill_type = json.dumps(stype_labels)  # store clean JSON array of IDs

                # ‚úÖ Topics (via file or default rules)
                unique_topics = []
                Quants, Logical, Verbal = [], [], []
                C, CPP, Java, Python = [], [], [], []

                if 'remarks_file' in request.FILES:
                    file = request.FILES['remarks_file']
                    print(f"üìÇ Remarks file uploaded: {file.name}")

                    ext = file.name.lower().split('.')[-1]
                    print(f"üìÑ File extension detected: {ext}")

                    if ext in ['xlsx', 'xls']:
                        text = extract_table_from_excel(file)
                    elif ext == 'docx':
                        text = extract_table_from_docxs(file)
                    elif ext == 'pdf':
                        text = extract_table_from_pdfs(file)
                    elif ext == 'txt':
                        text = extract_text_from_txt(file)
                    else:
                        text = []
                        print(f"‚ö†Ô∏è Unsupported file extension: {ext}")

                    print(f"üîç Extracted text/topics from file: {text}")
                    unique_topics = text

                else:
                    print("‚ö†Ô∏è No remarks file uploaded, falling back to year/qtype rules")
   
                    # ‚úÖ No file: pick topics by year/qtype
                    selected_years = [str(y) for y in year]
                    selected_departments = list(department_ids.values_list('department', flat=True))
                    
                    # ---- Year 1 ----
                    if '1' in selected_years:
                        Quants = ["Number System", "HCF and LCM",  "Average" ]
                        Logical = ["Number Series", "Puzzles", "Mirror Image & Water Images",
                                   "Blood Relations"]
                        Verbal = ["Articles & Prepositions", "Tenses", "Sequence of Words",
                                  "Inserting the Missing Character", "Verification Of Truth"]
                        SoftSkills= []
                        if "Aptitude" in qtype_labels:
                            unique_topics += Quants + Logical + Verbal

                    # ---- Year 2 ----
                    elif '2' in selected_years:
                        Quants = ["Percentage", "Profit & Loss", "Ages", "SI & CI", "Ratio Proportion",
                                  "Time and Work", "Permutation Combination", "Time Speed and Distance",
                                  "Arithmetic Progression", "Data Sufficiency"]
                        Logical = ["Odd One Out", "Logical Sequencing", "Syllogism", 
                                   "Logical Game", "Problem Solving", "Statements and Arguments",
                                   "Assumptions", "Conclusions", "Directions"]
                        Verbal= ["Synonyms & Antonyms", "Idioms and Phrases", "Direct & Indirect Speech",
                                    "Conjunctions and Punctuations", "Sentence Formation", "Error Corrections",
                                    "Sentences Jumbling", "Reading Comprehension", "Paragraph Formation"]
                        SoftSkills= ["Oral Communication", "Body language", "Personality Development",
                                    "Grooming", "Talk on a topic", "Communication", "Writing Skills",
                                    "Reading Skills", "Listening Skills", "Behavioural Skills"]

                        C = [
                            "C - Introduction & Setup",
                            "C - Data Types and Variables",
                            "C - Operators and Expressions",
                            "C - Control Structures",
                            "C - Looping Constructs",
                            "C - Functions",
                            "C - Arrays",
                            "C - Strings",
                            "C - Pointers",
                            "C - Structures and Unions",
                            "C - File Handling",
                            "C - Dynamic Memory Allocation"
                            ]

                        CPP = [
                            "C++ Basics & First Program",
                            "C++ Data Types & Variables",
                            "Operators & Control Structures in C++",
                            "Functions & Function Overloading in C++",
                            "Classes & Objects in C++",
                            "Constructors & Destructors in C++",
                            "Inheritance in C++",
                            "Polymorphism & Virtual Functions in C++",
                            "Templates in C++",
                            "Exception Handling in C++",
                            "STL - Introduction in C++",
                            "STL - Containers (Vectors, Lists, Maps, Sets) in C++",
                            "STL - Iterators & Algorithms in C++",
                            "Arrays in C++" ,"Strings in C++" ,"Sorting in C++" ,"Queue in C++" ,"Stack in C++" ,"Heaps in C++" ,"Linked List in C++" , "Trees in C++"  , "Graph in C++"
                        ]

                        if "Aptitude" in qtype_labels:
                           unique_topics += Quants + Logical + Verbal
                        if "Technical" in qtype_labels:
                            unique_topics += C + CPP

                    # ---- Year 3 ----
                    elif '3' in selected_years:
                        Quants = ["Boat and Streams", "Train", "Pipes and Cisterns", "Data Interpretation",
                                  "Flow Chart", "Calendar", "Clock", "Alligation & Mixture", "Geometry", "Mensuration"]
                        Logical = ["Seating Arrangements",  "Arithmetical Reasoning",
                                  "Probability"]
                        Verbal= ["Synonyms & Antonyms", "Idioms and Phrases", "Analogies", "Sentence Jumbling"]
                        SoftSkills =["Presentation Skills", "Goal Setting", "Time Management", "Team Building",
                           "Resume Building", "Public Speaking", "Error Spotting", "Parts of Speech"]
                        Java = ["Java-intro","Java-Setup and First Program" ,"Java-Data Types and Variables", "Java-Operators and Control Statements", "Java-Classes and Objects", "Java-Methods and Method Overloading", "Java-Inheritance", "Java-Polymorphism", "Java-Abstraction and Interfaces", "Java-Packages and Access Modifiers", "Java-Exception Handling", "Java-Basic Input and Output","Java-Heaps" ,"Java-Hashing" ,"Java-Queues", "Java-Stack" , "Java-Arrays" , "Java-Sorting" ,"Java-Strings", "Java-Tree"]

                        Python = ["Python-Intro", "Python-Setup and First Program", "Python-Data Types and Variables", "Python-Operators and Expressions", "Python-Control Flow", "Python-Loops", "Python-Functions", "Python-Lists and Tuples", "Python-Dictionaries and Sets", "Python-Strings", "Python-Modules and Packages", "Python-File I/O","Python-Hashing" , "Python-Heaps" ,"Python-Queues" , "Python-Sorting Algorithm" ]

                        if "Aptitude" in qtype_labels:
                            unique_topics += Quants + Logical + Verbal
                        if "Technical" in qtype_labels:
                            unique_topics += Java + Python

                    # ---- Year 4 ----
                    elif '4' in selected_years:
                        Quants = ["Time and Work", "Ages", "Ratio Proportion", "Speed and Distance", "Data Sufficiency"]
                        Logical = ["Pattern Completion", "Image Analysis", "Blood Relations", "Coding Decoding",
                                   "Seating Arrangements"]
                        Verbal=["Synonyms & Antonyms"]
                        SoftSkills = [ "Resume Building", "Interview Skills", "GD", "Mock Interview"]
                        Java = ["Java-Generics","Java-Collections Framework","Java-Multi-threading and Concurrency","Java-Streams and Lambda Expressions","Java-File I/O (NIO.2)","Java-JDBC","Java-Networking (Sockets)","Java-JavaFX","Java-Annotations","Java-Reflection","Java-Serialization","Java-Internationalization (i18n) & Localization (l10n)","Java-Security (Cryptography & Access Control)","Java-Regular Expressions","Java-Modules (Java 9+ Module System)","Java-Memory Management & Garbage Collection","Java-JVM Internals & Performance Tuning"]
                        Python = [
                            "Python - Object-Oriented Programming", "Python - Advanced Functions (Decorators, Generators)", "Python - Exception Handling", "Python - Working with JSON and CSV files", "Python - Regular Expressions",
                            "Python - Multithreading and Multiprocessing", "Python - Networking (Sockets)", "Python - Web Scraping (BeautifulSoup, Scrapy)", "Python - Data Analysis (Pandas)", "Python - Visualization (Matplotlib, Seaborn)"
                            ]

                        if "Aptitude" in qtype_labels:
                            unique_topics += Quants + Logical + Verbal
                        if "Technical" in qtype_labels:
                            unique_topics += Java + Python

                # ‚úÖ Filter by selected skill types
                # ‚úÖ Filter by selected skill types
                if stype_labels:
                    skill_names = list(skill_type.objects.filter(id__in=stype_labels).values_list("skill_type", flat=True))

                    def normalize_skill(s):
                        s_upper = str(s).strip().upper()
                        mapping = {
                            "C++": "CPP", "CPP": "CPP",
                            "JAVA": "Java",
                            "PYTHON": "Python",
                            "QUANTS": "Quants", "QUANTITATIVE": "Quants",
                            "LOGICAL": "Logical",
                            "VERBAL": "Verbal",
                            "C": "C"
                        }
                        return mapping.get(s_upper, str(s).strip())

                    normalized_stypes = [normalize_skill(s) for s in skill_names]

                    skill_topic_map = {
                        "Quants": Quants,
                        "Logical": Logical,
                        "Verbal": Verbal,
                        "C": C,
                        "CPP": CPP,
                        "Java": Java,
                        "Python": Python,
                    }

                    filtered_topics = []
                    for s in normalized_stypes:
                        filtered_topics.extend(skill_topic_map.get(s, []))

                    # ‚úÖ merge, don‚Äôt overwrite
                    unique_topics = list(dict.fromkeys(unique_topics + filtered_topics))

                print(f"üìå Final topics going to DB: {unique_topics}")
                print(f"üìå No. of topics: {len(unique_topics)}")

                # ‚úÖ Save topics & metadata
                training_schedule.topics = unique_topics
                training_schedule.no_of_topics = len(unique_topics)
                training_schedule.no_of_trainer = training_schedule.no_of_batch
                training_schedule.trainer_ids = request.POST.get('trainer_ids')

                college_name_clean = str(college.college).replace(" ", "").replace("-", "").replace("&", "and")
                year_str = '_'.join(sorted(training_schedule.year.split(',')))
                training_schedule.training_name = f"{college_name_clean}_{year_str}yr_training"

                # ‚úÖ Trainer Date JSON
                trainer_date_str = request.POST.get('trainer_date')
                if trainer_date_str:
                    try:
                        training_schedule.trainer_date = json.loads(trainer_date_str)
                    except json.JSONDecodeError:
                        return HttpResponse("Invalid trainer_date format", status=400)

                training_schedule.save()

                return JsonResponse({
                    "success": True,
                    "message": "‚úÖ New training schedule created successfully",
                    "id": training_schedule.id
                })

            except Exception as e:
                logger.error(f"‚ùå Error creating training schedule: {str(e)}", exc_info=True)
                return HttpResponse(f"‚ùå Error: {str(e)}", status=500)

        else:
            print("‚ùå Form is not valid")
            print("‚ùå Form errors:", form.errors)
            return HttpResponse(f"‚ùå Form errors: {form.errors}", status=400)

    # -------- GET method --------
    else:
        college_id = request.GET.get('college_id')
        if not college_id:
            return HttpResponse("college_id query param required for GET", status=400)

        try:
            college = college_master.objects.get(id=college_id, deleted=0)
        except college_master.DoesNotExist:
            return HttpResponse("Invalid college_id", status=400)

        temp_instance = training_schedule_temp(college_id=college)
        form = TrainingScheduleFormUpdate(instance=temp_instance)

        return render(request, 'add_training_schedule.html', {
            'form': form,
            'college_id': college_id
        })

@csrf_exempt
def update_training_schedule(request, training_id):
    try:
        training_schedule = training_schedule_temp.objects.get(id=training_id)
    except training_schedule_temp.DoesNotExist:
        return HttpResponse("Training schedule not found", status=404)

    if request.method == 'POST':
        print("‚úèÔ∏è POST request for update")

        college_id = request.POST.get('college_id')
        if not college_id:
            return HttpResponse("college_id is required", status=400)

        try:
            college = college_master.objects.get(id=college_id, deleted=0)
        except college_master.DoesNotExist:
            return HttpResponse("Invalid college_id", status=400)

        training_schedule.college_id = college

        form = TrainingScheduleFormUpdate(request.POST, request.FILES, instance=training_schedule)

        if form.is_valid():
            try:
                training_schedule = form.save(commit=False)
                training_schedule.college_id = college
                training_schedule.batches = form.cleaned_data.get('batches', [])
                training_schedule.trainers = form.cleaned_data.get('trainers', [])

                # ‚úÖ Department & Year
                department_ids = form.cleaned_data.get('department_id') or []
                year = form.cleaned_data.get('year') or []
                training_schedule.department_id = ','.join([str(dept.id) for dept in department_ids])
                training_schedule.year = ','.join([str(y) for y in year])

                # --- Question Types ---
                qtype_raw = request.POST.get("question_type")
                qtype_labels = []
                if qtype_raw:
                    try:
                        qtype_data = json.loads(qtype_raw)   # [{'id': 1, 'name': 'Aptitude'}, ...]
                        qtype_labels = [q['name'] for q in qtype_data if 'name' in q]  # ‚úÖ use names for matching
                        training_schedule.question_type = json.dumps([q['id'] for q in qtype_data if 'id' in q])
                    except Exception as e:
                        print("‚ùå Failed to parse question_type:", e)

                # --- Skill Types ---
                stype_raw = request.POST.get("skill_type")
                stype_labels = []
                if stype_raw:
                    try:
                        stype_data = json.loads(stype_raw)
                        stype_labels = [s['id'] for s in stype_data if 'id' in s]
                        training_schedule.skill_type = json.dumps(stype_labels)
                    except Exception as e:
                        print("‚ùå Failed to parse skill_type:", e)


                unique_topics = []
                Quants, Logical, Verbal = [], [], []
                C, CPP, Java, Python = [], [], [], []

                if 'remarks_file' in request.FILES:
                    file = request.FILES['remarks_file']
                    print(f"üìÇ Remarks file uploaded: {file.name}")

                    ext = file.name.lower().split('.')[-1]
                    print(f"üìÑ File extension detected: {ext}")

                    if ext in ['xlsx', 'xls']:
                        text = extract_table_from_excel(file)
                    elif ext == 'docx':
                        text = extract_table_from_docxs(file)
                    elif ext == 'pdf':
                        text = extract_table_from_pdfs(file)
                    elif ext == 'txt':
                        text = extract_text_from_txt(file)
                    else:
                        text = []
                        print(f"‚ö†Ô∏è Unsupported file extension: {ext}")

                    print(f"üîç Extracted text/topics from file: {text}")
                    unique_topics = text

                else:
                    print("‚ö†Ô∏è No remarks file uploaded, falling back to year/qtype rules")
   
                    # ‚úÖ No file: pick topics by year/qtype
                    selected_years = [str(y) for y in year]
                    selected_departments = list(department_ids.values_list('department', flat=True))
                    
                    # ---- Year 1 ----
                    if '1' in selected_years:
                        Quants = ["Number System", "HCF and LCM",  "Average" ]
                        Logical = ["Number Series", "Puzzles", "Mirror Image & Water Images",
                                   "Blood Relations"]
                        Verbal = ["Articles & Prepositions", "Tenses", "Sequence of Words",
                                  "Inserting the Missing Character", "Verification Of Truth"]
                        SoftSkills= []
                        if "Aptitude" in qtype_labels:
                            unique_topics += Quants + Logical + Verbal

                    # ---- Year 2 ----
                    elif '2' in selected_years:
                        Quants = ["Percentage", "Profit & Loss", "Ages", "SI & CI", "Ratio Proportion",
                                  "Time and Work", "Permutation Combination", "Time Speed and Distance",
                                  "Arithmetic Progression", "Data Sufficiency"]
                        Logical = ["Odd One Out", "Logical Sequencing", "Syllogism", 
                                   "Logical Game", "Problem Solving", "Statements and Arguments",
                                   "Assumptions", "Conclusions", "Directions"]
                        Verbal= ["Synonyms & Antonyms", "Idioms and Phrases", "Direct & Indirect Speech",
                                    "Conjunctions and Punctuations", "Sentence Formation", "Error Corrections",
                                    "Sentences Jumbling", "Reading Comprehension", "Paragraph Formation"]
                        SoftSkills= ["Oral Communication", "Body language", "Personality Development",
                                    "Grooming", "Talk on a topic", "Communication", "Writing Skills",
                                    "Reading Skills", "Listening Skills", "Behavioural Skills"]

                        C = [
                            "C - Introduction & Setup",
                            "C - Data Types and Variables",
                            "C - Operators and Expressions",
                            "C - Control Structures",
                            "C - Looping Constructs",
                            "C - Functions",
                            "C - Arrays",
                            "C - Strings",
                            "C - Pointers",
                            "C - Structures and Unions",
                            "C - File Handling",
                            "C - Dynamic Memory Allocation"
                            ]

                        CPP = [
                            "C++ Basics & First Program",
                            "C++ Data Types & Variables",
                            "Operators & Control Structures in C++",
                            "Functions & Function Overloading in C++",
                            "Classes & Objects in C++",
                            "Constructors & Destructors in C++",
                            "Inheritance in C++",
                            "Polymorphism & Virtual Functions in C++",
                            "Templates in C++",
                            "Exception Handling in C++",
                            "STL - Introduction in C++",
                            "STL - Containers (Vectors, Lists, Maps, Sets) in C++",
                            "STL - Iterators & Algorithms in C++",
                            "Arrays in C++" ,"Strings in C++" ,"Sorting in C++" ,"Queue in C++" ,"Stack in C++" ,"Heaps in C++" ,"Linked List in C++" , "Trees in C++"  , "Graph in C++"
                        ]

                        if "Aptitude" in qtype_labels:
                           unique_topics += Quants + Logical + Verbal
                        if "Technical" in qtype_labels:
                            unique_topics += C + CPP

                    # ---- Year 3 ----
                    elif '3' in selected_years:
                        Quants = ["Boat and Streams", "Train", "Pipes and Cisterns", "Data Interpretation",
                                  "Flow Chart", "Calendar", "Clock", "Alligation & Mixture", "Geometry", "Mensuration"]
                        Logical = ["Seating Arrangements",  "Arithmetical Reasoning",
                                  "Probability"]
                        Verbal= ["Synonyms & Antonyms", "Idioms and Phrases", "Analogies", "Sentence Jumbling"]
                        SoftSkills =["Presentation Skills", "Goal Setting", "Time Management", "Team Building",
                           "Resume Building", "Public Speaking", "Error Spotting", "Parts of Speech"]
                        Java = ["Java-intro","Java-Setup and First Program" ,"Java-Data Types and Variables", "Java-Operators and Control Statements", "Java-Classes and Objects", "Java-Methods and Method Overloading", "Java-Inheritance", "Java-Polymorphism", "Java-Abstraction and Interfaces", "Java-Packages and Access Modifiers", "Java-Exception Handling", "Java-Basic Input and Output","Java-Heaps" ,"Java-Hashing" ,"Java-Queues", "Java-Stack" , "Java-Arrays" , "Java-Sorting" ,"Java-Strings", "Java-Tree"]

                        Python = ["Python-Intro", "Python-Setup and First Program", "Python-Data Types and Variables", "Python-Operators and Expressions", "Python-Control Flow", "Python-Loops", "Python-Functions", "Python-Lists and Tuples", "Python-Dictionaries and Sets", "Python-Strings", "Python-Modules and Packages", "Python-File I/O","Python-Hashing" , "Python-Heaps" ,"Python-Queues" , "Python-Sorting Algorithm" ]

                        if "Aptitude" in qtype_labels:
                            unique_topics += Quants + Logical + Verbal
                        if "Technical" in qtype_labels:
                            unique_topics += Java + Python

                    # ---- Year 4 ----
                    elif '4' in selected_years:
                        Quants = ["Time and Work", "Ages", "Ratio Proportion", "Speed and Distance", "Data Sufficiency"]
                        Logical = ["Pattern Completion", "Image Analysis", "Blood Relations", "Coding Decoding",
                                   "Seating Arrangements"]
                        Verbal=["Synonyms & Antonyms"]
                        SoftSkills = [ "Resume Building", "Interview Skills", "GD", "Mock Interview"]
                        Java = ["Java-Generics","Java-Collections Framework","Java-Multi-threading and Concurrency","Java-Streams and Lambda Expressions","Java-File I/O (NIO.2)","Java-JDBC","Java-Networking (Sockets)","Java-JavaFX","Java-Annotations","Java-Reflection","Java-Serialization","Java-Internationalization (i18n) & Localization (l10n)","Java-Security (Cryptography & Access Control)","Java-Regular Expressions","Java-Modules (Java 9+ Module System)","Java-Memory Management & Garbage Collection","Java-JVM Internals & Performance Tuning"]
                        Python = [
                            "Python - Object-Oriented Programming", "Python - Advanced Functions (Decorators, Generators)", "Python - Exception Handling", "Python - Working with JSON and CSV files", "Python - Regular Expressions",
                            "Python - Multithreading and Multiprocessing", "Python - Networking (Sockets)", "Python - Web Scraping (BeautifulSoup, Scrapy)", "Python - Data Analysis (Pandas)", "Python - Visualization (Matplotlib, Seaborn)"
                            ]

                        if "Aptitude" in qtype_labels:
                            unique_topics += Quants + Logical + Verbal
                        if "Technical" in qtype_labels:
                            unique_topics += Java + Python

                # ‚úÖ Filter by selected skill types
                # ‚úÖ Filter by selected skill types
                if stype_labels:
                    skill_names = list(skill_type.objects.filter(id__in=stype_labels).values_list("skill_type", flat=True))

                    def normalize_skill(s):
                        s_upper = str(s).strip().upper()
                        mapping = {
                            "C++": "CPP", "CPP": "CPP",
                            "JAVA": "Java",
                            "PYTHON": "Python",
                            "QUANTS": "Quants", "QUANTITATIVE": "Quants",
                            "LOGICAL": "Logical",
                            "VERBAL": "Verbal",
                            "C": "C"
                        }
                        return mapping.get(s_upper, str(s).strip())

                    normalized_stypes = [normalize_skill(s) for s in skill_names]

                    skill_topic_map = {
                        "Quants": Quants,
                        "Logical": Logical,
                        "Verbal": Verbal,
                        "C": C,
                        "CPP": CPP,
                        "Java": Java,
                        "Python": Python,
                    }

                    filtered_topics = []
                    for s in normalized_stypes:
                        filtered_topics.extend(skill_topic_map.get(s, []))

                    # ‚úÖ merge, don‚Äôt overwrite
                    unique_topics = list(dict.fromkeys(unique_topics + filtered_topics))

                print(f"üìå Final topics going to DB: {unique_topics}")
                print(f"üìå No. of topics: {len(unique_topics)}")

                training_schedule.topics = unique_topics
                training_schedule.no_of_topics = len(unique_topics)
                training_schedule.no_of_trainer = training_schedule.no_of_batch
                training_schedule.trainer_ids = request.POST.get('trainer_ids')

                # ‚úÖ Training name
                college_name_clean = str(college.college).replace(" ", "").replace("-", "").replace("&", "and")
                year_str = '_'.join(sorted(training_schedule.year.split(',')))
                training_schedule.training_name = f"{college_name_clean}_{year_str}yr_training"

                # ‚úÖ Trainer date JSON
                trainer_date_str = request.POST.get('trainer_date')
                if trainer_date_str:
                    try:
                        training_schedule.trainer_date = json.loads(trainer_date_str)
                    except json.JSONDecodeError:
                        return HttpResponse("Invalid trainer_date format", status=400)

                training_schedule.save()

                return JsonResponse({
                    "success": True,
                    "message": "‚úÖ Training schedule updated successfully",
                    "id": training_schedule.id
                })

            except Exception as e:
                print(f"‚ùå Error updating training schedule: {str(e)}")
                return HttpResponse(f"‚ùå Error updating training schedule: {str(e)}", status=500)

        else:
            print("‚ùå Form errors:", form.errors)
            return HttpResponse(f"‚ùå Form errors: {form.errors}", status=400)

    else:  # GET
        form = TrainingScheduleFormUpdate(instance=training_schedule)
        return render(request, 'update_training_schedule.html', {
            'form': form,
            'college_id': training_schedule.college_id.id if training_schedule.college_id else ''
        })

import ast

@csrf_exempt
def get_training_schedule_details(request, training_id):
    if request.method != "GET":
        return JsonResponse({"error": "Only GET method is allowed"}, status=405)

    try:
        training_schedule_temp_obj = training_schedule_temp.objects.get(id=training_id)
    except training_schedule_temp.DoesNotExist:
        return JsonResponse({"error": "Training schedule not found"}, status=404)

    # Parse trainer_date dates
    trainer_date = training_schedule_temp_obj.trainer_date or {}
    date_values = []

    for key, val in trainer_date.items():
        if isinstance(val, list):
            date_values.extend(val)
        elif isinstance(val, str):
            date_values.append(val)

    parsed_dates = []
    for d in date_values:
        try:
            parsed_date = parse_date(d.strip())
            if parsed_date:
                parsed_dates.append(parsed_date)
        except:
            pass

    parsed_dates = sorted(set(parsed_dates))  # Remove duplicates

    start_date = min(parsed_dates).isoformat() if parsed_dates else None
    end_date = max(parsed_dates).isoformat() if parsed_dates else None

    holidays = []
    trainers_data = []

    if parsed_dates:
        # Calculate holiday dates
        full_range = set(min(parsed_dates) + timedelta(days=i)
                         for i in range((max(parsed_dates) - min(parsed_dates)).days + 1))
        holidays = sorted(list(full_range - set(parsed_dates)))

        # Fetch trainers and deduplicate
        trainer_entries = training_schedule.objects.filter(training_id=training_schedule_temp_obj).select_related('trainer_id')
        trainer_dict = {}

        for entry in trainer_entries:
            t = entry.trainer_id
            if t and t.id not in trainer_dict:
                trainer_dict[t.id] = {
                    "id": t.id,
                    "trainer_name": t.trainer_name,
                    "user_name": t.user_name,
                    "skill_type": [s.skill_type for s in t.skill_id.all()]
                }

        trainers_data = list(trainer_dict.values())

    response_data = {
        "training_id": training_schedule_temp_obj.id,
        "college_id": training_schedule_temp_obj.college_id.id if training_schedule_temp_obj.college_id else None,
        "batches": training_schedule_temp_obj.batches,
        "department_id": training_schedule_temp_obj.department_id,
        "year": ast.literal_eval(training_schedule_temp_obj.year) if training_schedule_temp_obj.year else [],
        "no_of_batch": training_schedule_temp_obj.no_of_batch,
        "no_of_days": training_schedule_temp_obj.no_of_days,
        "location": training_schedule_temp_obj.location,
        "topics": training_schedule_temp_obj.topics,
        "trainer_date": training_schedule_temp_obj.trainer_date,
        "start_date": start_date,
        "end_date": end_date,
        "holiday_dates": [d.isoformat() for d in holidays],
        "trainers": trainers_data,
        
        # ‚úÖ Newly added fields
        "question_type": training_schedule_temp_obj.question_type or [],
        "skill_type": training_schedule_temp_obj.skill_type or []
    }

    return JsonResponse(response_data, status=200)

@api_view(['GET'])
def get_training_schedule_tempdata(request, schedule_id):
    try:
        schedule = get_object_or_404(training_schedule_temp, id=schedule_id)

        # --- Question Type ---
        try:
            question_type_ids = json.loads(schedule.question_type) if schedule.question_type else []
        except Exception:
            question_type_ids = []
        question_type_data = list(
            question_type.objects.filter(id__in=question_type_ids).values("id", "question_type")
        )

        # --- Skill Type ---
        try:
            skill_type_ids = json.loads(schedule.skill_type) if schedule.skill_type else []
        except Exception:
            skill_type_ids = []
        skill_type_data = list(
            skill_type.objects.filter(id__in=skill_type_ids).values("id", "skill_type")
        )

        # --- Batch Skill (direct JSONField, no extra query) ---
        batch_skill_data = schedule.batch_skill if isinstance(schedule.batch_skill, dict) else {}

        response_data = {
            "id": schedule.id,
            "college_id": schedule.college_id_id,
            "question_type_ids": question_type_ids,
            "question_type": question_type_data,
            "skill_type_ids": skill_type_ids,
            "skill_type": skill_type_data,
            "batch_skill": batch_skill_data,
        }
        return Response(response_data)

    except Exception as e:
        return Response({"error": str(e)}, status=500)

#____________________________vishal code______________________#

class QuestionPaperGroupedAPIView(APIView):
    def get(self, request):
        records = question_paper_master.objects.filter(deleted=0).values(
            'id', 'test_type', 'topic', 'sub_topic', 'folder_name','is_testcase'
        ).distinct()
        return Response(list(records), status=status.HTTP_200_OK)

class CollegecodeListView(generics.ListAPIView):
    queryset = college_master.objects.filter(deleted=0).order_by('college')
    serializer_class = CollegeSimpleSerializer


from .serializers import QuestionCountSerializer

class QuestionCountByPaperView(APIView):
    def get(self, request, format=None):
        # Group by question_name_id and count
        queryset = question_master.objects.filter(deleted=0).values('question_name_id').annotate(no_of_questions=Count('id')).order_by('question_name_id')
        
        serializer = QuestionCountSerializer(queryset, many=True)
        return Response(serializer.data)



@api_view(['GET'])
def get_practice_test_type_id(request):
    test_type_name = request.GET.get('test_type')

    if not test_type_name:
        return Response({'error': 'test_type is required'}, status=400)

    try:
        obj = test_type.objects.get(
            test_type__iexact=test_type_name.strip(),  # case-insensitive match
            test_type_categories__iexact="PracticeTest",deleted=0
        )
        return Response({
            'id': obj.id,
            'test_type': obj.test_type,
            'test_type_categories': obj.test_type_categories
        })
    except test_type.DoesNotExist:
        return Response({'error': 'Matching test type not found in PracticeTest category'}, status=404)



@api_view(['GET'])
def get_question_and_skill_ids(request):
    question_type_name = request.query_params.get('question_type')
    skill_type_name = request.query_params.get('skill_type')

    result = {}

    if question_type_name:
        try:
            qtype = question_type.objects.get(question_type=question_type_name,deleted=0)
            result['question_type_id'] = qtype.id
        except question_type.DoesNotExist:
            result['question_type_id'] = None

    if skill_type_name:
        try:
            stype = skill_type.objects.get(skill_type=skill_type_name,deleted=0)
            result['skill_type_id'] = stype.id
        except skill_type.DoesNotExist:
            result['skill_type_id'] = None

    return Response(result)

@api_view(['GET'])
def get_question_paper_withtestdetails(request):
    print("\nüì• API Triggered: get_question_paper_withtestdetails")

    test_type_id = request.query_params.get('test_type_id')
    question_type_id = request.query_params.get('question_type_id')
    skill_type_id = request.query_params.get('skill_type_id')

    print(f"üîç Received Params ‚û§ test_type_id={test_type_id}, question_type_id={question_type_id}, skill_type_id={skill_type_id}")

    if not (test_type_id and question_type_id and skill_type_id):
        print("‚ùå Missing one or more required parameters.")
        return Response({'error': 'Missing required parameters'}, status=400)

    try:
        print("üîÑ Fetching objects by IDs...")
        test_type_obj = test_type.objects.filter(id=test_type_id,deleted=0).first()
        question_type_obj = question_type.objects.filter(id=question_type_id,deleted=0).first()
        skill_type_obj = skill_type.objects.filter(id=skill_type_id,deleted=0).first()

        if not test_type_obj:
            print(f"‚ùå Invalid test_type_id={test_type_id}")
        if not question_type_obj:
            print(f"‚ùå Invalid question_type_id={question_type_id}")
        if not skill_type_obj:
            print(f"‚ùå Invalid skill_type_id={skill_type_id}")

        if not test_type_obj or not question_type_obj or not skill_type_obj:
            return Response({'error': 'Invalid ID(s) provided'}, status=404)

        # Strip and print comparison values
        test_type_str = test_type_obj.test_type.strip()
        topic_str = question_type_obj.question_type.strip()
        sub_topic_str = skill_type_obj.skill_type.strip()

        print(f"üîç Matching with ‚û§ test_type='{test_type_str}', topic='{topic_str}', sub_topic='{sub_topic_str}'")

        # Filter using exact match
        papers = question_paper_master.objects.filter(
            test_type=test_type_str,
            topic=topic_str,
            sub_topic=sub_topic_str,
            deleted=0
        )

        print(f"üìÑ Total papers matched: {papers.count()}")

        result = []
        for p in papers:
            print(f"‚úÖ Matched Paper ‚û§ ID: {p.id}, Name: {p.question_paper_name}")
            result.append({
                'question_paper_id': p.id, 
                'question_paper_name': p.question_paper_name,
                'duration_of_test': p.duration_of_test,
                'test_type': p.test_type,
                'topic': p.topic,
                'sub_topic': p.sub_topic,
                'no_of_questions': p.no_of_questions,
                'folder_name': p.folder_name,
            })

        print("‚úÖ Returning final response.")
        return Response(result)

    except Exception as e:
        import traceback
        traceback.print_exc()
        print("‚ùå Exception occurred:", str(e))
        return Response({'error': str(e)}, status=500)

@api_view(['GET'])
def get_difficulty_level_counts(request):
    try:
        question_paper_id = request.GET.get('question_paper_id')

        if not question_paper_id:
            return Response({'error': 'Missing question_paper_id'}, status=400)

        paper = question_paper_master.objects.filter(id=question_paper_id, deleted=0).first()
        if not paper:
            return Response({'error': 'No question paper found for this ID'}, status=404)

        # Filter questions by question_name_id (paper ID) and deleted = 0
        questions = question_master.objects.filter(question_name_id=paper.id, deleted=0)

        difficulty_data = defaultdict(lambda: {"count": 0, "question_ids": []})

        for q in questions:
            difficulty = q.difficulty_level or 'Unknown'
            difficulty_data[difficulty]["count"] += 1
            difficulty_data[difficulty]["question_ids"].append(q.id)

        # Ensure required levels are present
        all_levels = ['Easy', 'Intermediate', 'Difficulty', 'Company_specific']
        response_data = {}
        for level in all_levels:
            response_data[level] = {
                "count": difficulty_data[level]["count"],
                "question_ids": difficulty_data[level]["question_ids"]
            }

        # Add total
        response_data["Total"] = {
            "count": sum(d["count"] for d in response_data.values()),
            "question_ids": [qid for d in response_data.values() for qid in d["question_ids"]]
        }

        return Response({
            "folder_name": paper.folder_name,
            "question_paper_id": paper.id,
            "difficulty_data": response_data
        })

    except Exception as e:
        return Response({'error': str(e)}, status=500)

@api_view(['POST'])
def assign_difficulty_questions(request):
    data = request.data
    print("üì• Incoming Payload:", data)

    required_fields = [
        "student_id", "test_type_id", "question_type_id",
        "skill_type_id", "question_name_id", "question_ids"
    ]
    

    if not all(field in data for field in required_fields):
        return Response({"error": "Missing required parameters"}, status=400)

    paper = question_paper_master.objects.filter(id=data["question_name_id"],deleted=0).first()
    if not paper:
        return Response({"error": "Invalid question paper ID"}, status=404)

    folder_name = paper.folder_name
    test_name = data.get("test_name")
    if not test_name:
        folder_name = paper.folder_name
        test_name = f"{folder_name}_{data['student_id']}"  # fallback


    print("üìÇ Test Name:", test_name)

    difficulty_counts = defaultdict(int)
    difficulty_values = question_master.objects.filter(id__in=data["question_ids"]).values("difficulty_level")
    for entry in difficulty_values:
        difficulty_counts[entry["difficulty_level"]] += 1

    test_type_obj = test_type.objects.filter(id=data["test_type_id"]).first()
    if not test_type_obj:
        return Response({"error": "Invalid test type ID"}, status=404)

    test_type_str = test_type_obj.test_type.lower()
    no_of_questions = len(data["question_ids"])
    duration_map = {12: 15, 15: 20, 25: 30, 40: 45, 55: 60}
    duration_of_test = (
        10 if no_of_questions < 10 else
        duration_map.get(no_of_questions, 30) if test_type_str == "mcq test"
        else {1: 20, 2: 40, 3: 60}.get(no_of_questions, 60)
    )

    student = candidate_master.objects.filter(id=data["student_id"],deleted=0).first()
    if not student:
        return Response({"error": "Student not found"}, status=404)

    # ‚úÖ Use existing test_master or create if not exists
    tm, created = test_master.objects.get_or_create(
        test_name=test_name,
        defaults={
            "test_type_id_id": data["test_type_id"],
            "question_type_id_id": data["question_type_id"],
            "skill_type_id_id": data["skill_type_id"]
        }
    )

    rule_obj = rules.objects.filter(rule_name__iexact=test_type_obj.test_type,deleted=0).first()
    if not rule_obj:
        rule_obj = rules.objects.filter(id=1).first()
        if not rule_obj:
            return Response({"error": "No rule found"}, status=500)
    # Fetch role from login table using student.user_name
    user_login = login.objects.filter(user_name=student.user_name,deleted=0).first()
    user_role = user_login.role if user_login else "unknown"


    # ‚úÖ Check if test already assigned to candidate
    existing = tests_candidates_map.objects.filter(test_name=test_name, student_id=student,deleted=0).first()

    if existing:
        print("üîÑ Updating existing test assignment")
        assign_count = (existing.assign_count or 1) + 1

        existing.assign_count = assign_count
        existing.question_id = paper
        existing.question_ids = data["question_ids"]
        existing.no_of_question = no_of_questions
        existing.college_id = student.college_id
        existing.department_id = student.department_id
        existing.dtm_start = timezone.now()
        existing.dtm_start1 = timezone.now()
        existing.dtm_created = timezone.now()
        existing.duration = duration_of_test
        existing.duration_type = "QuestionTime"
        existing.rules_id = rule_obj
        existing.is_active = False
        existing.created_by = user_role

        existing.save()
        tcm = existing

    else:
        print("üÜï Creating new test assignment")
        tcm = tests_candidates_map.objects.create(
            test_name=test_name,
            question_id=paper,
            question_ids=data["question_ids"],
            no_of_question=no_of_questions,
            student_id=student,
            college_id=student.college_id,
            department_id=student.department_id,
            dtm_start=timezone.now(),
            dtm_start1=timezone.now(),
            dtm_created=timezone.now(),
            duration=duration_of_test,
            duration_type="QuestionTime",
            is_active=False,
            rules_id=rule_obj,
            assign_count=1,
            avg_mark=0,
            total_score=0,
            stu_avg_mark=0,
            created_by=user_role

        )

    return Response({
        "test_master_id": tm.id,
        "candidates_map_id": tcm.id,
        "question_ids": data["question_ids"],
        "test_name": tm.test_name,
        "duration": duration_of_test,
        "assign_count": tcm.assign_count,
        "stu_avg_mark": tcm.stu_avg_mark
    }, status=201)

@api_view(['GET'])
def get_tests_candidates_map_by_id(request, test_candidates_id):
    try:
        # Fetch by primary key (ID)
        test_map = tests_candidates_map.objects.filter(
            id=test_candidates_id,
            deleted=0
        ).select_related(
            'college_id', 'department_id', 'question_id', 'student_id', 'rules_id'
        ).values(
            'id',
            'test_name',
            'college_id__id',
            'college_id__college',
            'department_id__id',
            'department_id__department',
            'question_id__id',
            'question_id__question_paper_name',
            'question_id__test_type',
            'student_id__id',
            'student_id__students_name',
            'student_id__user_name',
            'dtm_start',
            'dtm_end',
            'attempt_count',
           'is_camera_on',
            'is_active',
            'duration',
            'duration_type',
            'year',
            'rules_id__id',
            'rules_id__rule_name',
            'rules_id__instruction',
            'need_candidate_info',
            'total_score',
            'avg_mark'
        ).first()

        if not test_map:
            return Response({"error": "Test candidate map not found"}, status=status.HTTP_404_NOT_FOUND)

        # Format response
        result = {
            'id': test_map['id'],
            'test_name': test_map['test_name'],
            'college_id_id': test_map['college_id__id'],
            'college_id': test_map['college_id__college'],
            'department_id_id': test_map['department_id__id'],
            'department_id': test_map['department_id__department'],
            'question_id': test_map['question_id__id'],
            'question_paper_name': test_map['question_id__question_paper_name'],
            'test_type': test_map['question_id__test_type'],
            'student_id': test_map['student_id__id'],
            'student_name': test_map['student_id__students_name'],
            'user_name': test_map['student_id__user_name'],
            'dtm_start': test_map['dtm_start'],
            'dtm_end': test_map['dtm_end'],
            'attempt_count': test_map['attempt_count'],
            'is_camera_on': test_map['is_camera_on'],
            'is_active': test_map['is_active'],
            'duration': test_map['duration'],
            'duration_type': test_map['duration_type'],
            'year': test_map['year'],
            'rules_id': test_map['rules_id__id'],
            'rules': test_map['rules_id__rule_name'],
            'instruction': test_map['rules_id__instruction'],
            'need_candidate_info': test_map['need_candidate_info'],
            'total_score': test_map['total_score'],
            'avg_mark': test_map['avg_mark']
        }

        return Response(result)

    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['POST']) 
def increment_attempt_count(request):
    """
    Increment attempt_count for a specific test_name and student_id.
    Required POST body: { "test_name": "XYZ", "student_id": 123 }
    """
    print("üöÄ Starting increment_attempt_count view")

    test_name = request.data.get("test_name")
    student_id = request.data.get("student_id")
    print(f"üì• Backend received data: test_name={test_name}, student_id={student_id}")

    if not test_name or not student_id:
        print("‚ùå Missing test_name or student_id")
        return Response(
            {"error": "Both 'test_name' and 'student_id' are required."},
            status=status.HTTP_400_BAD_REQUEST
        )

    print("üîç Querying for candidate with test_name, student_id and deleted=0")
    candidate = tests_candidates_map.objects.filter(
        test_name=test_name, student_id=student_id, deleted=0
    ).order_by('-id').first()

    if not candidate:
        print("‚ùå No matching candidate found.")
        return Response(
            {"error": "No matching record found for the given test_name and student_id."},
            status=status.HTTP_404_NOT_FOUND
        )

    print(f"‚úÖ Candidate found: ID={candidate.id}, current attempt_count={candidate.attempt_count}")

    # Increment the attempt_count
    if candidate.attempt_count is None:
        candidate.attempt_count = 1
        print("‚ûï attempt_count was None, setting to 1")
    else:
        candidate.attempt_count += 1
        print(f"üîÅ Incremented attempt_count to {candidate.attempt_count}")

    candidate.save(update_fields=['attempt_count'])
    print(f"üíæ Saved updated attempt_count={candidate.attempt_count} to DB")

    return Response(
        {
            "message": "Attempt count incremented.",
            "test_name": test_name,
            "student_id": student_id,
            "attempt_count": candidate.attempt_count
        },
        status=status.HTTP_200_OK
    )

@api_view(['POST'])
def get_existing_test_stats(request):
    student_id = request.data.get("student_id")
    question_name_id = request.data.get("question_name_id")  # ‚úÖ question_paper_master.id
    difficulty_level = request.data.get("difficulty_level")

    if not all([student_id, question_name_id, difficulty_level]):
        return Response({"error": "Missing parameters"}, status=400)

    # Get folder name from question paper
    paper = question_paper_master.objects.filter(id=question_name_id,deleted=0).first()
    if not paper:
        return Response({"error": "Invalid question paper ID"}, status=404)

    folder_name = paper.folder_name

    # ‚úÖ Now include difficulty_level in the test name
    test_name = f"{folder_name}_{difficulty_level}_{student_id}"

    # Fetch matching test record
    test_map = tests_candidates_map.objects.filter(
        test_name=test_name,
        student_id=student_id,
        question_id_id=question_name_id,deleted=0
    ).order_by("-dtm_created").first()

    if not test_map:
        return Response({
            "test_name": test_name,
            "assign_count": 0,
            "stu_avg_mark": 0
        })

    return Response({
        "test_name": test_map.test_name,
        "assign_count": test_map.assign_count or 0,
        "stu_avg_mark": test_map.stu_avg_mark or 0
    })

from random import sample
from collections import defaultdict

@api_view(['POST'])
def get_tests_by_difficulty_and_folder(request):
    folder_name = request.data.get('folder_name')
    topic = request.data.get('topic')
    sub_topic = request.data.get('sub_topic')  # ‚úÖ new field

    print(f"üîç Incoming folder_name: {folder_name}")
    print(f"üîç Incoming topic: {topic}")
    print(f"üîç Incoming sub_topic: {sub_topic}")

    if not folder_name or not topic or not sub_topic:
        print("‚ùå Missing folder_name, topic, or sub_topic in request.")
        return Response({'error': 'Missing folder_name, topic, or sub_topic'}, status=400)

    try:
        # 1. Get matching question paper
        paper_qs = question_paper_master.objects.filter(
            folder_name=folder_name,
            topic=topic,
            sub_topic=sub_topic,
            deleted=0
            #no_of_questions__gt=0
        ).order_by('-id')

        if not paper_qs.exists():
            print("‚ö†Ô∏è No matching question_paper_master found.")
            return Response({'error': 'No question paper found for the given criteria'}, status=404)

        question_paper = paper_qs.first()
        print(f"üìÑ Selected question_paper_id: {question_paper.id}")

        # 2. Get questions from that paper
        questions = question_master.objects.filter(
            question_name_id=question_paper,
            deleted=0
        )

        print(f"üìä Total valid questions fetched: {questions.count()}")

        if not questions.exists():
            return Response({'error': 'No questions found for this paper'}, status=404)

        # 3. Group questions by difficulty
        difficulty_groups = defaultdict(list)
        for q in questions:
            level = q.difficulty_level.strip() if q.difficulty_level else 'Unknown'
            difficulty_groups[level].append(q.id)

        print(f"üìÅ Grouped question IDs by difficulty: {dict(difficulty_groups)}")

        # 4. Sort by group size
        sorted_groups = sorted(difficulty_groups.items(), key=lambda x: len(x[1]), reverse=True)

        # 5. Determine group size
        topic_lower = topic.lower()
        group_size = 25 if topic_lower in ['aptitude', 'softskill'] else 3
        print(f"‚öôÔ∏è Group size set: {group_size}")

        final_result = {}

        for difficulty, q_ids in sorted_groups:
            total = len(q_ids)
            remaining = q_ids.copy()
            test_list = []
            test_count = 1

            print(f"\nüìà Difficulty: {difficulty} | Total: {total}")

            while len(remaining) >= group_size:
                selected = sample(remaining, group_size)
                test_name = f"{folder_name}_Test{test_count}"
                test_list.append({'test_name': test_name, 'question_ids': selected})
                print(f"‚úÖ Test Created: {test_name} | Questions: {selected}")
                remaining = list(set(remaining) - set(selected))
                test_count += 1

            if remaining:
                test_name = f"{folder_name}_Test{test_count}"
                test_list.append({'test_name': test_name, 'question_ids': remaining})
                print(f"üîÑ Leftover Test Created: {test_name} | Questions: {remaining}")

            final_result[difficulty] = {
                'total_questions': total,
                'test_groups': test_list
            }

        return Response({
            'folder_name': folder_name,
            'topic': topic,
            'sub_topic': sub_topic,
            'question_paper_master_id': question_paper.id,
            'difficulty_level_distribution': final_result
        })

    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        return Response({'error': str(e)}, status=500)

from django.db.models import F


@api_view(['GET'])
def get_combined_question_type_skill_folder(request):
    try:
        # Step 1: Fetch distinct test_types used in question_paper_master
        valid_test_types = question_paper_master.objects.filter(
            test_type__isnull=False,
            folder_name__isnull=False
        ).values_list('test_type', flat=True).distinct()

        valid_test_types = set(t.strip() for t in valid_test_types if t)
        print(f"‚úÖ Valid test types: {valid_test_types}")

        # Step 2: Get valid (non-deleted) (question_type, skill_type) pairs
        skills = skill_type.objects.filter(
            deleted=0,
            question_type_id__isnull=False
        ).values(
            question_type=F('question_type_id__question_type'),
            skill=F('skill_type')
        )
        valid_pairs = set((s['question_type'], s['skill']) for s in skills)
        print(f"‚úÖ Valid (question_type, skill_type) pairs: {valid_pairs}")

        # Step 3: Fetch all valid question_paper_master rows
        qpm_rows = question_paper_master.objects.filter(
            test_type__in=valid_test_types,
            folder_name__isnull=False,deleted=0
        ).values(
            'test_type', 'topic', 'sub_topic', 'folder_name'
        )

        print(f"üìù Total question_paper_master rows: {len(qpm_rows)}")

        # Step 4: Build nested structure: test_type -> topic -> sub_topic -> folder
        result = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))

        for row in qpm_rows:
            test_type = row['test_type'] or 'Unknown'
            topic = row['topic'] or 'Unknown'
            sub_topic = row['sub_topic'] or 'Unknown'
            folder = row['folder_name']

            if (topic, sub_topic) in valid_pairs:
                result[test_type][topic][sub_topic].add(folder)

        # Step 5: Convert sets to list and format properly
        final = {}
        for test_type, topics in result.items():
            final[test_type] = {}
            for topic, subtopics in topics.items():
                topic_list = []
                for sub_topic, folders in subtopics.items():
                    folders = list(folders)
                    if len(folders) == 1 and folders[0] == sub_topic:
                        topic_list.append(sub_topic)
                    else:
                        topic_list.append({sub_topic: folders})
                final[test_type][topic] = topic_list

        return Response(final, status=status.HTTP_200_OK)

    except Exception as e:
        print("‚ùå Error:", str(e))
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

@api_view(['GET'])
def get_student_test_attempts(request):
    student_id = request.GET.get('student_id')

    if not student_id:
        return Response({"error": "Missing student_id"}, status=400)

    attempts = tests_candidates_map.objects.filter(student_id=student_id,deleted=0)
    data = []

    for attempt in attempts:
        data.append({
            "test_name": attempt.test_name,
            "is_active": attempt.is_active,
            "status":attempt.status,
            "attempt_count": attempt.attempt_count or 0,
            "stu_avg_mark": attempt.stu_avg_mark or 0,
        })

    return Response({"attempts": data}, status=200)


@api_view(['POST'])
def update_test_status_request(request):
    test_name = request.data.get('test_name')
    student_id = request.data.get('student_id')
    new_status = request.data.get('status') or 'Requested'  # ‚úÖ Default value

    if not test_name or not student_id:
        return Response({"error": "Missing test_name or student_id"}, status=400)

    try:
        test_record = tests_candidates_map.objects.filter(
            test_name=test_name,
            student_id_id=student_id,deleted=0
        ).first()

        if not test_record:
            return Response({"error": "Test record not found"}, status=404)

        test_record.status = new_status
        test_record.save()

        return Response({
            "message": "Status updated successfully",
            "status": test_record.status
        }, status=200)

    except Exception as e:
        return Response({"error": str(e)}, status=500)

@api_view(['POST'])
def update_student_avg_mark(request):
    test_name = request.data.get("test_name")
    student_id = request.data.get("student_id")
    avg_mark = request.data.get("avg_mark")

    print("üì• Incoming data:")
    print(f"Test Name: {test_name}")
    print(f"Student ID: {student_id}")
    print(f"Avg Mark: {avg_mark}")

    if not test_name or not student_id or avg_mark is None:
        print("‚ùå Missing data in request.")
        return Response({"error": "Missing test_name, student_id, or avg_mark"}, status=400)

    try:
        tcm = tests_candidates_map.objects.filter(test_name=test_name, student_id_id=student_id,deleted=0).first()

        if not tcm:
            print("‚ùå No test record found for the given student and test.")
            return Response({"error": "Test record not found"}, status=404)

        attempt_count = tcm.attempt_count or 1  # Default to 1 if None
        avg_mark = float(avg_mark)

        print(f"üî¢ Current attempt count: {attempt_count}")
        print(f"üìä Existing stu_avg_mark: {tcm.stu_avg_mark}")
        print(f"üì• Incoming avg_mark: {avg_mark}")

        # Apply new logic
        if attempt_count == 1:
            new_stu_avg = avg_mark
            print(f"üìò attempt_count == 1 ‚Üí stu_avg_mark = {avg_mark}")
        else:
            prev_avg = tcm.stu_avg_mark or 0.0
            new_stu_avg = (prev_avg + avg_mark) / attempt_count
            print(f"üìò attempt_count >= 2 ‚Üí stu_avg_mark = ({prev_avg} + {avg_mark}) / {attempt_count} = {new_stu_avg}")

        # Update only stu_avg_mark
        tcm.stu_avg_mark = round(new_stu_avg, 2)
        tcm.save()

        print("‚úÖ Record updated successfully.")
        print(f"‚úÖ Final stu_avg_mark: {round(new_stu_avg, 2)}")

        return Response({
            "message": "Student average updated successfully",
            "stu_avg_mark": round(new_stu_avg, 2),
            "attempt_count": attempt_count
        }, status=200)

    except Exception as e:
        print(f"‚ùå Exception occurred: {e}")
        return Response({"error": str(e)}, status=500)

@api_view(['POST'])
def update_trainer_batches(request):
    user_names = request.data.get('user_names', [])
    batch_no = request.data.get('batch_no', '')

    if not user_names or not batch_no:
        return Response({'error': 'user_names and batch_no are required'}, status=400)

    trainer_master.objects.filter(user_name__in=user_names,deleted=0).update(batch_no=batch_no)

    return Response({'message': 'Batch updated successfully'}, status=200)

@api_view(['GET'])
def get_requested_test_candidates(request):
    queryset = tests_candidates_map.objects.filter(status='Requested', deleted=0).select_related('student_id')

    data = [
        {
            'id': item.id,
            'student_id': item.student_id.id if item.student_id else None,
            'user_name': item.student_id.user_name if item.student_id else None,
            'test_name': item.test_name,
        }
        for item in queryset
    ]

    return Response(data)



@api_view(['POST'])
def reassign_test_candidate(request):
    id = request.data.get('id')
    action = request.data.get('action')  # 'accept' or 'decline'
    
    try:
        candidate = tests_candidates_map.objects.get(id=id)
        if action == 'accept':
            candidate.status = 'reassigned'
            candidate.is_reassigned = True
            candidate.is_active = False
            candidate.total_score = 0
            candidate.avg_mark = 0
          #  candidate.assign_count = (candidate.assign_count or 0) + 1
        elif action == 'decline':
            candidate.status = 'Declined'
        candidate.save()
        return Response({'message': f'{action.capitalize()} successful'}, status=200)
    except tests_candidates_map.DoesNotExist:
        return Response({'error': 'Candidate not found'}, status=404)
    except Exception as e:
        return Response({'error': str(e)}, status=500)


from .models import employee_db, login
from .serializers import EmployeeSerializer

class ExcelImportView_EmployeeDBol(APIView):
    def post(self, request, format=None):
        print("üì• Incoming FILES:", request.FILES) 
        current_date_time = timezone.now()

        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded.'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']
        if not file.name.endswith('.xlsx'):
            return Response({'error': 'Only .xlsx files are accepted.'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
        except Exception as e:
            return Response({'error': f'Error reading Excel file: {str(e)}'}, status=status.HTTP_400_BAD_REQUEST)

        # Rename Excel headers to model fields
        header_mapping = {
            'Name': 'name',
            'Emp ID**': 'emp_id',
            'Designation': 'designation',
            'Location': 'location',
            'Mobile No': 'mobile_no',
            'Email ID': 'email_id',
            'Password**': 'password'
        }
        df.rename(columns=header_mapping, inplace=True)

        # Required fields
        required_fields = ['emp_id', 'password']
        missing = [field for field in required_fields if field not in df.columns]
        if missing:
            return Response({'error': f'Missing column(s): {", ".join(missing)}'}, status=status.HTTP_400_BAD_REQUEST)

        # Check blank values in required fields
        blank_fields = [field.title().replace('_', ' ') for field in required_fields
                        if df[field].isnull().any() or df[field].astype(str).str.strip().eq('').any()]
        if blank_fields:
            return Response({'error': f"{', '.join(blank_fields)} column(s) have blank values."}, status=status.HTTP_400_BAD_REQUEST)

        # Remove duplicates in Excel itself
        duplicate_ids = df[df.duplicated(subset=['emp_id'], keep='first')]['emp_id'].astype(str).unique()
        if duplicate_ids.size > 0:
            return Response({'error': f'Duplicate Emp IDs in file: {", ".join(duplicate_ids)}'}, status=status.HTTP_400_BAD_REQUEST)

        df = df.drop_duplicates(subset=['emp_id'], keep='first')

        # Add derived and default fields
        df['user_name'] = df['emp_id']  # user_name = emp_id
        df['deleted'] = 0
        df['created_by'] = 'excel_upload'
        df['dtm_created'] = current_date_time
        # Clean email_id
        if 'email_id' in df.columns:
            df['email_id'] = df['email_id'].astype(str).str.strip()
            df['email_id'] = df['email_id'].replace({'': None, 'nan': None, 'NaN': None})

        # Check existing emp_ids and user_names
        existing_empids = set(employee_db.objects.filter(emp_id__in=df['emp_id']).values_list('emp_id', flat=True))
        existing_usernames = set(login.objects.filter(user_name__in=df['user_name']).values_list('user_name', flat=True))
        already_existing = existing_empids.union(existing_usernames)

        if already_existing:
            return Response({'error': f"Already existing Emp ID(s) or Username(s): {', '.join(map(str, already_existing))}"}, status=status.HTTP_400_BAD_REQUEST)

        try:
            with transaction.atomic():
                # Save employee records
                employee_serializer = EmployeeSerializer(data=df.to_dict(orient='records'), many=True)
                if not employee_serializer.is_valid():
                    print("‚ùå Serializer Errors:", employee_serializer.errors)  # Add this
                    return Response({
                        'error': 'Employee data validation failed',
                        'details': employee_serializer.errors
                    }, status=status.HTTP_400_BAD_REQUEST)


                # Save login records
                login_records = [
                    login(
                        user_name=row['emp_id'],
                        email_id=row.get('email_id', None),
                        password=row['password'],
                        role='Employee'
                    )
                    for _, row in df.iterrows()
                ]
                login.objects.bulk_create(login_records)

        except Exception as e:
            traceback.print_exc()  # ‚úÖ Print to terminal for debugging
            return Response({'error': f'Unexpected error during save: {str(e)}'}, status=status.HTTP_400_BAD_REQUEST)

        return Response({
            'message': 'Employee and login data uploaded successfully.',
            'uploaded_count': len(df)
        }, status=status.HTTP_201_CREATED)

from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from django.db import transaction
from django.utils import timezone
import pandas as pd
import traceback

from .models import employee_db, login
from .serializers import EmployeeSerializer


class ExcelImportView_EmployeeDB(APIView):
    def post(self, request, format=None):
        print("üì• Incoming FILES:", request.FILES)
        current_date_time = timezone.now()

        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded.'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']
        if not file.name.endswith('.xlsx'):
            return Response({'error': 'Only .xlsx files are accepted.'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
        except Exception as e:
            return Response({'error': f'Error reading Excel file: {str(e)}'}, status=status.HTTP_400_BAD_REQUEST)

        # Rename headers
        header_mapping = {
            'Name': 'name',
            'Emp ID**': 'emp_id',
            'Designation': 'designation',
            'Location': 'location',
            'Mobile No': 'mobile_no',
            'Email ID': 'email_id',
            'Password**': 'password'
        }
        df.rename(columns=header_mapping, inplace=True)

        required_fields = ['emp_id', 'password']
        missing = [f for f in required_fields if f not in df.columns]
        if missing:
            return Response({'error': f'Missing column(s): {", ".join(missing)}'}, status=status.HTTP_400_BAD_REQUEST)

        blank_fields = [field.title().replace('_', ' ') for field in required_fields
                        if df[field].isnull().any() or df[field].astype(str).str.strip().eq('').any()]
        if blank_fields:
            return Response({'error': f"{', '.join(blank_fields)} column(s) have blank values."}, status=status.HTTP_400_BAD_REQUEST)

        # Remove duplicates within the file
        df = df.drop_duplicates(subset=['emp_id'], keep='first')

        # Add extra fields
        df['user_name'] = df['emp_id']
        df['deleted'] = 0
        df['created_by'] = 'excel_upload'
        df['dtm_created'] = current_date_time

        # Clean email
        if 'email_id' in df.columns:
            df['email_id'] = df['email_id'].astype(str).str.strip().replace({'': None, 'nan': None, 'NaN': None})

        try:
            with transaction.atomic():
                inserted = 0
                updated = 0

                for _, row in df.iterrows():
                    emp_id = str(row['emp_id']).strip()

                    # Build employee data dict
                    emp_data = {
                        'name': row.get('name'),
                        'emp_id': emp_id,
                        'designation': row.get('designation'),
                        'location': row.get('location'),
                        'mobile_no': row.get('mobile_no'),
                        'email_id': row.get('email_id'),
                        'user_name': emp_id,
                        'deleted': 0,
                        'created_by': 'excel_upload',
                        'dtm_created': current_date_time
                    }

                    emp_instance = employee_db.objects.filter(emp_id=emp_id).first()
                    if emp_instance:
                        for k, v in emp_data.items():
                            setattr(emp_instance, k, v)
                        emp_instance.save()
                        updated += 1
                    else:
                        serializer = EmployeeSerializer(data=emp_data)
                        if serializer.is_valid():
                            serializer.save()
                            inserted += 1
                        else:
                            print("‚ùå Serializer Errors:", serializer.errors)
                            return Response({
                                'error': 'Employee data validation failed',
                                'details': serializer.errors
                            }, status=status.HTTP_400_BAD_REQUEST)

                    # Create or update login
                    login_instance = login.objects.filter(user_name=emp_id).first()
                    if login_instance:
                        login_instance.email_id = row.get('email_id')
                        login_instance.password = row['password']
                        login_instance.role = 'Employee'
                        login_instance.save()
                    else:
                        login.objects.create(
                            user_name=emp_id,
                            email_id=row.get('email_id'),
                            password=row['password'],
                            role='Employee'
                        )

        except Exception as e:
            traceback.print_exc()
            return Response({'error': f'Unexpected error: {str(e)}'}, status=status.HTTP_400_BAD_REQUEST)

        return Response({
            'message': 'Employee and login records processed successfully.',
            'inserted': inserted,
            'updated': updated
        }, status=status.HTTP_200_OK)


from .models import employee_db, employee_test_assign,tests_emp_answer
class AssignTestToEmployees(APIView):
    def post(self, request):
        location_list = request.data.get("location", [])  # Expecting a list now
        employee_ids = request.data.get("employee_ids", [])
        test_type = request.data.get("test_type")
        test_date = request.data.get("test_date")

        if not test_type:
            return Response({"error": "test_type is required."}, status=400)

        try:
            test_date_obj = datetime.strptime(test_date, "%Y-%m-%d").date() if test_date else timezone.now().date()
        except Exception as e:
            return Response({"error": f"Invalid test_date format. Use YYYY-MM-DD. {str(e)}"}, status=400)

        # üéØ Multiple location support
        employees = employee_db.objects.filter(deleted=0)
        if location_list:
            employees = employees.filter(location__in=location_list)
        elif employee_ids:
            employees = employees.filter(emp_id__in=employee_ids)
        else:
            return Response({"error": "Either location or employee_ids must be provided."}, status=400)

        if not employees.exists():
            return Response({"error": "No matching employees found."}, status=404)

        # ‚úÖ Auto-generate test_name like: HDFC-pre-assessment-test-1
        base_name = f"HDFC-{test_type}-test"
        existing_test_names = employee_test_assign.objects.filter(
            test_type=test_type,
            test_name__startswith=base_name
        ).values_list("test_name", flat=True)

        existing_numbers = []
        for name in existing_test_names:
            try:
                suffix = int(name.split("-")[-1])
                existing_numbers.append(suffix)
            except:
                continue

        next_number = max(existing_numbers, default=0) + 1
        auto_test_name = f"{base_name}-{next_number}"

        # ‚úÖ Fetch appropriate question_paper & questions based on test_type
        folder_name = ''
        if test_type.lower() == 'pre-assessment':
            folder_name = 'pre-assessment'
        elif test_type.lower() == 'post-assessment':
            folder_name = 'post-assessment'

        question_paper = question_paper_master.objects.filter(
            test_type='MCQ Test',
            topic='HDFC',
            folder_name=folder_name
        ).first()

        if not question_paper:
            return Response({
                "error": f"No question paper found for folder '{folder_name}'."
            }, status=404)

        question_ids = list(question_master.objects.filter(
            question_name_id=question_paper.id
        ).values_list('id', flat=True))

        # ‚úÖ Assign the test to employees
        assigned_count = 0
        for emp in employees:
            if not employee_test_assign.objects.filter(employee_id=emp, test_name=auto_test_name).exists():
                employee_test_assign.objects.create(
                    employee_id=emp,
                    test_name=auto_test_name,
                    test_type=test_type,
                    test_date=test_date_obj,
                    test_status="assigned",
                    assign_count=1,
                    question_id=question_paper,
                    question_ids=question_ids
                )
                assigned_count += 1

        return Response({
            "message": f"Test '{auto_test_name}' assigned to {assigned_count} employee(s)."
        }, status=200)


from .serializers import tests_emp_answerSerializer

class TestEmployeeAnswerCreateAPIView(APIView):

    def _create_or_update_answer(self, data):
        print("üîß Step 1: Extracting input data")
        emp_id = data.get("emp_id")
        test_name = data.get("test_name")
        question_id = data.get("question_id")
        print(f"‚û°Ô∏è emp_id: {emp_id}, test_name: {test_name}, question_id: {question_id}")

        if not (emp_id and test_name and question_id):
            print("‚ùå Missing required fields")
            return Response({
                "status": "fail",
                "message": "Missing emp_id, test_name or question_id"
            }, status=status.HTTP_400_BAD_REQUEST)

        try:
            print("üîç Step 2: Fetching employee record")
            employee = employee_db.objects.get(id=emp_id, deleted=0)
            print(f"‚úÖ Found employee: {employee}")
        except employee_db.DoesNotExist:
            print(f"‚ùå Employee with emp_id '{emp_id}' not found")
            return Response({
                "status": "fail",
                "message": f"Employee with emp_id '{emp_id}' not found."
            }, status=status.HTTP_404_NOT_FOUND)

        try:
            print("üîç Step 3: Fetching question record")
            question = question_master.objects.get(id=question_id)
            print(f"‚úÖ Found question: {question}")
        except question_master.DoesNotExist:
            print(f"‚ùå Question with ID '{question_id}' not found")
            return Response({
                "status": "fail",
                "message": f"Question with ID '{question_id}' not found."
            }, status=status.HTTP_404_NOT_FOUND)

        print("üõ†Ô∏è Step 4: Preparing data for update or create")
        defaults = {
            "answer": data.get("answer"),
            "result": data.get("result"),
        }
        print(f"‚û°Ô∏è Defaults: {defaults}")

        print("üíæ Step 5: Updating or creating answer record")
        obj, created = tests_emp_answer.objects.update_or_create(
            emp_id=employee,
            test_name=test_name,
            question_id=question,
            defaults=defaults
        )
        print("‚úÖ Record created" if created else "‚úÖ Record updated")

        print("üì¶ Step 6: Serializing response data")
        serializer = tests_emp_answerSerializer(obj)
        print("‚úÖ Serialization complete")

        return Response({
            "status": "success",
            "message": "Created" if created else "Updated",
            "data": serializer.data
        }, status=status.HTTP_200_OK)

    def post(self, request, *args, **kwargs):
        print("\nüì• POST request received")
        return self._create_or_update_answer(request.data)

    def put(self, request, *args, **kwargs):
        print("\nüì• PUT request received")
        return self._create_or_update_answer(request.data)

@api_view(['GET'])
@cache_page(60)  # cache the response for 60 seconds
def get_tests_emp_answer(request):
    username = request.query_params.get('username') 
    test_name = request.query_params.get('testName')

    if not username or not test_name:
        return Response({
            "status": "fail",
            "message": "Both 'username' and 'testName' query parameters are required."
        }, status=status.HTTP_400_BAD_REQUEST)

    # Fetch test assignment record
    assign_qs = employee_test_assign.objects.filter(
        deleted=0, employee_id__user_name=username, test_name=test_name
    ).values('is_active', 'test_status')

    if assign_qs.exists() and assign_qs.first().get('is_active') is False:
        test_candidate_answer_data = []  # Test reassigned or inactive
    else:
        # Fetch candidate answers
        test_candidate_answer_data = tests_emp_answer.objects.filter(
            emp_id__user_name=username,
            test_name=test_name
        ).select_related('emp_id', 'question_id').order_by('-id').values(
            'id',
            'emp_id__id',
            'question_id__id',
            'test_name',
            'answer',
            'result',
        )

    return Response(test_candidate_answer_data)

@csrf_exempt
@cache_page(60 * 60)
def get_questions_HDFC_filter_mcq_pre(request, test_name):
    try:
        print(f"üì• Fetching MCQ Questions for test_name: {test_name}")

        # 1. Fetch test entry by test_name
        test_entry = employee_test_assign.objects.filter(test_name=test_name).first()

        if not test_entry:
            return JsonResponse({'error': 'Invalid test_name or test not found'}, status=404)

        question_paper_id = test_entry.question_id.id if test_entry.question_id else None
        question_ids_list = test_entry.question_ids or []

        if not question_paper_id or not question_ids_list:
            return JsonResponse({'error': 'Test entry missing question_id or question_ids'}, status=400)

        cache_key = f'questions_IO_filter_mcq_{test_name}'
        question_data = cache.get(cache_key)

        if question_data:
            print(f'[CACHE HIT] {cache_key}')
            return JsonResponse(question_data, safe=False)

        print(f'[CACHE MISS] {cache_key}')

        # 2. Fetch filtered questions
        questions = question_master.objects.filter(
            deleted=0,
            question_name_id=question_paper_id,
            id__in=question_ids_list
        ).select_related('question_name_id').only(
            'id', 'question_name_id__id', 'question_name_id__question_paper_name',
            'question_text', 'question_image_data',
            'option_a_image_data', 'option_b_image_data',
            'option_c_image_data', 'option_d_image_data',
            'option_a', 'option_b', 'option_c', 'option_d',
            'mark', 'answer', 
        )

        def encode(img):
            return base64.b64encode(img).decode('utf-8') if img else None

        question_data = [{
            'id': q.id,
            'question_name_id': q.question_name_id.id,
            'question_paper_name': q.question_name_id.question_paper_name,
            'question_text': q.question_text,
            'question_image_data': encode(q.question_image_data),
            'option_a_image_data': encode(q.option_a_image_data),
            'option_b_image_data': encode(q.option_b_image_data),
            'option_c_image_data': encode(q.option_c_image_data),
            'option_d_image_data': encode(q.option_d_image_data),
            'option_a': q.option_a,
            'option_b': q.option_b,
            'option_c': q.option_c,
            'option_d': q.option_d,
            'mark': q.mark,
           
            'answer': q.answer,

        } for q in questions]

        random.shuffle(question_data)
        cache.set(cache_key, question_data, timeout=3600)

        return JsonResponse(question_data, safe=False)

    except Exception as e:
        print(f"‚ùå Unexpected error: {str(e)}")
        return JsonResponse({'error': str(e)}, status=500)

@api_view(['PUT', 'PATCH'])
def update_testemp_is_active(request, pk):
    """
    Mark the candidate record as active and reset scores.
    """
    # Fetch the instance or return 404
    tests_candidate = get_object_or_404(employee_test_assign, pk=pk)

    # Set the fields
    tests_candidate.is_active = True
    tests_candidate.total_score = 0
    tests_candidate.avg_mark   = 0

    # Save only the three changed fields for efficiency
    tests_candidate.save(update_fields=['is_active', 'total_score', 'avg_mark'])

    return Response(
        {
            "message": "Candidate activated and scores reset.",
            "id": pk,
            "is_active": tests_candidate.is_active,
            "total_score": tests_candidate.total_score,
            "avg_mark": tests_candidate.avg_mark
        },
        status=status.HTTP_200_OK
    )

class UpdateEmployeeTestScoreAPIView(APIView):
    def post(self, request):
        emp_id = request.data.get("emp_id")
        test_name = request.data.get("test_name")

        print(f"üîç Received emp_id: {emp_id}, test_name: {test_name}")

        if not emp_id or not test_name:
            print("‚ùå emp_id or test_name is missing")
            return Response({
                "status": "fail",
                "message": "emp_id and test_name are required"
            }, status=status.HTTP_400_BAD_REQUEST)

        try:
            employee = employee_db.objects.get(id=emp_id, deleted=0)
            print(f"‚úÖ Found employee: {employee}")
        except employee_db.DoesNotExist:
            print(f"‚ùå Employee with id {emp_id} not found or deleted")
            return Response({
                "status": "fail",
                "message": f"Employee with emp_id '{emp_id}' not found."
            }, status=status.HTTP_404_NOT_FOUND)

        try:
            assign_obj = employee_test_assign.objects.get(
                employee_id=employee,
                test_name=test_name,
                deleted=0
            )
            print(f"‚úÖ Found assignment object for employee {emp_id} and test {test_name}")
        except employee_test_assign.DoesNotExist:
            print(f"‚ùå No test assignment found for employee '{emp_id}' and test '{test_name}'")
            return Response({
                "status": "fail",
                "message": f"No test assignment found for employee '{emp_id}' and test '{test_name}'"
            }, status=status.HTTP_404_NOT_FOUND)

        # Get answered questions and their result
        answers = tests_emp_answer.objects.filter(
            emp_id=employee,
            test_name=test_name
        )
        print(f"üìù Total answers submitted: {answers.count()}")

        total_score = sum(answer.result for answer in answers if answer.result is not None)
        print(f"‚úÖ Total score (sum of result): {total_score}")

        # Calculate total marks by summing marks of all assigned questions
        total_marks = 0
        question_ids = assign_obj.question_ids or []
        print(f"üì¶ Assigned question IDs: {question_ids}")

        if question_ids:
            from django.db.models import Sum

            total_marks = question_master.objects.filter(id__in=question_ids).aggregate(
                total=Sum('mark')
            )['total'] or 0

        print(f"üìö Total marks (sum of question marks): {total_marks}")

        avg_mark = round((total_score / total_marks) * 100) if total_marks > 0 else 0
        print(f"üìä Calculated average mark (avg_mark): {avg_mark}")

        # Update the assignment record
        assign_obj.total_score = total_score
        assign_obj.avg_mark = avg_mark
        assign_obj.save()
        print("‚úÖ Assignment record updated successfully")

        return Response({
            "status": "success",
            "message": "Score and average updated successfully",
            "data": {
                "emp_id": emp_id,
                "test_name": test_name,
                "total_score": total_score,
                "total_marks": total_marks,
                "avg_mark": avg_mark
            }
        }, status=status.HTTP_200_OK)

@api_view(['GET'])
def get_employee_dropdown(request):
    """
    Returns all active (non-deleted) employee names and emp_ids for dropdown use.
    """
    employees = employee_db.objects.filter(deleted=0).values('emp_id', 'name')
    return Response(list(employees))

from .models import employee_db

@api_view(['GET'])
def get_location_dropdown(request):
    locations = (
        employee_db.objects.filter(deleted=0)
        .exclude(location__isnull=True)
        .exclude(location__exact='')
        .values_list('location', flat=True)
        .distinct()
    )
    return Response(sorted(locations))



@api_view(['GET'])
def test_assignment_summary(request):
    search_term = request.GET.get('search', '')  # Get `search` from query params

    # Get filtered base queryset
    queryset = employee_test_assign.objects.filter(deleted=0)
    if search_term:
        queryset = queryset.filter(test_name__icontains=search_term)

    # Group by test_name with annotations
    grouped_data = (
        queryset
        .values('test_name')
        .annotate(
            total_assigned=Count('id'),
            total_attended=Count('id', filter=Q(is_active=True)),
            latest_assigned=Max('dtm_created')
        )
        .order_by('test_name')
    )

    # Apply pagination
    paginator = CustomPagination()
    paginated_data = paginator.paginate_queryset(grouped_data, request)

    return paginator.get_paginated_response(paginated_data)


from .serializers import EmployeeCreateSerializer

@api_view(['POST'])
def create_employee(request):
    serializer = EmployeeCreateSerializer(data=request.data)
    if serializer.is_valid():
        serializer.save()
        return Response({"message": "Employee created successfully"}, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


from .serializers import EmployeedisplaySerializer

@api_view(['GET'])
def employee_list(request):
    search = request.GET.get('search', '')
    queryset = employee_db.objects.filter(deleted=0)

    if search:
        queryset = queryset.filter(
            Q(name__icontains=search) |
            Q(emp_id__icontains=search) |
            Q(location__icontains=search) |
            Q(mobile_no__icontains=search) |
            Q(email_id__icontains=search) |
            Q(designation__icontains=search)
        )

    paginator = CustomPagination()
    result_page = paginator.paginate_queryset(queryset, request)
    serializer = EmployeedisplaySerializer(result_page, many=True)
    return paginator.get_paginated_response(serializer.data)


@api_view(['GET'])
def get_attended_test_details(request):
    test_name = request.GET.get('test_name')

    if not test_name:
        return Response({'error': 'test_name parameter is required'}, status=400)

    assignments = (
        employee_test_assign.objects
        .filter(test_name=test_name, is_active=True, deleted=0)
        .select_related('employee_id')
        .values(
            'test_name',
            'total_score',
            'avg_mark',
            'test_date',
            emp_id=F('employee_id__emp_id'),
            name=F('employee_id__name'),
            email_id=F('employee_id__email_id'),
            mobile_no=F('employee_id__mobile_no'),
            location=F('employee_id__location'),
            designation=F('employee_id__designation'),
        )
    )

    return Response(list(assignments))


@api_view(['GET'])
def get_upcomming_MCQ_emp(request, user_name):
    print(f"üîç Received request to fetch upcoming MCQ tests for username: {user_name}")

    # Step 1: Get current date
    current_date = datetime.now().date()
    print(f"üìÖ Current Date: {current_date}")

    # Step 2: Query to fetch upcoming pre-assessment tests
    print("üîé Fetching data from employee_test_assign table...")
    tests_candidates = employee_test_assign.objects.filter(
        Q(deleted=0),
        Q(employee_id__user_name=user_name),
       # Q(test_type='pre-assessment'),
        Q(is_active=False),
      #  Q(test_date__gte=current_date)
    ).select_related(
        'question_id', 'employee_id'
    ).values(
        'id',
        'test_name',
        'test_type',
        'question_id__id',
        'question_id__question_paper_name',
        'question_ids',
        'employee_id__id',
        'employee_id__name',
        'employee_id__user_name',
        'is_active',
        'test_date',
    )

    print(f"‚úÖ Total records fetched: {len(tests_candidates)}")

    # Step 3: Transform data keys
    test_candidate_map_data = []
    for testing in tests_candidates:
        print(f"üì¶ Processing test: {testing['test_name']} | Date: {testing['test_date']}")
        test_candidate_map_data.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
            'test_type': testing['test_type'],
            'question_id': testing['question_id__id'],
            'question_paper_name': testing['question_id__question_paper_name'],
            'question_ids': testing['question_ids'],
            'employee_id': testing['employee_id__id'],
            'employee_user_name': testing['employee_id__user_name'],
            'employee_name': testing['employee_id__name'],
            'is_active': testing['is_active'],
            'test_date': testing['test_date'],
        })

    # Step 4: Return response
    print("üì§ Returning response with upcoming test data.")
    return Response(test_candidate_map_data)

@api_view(['GET', 'PUT'])
def employee_by_username(request):
    user_name = request.GET.get('user_name')

    if not user_name:
        return Response({'error': 'user_name parameter is required'}, status=status.HTTP_400_BAD_REQUEST)

    try:
        employee = employee_db.objects.get(user_name=user_name, deleted=0)
    except employee_db.DoesNotExist:
        return Response({'error': 'Employee not found'}, status=status.HTTP_404_NOT_FOUND)

    if request.method == 'GET':
        serializer = EmployeeSerializer(employee)
        return Response(serializer.data)

    elif request.method == 'PUT':
        serializer = EmployeeSerializer(employee, data=request.data, partial=True)
        if serializer.is_valid():
            serializer.save()
            return Response({'message': 'Employee updated successfully', 'data': serializer.data})
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

class CollegeListViewTest(generics.ListAPIView):
    serializer_class = collegeSerializers

    def get_queryset(self):
        queryset = (
            college_master.objects
            .filter(deleted=0)
            .values('id', 'college',  'college_group', 'college_code')
            .distinct()
        )
        return queryset

class UpdateEligibleStudentselectedView(APIView):
    def post(self, request, format=None):
        print("üì® Received POST request to update selected students")

        student_ids = request.data.get('student_ids', [])
        round_of_interview = request.data.get('round_of_interview')
        job_id_value = request.data.get('job_id')

        print(f"üî¢ Total student IDs received: {len(student_ids)}")
        print(f"üåÄ Round of Interview: {round_of_interview}")
        print(f"üè¢ Job ID: {job_id_value}")

        if not student_ids:
            print("üö´ No student IDs provided")
            return Response({'error': 'No student IDs provided'}, status=status.HTTP_400_BAD_REQUEST)

        if not round_of_interview:
            print("üö´ round_of_interview is required")
            return Response({'error': 'round_of_interview is required'}, status=status.HTTP_400_BAD_REQUEST)

        if not job_id_value:
            print("üö´ job_id is required")
            return Response({'error': 'job_id is required'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            print("üîç Fetching job offer...")
            job = job_offers.objects.get(id=job_id_value, deleted=0)
            job_type = job.job_type
            struct = f'{job.company_name}_{job.post_name}_{round_of_interview}'
            print(f"üèóÔ∏è Constructed batch name: {struct}")

            with transaction.atomic():
                print("üì¶ Fetching eligible students...")
                eligible_students = eligible_student_list.objects.filter(
                    students_id__id__in=student_ids,
                    job_id=job_id_value,
                    deleted=0
                )
                print(f"üì• Total eligible student records fetched: {eligible_students.count()}")

                for student in eligible_students:
                    print(f"‚û°Ô∏è Processing eligible_student_list ID: {student.id}")

                    student.round_of_interview = round_of_interview
                    student.batch_name = struct
                    student.is_eligible = True
                    student.save()
                    print(f"‚úÖ Updated student: {student.students_id.registration_number}")

                    try:
                        if round_of_interview == 'Offer':
                            print(f"üéÅ Round is Offer. Updating candidate info for: {student.students_id.registration_number}")
                            candidate = candidate_master.objects.filter(
                                registration_number=student.students_id.registration_number
                            ).first()

                            if candidate:
                                print(f"üîß Updating candidate offer count for {candidate.registration_number}")
                                if job_type == 'IT':
                                    candidate.it_of_offers = (candidate.it_of_offers or 0) + 1
                                elif job_type == 'Core':
                                    candidate.core_of_offers = (candidate.core_of_offers or 0) + 1

                                candidate.is_offered = True
                                candidate.save()
                                print(f"üéØ Candidate offer updated: {candidate.registration_number}")
                            else:
                                print(f"‚ö†Ô∏è Candidate not found for reg no: {student.students_id.registration_number}")
                    except Exception as ce:
                        print(f"‚ùå Error updating candidate for {student.students_id.registration_number}: {str(ce)}")

        except job_offers.DoesNotExist:
            print(f"‚ùå Job with ID {job_id_value} does not exist")
            return Response({'error': 'Job not found'}, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            print(f"‚ùå Unexpected error occurred: {str(e)}")
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        print("‚úÖ All selected students updated successfully")
        return Response({'success': 'Selected students updated successfully'}, status=status.HTTP_200_OK)

@api_view(['GET'])
def get_students_by_job_interview_date(request, job_id):
    try:
        # Default round_of_interview = "Interview Date"
       # default_round = "Interview Date"

        students_data = eligible_student_list.objects.filter(
            job_id=job_id,
           
        ).select_related('students_id').values(
            'id',
             'students_id__id',
            'students_id__students_name',
            'students_id__registration_number',
            'students_id__department_id__department',
            'students_id__email_id',
            'students_id__mobile_number',
            'students_id__year',
            'students_id__cgpa',
            'students_id__marks_10th',
            'students_id__marks_12th',
            'students_id__history_of_arrears',
            'students_id__standing_arrears',
        )

        return Response(list(students_data), status=status.HTTP_200_OK)

    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['POST'])
def RemoveEligibleStudentRoundView(request):
    try:
        data = request.data
        print("üìù Incoming POST data:", data)

        student_ids = data.get("student_ids", [])
        round_id = data.get("current_round")  # Corrected from "round_id"

        if not student_ids or not round_id:
            return JsonResponse({"error": "Missing student_ids or current_round"}, status=400)

        print(f"üìå round_id: {round_id}")
        print(f"üìå student_ids received: {student_ids}")

        # Ensure IDs are integers
        student_ids = list(map(int, student_ids))

        # OPTIONAL: print all eligible student list entries
        all_ids = eligible_student_list.objects.values_list("students_id", flat=True)
        print("üìã All student foreign keys (students_id):", list(all_ids))

        # Fetch the eligible students using students_id
        students = eligible_student_list.objects.filter(students_id__in=student_ids, round_of_interview=round_id)
        print(f"üë• QuerySet: {students.query}")
        print(f"üë• Total students found: {students.count()}")

        if not students.exists():
            return JsonResponse({"error": "No matching students found for given IDs and round"}, status=404)

        # Set round_of_interview to None
        students.update(round_of_interview=None)
        print("‚úÖ round_of_interview set to None for matched students.")

        return JsonResponse({"message": "Students removed from the round successfully."}, status=200)

    except Exception as e:
        print("‚ùå Exception occurred:", str(e))
        return JsonResponse({"error": "Something went wrong"}, status=500)

@csrf_exempt
def get_topics_by_year(request):
    if request.method != 'POST':
        return JsonResponse({"error": "Only POST method is allowed."}, status=405)

    try:
        data = json.loads(request.body)
    except json.JSONDecodeError:
        return JsonResponse({"error": "Invalid JSON body."}, status=400)

    selected_years = data.get('years', [])
    department_names = data.get('departments', [])  # Optional

    topics = []

    if '1' in selected_years:
        topics += [
            "Number System, Speed Maths", "HCF & LCM", "Decimal Fractions", "Square Roots", "Cube Roots", "Average", "Orientation",
            "Number Series", "Puzzles", "Mirro Image & Water Images", "Logical Puzzle", "Blood Relations",
            "Articles & Prepositions", "Tenses", "Sequence of Words", "Inserting the missing Character", "Verification Of Truth"
        ]

    if '2' in selected_years:
        topics += [
            "Percentage", "Profit & Loss", "Ages", "SI & CI", "Ratio Proportion", "Time and Work", "Permutation Combination", 
            "Time Speed and Distance", "Arithmetic Progression", "Data Sufficiency",
            "Odd One Out", "Logical Sequencing",  "Syllogism", "Analogies",
            "Logical Game", "Problem Solving", "Statements and Arguments", "Assumptipns", "Conclusions", "Directions",
            "Synonmys & Antonyms", "Idioms and Phrases", "Direct & Indirect Speech", "Conjuctions and Punctuations", 
            "Oral Communication", "Body language", "Personality Development", "Grooming", "Talk on a topic",
            "Sentence Formation", "Error Corrections", "Jumbling of Sentences", "Reading Comprehentions", 
            "Paragraph Formation", "Communication", "Writing skills", "Reading Skillls", "Listening Skills", "Behavioural Skills"
        ]

    if '3' in selected_years:
        topics += [
            "Boat and Streams", "Train", "Pipes and cisterns", "Data Interpretation", "Data Sufficiency",
            "Flow Chart", "Calander", "Clock", "Cryt Arithmetic", "Alligation & Mixture", "Geometry", "Mensuration",
            "Seating Arrangements", "Mathematical Opeartions", "Arithmatical Reasoning", "Cubes and Dice", "Probability", 
            "Paper folding", "Essential Parts", "Making Judgement", "Theme Detection", "Cause and Effect",
            "Matching Definitions", "Pattern Completion", "Shape Construction", "Dot Situation", "Image Analysis",
            "Logical Deduction", "Assertion and Reaction",
            "Synonmys & Antonyms", "Idioms and Phrases", "Analogies", "Sentence Jumbling", "Para Jumbling", 
            "Presentation Skills", "Goal Setting", "Time Management", "Team Building", "Work Ethiquette", 
            "One word substitution", "Change of Voice", "Completing Statements", "Completing Sentences", 
            "Email Writing", "Resume Building", "Telephone Etiquette", "Public Speaking", "cloze Test", 
            "Parts of Speech", "Subject Verb Agreement", "Error Spotting", "Root words", 
            "Direct-indirect Speech", "Analogies", "Conjuctions and Punctuations"
        ]

    if '4' in selected_years:
        topics += [
            "Time and work", "Ages", "Ratio Proportion", "Time Speed and Distance", "Train", "Boat and Streams",
            "Data Interpretation", "Flow Chart", "Data Sufficiency", "Clocks", "Calenders", "Cryt Arithmetics",
            "Pattern Completion", "Shape Construction", "Dot Situation", "Image Analysis",
            "Blood Relationship", "Coding Decoding", "Directions", "Seating arrangements",
            "Synonyms Antonyms"
        ]

    return JsonResponse({
        "topics": sorted(set(topics))
    })



@api_view(['GET'])
def get_group_test_name_commun_Test(request):
    college_id = request.GET.get('college_id')  
    department_filter = request.GET.get('department')  # Get selected department
    year_filter = request.GET.get('year')  # Get selected year

    # Get test names of 'Aptitude' type
    test_names = test_master.objects.filter(question_type_id__question_type='Softskills').values_list('test_name', 'skill_type_id')

    # Create a dictionary for mapping test_name to skill_type_id
    skill_types = skill_type.objects.filter(id__in=[test[1] for test in test_names if test[1] is not None]).values_list('id', 'skill_type')
    skill_type_mapping = {skill[0]: skill[1] for skill in skill_types}

    # Map test_name to skill_type_id
    test_skill_mapping = {test[0]: skill_type_mapping.get(test[1], None) for test in test_names}

    # Base filters
    filters = {'deleted': 0, 'test_name__in': test_skill_mapping.keys()}
    if college_id:
        filters['college_id'] = college_id  # Apply college filter

    # Aggregate all department and year data into a single row per `test_name`
    base_query = tests_candidates_map.objects.filter(**filters).exclude(created_by='Student').values(
        'test_name',
        'college_id',
        'college_id__college'
    ).annotate(
        student_count=Count('student_id', distinct=True),  # ‚úÖ Aggregate student count
        active_student_count=Count('student_id', filter=Q(is_active=True), distinct=True),  # ‚úÖ Aggregate active student count
        dtm_created=Max('dtm_created'),  # ‚úÖ Get latest creation date
        department_names=Concat(Value(''), 'department_id__department', output_field=CharField()),  # ‚úÖ Concatenate department names
        all_years=Concat(Value(''), 'year', output_field=CharField())  # ‚úÖ Concatenate all years
    ).order_by('-dtm_created')

    # Apply filtering only when department or year is selected
    if department_filter or year_filter:
        filtered_query = tests_candidates_map.objects.filter(**filters)

        if department_filter:
            filtered_query = filtered_query.filter(department_id__department=department_filter)
        if year_filter:
            filtered_query = filtered_query.filter(year=year_filter)

        filtered_query = filtered_query.values(
            'test_name',
            'college_id',
            'college_id__college'
        ).annotate(
            student_count=Count('student_id', distinct=True),  
            active_student_count=Count('student_id', filter=Q(is_active=True), distinct=True),
            dtm_created=Max('dtm_created'),
            department_names=Concat(Value(''), 'department_id__department', output_field=CharField()),
            all_years=Concat(Value(''), 'year', output_field=CharField())
        ).order_by('-dtm_created')

        results = filtered_query
    else:
        results = base_query  # ‚úÖ Default view: one row per test_name

    # Format response data
    test_candidate_map_data = []
    seen_tests = {}

    for testing in results:
        test_name = testing['test_name']

        if test_name not in seen_tests:
            seen_tests[test_name] = {
                'test_name': test_name,
                'student_count': 0,  # ‚úÖ Start from zero to sum properly
                'active_student_count': 0,
                'dtm_created': testing['dtm_created'],
                'college_id': testing['college_id'],
                'college_name': testing['college_id__college'],
                'skill_type': test_skill_mapping.get(test_name),
                'department_name': set(),  # ‚úÖ Store multiple departments
                'year': set()  # ‚úÖ Store multiple years
            }

        # ‚úÖ Aggregate student counts correctly
        seen_tests[test_name]['student_count'] += testing['student_count']
        seen_tests[test_name]['active_student_count'] += testing['active_student_count']
        seen_tests[test_name]['department_name'].add(testing['department_names'])
        seen_tests[test_name]['year'].add(testing['all_years'])

    # Convert sets to comma-separated strings
    for test in seen_tests.values():
        test['department_name'] = ", ".join(test['department_name'])
        test['year'] = ", ".join(test['year'])
        test_candidate_map_data.append(test)

    return Response(test_candidate_map_data)


@api_view(['GET'])
def get_group_test_name_company_Test(request):
    college_id = request.GET.get('college_id')  
    department_filter = request.GET.get('department')  # Get selected department
    year_filter = request.GET.get('year')  # Get selected year

    # Get test names of 'Aptitude' type
    test_names = test_master.objects.filter(
        Q(question_type_id__question_type='Mock/Interview') |
        Q(question_type_id__question_type='CompanySpecific')
    ).values_list('test_name', 'skill_type_id')
    # Create a dictionary for mapping test_name to skill_type_id
    skill_types = skill_type.objects.filter(id__in=[test[1] for test in test_names if test[1] is not None]).values_list('id', 'skill_type')
    skill_type_mapping = {skill[0]: skill[1] for skill in skill_types}

    # Map test_name to skill_type_id
    test_skill_mapping = {test[0]: skill_type_mapping.get(test[1], None) for test in test_names}

    # Base filters
    filters = {'deleted': 0, 'test_name__in': test_skill_mapping.keys()}
    if college_id:
        filters['college_id'] = college_id  # Apply college filter

    # Aggregate all department and year data into a single row per `test_name`
    base_query = tests_candidates_map.objects.filter(**filters).exclude(created_by='Student').values(
        'test_name',
        'college_id',
        'college_id__college'
    ).annotate(
        student_count=Count('student_id', distinct=True),  # ‚úÖ Aggregate student count
        active_student_count=Count('student_id', filter=Q(is_active=True), distinct=True),  # ‚úÖ Aggregate active student count
        dtm_created=Max('dtm_created'),  # ‚úÖ Get latest creation date
        department_names=Concat(Value(''), 'department_id__department', output_field=CharField()),  # ‚úÖ Concatenate department names
        all_years=Concat(Value(''), 'year', output_field=CharField())  # ‚úÖ Concatenate all years
    ).order_by('-dtm_created')

    # Apply filtering only when department or year is selected
    if department_filter or year_filter:
        filtered_query = tests_candidates_map.objects.filter(**filters)

        if department_filter:
            filtered_query = filtered_query.filter(department_id__department=department_filter)
        if year_filter:
            filtered_query = filtered_query.filter(year=year_filter)

        filtered_query = filtered_query.values(
            'test_name',
            'college_id',
            'college_id__college'
        ).annotate(
            student_count=Count('student_id', distinct=True),  
            active_student_count=Count('student_id', filter=Q(is_active=True), distinct=True),
            dtm_created=Max('dtm_created'),
            department_names=Concat(Value(''), 'department_id__department', output_field=CharField()),
            all_years=Concat(Value(''), 'year', output_field=CharField())
        ).order_by('-dtm_created')

        results = filtered_query
    else:
        results = base_query  # ‚úÖ Default view: one row per test_name

    # Format response data
    test_candidate_map_data = []
    seen_tests = {}

    for testing in results:
        test_name = testing['test_name']

        if test_name not in seen_tests:
            seen_tests[test_name] = {
                'test_name': test_name,
                'student_count': 0,  # ‚úÖ Start from zero to sum properly
                'active_student_count': 0,
                'dtm_created': testing['dtm_created'],
                'college_id': testing['college_id'],
                'college_name': testing['college_id__college'],
                'skill_type': test_skill_mapping.get(test_name),
                'department_name': set(),  # ‚úÖ Store multiple departments
                'year': set()  # ‚úÖ Store multiple years
            }

        # ‚úÖ Aggregate student counts correctly
        seen_tests[test_name]['student_count'] += testing['student_count']
        seen_tests[test_name]['active_student_count'] += testing['active_student_count']
        seen_tests[test_name]['department_name'].add(testing['department_names'])
        seen_tests[test_name]['year'].add(testing['all_years'])

    # Convert sets to comma-separated strings
    for test in seen_tests.values():
        test['department_name'] = ", ".join(test['department_name'])
        test['year'] = ", ".join(test['year'])
        test_candidate_map_data.append(test)

    return Response(test_candidate_map_data)


class Update_Db_CandidatesPlacement(APIView):
    def post(self, request, format=None):
        college_id = request.query_params.get('college_id')
        if not college_id:
            return Response({'error': 'No college_id provided'}, status=status.HTTP_400_BAD_REQUEST)

        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']
        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
            print("‚úÖ Excel file read successfully.")
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        # Column mapping
        header_mapping = {
            'Batch No': 'batch_no',
            'Student Name': 'students_name',
            'User Name**': 'user_name',
            'Reg No': 'registration_number',
            'Gender': 'gender',
            'Email ID': 'email_id',
            'Mobile Number': 'mobile_number',
            'Year**': 'year',
            'CGPA': 'cgpa',
            'Department**': 'department_id',
            '10th Mark': 'marks_10th',
            '12th Mark': 'marks_12th',
            'Semaster Wise': 'marks_semester_wise',
            'History Of Arrears': 'history_of_arrears',
            'Standing Arrears': 'standing_arrears',
            'No.Of.IT Offers': 'it_of_offers',
            'No.Of.Core Offers': 'core_of_offers',
            'No.Of.Offers': 'number_of_offers',
            'Password**': 'password',
        }

        df.rename(columns=header_mapping, inplace=True)
        valid_rows = []

        def clean_value(val):
            if pd.isna(val):
                return None
            val_str = str(val).strip()
            return val_str[:-2] if val_str.endswith(".0") else val_str

        for _, row in df.iterrows():
            username = clean_value(row.get('user_name'))
            if not username:
                continue  # Skip if user_name not present

            print(f"‚û°Ô∏è Processing user: {username}")

            # Login model
            existing_user = login.objects.filter(user_name=username, deleted=0).first()
            if not existing_user:
                return Response({'error': f'User "{username}" not found.'}, status=status.HTTP_400_BAD_REQUEST)

            candidate_instance = candidate_master.objects.filter(user_name=username, deleted=0).first()
            if not candidate_instance:
                return Response({'error': f'Candidate "{username}" does not exist.'}, status=status.HTTP_400_BAD_REQUEST)    
    

            email = clean_value(row.get('email_id'))
            if email:
                existing_user.email_id = email
                candidate_instance.email_id = email

            password = clean_value(row.get('password'))
            if password:
                existing_user.password = password
            mobile_number = clean_value(row.get('mobile_number'))
            if mobile_number:
                existing_user.mobile_number = mobile_number    
            existing_user.save()

          
            college_name = clean_value(row.get('college_id'))
            college_group = clean_value(row.get('college_group'))
            if college_name:
                try:
                    if college_group:
                        college_instance = college_master.objects.get(
                            college__iexact=college_name,
                            college_group__iexact=college_group,
                            deleted=0
                        )
                    else:
                        college_instance = college_master.objects.get(
                            college__iexact=college_name,
                            deleted=0
                        )
                    candidate_instance.college_id = college_instance
                    existing_user.college_id = college_instance
                except college_master.DoesNotExist:
                    return Response({'error': f'College "{college_name}" does not exist.'}, status=status.HTTP_400_BAD_REQUEST)

            # Department assignment
            department_name = clean_value(row.get('department_id'))
            if department_name:
                department_instance = department_master.objects.filter(department=department_name, deleted=0).first()
                if not department_instance:
                    return Response({'error': f'Department "{department_name}" not found.'}, status=status.HTTP_400_BAD_REQUEST)
                candidate_instance.department_id = department_instance

            # Fields to update
            updatable_fields = [
                'cgpa', 'marks_10th', 'marks_12th', 'marks_semester_wise',
                'history_of_arrears', 'standing_arrears', 'number_of_offers',
                'it_of_offers', 'core_of_offers', 'students_name',
                'registration_number', 'gender', 'mobile_number',
                'year', 'batch_no'
            ]

            # Fields that should be cleaned (stringified without .0)
            string_clean_fields = ['students_name', 'registration_number', 'mobile_number', 'year']

            for field in updatable_fields:
                value = row.get(field)
                if pd.notna(value) and str(value).strip() != '':
                    if field in string_clean_fields:
                        setattr(candidate_instance, field, clean_value(value))
                    else:
                        setattr(candidate_instance, field, value)

            candidate_instance.is_database = True
            candidate_instance.save()
            valid_rows.append(username)
            print(f"‚úÖ Updated candidate: {username}")

        return Response(
            {'message': f'‚úÖ Updated {len(valid_rows)} record(s).', 'usernames': valid_rows},
            status=status.HTTP_200_OK
        )

class Update_Db_Candidates(APIView):
    def post(self, request, format=None):
        if 'file' not in request.FILES:
            return Response({'error': 'No file uploaded'}, status=status.HTTP_400_BAD_REQUEST)

        file = request.FILES['file']
        if not file.name.endswith('.xlsx'):
            return Response({'error': 'File is not in Excel format'}, status=status.HTTP_400_BAD_REQUEST)

        try:
            df = pd.read_excel(file)
            print("‚úÖ Excel file read successfully.")
        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)

        header_mapping = {
            'College Name**': 'college_id',
            'College Group': 'college_group',
            'Student Name': 'students_name',
            'User Name**': 'user_name',
            'Reg No': 'registration_number',
            'Gender': 'gender',
            'Email ID': 'email_id',
            'Mobile Number': 'mobile_number',
            'Year**': 'year',
            'CGPA': 'cgpa',
            'Department**': 'department_id',
            '10th Mark': 'marks_10th',
            '12th Mark': 'marks_12th',
            'Batch': 'batch_no',
            'History Of Arrears': 'history_of_arrears',
            'Standing Arrears': 'standing_arrears',
            'No.Of.IT Offers': 'it_of_offers',
            'No.Of.Core Offers': 'core_of_offers',
            'No.Of.Offers': 'number_of_offers',
            'Password**': 'password'
        }

        df.rename(columns=header_mapping, inplace=True)
        valid_rows = []

        def clean_value(val):
            if pd.isna(val):
                return None
            val_str = str(val).strip()
            # Remove trailing ".0" if it's a float-converted string
            return val_str[:-2] if val_str.endswith(".0") else val_str

        for _, row in df.iterrows():
            username = clean_value(row.get('user_name'))
            if not username:
                continue

            print(f"‚û°Ô∏è Processing user: {username}")

            existing_user = login.objects.filter(user_name=username, deleted=0).first()
            if not existing_user:
                return Response({'error': f'User "{username}" does not exist.'}, status=status.HTTP_400_BAD_REQUEST)

            candidate_instance = candidate_master.objects.filter(user_name=username, deleted=0).first()
            if not candidate_instance:
                return Response({'error': f'Candidate "{username}" does not exist.'}, status=status.HTTP_400_BAD_REQUEST)    

            # Update login fields
            email = clean_value(row.get('email_id'))
            if email:
                existing_user.email_id = email
                candidate_instance.email_id = email


            password = clean_value(row.get('password'))
            if password:
                existing_user.password = password
            mobile_number = clean_value(row.get('mobile_number'))
            if mobile_number:
                existing_user.mobile_number = mobile_number    
            existing_user.save()

            
            college_name = clean_value(row.get('college_id'))
            college_group = clean_value(row.get('college_group'))
            if college_name:
                try:
                    if college_group:
                        college_instance = college_master.objects.filter(
                            college__iexact=college_name,
                            college_group__iexact=college_group,
                            deleted=0
                        ).first()
                    else:
                        college_instance = college_master.objects.filter(
                            college__iexact=college_name,
                            deleted=0
                        ).first()

                    if not college_instance:
                        return Response({'error': f'College "{college_name}" does not exist.'}, status=status.HTTP_400_BAD_REQUEST)

                    candidate_instance.college_id = college_instance
                    existing_user.college_id = college_instance

                except Exception as e:
                    return Response({'error': f'Error finding college: {str(e)}'}, status=status.HTTP_400_BAD_REQUEST)

            department_name = clean_value(row.get('department_id'))
            if department_name:
                department_instance = department_master.objects.filter(
                    department__iexact=department_name,
                    deleted=0
                ).first()
                if not department_instance:
                    return Response({'error': f'Department "{department_name}" does not exist.'}, status=status.HTTP_400_BAD_REQUEST)
                candidate_instance.department_id = department_instance

            # Fields to clean and update
            updatable_fields = [
                'students_name', 'registration_number', 'gender', 'mobile_number', 'year',
                'cgpa', 'marks_10th', 'marks_12th', 'history_of_arrears',
                'standing_arrears', 'number_of_offers', 'it_of_offers', 'core_of_offers', 'batch_no'
            ]

            for field in updatable_fields:
                value = row.get(field)
                if pd.notna(value) and str(value).strip() != '':
                    if field in ['students_name', 'registration_number', 'mobile_number', 'year']:
                        # Clean string values to remove trailing .0
                        setattr(candidate_instance, field, clean_value(value))
                    else:
                        setattr(candidate_instance, field, value)

            candidate_instance.is_database = True
            existing_user.save()
            candidate_instance.save()

            print(f"‚úÖ Updated candidate: {username}")
            valid_rows.append(username)

        return Response({
            'message': f'‚úÖ Excel file processed successfully. Updated {len(valid_rows)} record(s).',
            'updated_usernames': valid_rows
        }, status=status.HTTP_200_OK)


class CandidatesAndLoginCreateAPIView(generics.CreateAPIView):
    serializer_class = candidatesSerializer

    def post(self, request, *args, **kwargs):
        logger.info("üì• POST request received for candidate creation.")
        print("üì• POST request received for candidate creation.")

        user_name = request.data.get('user_name')
        email_id = request.data.get('email_id')

        logger.info(f"User: {user_name}, Email: {email_id}")
        print(f"User: {user_name}, Email: {email_id}")

        if not user_name:
            logger.warning("Missing user_name ")
            return Response(
                {"error": "Username is required."},
                status=status.HTTP_400_BAD_REQUEST
            )

        # Check for duplicates
        if login.objects.filter(Q(user_name=user_name)).exists():
            logger.warning("‚ùå Duplicate username ")
            print("‚ùå Duplicate username ")
            return Response(
                {"error": "Username  already exists"},
                status=status.HTTP_400_BAD_REQUEST
            )

        try:
            with transaction.atomic():
                logger.info("üöÄ Attempting to serialize candidate data")
                print("üöÄ Attempting to serialize candidate data")

                serializer = self.get_serializer(data=request.data)
                if not serializer.is_valid():
                    logger.error(f"‚ùå Validation failed: {serializer.errors}")
                    print(f"‚ùå Validation failed: {serializer.errors}")
                    return Response(
                        {"error": serializer.errors},
                        status=status.HTTP_400_BAD_REQUEST
                    )

                candidate = serializer.save()
                logger.info(f"‚úÖ Candidate saved: ID {candidate.id}")
                print(f"‚úÖ Candidate saved: ID {candidate.id}")

                # Get the actual college_master instance
                college_id_value = request.data.get('college_id')
                college_instance = None

                if college_id_value:
                    try:
                        college_instance = college_master.objects.get(pk=college_id_value)
                    except college_master.DoesNotExist:
                        logger.warning(f"‚ùå Invalid college_id: {college_id_value}")
                        return Response(
                            {"error": f"Invalid college_id: {college_id_value}"},
                            status=status.HTTP_400_BAD_REQUEST
                        )

                login_data = {
                    'user_name': user_name,
                    'password': request.data.get('password','1234'),
                    'email_id': email_id,
                    'college_id': college_instance,  # use instance, not raw ID
                    'role': 'Student',
                }

                logger.info("üë§ Creating login for candidate")
                login.objects.create(**login_data)

                logger.info("‚úÖ Profile and login created successfully")
                return Response(
                    {"message": "Profile and login created successfully"},
                    status=status.HTTP_201_CREATED
                )

        except Exception as e:
            logger.error(f"‚ùå Exception during profile creation: {str(e)}", exc_info=True)
            print(f"‚ùå Exception during profile creation: {str(e)}")
            return Response(
                {"error": f"Failed to create profile: {str(e)}"},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

@csrf_exempt
def get_filtered_topics(request):
    if request.method != "GET":
        return JsonResponse({"error": "Only GET method is allowed"}, status=405)

    training_id = request.GET.get("training_id")
    search = request.GET.get("search", "").strip().lower()
    skill = request.GET.get("skill", "").strip().lower()  # optional

    if not training_id:
        return JsonResponse({"error": "training_id is required"}, status=400)

    try:
        training_schedule = training_schedule_temp.objects.get(id=training_id)
    except training_schedule_temp.DoesNotExist:
        return JsonResponse({"error": "Training schedule not found"}, status=404)

    topics = training_schedule.topics or []

    # Optional: Skill mapping if you still want to organize them
    skill_map = {
        "quants": [
            "Number System", "HCF & LCM", 
             "Average", "Orientation",
            "Percentage", "Profit & Loss", "Ages", "SI & CI", "Ratio Proportion",
            "Time and Work", "Permutation Combination", "Time Speed and Distance",
            "Arithmetic Progression", "Data Sufficiency", "Boat and Streams",
            "Train", "Pipes and cisterns", "Data Interpretation", "Flow Chart",
            "Calander", "Clock", "Cryt Arithmetic", "Alligation & Mixture",
            "Geometry", "Mensuration"
        ],
        "logical": [
            "Number Series", "Puzzles", "Mirro Image & Water Images",
            "Logical Puzzle", "Blood Relations", "Odd One Out", "Logical Sequencing",
            "Venn Diagram", "Syllogism",  "Logical Game",
            "Problem Solving", "Statements and Arguments", "Assumptipns",
            "Conclusions",  "Seating Arrangements",
            "Mathematical Opeartions", "Arithmatical Reasoning", "Cubes and Dice",
            "Probability", "Paper folding", "Essential Parts", "Making Judgement",
            "Theme Detection", "Cause and Effect", "Matching Definitions",
            "Pattern Completion", "Shape Construction", "Dot Situation",
            "Image Analysis", "Logical Deduction", "Assertion and Reaction",
            "Coding Decoding", "Directions"
        ],
        'verbal' : [
            "Articles & Prepositions", "Tenses", "Sequence of Words",
            "Inserting the missing Character", "Verification Of Truth",
            "Synonmys & Antonyms", "Idioms and Phrases", "Direct & Indirect Speech",
            "Conjuctions and Punctuations", "Sentence Formation", "Error Corrections",
            "Jumbling of Sentences", "Reading Comprehentions", "Paragraph Formation",
            "One word substitution", "Change of Voice", "Completing Statements",
            "Completing Sentences", "cloze Test", "Parts of Speech",
            "Subject Verb Agreement", "Error Spotting", "Root words",
            "Direct-indirect Speech", "Analogies", "Grammar mistakes"
        ],
       'softskills' :[
            "Oral Communication", "Body language", "Personality Development",
            "Grooming", "Talk on a topic", "Communication",
            "Writing skills", "Reading Skillls", "Listening Skills",
            "Behavioural Skills", "Sentence Jumbling", "Para Jumbling",
            "Presentation Skills", "Goal Setting", "Time Management",
            "Team Building", "Work Ethiquette", "Email Writing",
            "Resume Building", "Telephone Etiquette", "Public Speaking",
            "Interview Skills", "GD", "Mock Interview", "Mock GD",
            "Company specific"
        ],

     "c": [
             "C - Introduction & Setup",
             "C - Data Types and Variables",
             "C - Operators and Expressions",
             "C - Control Structures",
             "C - Looping Constructs",
             "C - Functions",
             "C - Arrays",
             "C - Strings",
             "C - Pointers",
             "C - Structures and Unions",
             "C - File Handling",
             "C - Dynamic Memory Allocation"],
        
         "c++" :[
             "C++ Basics & First Program",
             "C++ Data Types & Variables",
             "Operators & Control Structures in C++",
             "Functions & Function Overloading in C++",
             "Classes & Objects in C++",
             "Constructors & Destructors in C++",
             "Inheritance in C++",
             "Polymorphism & Virtual Functions in C++",
             "Templates in C++",
             "Exception Handling in C++",
             "STL - Introduction in C++",
             "STL - Containers (Vectors, Lists, Maps, Sets) in C++",
             "STL - Iterators & Algorithms in C++","Arrays in C++" ,"Strings in C++" ,"Sorting in C++" ,"Queue in C++" ,"Stack in C++" ,"Heaps in C++" ,"Linked List in C++" , "Trees in C++"  , "Graph in C++"],
    
         "java" : ["Java-intro","Java-Setup and First Program" ,"Java-Data Types and Variables", "Java-Operators and Control Statements", "Java-Classes and Objects", "Java-Methods and Method Overloading", "Java-Inheritance", "Java-Polymorphism", "Java-Abstraction and Interfaces", "Java-Packages and Access Modifiers", "Java-Exception Handling", "Java-Basic Input and Output","Java-Heaps" ,"Java-Hashing" ,"Java-Queues", "Java-Stack" , "Java-Arrays" , "Java-Sorting" , "Java-Tree","Java-Strings",
                  "Java-Generics","Java-Collections Framework","Java-Multi-threading and Concurrency","Java-Streams and Lambda Expressions","Java-File I/O (NIO.2)","Java-JDBC","Java-Networking (Sockets)","Java-JavaFX","Java-Annotations","Java-Reflection","Java-Serialization","Java-Internationalization (i18n) & Localization (l10n)","Java-Security (Cryptography & Access Control)","Java-Regular Expressions","Java-Modules (Java 9+ Module System)","Java-Memory Management & Garbage Collection","Java-JVM Internals & Performance Tuning"],
    
         "python":["Python-Intro", "Python-Setup and First Program", "Python-Data Types and Variables", "Python-Operators and Expressions", "Python-Control Flow", "Python-Loops", "Python-Functions", "Python-Lists and Tuples", "Python-Dictionaries and Sets", "Python-Strings", "Python-Modules and Packages", "Python-File I/O","Python-Hashing" , "Python-Heaps" ,"Python-Queues" , "Python-Sorting Algorithm" ,
                "Python - Object-Oriented Programming", "Python - Advanced Functions (Decorators, Generators)", "Python - Exception Handling", "Python - Working with JSON and CSV files", "Python - Regular Expressions",
                "Python - Multithreading and Multiprocessing", "Python - Networking (Sockets)", "Python - Web Scraping (BeautifulSoup, Scrapy)", "Python - Data Analysis (Pandas)", "Python - Visualization (Matplotlib, Seaborn)"
             ]
    }

    
    # Filter by skill (if requested)
    if skill in skill_map:
        skill_keywords = set(s.lower() for s in skill_map[skill])
        topics = [t for t in topics if t.lower() in skill_keywords]

    # Filter by search term (if provided)
    if search:
        topics = [t for t in topics if search in t.lower()]

    return JsonResponse({
        "topics": topics,
        "available_skills": list(skill_map.keys())
    })

@csrf_exempt
def update_training_topics(request, training_id):
    print("üîÅ Entered `update_training_topics` view")  # Step 1

    if request.method != "POST":
        print("‚ùå Invalid request method:", request.method)  # Step 2
        return JsonResponse({"error": "Only POST method is allowed"}, status=405)

    try:
        print("üì• Raw request body:", request.body)  # Step 3
        data = json.loads(request.body)
        selected_topics = data.get("topics", [])
        print("‚úÖ Parsed topics:", selected_topics)  # Step 4
    except Exception as e:
        print("‚ùå Error parsing JSON:", str(e))  # Step 5
        return JsonResponse({"error": f"Invalid JSON or payload: {str(e)}"}, status=400)

    if not isinstance(selected_topics, list):
        print("‚ùå Invalid data type for topics:", type(selected_topics))  # Step 6
        return JsonResponse({"error": "topics must be a list"}, status=400)

    try:
        print("üîç Fetching training schedule with ID:", training_id)  # Step 7
        schedule = training_schedule_temp.objects.get(id=training_id)
        print("‚úÖ Schedule found:", schedule)  # Step 8

        schedule.topics = selected_topics
        schedule.save()
        print("üíæ Topics updated and saved successfully")  # Step 9

        return JsonResponse({
            "success": True,
            "message": "Topics updated successfully",
            "topics": selected_topics
        })
    except training_schedule_temp.DoesNotExist:
        print("‚ùå Training schedule not found with ID:", training_id)  # Step 10
        return JsonResponse({"error": "Training schedule not found"}, status=404)
    except Exception as e:
        print("‚ùå Unexpected error while saving topics:", str(e))  # Step 11
        return JsonResponse({"error": f"Failed to update topics: {str(e)}"}, status=500)

#_______________________________Vishal Practice Test__________________________#


from .serializers import QuestionTypeSerializer, SkillTypeSerializer_filter, FolderMasterCreateSerializer

class QuestionTypeListAPIView(generics.ListAPIView):
    queryset = question_type.objects.filter(deleted=0)
    serializer_class = QuestionTypeSerializer

class SkillTypeListByTopicAPIView(generics.ListAPIView):
    serializer_class = SkillTypeSerializer_filter

    def get_queryset(self):
        topic_id = self.kwargs.get('topic_id')
        return skill_type.objects.filter(question_type_id=topic_id, deleted=0)

class FolderMasterCreateAPIView(generics.CreateAPIView):
    serializer_class = FolderMasterCreateSerializer

    def perform_create(self, serializer):
        serializer.save(dtm_created=timezone.now())



from .models import folder_master
from .serializers import FolderMasterSerializer,FolderMasterUpdateSerializer

class FolderMasterListAPIView(generics.ListAPIView):
    queryset = folder_master.objects.filter(deleted=0)  # show only non-deleted if you want
    serializer_class = FolderMasterSerializer

class FolderNameUpdateAPIView(generics.RetrieveUpdateAPIView):
    queryset = folder_master.objects.filter(deleted=0)
    serializer_class = FolderMasterUpdateSerializer


class FolderMasterDeleteAPIView(generics.RetrieveDestroyAPIView):
    queryset = folder_master.objects.filter(deleted=0)
    serializer_class = FolderMasterUpdateSerializer


class QuestionUploadAPIView(APIView):
    def post(self, request, *args, **kwargs):
        data = request.data

        # Extract string values from request
        topic = data.get('topic', '').strip()
        test_type = data.get('test_type', '').strip()
        test_type_categories = data.get('test_type_categoriess', '').strip()
        sub_topic = data.get('subtopic', '').strip()
        folder_name = data.get('folder_name', '').strip()
        is_testcase = data.get('is_testcase', False) # boolean
        print("Received data:")
        print(f"topic: '{topic}'")
        print(f"test_type: '{test_type}'")
        print(f"test_type_categories: '{test_type_categories}'")
        print(f"subtopic: '{sub_topic}'")
        print(f"folder_name: '{folder_name}'")
        print(f"is_testcase: {is_testcase}")

        # Safely parse mark
        mark = data.get('mark')
        try:
            mark = int(mark)
        except (TypeError, ValueError):
            mark = 0

        try:
            with transaction.atomic():
                # Try to find existing question_paper_master matching all foreign keys and is_testcase
                qpm = question_paper_master.objects.filter(
                    test_type=test_type,
                    topic=topic,
                    sub_topic=sub_topic,
                    folder_name=folder_name,
                    is_testcase=is_testcase,
                    remarks="PracticeTest",
                    deleted=0
                ).first()

                if qpm:
                    # If found, increment no_of_questions
                    qpm.no_of_questions = (qpm.no_of_questions or 0) + 1
                    qpm.save()
                    created = False
                else:
                    # If not found, create new question_paper_master
                    qpm = question_paper_master.objects.create(
                        test_type=test_type,
                        topic=topic,
                        sub_topic=sub_topic,
                        folder_name=folder_name,
                        is_testcase=is_testcase,
                        question_paper_name=f"{topic} - {test_type} - {sub_topic} - {folder_name or 'Overall'}",
                        no_of_questions=1,
                        dtm_created=datetime.now(),
                        deleted=0,
                        remarks="PracticeTest"
                    )
                    created = True

                # Create question_master linked to this question_paper_master
                question = question_master.objects.create(
                    question_name_id=qpm,
                    question_text=data.get('question_text', ''),
                    option_a=data.get('option_a', ''),
                    option_b=data.get('option_b', ''),
                    option_c=data.get('option_c', ''),
                    option_d=data.get('option_d', ''),
                    answer=data.get('answer', ''),
                    mark=mark,
                    difficulty_level=data.get('difficulty_level', ''),
                    explain_answer=data.get('explain_answer', ''),
                    is_active=True,
                    deleted=0,
                    dtm_created=datetime.now(),
                )

                print(f"Stored question under question_paper_master id={qpm.id} (created={created})")

        except Exception as e:
            print(f"Exception: {e}")
            return Response({'error': f'Internal server error: {e}'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        return Response({'message': 'Question uploaded successfully.', 'question_paper_master_id': qpm.id}, status=status.HTTP_201_CREATED)




class CodingQuestionUploadAPIView(APIView):
    def post(self, request):
        data = request.data

        # Extract string values from request for related models
        topic = data.get('topic', '').strip()
        test_type = data.get('test_type', '').strip()
        test_type_categories = data.get('test_type_categories', '').strip()
        sub_topic = data.get('subtopic', '').strip()
        folder_name = data.get('folder_name', '').strip()
        is_testcase = data.get('is_testcase', False)  # boolean, optional fallback
        print("Received data:")
        print(f"topic: '{topic}'")
        print(f"test_type: '{test_type}'")
        print(f"test_type_categories: '{test_type_categories}'")
        print(f"subtopic: '{sub_topic}'")
        print(f"folder_name: '{folder_name}'")
        print(f"is_testcase: {is_testcase}")
        # Safely parse mark
        mark = data.get('mark', 0)
        try:
            mark = int(mark)
        except (TypeError, ValueError):
            mark = 0


        try:
            with transaction.atomic():
                # Find or create question_paper_master
                qpm = question_paper_master.objects.filter(
                    test_type=test_type,
                    topic=topic,
                    sub_topic=sub_topic,
                    folder_name=folder_name,
                    is_testcase=is_testcase,
                    remarks="PracticeTest",
                    deleted=0
                ).first()

                if qpm:
                    qpm.no_of_questions = (qpm.no_of_questions or 0) + 1
                    qpm.save()
                else:
                    qpm = question_paper_master.objects.create(
                        test_type=test_type,
                        topic=topic,
                        sub_topic=sub_topic,
                        folder_name=folder_name,
                        is_testcase=is_testcase,
                        question_paper_name=f"{topic} - {test_type} - {sub_topic} - {folder_name or 'Overall'}",
                        no_of_questions=1,
                        dtm_created=datetime.now(),
                        deleted=0,
                        remarks="PracticeTest"
                    )

                # Determine if this is a testcase coding question
                # The frontend should send "test_case1" if testcase is checked
                is_testcase_flag = 'test_case1' in data

                create_kwargs = dict(
                    question_name_id=qpm,
                    question_text=data.get('question_text', ''),
                    answer=data.get('answer', ''),
                    mark=mark,
                    explain_answer=data.get('explain_answer', ''),
                    input_format=data.get('input_format', ''),
                    difficulty_level=data.get('difficulty_level', ''),
                    is_active=True,
                    deleted=0,
                    dtm_created=timezone.now()
                )

                if is_testcase_flag:
                    create_kwargs['test_case1'] = data.get('test_case1', '')
                    create_kwargs['test_case2'] = data.get('test_case2', '')
                    create_kwargs['test_case3'] = data.get('test_case3', '')

                question = question_master.objects.create(**create_kwargs)

        except Exception as e:
            return Response({'error': f'Failed to create coding question: {e}'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        return Response({'success': True, 'question_id': question.id}, status=status.HTTP_201_CREATED)



class AddTestMasterView(APIView):
    def post(self, request):
        data = request.data
        test_name = data.get('test_name')
        test_type_str = data.get('test_type')
        skill_type_str = data.get('skill_type')
        question_type_str = data.get('question_type')

        # 1. Find question_type object by string
        try:
            question_type_obj = question_type.objects.get(question_type=question_type_str)
        except question_type.DoesNotExist:
            return Response({"error": f"Question Type '{question_type_str}' not found."}, status=status.HTTP_400_BAD_REQUEST)

        # 2. Find skill_type object by skill_type string AND question_type_id
        try:
            skill_type_obj = skill_type.objects.get(
                skill_type=skill_type_str,
                question_type_id=question_type_obj.id
            )
        except skill_type.DoesNotExist:
            return Response(
                {"error": f"Skill Type '{skill_type_str}' with Question Type '{question_type_str}' not found."},
                status=status.HTTP_400_BAD_REQUEST
            )

        # 3. Find test_type object by test_type string AND test_type_categories="Assessment"
        try:
            test_type_obj = test_type.objects.get(
                test_type=test_type_str,
                test_type_categories="PracticeTest"
            )
        except test_type.DoesNotExist:
            return Response(
                {"error": f"Test Type '{test_type_str}' with Category 'PracticeTest' not found."},
                status=status.HTTP_400_BAD_REQUEST
            )

        # 4. Create test_master using the found IDs
        test, created = test_master.objects.update_or_create(
            test_name=test_name,
            defaults={
                'test_type_id': test_type_obj,
                'skill_type_id': skill_type_obj,
                'question_type_id': question_type_obj,
            }
        )
        message = "Test created successfully" if created else "Test updated successfully"
        return Response({"id": test.id, "message": message}, status=status.HTTP_200_OK)



class TestCandidatesMapBatchCreate(APIView):
    def post(self, request, format=None):
        test_name = request.data.get('test_name')
        question_id = request.data.get('question_id')
        created_by = request.data.get('created_by', 'System')
        college_id = request.data.get('college_id', [])
        batch_no = request.data.get('batch_no', [])
        department_id = request.data.get('department_id', [])
        dtm_start = request.data.get('dtm_start')
        dtm_end = request.data.get('dtm_end')
        is_camera_on = request.data.get('is_camera_on', False)
        duration_type = request.data.get('duration_type')
        year = request.data.get('year', [])
        rules_id = request.data.get('rules_id')
        need_candidate_info = request.data.get('need_candidate_info', False)
        # duration_of_test = request.data.get('duration_of_test')
        duration = request.data.get('duration')

        no_of_question = request.data.get('no_of_question')
        test_type_id = request.data.get('test_type_id')
        question_type_id = request.data.get('question_type_id')
        skill_type_id = request.data.get('skill_type_id')
        company_name = request.data.get('company_name')
        company_email = request.data.get('company_email')

        # Map year (1,2,3,4) to difficulty_level
        year_map = {
            '1': 'Easy',
            '2': 'Intermediate',
            '3': 'Difficulty',
            '4': 'Challenging',
            '5': 'Company_Specific'

        }
        # Flatten year if sent as list of objects
        if isinstance(year, list):
            year_values = []
            for y in year:
                if isinstance(y, dict) and 'value' in y:
                    year_values.append(y['value'])
                else:
                    year_values.append(str(y))
            year = year_values

        # Get students by filters
        students = candidate_master.objects.filter(is_database=True)
        if college_id:
            students = students.filter(college_id__in=college_id)
        if not college_id:
            return Response({'error': 'college_id is required'}, status=status.HTTP_400_BAD_REQUEST)

        if department_id:
            students = students.filter(department_id__in=department_id)
        if year:
            students = students.filter(year__in=year)
        if batch_no:
            students = students.filter(batch_no__in=batch_no)
        if not students.exists():
            return Response({'error': 'No students match the provided criteria.'}, status=status.HTTP_404_NOT_FOUND)

        if not question_id:
            return Response({'error': 'question_id is required'}, status=status.HTTP_400_BAD_REQUEST)
        if not year:
            return Response({'error': 'year is required for difficulty level'}, status=status.HTTP_400_BAD_REQUEST)
        if not no_of_question:
            return Response({'error': 'no_of_question is required'}, status=status.HTTP_400_BAD_REQUEST)

        difficulty_level = year_map.get(str(year[0]), 'Easy')
        # Get all possible questions once
        all_questions = list(
            question_master.objects.filter(
                question_name_id=question_id,
                difficulty_level=difficulty_level
            )
        )
        if len(all_questions) < int(no_of_question):
            return Response({'error': f'Not enough questions for difficulty level {difficulty_level}.'}, status=status.HTTP_400_BAD_REQUEST)

        # 1. Pick the same N questions for all students
        base_question_ids = random.sample([q.id for q in all_questions], int(no_of_question))

        current_date_and_time = datetime.now()
        data = []

        with transaction.atomic():
            for student in students:
                # 2. Shuffle for each student (but use the same base set)
                shuffled_ids = base_question_ids.copy()
                random.shuffle(shuffled_ids)

                test_candidate_data = {
                    'test_name': test_name,
                    'question_id': question_id,
                    'question_ids': shuffled_ids,
                    'duration': duration,
                    'no_of_question': no_of_question,
                    'student_id': student.id,
                    'college_id': student.college_id.id if student.college_id else None,
                    'department_id': student.department_id.id if student.department_id else None,
                    'dtm_start': dtm_start,
                    'dtm_end': dtm_end,
                    'dtm_start1': dtm_start,
                    'dtm_end1': dtm_end,
                    'is_camera_on': is_camera_on,
                    'duration_type': duration_type,
                    'year': student.year,
                    'rules_id': rules_id,
                    'need_candidate_info': need_candidate_info,
                    'dtm_created': current_date_and_time,
                    'created_by': created_by,
                    'test_type_id': test_type_id,
                    'question_type_id': question_type_id,
                    'skill_type_id': skill_type_id,
                    'company_name': company_name,
                    'company_email': company_email,
                }
                serializer = testcandidatemapSerializers(data=test_candidate_data)
                if serializer.is_valid():
                    serializer.save()
                    data.append(serializer.data)
                else:
                    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        return Response(data, status=status.HTTP_201_CREATED)

@csrf_exempt
@api_view(['GET', 'POST'])
def get_tests_by_type_and_difficulty(request):

    if request.method == 'GET':
        student_id = request.GET.get("student_id")
        time = request.GET.get("time")
        test_type = request.GET.get("test_type")
        topic = request.GET.get("topic")
        sub_topic = request.GET.get("sub_topic")
        folder_name = request.GET.get("folder_name")
        is_testcase = request.GET.get("is_testcase")
        difficulty_level = request.GET.get("difficulty_level") 
    else:  # POST
        student_id = request.data.get("student_id")
        time = request.data.get("time")
        test_type = request.data.get("test_type")
        topic = request.data.get("topic")
        sub_topic = request.data.get("sub_topic")
        folder_name = request.data.get("folder_name")
        is_testcase = request.data.get("is_testcase")
        difficulty_level = request.data.get("difficulty_level")

    # Helper to check if value is valid for filtering
    def is_valid_filter_value(val):
        if val is None:
            return False
        if isinstance(val, str) and val.strip().lower() == 'none':
            return False
        return True

    sub_topic_for_filter = sub_topic
    if (topic and topic.strip() in ["CompanySpecific", "Technical"]) \
            and test_type == "Coding Test" \
            and not is_valid_filter_value(sub_topic):
        sub_topic_for_filter = "All Languages"

    print("Received student_id from frontend:", student_id)
    print("time is : ", time)
    print("test_type is : ", test_type)
    print("topic : ", topic)
    print("sub_topic : ", sub_topic)
    print("folder_name : ", folder_name)
    print("is_testcase : ", is_testcase)
    print("after new sub_topic : ", sub_topic_for_filter)

    # Convert is_testcase to a Python bool or None
    is_testcase_bool = None
    if is_testcase is not None:
        if isinstance(is_testcase, bool):
            is_testcase_bool = is_testcase
        elif isinstance(is_testcase, str):
            lowered = is_testcase.strip().lower()
            if lowered == 'true':
                is_testcase_bool = True
            elif lowered == 'false':
                is_testcase_bool = False

    try:
        filter_criteria = {}
        if is_valid_filter_value(test_type):
            filter_criteria['test_type'] = test_type
        if is_valid_filter_value(topic):
            filter_criteria['topic'] = topic
        if is_valid_filter_value(sub_topic_for_filter):
            filter_criteria['sub_topic'] = sub_topic_for_filter
        if is_valid_filter_value(folder_name):
            filter_criteria['folder_name'] = folder_name
        if is_testcase_bool is not None:
            filter_criteria['is_testcase'] = is_testcase_bool
        filter_criteria['remarks'] = "PracticeTest"
        print("Filtering question_paper_master with:", filter_criteria)

        paper_qs = question_paper_master.objects.filter(**filter_criteria, deleted=0)
        paper_ids = list(paper_qs.values_list('id', flat=True))

        print("Extracted question_name_ids (id field):", paper_ids)

        if not paper_ids:
            print("‚ùå No question papers found matching the criteria.")
            return Response({'error': 'No question papers found matching the criteria'}, status=404)

        questions = question_master.objects.filter(
            question_name_id__in=paper_ids,
            deleted=0
        )
        if is_valid_filter_value(difficulty_level):
            questions = questions.filter(difficulty_level__iexact=difficulty_level.strip())

        if not questions.exists():
            print("‚ùå No questions found for this type.")
            return Response({'error': 'No questions found for this type'}, status=404)

        # ‚úÖ Remove duplicates by question_text
        unique_questions = {}
        for q in questions:
            if q.question_text not in unique_questions:
                unique_questions[q.question_text] = q  # keep first occurrence

        id_to_text = {q.id: q.question_text for q in unique_questions.values()}

        difficulty_groups = defaultdict(list)
        for q in unique_questions.values():
            level = q.difficulty_level.strip() if q.difficulty_level else 'Unknown'
            difficulty_groups[level].append(q.id)

        time = int(time)

        # Set questions_per_test and min_difference according to test_type and time
        if test_type == "Coding Test":
            if time == 15:
                questions_per_test = 1
                min_difference = 1
            elif time == 30:
                questions_per_test = 2
                min_difference = 1
            elif time == 45:
                questions_per_test = 3
                min_difference = 2
            elif time == 60:
                questions_per_test = 4
                min_difference = 3
            else:
                return Response({'error': 'Unsupported time value for Coding Test'}, status=400)
        else:
            if time == 15:
                questions_per_test = 10
                min_difference = 7
            elif time == 30:
                questions_per_test = 25
                min_difference = 15
            elif time == 45:
                questions_per_test = 40
                min_difference = 22
            elif time == 60:
                questions_per_test = 55
                min_difference = 30
            else:
                return Response({'error': 'Unsupported time value'}, status=400)

        final_result = {}
        max_random_tests = 5

        def valid_str(val):
            return val and isinstance(val, str) and val.strip().lower() != 'none'

        for difficulty, q_ids in difficulty_groups.items():
            total_questions = len(q_ids)
            print(f"üìå Total questions available for difficulty '{difficulty}': {total_questions}")
            if total_questions < questions_per_test:
                print(f"‚è© Not enough questions for {difficulty} (needed {questions_per_test}, found {total_questions}) -- skipping.")
                continue
            try:
                num_possible_tests = math.comb(total_questions, questions_per_test)
            except OverflowError:
                num_possible_tests = "Too large"

            seen_tests = []
            test_list = []
            attempts = 0
            max_attempts = max_random_tests * 20

            while len(test_list) < max_random_tests and attempts < max_attempts:
                picked = sample(q_ids, questions_per_test)
                picked_set = set(picked)
                is_valid = True
                if min_difference > 0:
                    for existing_set in seen_tests:
                        overlap = len(picked_set & existing_set)
                        if overlap > (questions_per_test - min_difference):
                            is_valid = False
                            break

                if is_valid:
                    received_sub_topic = valid_str(sub_topic)  # ORIGINAL sub_topic from frontend
                    received_folder_name = valid_str(folder_name)
                    prefix = "Test"

                    if topic and topic.strip() == "CompanySpecific":
                        # CompanySpecific prefix logic:
                        if received_folder_name and not received_sub_topic:
                            prefix = folder_name.strip()
                        elif received_folder_name and received_sub_topic:
                            prefix = f"{folder_name.strip()}_{sub_topic.strip()}"
                        elif not received_folder_name and not received_sub_topic:
                            prefix = topic.strip()
                        elif not received_folder_name and received_sub_topic:
                            prefix = sub_topic.strip()
                    else:
                        # Other topics: folder_name > sub_topic > topic
                        if received_folder_name:
                            prefix = folder_name.strip()
                        elif received_sub_topic:
                            prefix = sub_topic.strip()
                        elif topic and topic.strip():
                            prefix = topic.strip()

                    test_name = f"{prefix}_{difficulty}_Test{len(test_list) + 1}"

                    # Map picked IDs ‚Üí question_text
                    picked_texts = [id_to_text[qid] for qid in picked]

                    test_list.append({
                        'test_name': test_name,
                        'difficulty_level': difficulty,
                        'question_ids': picked,
                        'question_texts': picked_texts   # ‚úÖ include texts in response
                    })

                    seen_tests.append(picked_set)
                    print(f"Generated test set '{test_name}' with question IDs: {picked}")
                attempts += 1

            if test_list:
                final_result[difficulty] = {
                    'total_questions': total_questions,
                    'questions_per_test': questions_per_test,
                    'num_possible_tests': num_possible_tests,
                    'test_groups': test_list
                }
                print(f"‚úÖ Generated {len(test_list)} tests for difficulty '{difficulty}' with time {time} minutes:")

        if not final_result:
            print("‚ùå No difficulty groups had enough questions to generate tests.")
            return Response({'error': 'Not enough questions to generate tests for given criteria'}, status=404)

        return Response({
            'question_type_id': None,
            'questions_per_test': questions_per_test,
            'difficulty_level_distribution': final_result,
            
        })

    except Exception as e:
        import traceback
        print("‚ùå Exception occurred:")
        print(traceback.format_exc())
        return Response({'error': str(e)}, status=500)
  
  
from .serializers import CandidateMasterSerializer

class CandidateMasterListAPIView(APIView):
    def get(self, request):
        candidates = candidate_master.objects.filter(deleted=0)  # Optional: Only non-deleted
        serializer = CandidateMasterSerializer(candidates, many=True)
        return Response(serializer.data, status=status.HTTP_200_OK)



class PracticeAssignAPIView(APIView):
    def post(self, request):
        data = request.data

        # Extract input fields
        topic = data.get("topic")
        test_type_value = data.get("test_type")
        sub_topic = data.get("sub_topic")
        folder_name = data.get("folder_name")
        is_testcase = data.get("is_testcase")
        duration = data.get("time")
        test_name = data.get("test_name")
        difficulty_level = data.get("difficulty_level")
        student_id_val = data.get("student_id")
        college_id_val = data.get("college_id")
        department_id_val = data.get("department_id")
        year = data.get("year")
        question_ids = data.get("question_ids")

        # Clean and convert duration to int if possible
        if isinstance(duration, str):
            match = re.search(r'\d+', duration)
            if match:
                duration = int(match.group())
            else:
                duration = None
        elif isinstance(duration, int):
            pass
        else:
            try:
                duration = int(duration)
            except (ValueError, TypeError):
                duration = None

        no_of_question = len(question_ids) if isinstance(question_ids, list) else 0

        # Fetch related model objects safely
        question_type_obj = None
        if topic:
            question_type_obj = question_type.objects.filter(question_type=topic, deleted=0).first()

        skill_type_obj = None
        if sub_topic and question_type_obj:
            skill_type_obj = skill_type.objects.filter(
                skill_type=sub_topic,
                question_type_id=question_type_obj.id,
                deleted=0
            ).first()

        test_type_obj = None
        if test_type_value:
            test_type_obj = test_type.objects.filter(
                test_type=test_type_value,
                test_type_categories='PracticeTest',
                deleted=0
            ).first()

        question_paper_obj = None
        if topic and sub_topic and folder_name and is_testcase is not None:
            question_paper_obj = question_paper_master.objects.filter(
                topic=topic,
                sub_topic=sub_topic,
                folder_name=folder_name,
                is_testcase=is_testcase,
                deleted=0
            ).first()

        candidate_obj = None
        if student_id_val:
            try:
                candidate_obj = candidate_master.objects.get(id=student_id_val)
            except candidate_master.DoesNotExist:
                candidate_obj = None

        college_obj = None
        if college_id_val:
            try:
                college_obj = college_master.objects.get(id=college_id_val)
            except college_master.DoesNotExist:
                college_obj = None

        department_obj = None
        if department_id_val:
            try:
                department_obj = department_master.objects.get(id=department_id_val)
            except department_master.DoesNotExist:
                department_obj = None

        # Fetch rules object matching rule_name == test_type_value for rules_id
        rules_obj = None
        if test_type_value:
            rules_obj = rules.objects.filter(rule_name=test_type_value).first()

        # Prepare fields dict for test_master, add only if value exists (not None)
        test_master_fields = {}
        for key, val in [
            ('test_name', test_name),
            ('test_type_id', test_type_obj),
            ('skill_type_id', skill_type_obj),
            ('question_type_id', question_type_obj),
            ('duration', duration),
            ('year', year),
        ]:
            if val is not None and val != '':
                test_master_fields[key] = val

        # ‚úÖ Safe create/update for test_master without unique=True
        test_master_instance = None
        created = False
        try:
            test_master_qs = test_master.objects.filter(test_name=test_master_fields['test_name'])
            if test_master_qs.exists():
                # If duplicates exist, pick the latest one and update it
                test_master_instance = test_master_qs.order_by('-id').first()
                for key, val in test_master_fields.items():
                    setattr(test_master_instance, key, val)
                test_master_instance.save()
                created = False
                print("üîÅ Updated existing test_master:", test_master_instance.id)
            else:
                # Create new record
                test_master_instance = test_master.objects.create(**test_master_fields)
                created = True
                print("üÜï Created new test_master:", test_master_instance.id)
        except Exception as e:
            print(f"‚ùå Error saving test_master: {e}")
            return Response({"error": "Failed to save test master"}, status=500)

        existing_map = tests_candidates_map.objects.filter(
        test_name=test_name,
        student_id=candidate_obj
        ).order_by('-id').first()      
        # Determine assign_count
        assign_count = 1
        if existing_map:
            assign_count = existing_map.assign_count + 1
        # Prepare fields dict for tests_candidates_map, adding rules_id as foreign key
        tests_candidates_map_fields = {}
        for key, val in [
            ('test_name', test_name),
            ('question_id', question_paper_obj),
            ('question_ids', question_ids if isinstance(question_ids, list) else None),
            ('no_of_question', no_of_question if no_of_question > 0 else None),
            ('student_id', candidate_obj),
            ('college_id', college_obj),
            ('department_id', department_obj),
            ('duration', duration),
            ('year', year),
            ('rules_id', rules_obj),
            ('assign_count', assign_count),
            ('is_active', False),
        ]:
            if val is not None and val != '':
                tests_candidates_map_fields[key] = val
        # Add datetime and duration_type fields
        tests_candidates_map_fields.update({
            'dtm_start': timezone.now(),
            'dtm_start1': timezone.now(),
            'dtm_created': timezone.now(),
            'duration_type': 'QuestionTime',
            'created_by':'Student'
        })

        tests_candidates_map_instance = None

        if existing_map:
            print("üîÅ Existing tests_candidates_map found. Updating instead of creating.")
            for key, value in tests_candidates_map_fields.items():
                setattr(existing_map, key, value)
            existing_map.save()
            tests_candidates_map_instance = existing_map
        else:
            print("üÜï No existing entry found. Creating new tests_candidates_map.")
            tests_candidates_map_instance = tests_candidates_map(**tests_candidates_map_fields)
            tests_candidates_map_instance.save()


        # Logging / Printing (optional)
        print("Assign Data Received:")
        print(f"Topic: {topic}")
        print(f"Test Type: {test_type_value}")
        print(f"Sub Topic: {sub_topic}")
        print(f"Folder Name: {folder_name}")
        print(f"Is Testcase: {is_testcase}")
        print(f"Duration: {duration}")
        print(f"Test Name: {test_name}")
        print(f"Difficulty Level: {difficulty_level}")
        print(f"Student ID: {student_id_val}")
        print(f"College ID: {college_id_val}")
        print(f"Department ID: {department_id_val}")
        print(f"Year: {year}")
        print(f"Question IDs: {question_ids}")
        print(f"No of Questions: {no_of_question}")
        print(f"Question Type ID: {question_type_obj.id if question_type_obj else None}")
        print(f"Skill Type ID: {skill_type_obj.id if skill_type_obj else None}")
        print(f"Test Type ID: {test_type_obj.id if test_type_obj else None}")
        print(f"Question ID: {question_paper_obj.id if question_paper_obj else None}")
        print(f"Rules ID: {rules_obj.id if rules_obj else None}")
        print(f"Test Master Saved: {bool(test_master_instance)}")
        print(f"Tests Candidates Map Saved: {bool(tests_candidates_map_instance)}")

        return Response({
            "message": "Assign data received successfully",
            "no_of_question": no_of_question,
            "question_type_id": question_type_obj.id if question_type_obj else None,
            "skill_type_id": skill_type_obj.id if skill_type_obj else None,
            "test_type_id": test_type_obj.id if test_type_obj else None,
            "question_id": question_paper_obj.id if question_paper_obj else None,
            "rules_id": rules_obj.id if rules_obj else None,
            "test_master_saved": bool(test_master_instance),
            "tests_candidates_map_saved": bool(tests_candidates_map_instance),
            "test_name": test_name,
           "tests_candidates_map_id": tests_candidates_map_instance.id if tests_candidates_map_instance else None
        }, status=status.HTTP_200_OK)


@api_view(['GET'])
def get_trainer_all_Reports(request):
    try:
        # Fetch trainers with related skills using prefetch_related for ManyToMany field
        trainers = trainer_master.objects.filter(deleted=0).prefetch_related('skill_id')

        # Serialize the data
        serializer = trainerSerializerSkills(trainers, many=True, context={'request': request})

        return Response(serializer.data)
    except Exception as e:
        return Response({'error': str(e)}, status=500)

class question_type_listViewTraining(generics.ListAPIView):
    serializer_class = questiontypeSerializers

    def get_queryset(self):
        allowed_question_types = ["Aptitude", "Technical"]
        queryset = question_type.objects.filter(
            deleted=0,
            question_type__in=allowed_question_types
        ).order_by('-id')
        return queryset

@csrf_exempt
def PracticeAssignTest(request):
    if request.method == "POST":
        try:
            data = json.loads(request.body)

            # Extract string values from JSON request body
            test_name = data.get('test_name')
            test_type_str = data.get('test_type')
            skill_type_str = data.get('skill_type')
            question_type_str = data.get('question_type')
            folder_name = data.get('folder_name')
            created_by = data.get('created_by')
            question_ids = data.get('question_ids')    # expected list of question ids
            is_testcase = data.get('is_testcase')      # boolean
            college_id = data.get('college_id')
            batch_no = data.get('batch_no')
            department_id = data.get('department_id')
            dtm_start = data.get('dtm_start')
            dtm_end = data.get('dtm_end')
            is_camera_on = data.get('is_camera_on')
            duration_type = data.get('duration_type')
            year = data.get('year')
            rules_id = data.get('rules_id')
            need_candidate_info = data.get('need_candidate_info')
            duration = data.get('duration')
            no_of_question = data.get('no_of_question')
            company_name = data.get('company_name') if 'company_name' in data else None
            company_email = data.get('company_email') if 'company_email' in data else None
            test_type_categories = data.get('test_type_categories')
            print("aa gya ",question_ids)
            # Query model instances
            question_type_obj = None
            if question_type_str:
                question_type_obj = question_type.objects.filter(
                    question_type=question_type_str,
                    deleted=0
                ).first()

            skill_type_obj = None
            if skill_type_str and question_type_obj:
                skill_type_obj = skill_type.objects.filter(
                    skill_type=skill_type_str,
                    question_type_id=question_type_obj.id,
                    deleted=0
                ).first()

            test_type_obj = None
            if test_type_str:
                test_type_obj = test_type.objects.filter(
                    test_type=test_type_str,
                    test_type_categories=test_type_categories,
                    deleted=0
                ).first()

            question_id_obj = None
            if question_type_str and skill_type_str and folder_name and is_testcase is not None:
                question_id_obj = question_paper_master.objects.filter(
                    topic=question_type_str,
                    sub_topic=skill_type_str,
                    folder_name=folder_name,
                    is_testcase=is_testcase,
                    deleted=0
                ).first()

            # Extract IDs safely from the objects, or None if not found
            test_type_id = test_type_obj.id if test_type_obj else None
            skill_type_id = skill_type_obj.id if skill_type_obj else None
            question_type_id = question_type_obj.id if question_type_obj else None
            question_id = question_id_obj.id if question_id_obj else None

            try:
                test_master_instance = test_master.objects.create(
                    test_name=test_name,
                    test_type_id=test_type_obj,
                    skill_type_id=skill_type_obj,
                    question_type_id=question_type_obj
                )
            except Exception as e:
                print(f"Error saving test_master: {e}")
                return JsonResponse({"error": "Test name already exists. Please change test name to proceed"}, status=500)

            

            # Basic validations
            if not college_id:
                return JsonResponse({'error': 'college_id is required'}, status=400)
            
            # Query students (deleted = 0, is_database = True)
            students = candidate_master.objects.filter(
                # is_database=True,
                deleted=0,
                college_id__in=college_id if isinstance(college_id, list) else [college_id]
            )
            if department_id:
                students = students.filter(department_id__in=department_id if isinstance(department_id, list) else [department_id])
            if year:
                students = students.filter(year__in=year if isinstance(year, list) else [year])
            if batch_no:
                students = students.filter(batch_no__in=batch_no if isinstance(batch_no, list) else [batch_no])

            if not students.exists():
                return JsonResponse({'error': 'No students match the provided criteria.'}, status=404)

            current_time = datetime.now()
            response_data = []

            with transaction.atomic():
                for student in students:
                    test_candidate_data = {
                        'test_name': test_name,
                        'question_id': question_id,
                        'question_ids': question_ids[:int(no_of_question)],
                        'duration': duration,
                        'no_of_question': no_of_question,
                        'student_id': student.id,
                        'college_id': student.college_id.id if student.college_id else None,
                        'department_id': student.department_id.id if student.department_id else None,
                        'dtm_start': dtm_start,
                        'dtm_end': dtm_end,
                        'dtm_start1': dtm_start,
                        'dtm_end1': dtm_end,
                        'is_camera_on': is_camera_on,
                        'duration_type': duration_type,
                        'year': student.year,
                        'rules_id': rules_id,
                        'need_candidate_info': need_candidate_info,
                        'dtm_created': current_time,
                        'created_by': created_by,
                        'test_type_id': test_type_id,
                        'question_type_id': question_type_id,
                        'skill_type_id': skill_type_id,
                        'company_name': company_name,
                        'company_email': company_email,
                    }

                    serializer = testcandidatemapSerializers(data=test_candidate_data)
                    if serializer.is_valid():
                        serializer.save()
                        response_data.append(serializer.data)
                    else:
                        return JsonResponse(serializer.errors, status=400)

            return JsonResponse(response_data, status=201, safe=False)

        except json.JSONDecodeError:
            return JsonResponse({"error": "Invalid JSON"}, status=400)

        except Exception as e:
            print(f"Error in PracticeAssignTest: {e}")
            return JsonResponse({"error": "Internal server error"}, status=500)

    return JsonResponse({"error": "Invalid request method"}, status=405)

@api_view(['PUT', 'PATCH'])
def delete_training_schedule(request, pk):
    try:
        # Get the training_schedule_temp object
        college = training_schedule_temp.objects.get(id=pk)
    except training_schedule_temp.DoesNotExist:
        logger.error(f"College with id {pk} not found")
        return Response("college not found", status=404)

    # Soft delete the training_schedule_temp
    college.deleted = 1  # If this field is not in model, add it.
    college.save()

    # Soft delete all related training_schedule records
    related_schedules = training_schedule.objects.filter(training_id=pk, deleted=0)
    for schedule in related_schedules:
        schedule.deleted = 1
        schedule.save()

    return Response("Training and related schedules 'deleted' field updated successfully")

#_____________________________________folder_master_________________#

from .models import folder_master
from .serializers import folderSerializer,folderNewSerializer

# ‚úÖ GET (List All)
class foldergetAPIView(generics.ListAPIView):
    queryset = folder_master.objects.filter(deleted=0).order_by('-id')
    serializer_class = folderNewSerializer

# ‚úÖ POST (Create New)
class foldercreateAPIView(generics.CreateAPIView):
    queryset = folder_master.objects.all()
    serializer_class = folderSerializer

# ‚úÖ GET / PUT / DELETE (Detail, Update, Delete)
class FolderRetrieveUpdateDestroyAPIView(generics.RetrieveUpdateDestroyAPIView):
    queryset = folder_master.objects.all()
    serializer_class = folderSerializer

# ‚úÖ PATCH (Soft Delete)
@api_view(['PATCH'])
def delete_folder_master(request, pk):
    try:
        folder = folder_master.objects.get(id=pk)
    except folder_master.DoesNotExist:
        return Response({"error": "Folder not found"}, status=status.HTTP_404_NOT_FOUND)

    folder.deleted = 1
    folder.save()
    return Response({"message": "Folder marked as deleted"}, status=status.HTTP_200_OK)


@api_view(['POST'])
def update_test_employee_reassign(request):
    try:
        test_name = request.data.get('test_name')
        employee_ids = request.data.get('employee_ids', [])  # updated key

        print(f"Received test_name: {test_name}")
        print(f"Received employee_ids: {employee_ids}")

        if not test_name:
            return Response({"error": "test_name is required"}, status=400)

        if not employee_ids or not isinstance(employee_ids, list):
            return Response({"error": "A list of employee_ids is required"}, status=400)

        # Get today's date range from 6 AM to 11 PM
        today_str = timezone.localtime().strftime('%Y-%m-%d')
        dtm_start = timezone.make_aware(datetime.strptime(f"{today_str} 06:00:00", "%Y-%m-%d %H:%M:%S"))
     
        print(f"Start Time (6 AM): {dtm_start}")
      
        # Get existing test-employee map records
        existing_records = employee_test_assign.objects.filter(
            test_name=test_name,
            employee_id__emp_id__in=employee_ids,
            deleted=0
        )


        if not existing_records.exists():
            print("No matching records found.")
            return Response({"error": "No records found for the given test_name and employee_ids"}, status=404)

        # Delete previous answers for this test_name and employee_ids
        deleted_answers_count, _ = tests_emp_answer.objects.filter(
            test_name=test_name,
            emp_id__in=employee_ids
        ).delete()
        print(f"Deleted {deleted_answers_count} answer(s) from tests_emp_answer.")

        # Update test-employee map records
        updated_count = 0
        for record in existing_records:
            record.is_active = False
            record.test_status = "reassigned"  # use correct field name
            record.total_score = 0
            record.avg_mark = 0
            record.assign_count = (record.assign_count or 0) + 1
            record.save()
            updated_count += 1

        print(f"Updated {updated_count} record(s).")
        return Response({
            "message": f"{updated_count} record(s) updated successfully",
            "answers_deleted": deleted_answers_count
        }, status=200)

    except Exception as e:
        print(f"Error: {str(e)}")
        return Response({"error": "An internal error occurred", "details": str(e)}, status=500)



@api_view(['GET'])
def get_placement_officers_by_college_name(request, college_id):
    try:
        # Step 1: Get the selected college
        college = college_master.objects.get(id=college_id)
        college_name = college.college.strip().lower()

        # Step 2: Get all colleges with the same name (case-insensitive)
        related_colleges = college_master.objects.filter(college__iexact=college_name)
        related_college_ids = related_colleges.values_list('id', flat=True)

        # Step 3: Get Placement Officers from those colleges
        placement_officers = login.objects.filter(role='Placement Officer', college_id__in=related_college_ids)

        # Step 4: Prepare data
        data = [
            {
                'user_name': officer.user_name,
                'email_id': officer.email_id,
                'college_name': officer.college_id.college,
                'college_group': officer.college_id.college_group,
                'college_id': officer.college_id.id,
                'password':officer.password
            }
            for officer in placement_officers
        ]

        return Response(data, status=200)
    except Exception as e:
        return Response({'error': str(e)}, status=500)



@api_view(['POST'])
def create_student_test_request(request):
    try:
        student_id = request.data.get('student_id')
        test_name = request.data.get('test_name')

        if not student_id or not test_name:
            return Response({'error': 'student_id and test_name are required'}, status=400)

        # Check if student exists
        if not candidate_master.objects.filter(id=student_id).exists():
            return Response({'error': 'Invalid student_id'}, status=404)

        new_request = student_request.objects.create(
            student_id_id=student_id,
            remarks=test_name,
            student_query='Requested for assign company test',
            status='Pending',
            is_query_type='Company Test',
            dtm_request=timezone.now()
        )

        serializer = studentRequestSerializer(new_request)
        return Response(serializer.data, status=status.HTTP_201_CREATED)

    except Exception as e:
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class FilterCompanyTestAPIView(APIView):
    def get(self, request):
        student_id = request.query_params.get('student_id', None)

        if not student_id:
            return Response({"error": "student_id is required"}, status=status.HTTP_400_BAD_REQUEST)

        # ‚úÖ Get distinct test_names (remarks) for this student_id
        test_names = student_request.objects.filter(
            student_id=student_id,
            is_query_type__icontains="Company Test",
            status__iexact="Accepted",
            deleted=0
        ).values_list("remarks", flat=True).distinct()

        if not test_names:
            return Response({"error": "No matching test found for this student"}, status=status.HTTP_404_NOT_FOUND)

        # ‚úÖ Fetch all students mapped to those unique test_names
        queryset = (
            student_request.objects.filter(
                is_query_type__icontains="Company Test",
                status__iexact="Accepted",
                remarks__in=test_names,
                deleted=0
            )
            .select_related("student_id")
            .values(
                "remarks",                      # test_name
                "student_id__id",
                "student_id__user_name",        # get username also
                "student_query"
            )
            .distinct("remarks", "student_id__id")  # ‚úÖ ensure unique per test_name + student
        )

        # ‚úÖ Format response
        data = [
            {
                "test_name": row["remarks"],
                "student_id": row["student_id__id"],
                "user_name": row["student_id__user_name"],
                "student_query": row["student_query"],
            }
            for row in queryset
        ]

        return Response(data, status=status.HTTP_200_OK)
@api_view(['GET'])
def get_view_practiceReport_po(request):
    college_id = request.GET.get('college_id')
    department = request.GET.get('department')  # filter
    year_filter = request.GET.get('year')       # filter
    search_query = request.GET.get('search', '')  # search keyword
    test_name = request.GET.get('test_name')   # ‚úÖ strict test filter

    filters = {
        'deleted': 0,
        'created_by': 'Student',
        'is_active': True
    }
    if college_id:
        filters['college_id'] = college_id
    if department:
        filters['department_id__department__icontains'] = department
    if test_name:  # ‚úÖ exact filter
        filters['test_name'] = test_name

    # Base queryset
    qs = tests_candidates_map.objects.filter(**filters).select_related(
        'rules_id',
        'department_id',
        'student_id',
        'college_id'
    )

    # ‚úÖ Attach year from candidate_master
    qs = qs.annotate(
        candidate_year=F('student_id__year')
    )

    # Filter by year if provided
    if year_filter:
        qs = qs.filter(student_id__year=year_filter)

    # Search filter (for names, reg no, etc.)
    if search_query and not test_name:  # avoid double filtering
        qs = qs.filter(
            Q(test_name__icontains=search_query) |
            Q(student_id__students_name__icontains=search_query) |
            Q(student_id__registration_number__icontains=search_query) |
            Q(student_id__email_id__icontains=search_query) |
            Q(student_id__user_name__icontains=search_query)
        )

    # Select values
    qs = qs.values(
        'id',
        'test_name',
        'college_id__id',
        'college_id__college',
        'college_id__college_group',
        'department_id__department',
        'student_id__id',
        'student_id__students_name',
        'student_id__user_name',
        'student_id__email_id',
        'student_id__mobile_number',
        'student_id__registration_number',
        'dtm_start_test',
        'capture_duration',
        'is_active',
        'candidate_year',
        'stu_avg_mark',
        'is_reassigned',
        'attempt_count'
    ).order_by('-dtm_start_test')

    # Pagination
    paginator = CustomPagination()
    page = paginator.paginate_queryset(qs, request)

    # Format results
    results = []
    for testing in page:
        college_with_group = testing['college_id__college']
        if testing['college_id__college_group']:
            college_with_group += f"-{testing['college_id__college_group']}"
        avg_mark = testing['stu_avg_mark'] if testing['stu_avg_mark'] is not None else 0

        results.append({
            'id': testing['id'],
            'test_name': testing['test_name'],
            'collegeId': testing['college_id__id'],
            'college_id': college_with_group,
            'department_id': testing['department_id__department'],
            'student_id': testing['student_id__id'],
            'registration_number': testing['student_id__registration_number'],
            'email_id': testing['student_id__email_id'],
            'mobile_number': testing['student_id__mobile_number'],
            'student_name': testing['student_id__students_name'],
            'user_name': testing['student_id__user_name'],
            'capture_duration': testing['capture_duration'],
            'is_active': testing['is_active'],
            'year': testing['candidate_year'],
            'avg_mark': avg_mark,
            'is_reassigned': testing['is_reassigned'],
            'attempt_count': testing['attempt_count']
        })

    return paginator.get_paginated_response(results)


# -------------------- EXISTING REPORT API --------------------
class DayWiseReportAPIView(APIView):
    def get(self, request):
        try:
            # Params
            filter_date_str = request.query_params.get("date", None)
            college_id = request.query_params.get("college_id", None)
            department_id = request.query_params.get("department_id", None)
            year = request.query_params.get("year", None)
            test_name = request.query_params.get("test_name", None)
            search_query = request.query_params.get("search", None)
            export_all = request.query_params.get("export", "0") == "1"

            
            # Base queryset
            queryset = tests_candidates_map.objects.select_related(
                "student_id", "department_id", "college_id"
            ).filter(
                deleted=0,is_active=True
            ).exclude(
                created_by='Student'
            )

            # Date filter
            if filter_date_str:
                filter_date = parse_date(filter_date_str)
                if not filter_date:
                    return Response({"error": "Invalid date format. Use YYYY-MM-DD"}, status=status.HTTP_400_BAD_REQUEST)
                queryset = queryset.filter(
                    Q(dtm_start_test__date=filter_date)
                )

            # Optional filters
            if college_id:
                queryset = queryset.filter(college_id_id=college_id)
            if department_id:
                queryset = queryset.filter(department_id_id=department_id)
            if year:
                queryset = queryset.filter(year=year)
            if test_name:
                queryset = queryset.filter(test_name=test_name)

            # Search
            if search_query:
                queryset = queryset.filter(
                    Q(student_id__students_name__icontains=search_query) |
                    Q(student_id__user_name__icontains=search_query) |
                    Q(student_id__registration_number__icontains=search_query) |
                    Q(test_name__icontains=search_query) |
                    Q(student_id__email_id__icontains=search_query) |
                    Q(student_id__mobile_number__icontains=search_query)
                )

            # Order results
            queryset = queryset.order_by("-dtm_start_test")

            total_count = queryset.count()

            if export_all:
                page = queryset  # No pagination, get all filtered rows
            else:
                paginator = CustomPagination()
                page = paginator.paginate_queryset(queryset, request)
            
            results = [
                {
                    "user_name": obj.student_id.user_name,
                    "students_name": obj.student_id.students_name,
                    "reg_no": obj.student_id.registration_number,
                    "gender": obj.student_id.gender,
                    "email_id": obj.student_id.email_id,
                    "mobile_number": obj.student_id.mobile_number,
                    "college_id": obj.college_id.id if obj.college_id else None,
                    "college_name": (
                        f"{obj.college_id.college}-{obj.college_id.college_group}"
                        if obj.college_id and obj.college_id.college_group
                        else (obj.college_id.college if obj.college_id else None)
                    ),
                    "department_id": obj.student_id.department_id.id if obj.student_id.department_id else None,
                    "department": obj.student_id.department_id.department if obj.student_id.department_id else None,
                    "test_name": obj.test_name,
                    "dtm_start": obj.dtm_start,
                    "dtm_start_test": obj.dtm_start_test,
                    "year": obj.year,
                    "total_score": obj.total_score,
                    "avg_mark": obj.avg_mark,
                    "status": obj.status,
                    "capture_duration": obj.capture_duration,
                }
                for obj in page
            ]
            if export_all:
                return Response({
                    "count": total_count,
                    "data": results
                })

            return paginator.get_paginated_response({
                "count": queryset.count(),
                "data": results
            })

        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


from django.utils.dateparse import parse_date
from django.db.models import Q

class ReportFilterOptionsAPIView(APIView):
    def get(self, request):
        try:
            college_id = request.query_params.get("college_id", None)
            department_id = request.query_params.get("department_id", None)
            filter_date_str = request.query_params.get("date", None)

            filter_date = parse_date(filter_date_str) if filter_date_str else None

            # 1Ô∏è‚É£ Colleges
            colleges_qs = candidate_master.objects.filter(
                college_id__isnull=False
            ).select_related("college_id").values(
                "college_id", "college_id__college", "college_id__college_group"
            ).distinct()

            if filter_date:
                colleges_qs = colleges_qs.filter(
                    college_id__in=tests_candidates_map.objects.filter(
                        dtm_start_test__date=filter_date
                    ).values_list("college_id", flat=True)
                )

            colleges = [
                {
                    "id": c["college_id"],
                    "name": (
                        f"{c['college_id__college']} - {c['college_id__college_group']}"
                        if c["college_id__college_group"]
                        else c["college_id__college"]
                    )
                }
                for c in colleges_qs
            ]

            # 2Ô∏è‚É£ Departments
            dept_qs = candidate_master.objects.filter(department_id__isnull=False)
            if college_id:
                dept_qs = dept_qs.filter(college_id_id=college_id)
            if filter_date:
                dept_qs = dept_qs.filter(
                    department_id__in=tests_candidates_map.objects.filter(
                        dtm_start_test__date=filter_date
                    ).values_list("department_id", flat=True)
                )

            departments_qs = dept_qs.select_related("department_id").values(
                "department_id", "department_id__department"
            ).distinct()

            departments = [
                {"id": d["department_id"], "name": d["department_id__department"]}
                for d in departments_qs
            ]

            # 3Ô∏è‚É£ Years
            year_qs = candidate_master.objects.filter(year__isnull=False)
            if college_id:
                year_qs = year_qs.filter(college_id_id=college_id)
            if department_id:
                year_qs = year_qs.filter(department_id_id=department_id)
            if filter_date:
                student_ids = tests_candidates_map.objects.filter(
                    dtm_start_test__date=filter_date
                ).values_list("student_id_id", flat=True)
                year_qs = year_qs.filter(id__in=student_ids)

            years = sorted(list(set(year_qs.values_list("year", flat=True))))

            # 4Ô∏è‚É£ Test Names
            test_qs = tests_candidates_map.objects.filter(student_id__college_id__isnull=False)

            if filter_date:
                test_qs = test_qs.filter(dtm_start_test__date=filter_date)
            if college_id:
                test_qs = test_qs.filter(student_id__college_id=college_id)
            if department_id:
                test_qs = test_qs.filter(student_id__department_id=department_id)

            test_names = test_qs.values_list("test_name", flat=True).distinct()

            return Response({
                "colleges": colleges,
                "departments": departments,
                "years": years,
                "test_names": sorted(test_names)
            }, status=status.HTTP_200_OK)

        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class FolderListBySkillTypeAPIView(APIView):
    def get(self, request):
        try:
            skill_type_id = request.query_params.get("skill_type_id", None)
            if not skill_type_id:
                return Response(
                    {"error": "skill_type_id is required"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            folders = folder_master.objects.filter(skill_type_id=skill_type_id).values("id", "folder_name")

            return Response(list(folders), status=status.HTTP_200_OK)

        except Exception as e:
            return Response(
                {"error": str(e)},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

from .models import folder_master, training_schedule_temp

@csrf_exempt
def add_training_topics(request, training_id):
    print("STEP 1: Entered `add_training_topics` view")

    if request.method != "POST":
        return JsonResponse({"error": "Only POST method is allowed"}, status=405)

    try:
        print("üîç STEP 2: Request method =", request.method)
        print("üì¶ STEP 3: Raw request body =", request.body)
        data = json.loads(request.body)
        folder_ids = data.get("folder_ids", [])
        print("üìú STEP 4: Parsed JSON =", data)

        # Get folder names from the IDs
        folder_names = list(
            folder_master.objects.filter(id__in=folder_ids).values_list("folder_name", flat=True)
        )
        print("üÜï STEP 5: New topics from request =", folder_names)

        # Fetch schedule
        schedule = training_schedule_temp.objects.get(id=training_id)
        print("üìÑ STEP 7: Found schedule =", schedule)

        # Merge with existing topics
        existing_topics = schedule.topics if isinstance(schedule.topics, list) else []
        print("üìÇ STEP 9: Existing topics before update =", existing_topics)

        updated_topics = existing_topics + folder_names
        updated_topics = list(dict.fromkeys(updated_topics))  # remove duplicates, keep order
        print("üìå STEP 10: Updated topics to save =", updated_topics)

        # Save updated topics
        schedule.topics = updated_topics
        schedule.save()
        print("üíæ STEP 11: Schedule saved successfully")

        return JsonResponse({"success": True, "topics": updated_topics})

    except training_schedule_temp.DoesNotExist:
        return JsonResponse({"error": "Training schedule not found"}, status=404)
    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500)

from .serializers import TrainingScheduleTempSerializer

@api_view(['PATCH'])
def update_batch_skill(request, pk):
    """
    API to update batch_skill, question_type, and skill_type.
    Example payload:
    {
        "question_type": [1, 2],
        "skill_type": ["Quants", "Logical", "Verbal"],
        "batch_skill": {
            "Quants": "Batch1",
            "Logical": "Batch2",
            "Python": "Batch3"
        }
    }
    """
    try:
        schedule = training_schedule_temp.objects.get(pk=pk)
    except training_schedule_temp.DoesNotExist:
        return Response({"error": "Schedule not found"}, status=status.HTTP_404_NOT_FOUND)

    serializer = TrainingScheduleTempSerializer(schedule, data=request.data, partial=True)
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_200_OK)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

@api_view(['GET'])
def get_dropdown_filters(request):
    college_id = request.GET.get('college_id')

    qs = candidate_master.objects.all().select_related('college_id', 'department_id')

    if college_id:
        qs = qs.filter(college_id=college_id)

    # Get unique values
    colleges = qs.values('college_id__id', 'college_id__college', 'college_id__college_group').distinct()
    departments = qs.values('department_id__department').distinct()
    years = qs.values('year').distinct()

    # Format response
    college_list = [
        {
            'id': c['college_id__id'],
            'name': f"{c['college_id__college']}{'-'+c['college_id__college_group'] if c['college_id__college_group'] else ''}"
        } 
        for c in colleges
    ]
    department_list = [d['department_id__department'] for d in departments]
    year_list = sorted([y['year'] for y in years if y['year']])

    return Response({
        'colleges': college_list,
        'departments': department_list,
        'years': year_list
    }, status=200)



@csrf_exempt
def download_topics_excelold(request):
    year = request.GET.get("year")  # optional param
    question_type = request.GET.get("question_type", "Aptitude,Technical").split(",")

    # --- Topics by Year ---
    topics_map = {
        "1": {
            "Quants": ["Number System", "HCF and LCM", "Decimal Fractions",
                       "Square Roots", "Cube Roots", "Average", "Orientation"],
            "Logical": ["Number Series", "Puzzles", "Mirror Image & Water Images",
                        "Logical Puzzle", "Blood Relations"],
            "Verbal": ["Articles & Prepositions", "Tenses", "Sequence of Words",
                       "Inserting the Missing Character", "Verification Of Truth"]
        },
        "2": {
            "Quants": ["Percentage", "Profit & Loss", "Ages", "SI & CI", "Ratio Proportion",
                       "Time and Work", "Permutation Combination", "Time Speed and Distance",
                       "Arithmetic Progression", "Data Sufficiency"],
            "Logical": ["Odd One Out", "Logical Sequencing", "Venn Diagram", "Syllogism", "Analogies",
                        "Logical Game", "Problem Solving", "Statements and Arguments",
                        "Assumptions", "Conclusions", "Directions"],
            "Verbal": ["Synonyms & Antonyms", "Idioms and Phrases", "Direct & Indirect Speech",
                       "Conjunctions and Punctuations", "Oral Communication", "Body language",
                       "Personality Development", "Grooming", "Talk on a topic",
                       "Sentence Formation", "Error Corrections", "Jumbling of Sentences",
                       "Reading Comprehension", "Paragraph Formation", "Communication",
                       "Writing Skills", "Reading Skills", "Listening Skills", "Behavioural Skills"],
            "C": ["C - Introduction & Setup", "C - Data Types and Variables",
                  "C - Operators and Expressions", "C - Control Structures",
                  "C - Looping Constructs", "C - Functions", "C - Arrays", "C - Strings",
                  "C - Pointers", "C - Structures and Unions", "C - File Handling",
                  "C - Dynamic Memory Allocation"],
            "CPP": ["C++ Basics & First Program", "C++ Data Types & Variables",
                    "Operators & Control Structures in C++", "Functions & Function Overloading in C++",
                    "Classes & Objects in C++", "Constructors & Destructors in C++", "Inheritance in C++",
                    "Polymorphism & Virtual Functions in C++", "Templates in C++",
                    "Exception Handling in C++", "STL - Introduction in C++",
                    "STL - Containers (Vectors, Lists, Maps, Sets) in C++", "STL - Iterators & Algorithms in C++","Arrays in C++" ,"Strings in C++" ,"Sorting in C++" ,"Queue in C++" ,"Stack in C++" ,"Heaps in C++" ,"Linked List in C++" , "Trees in C++"  , "Graph in C++"]
       
        
        },
        '3':{
            "Quants": ["Boat and Streams", "Train", "Pipes and Cisterns", "Data Interpretation",
                                "Flow Chart", "Calendar", "Clock", "Alligation & Mixture", "Geometry", "Mensuration"],
            "Logical": ["Seating Arrangements", "Mathematical Operations", "Arithmetical Reasoning",
                                 "Cubes and Dice", "Probability", "Paper Folding", "Judgement", "Theme Detection"],
            "Verbal": ["Synonyms & Antonyms", "Idioms and Phrases", "Analogies", "Sentence Jumbling",
                                "Presentation Skills", "Goal Setting", "Time Management", "Team Building",
                                "Resume Building", "Public Speaking", "Error Spotting", "Parts of Speech"],
            "Java":  ["Java-intro","Java-Setup and First Program" ,"Java-Data Types and Variables", "Java-Operators and Control Statements", "Java-Classes and Objects", "Java-Methods and Method Overloading", "Java-Inheritance", "Java-Polymorphism", "Java-Abstraction and Interfaces", "Java-Packages and Access Modifiers", "Java-Exception Handling", "Java-Basic Input and Output","Java-Heaps" ,"Java-Hashing" ,"Java-Queues", "Java-Stack" , "Java-Arrays" , "Java-Sorting" , "Java-Strings","Java-Tree"],
            "Python" : ["Python-Intro", "Python-Setup and First Program", "Python-Data Types and Variables", "Python-Operators and Expressions", "Python-Control Flow", "Python-Loops", "Python-Functions", "Python-Lists and Tuples", "Python-Dictionaries and Sets", "Python-Strings", "Python-Modules and Packages", "Python-File I/O","Python-Hashing" , "Python-Heaps" ,"Python-Queues" , "Python-Sorting Algorithm" ]
                      
        },
                        
        '4':{
            "Quants" : ["Time and Work", "Ages", "Ratio Proportion", "Speed and Distance", "Data Sufficiency"],
            "Logical": ["Pattern Completion", "Image Analysis", "Blood Relations", "Coding Decoding",
                                   "Seating Arrangements"],
            "Verbal": ["Synonyms", "Resume Building", "Interview Skills", "GD", "Mock Interview"],
            "Java": ["Java-Generics","Java-Collections Framework","Java-Multi-threading and Concurrency","Java-Streams and Lambda Expressions","Java-File I/O (NIO.2)","Java-JDBC","Java-Networking (Sockets)","Java-JavaFX","Java-Annotations","Java-Reflection","Java-Serialization","Java-Internationalization (i18n) & Localization (l10n)","Java-Security (Cryptography & Access Control)","Java-Regular Expressions","Java-Modules (Java 9+ Module System)","Java-Memory Management & Garbage Collection","Java-JVM Internals & Performance Tuning"],
            "Python": [
                     "Python - Object-Oriented Programming", "Python - Advanced Functions (Decorators, Generators)", "Python - Exception Handling", "Python - Working with JSON and CSV files", "Python - Regular Expressions",
                    "Python - Multithreading and Multiprocessing", "Python - Networking (Sockets)", "Python - Web Scraping (BeautifulSoup, Scrapy)", "Python - Data Analysis (Pandas)", "Python - Visualization (Matplotlib, Seaborn)"
                     ]

        }
                       
        # add Year 3 & Year 4 same as in add_training_schedule
    }

    # --- Collect Topics ---
    collected_topics = []
    if year and year in topics_map:
        for subject, tlist in topics_map[year].items():
            collected_topics.extend(tlist)
    else:
        # No year ‚Üí merge all years
        for _, subjects in topics_map.items():
            for tlist in subjects.values():
                collected_topics.extend(tlist)

    collected_topics = list(dict.fromkeys(collected_topics))  # remove duplicates

    # --- Create Excel ---
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "Topics"

    ws.append(["Topics"])  # header row
    for topic in collected_topics:
        ws.append([topic])

    # --- Response ---
    buffer = io.BytesIO()
    wb.save(buffer)
    buffer.seek(0)

    response = HttpResponse(buffer, content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    filename = f"topics_year_{year if year else 'all'}.xlsx"
    response['Content-Disposition'] = f'attachment; filename={filename}'
    return response


@csrf_exempt
def download_topics_excel(request):
    # Example input: ?year=1,2,3
    year_param = request.GET.get("year", "")  # Default to empty string if not present
    years = [y.strip() for y in year_param.split(",") if y.strip()]  # Convert to list

    question_type = request.GET.get("question_type", "Aptitude,Technical").split(",")

    topics_map = {
        "1": {
            "Quants": ["Number System", "HCF and LCM", "Decimal Fractions",
                       "Square Roots", "Cube Roots", "Average", "Orientation"],
            "Logical": ["Number Series", "Puzzles", "Mirror Image & Water Images",
                        "Logical Puzzle", "Blood Relations"],
            "Verbal": ["Articles & Prepositions", "Tenses", "Sequence of Words",
                       "Inserting the Missing Character", "Verification Of Truth"]
        },
        "2": {
            "Quants": ["Percentage", "Profit & Loss", "Ages", "SI & CI", "Ratio Proportion",
                       "Time and Work", "Permutation Combination", "Time Speed and Distance",
                       "Arithmetic Progression", "Data Sufficiency"],
            "Logical": ["Odd One Out", "Logical Sequencing", "Venn Diagram", "Syllogism", "Analogies",
                        "Logical Game", "Problem Solving", "Statements and Arguments",
                        "Assumptions", "Conclusions", "Directions"],
            "Verbal": ["Synonyms & Antonyms", "Idioms and Phrases", "Direct & Indirect Speech",
                       "Conjunctions and Punctuations", "Oral Communication", "Body language",
                       "Personality Development", "Grooming", "Talk on a topic",
                       "Sentence Formation", "Error Corrections", "Jumbling of Sentences",
                       "Reading Comprehension", "Paragraph Formation", "Communication",
                       "Writing Skills", "Reading Skills", "Listening Skills", "Behavioural Skills"],
            "C": ["C - Introduction & Setup", "C - Data Types and Variables",
                  "C - Operators and Expressions", "C - Control Structures",
                  "C - Looping Constructs", "C - Functions", "C - Arrays", "C - Strings",
                  "C - Pointers", "C - Structures and Unions", "C - File Handling",
                  "C - Dynamic Memory Allocation"],
            "CPP": ["C++ Basics & First Program", "C++ Data Types & Variables",
                    "Operators & Control Structures in C++", "Functions & Function Overloading in C++",
                    "Classes & Objects in C++", "Constructors & Destructors in C++", "Inheritance in C++",
                    "Polymorphism & Virtual Functions in C++", "Templates in C++",
                    "Exception Handling in C++", "STL - Introduction in C++",
                    "STL - Containers (Vectors, Lists, Maps, Sets) in C++", "STL - Iterators & Algorithms in C++","Arrays in C++" ,"Strings in C++" ,"Sorting in C++" ,"Queue in C++" ,"Stack in C++" ,"Heaps in C++" ,"Linked List in C++" , "Trees in C++"  , "Graph in C++"]
       
        
        },
        '3':{
            "Quants": ["Boat and Streams", "Train", "Pipes and Cisterns", "Data Interpretation",
                                "Flow Chart", "Calendar", "Clock", "Alligation & Mixture", "Geometry", "Mensuration"],
            "Logical": ["Seating Arrangements", "Mathematical Operations", "Arithmetical Reasoning",
                                 "Cubes and Dice", "Probability", "Paper Folding", "Judgement", "Theme Detection"],
            "Verbal": ["Synonyms & Antonyms", "Idioms and Phrases", "Analogies", "Sentence Jumbling",
                                "Presentation Skills", "Goal Setting", "Time Management", "Team Building",
                                "Resume Building", "Public Speaking", "Error Spotting", "Parts of Speech"],
            "Java":  ["Java-intro","Java-Setup and First Program" ,"Java-Data Types and Variables", "Java-Operators and Control Statements", "Java-Classes and Objects", "Java-Methods and Method Overloading", "Java-Inheritance", "Java-Polymorphism", "Java-Abstraction and Interfaces", "Java-Packages and Access Modifiers", "Java-Exception Handling", "Java-Basic Input and Output","Java-Heaps" ,"Java-Hashing" ,"Java-Queues", "Java-Stack" , "Java-Arrays" , "Java-Sorting" , "Java-Strings","Java-Tree"],
            "Python" : ["Python-Intro", "Python-Setup and First Program", "Python-Data Types and Variables", "Python-Operators and Expressions", "Python-Control Flow", "Python-Loops", "Python-Functions", "Python-Lists and Tuples", "Python-Dictionaries and Sets", "Python-Strings", "Python-Modules and Packages", "Python-File I/O","Python-Hashing" , "Python-Heaps" ,"Python-Queues" , "Python-Sorting Algorithm" ]
                      
        },
                        
        '4':{
            "Quants" : ["Time and Work", "Ages", "Ratio Proportion", "Speed and Distance", "Data Sufficiency"],
            "Logical": ["Pattern Completion", "Image Analysis", "Blood Relations", "Coding Decoding",
                                   "Seating Arrangements"],
            "Verbal": ["Synonyms", "Resume Building", "Interview Skills", "GD", "Mock Interview"],
            "Java": ["Java-Generics","Java-Collections Framework","Java-Multi-threading and Concurrency","Java-Streams and Lambda Expressions","Java-File I/O (NIO.2)","Java-JDBC","Java-Networking (Sockets)","Java-JavaFX","Java-Annotations","Java-Reflection","Java-Serialization","Java-Internationalization (i18n) & Localization (l10n)","Java-Security (Cryptography & Access Control)","Java-Regular Expressions","Java-Modules (Java 9+ Module System)","Java-Memory Management & Garbage Collection","Java-JVM Internals & Performance Tuning"],
            "Python": [
                     "Python - Object-Oriented Programming", "Python - Advanced Functions (Decorators, Generators)", "Python - Exception Handling", "Python - Working with JSON and CSV files", "Python - Regular Expressions",
                    "Python - Multithreading and Multiprocessing", "Python - Networking (Sockets)", "Python - Web Scraping (BeautifulSoup, Scrapy)", "Python - Data Analysis (Pandas)", "Python - Visualization (Matplotlib, Seaborn)"
                     ]

        }
                       
        # add Year 3 & Year 4 same as in add_training_schedule
    }

    
    # --- Collect Topics ---
    collected_topics = []

    if years:
        for year in years:
            if year in topics_map:
                for subject, tlist in topics_map[year].items():
                    collected_topics.extend(tlist)
    else:
        # If no years provided, merge all topics
        for _, subjects in topics_map.items():
            for tlist in subjects.values():
                collected_topics.extend(tlist)

    collected_topics = list(dict.fromkeys(collected_topics))  # remove duplicates

    # --- Create Excel ---
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "Topics"
    ws.append(["Topics"])

    for topic in collected_topics:
        ws.append([topic])

    # --- Response ---
    buffer = io.BytesIO()
    wb.save(buffer)
    buffer.seek(0)

    filename = f"topics_year_{'_'.join(years) if years else 'all'}.xlsx"
    response = HttpResponse(buffer, content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    response['Content-Disposition'] = f'attachment; filename={filename}'

    return response


class FolderMasterListAPItestView(generics.ListAPIView):
    serializer_class = FolderMasterSerializer

    def get_queryset(self):
        # Step 1: Count questions per question_paper
        papers_with_counts = (
            question_paper_master.objects
            .annotate(q_count=Count('question_master'))  # uses related_name automatically
            .filter(q_count__gt=1)  # only papers with >1 questions
            .values_list('folder_name', flat=True)
            .distinct()
        )

        # Step 2: Filter folder_master using those folder_names
        return folder_master.objects.filter(
            folder_name__in=papers_with_counts,
            deleted=0
        )

@api_view(['GET'])
def get_group_test_name_multiple(request):
    try:
        search = request.query_params.get('search', '')
        college_ids = request.query_params.get('college_ids')  # e.g. "1,2,3"

        filters = {'deleted': 0}

        if college_ids:
            college_ids_list = [int(cid) for cid in college_ids.split(',') if cid.strip().isdigit()]
            filters['college_id__in'] = college_ids_list

        tests_candidates = tests_candidates_map.objects.filter(**filters).exclude(created_by='Student')

        if search:
            tests_candidates = tests_candidates.filter(
                Q(test_name__icontains=search)
            )

        # Group by only test_name, dtm_start1, dtm_end1
        tests_candidates = (
            tests_candidates
            .values('test_name', 'dtm_start1', 'dtm_end1', 'college_id')
            .annotate(
                student_count=Count('student_id'),
                active_student_count=Count('student_id', filter=Q(is_active=True)),
                reassigned_student_count=Count('student_id', filter=Q(is_reassigned=True)),
                dtm_created=Max('dtm_created')
            )
            .order_by('-dtm_created')
        )

        paginator = CustomPagination()
        paginated_data = paginator.paginate_queryset(tests_candidates, request)

        test_candidate_map_data = [
            {
                'test_name': row['test_name'],
                 'college_id': row['college_id'],
                'dtm_start': django_format_date(localtime(row['dtm_start1']), 'd-m-Y h:i A') if row['dtm_start1'] else "Not Available",
                'dtm_end': django_format_date(localtime(row['dtm_end1']), 'd-m-Y h:i A') if row['dtm_end1'] else "Not Available",
                'student_count': row['student_count'],
                'active_student_count': row['active_student_count'],
                'reassigned_student_count': row['reassigned_student_count'],
                'dtm_created': row['dtm_created'],
            }
            for row in paginated_data
        ]

        return paginator.get_paginated_response(test_candidate_map_data)

    except Exception as e:
        return Response({'error': str(e)}, status=500)


@api_view(['GET'])
def get_user_colleges(request):
    try:
        username = request.query_params.get("username", None)

        if not username:
            return Response({"error": "username query param is required"}, status=400)

        user = login.objects.filter(user_name=username, deleted=0).first()
        if not user:
            return Response({"error": "User not found"}, status=404)

        remarks_value = user.remarks
        college_ids = []

        if remarks_value:
            try:
                # case 1: stored as JSON (like '["1","2"]')
                college_ids = json.loads(remarks_value)
            except Exception:
                # case 2: stored as comma-separated string (like "1,2,3")
                college_ids = [cid.strip() for cid in remarks_value.split(",") if cid.strip()]

        return Response({
            "username": user.user_name,
            "role": user.role,
            "college_ids": college_ids
        })

    except Exception as e:
        return Response({"error": str(e)}, status=500)


# Generate OTP
def generate_otp():
    return str(random.randint(100000, 999999))

# Email sender (threaded)
def send_otp_email(email, otp):
    subject = "Your OTP for Campus Connections"
    message = f"""
    Dear User,

    Your One Time Password (OTP) is: {otp}

    This OTP is valid for the next 10 minutes.
    Please do not share it with anyone.

    Regards,
    Campus Connections
    www.campusconnection.co.in
    """
    from_email = settings.DEFAULT_FROM_EMAIL
    send_mail(subject, message, from_email, [email])

# API to request OTP
@csrf_exempt
def send_otp_view(request):
    if request.method != "POST":
        return JsonResponse({"error": "Method not allowed"}, status=405)

    try:
        data = json.loads(request.body.decode("utf-8"))
        username = data.get("username")

        if not username:
            return JsonResponse({"error": "Username is required"}, status=400)

        # Find user by username
        try:
            user = login.objects.get(user_name=username)
        except login.DoesNotExist:
            return JsonResponse({"error": "User not found"}, status=404)

        if not user.email_id:
            return JsonResponse({"error": "User has no email registered"}, status=400)

        # Generate OTP
        otp = generate_otp()
        user.otp_code = otp
        user.otp_created_at = datetime.now()
        user.save(update_fields=["otp_code", "otp_created_at"])

        # Send OTP to email in background
        threading.Thread(target=send_otp_email, args=(user.email_id, otp)).start()

        return JsonResponse({"message": "OTP sent to registered email"}, status=200)

    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500)


@csrf_exempt
def verify_otp_view(request):
    if request.method != "POST":
        return JsonResponse({"success": False, "error": "Method not allowed"}, status=405)

    try:
        data = json.loads(request.body.decode("utf-8"))
        username = data.get("username")
        otp = data.get("otp")

        if not username or not otp:
            return JsonResponse(
                {"success": False, "error": "Username and OTP are required"},
                status=400,
            )

        try:
            user = login.objects.get(user_name=username)
        except login.DoesNotExist:
            return JsonResponse(
                {"success": False, "error": "User not found"},
                status=404,
            )

        if not user.otp_code:
            return JsonResponse(
                {"success": False, "error": "No OTP generated. Please request a new OTP."},
                status=400,
            )

        # OTP expiry check (10 minutes)
        if user.otp_created_at and timezone.now() > user.otp_created_at + timedelta(minutes=10):
            return JsonResponse(
                {"success": False, "error": "OTP has expired. Please request a new OTP."},
                status=400,
            )

        # Match OTP
        if str(user.otp_code) != str(otp):
            return JsonResponse(
                {"success": False, "error": "Invalid OTP. Please try again."},
                status=400,
            )

        # OTP correct ‚Üí clear it
        user.otp_code = None
        user.otp_created_at = None
        user.save(update_fields=["otp_code", "otp_created_at"])

        return JsonResponse(
            {"success": True, "message": "OTP verified successfully. Login successful."},
            status=200,
        )

    except Exception as e:
        return JsonResponse(
            {"success": False, "error": f"Server error: {str(e)}"},
            status=500,
        )

@csrf_exempt
def check_user_status_view(request):
    if request.method != "GET":
        return JsonResponse({"error": "Method not allowed"}, status=405)

    try:
        username = request.GET.get("username")
        if not username:
            return JsonResponse({"error": "Username is required"}, status=400)

        # Find user
        try:
            user = login.objects.get(user_name=username)
        except login.DoesNotExist:
            return JsonResponse({"error": "User not found"}, status=404)

        response_data = {
            "user_name": user.user_name,
            "role": user.role,
            "email_id": user.email_id,
            "mobile_number": user.mobile_number,
        }

        # If role = Student ‚Üí check candidate_master
        if user.role == "Student":
            try:
                candidate = candidate_master.objects.get(user_name=username)
                response_data["is_database"] = candidate.is_database
            except candidate_master.DoesNotExist:
                response_data["is_database"] = None  # candidate not found

        return JsonResponse(response_data, status=200)

    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500)

@api_view(['GET'])
def get_content_tool_access(request):
    try:
        search = request.query_params.get('search', '') 
        college_id = request.query_params.get('college_id', '')
        question_type = request.query_params.get('question_type', '')  
        skill_type = request.query_params.get('skill_type', '')  

        # Step 1: Validate college_id
        if not college_id:
            return Response(
                {"message": "college_id is required."},
                status=status.HTTP_400_BAD_REQUEST
            )

        # Step 2: Check college access level
        college = college_master.objects.filter(id=college_id).first()
        if not college:
            return Response(
                {"message": "Invalid college_id."},
                status=status.HTTP_400_BAD_REQUEST
            )

        if college.level_of_access != "Platinum":
            return Response(
                {"message": f"Access denied. Your college does not have Platinum access (current: {college.level_of_access})."},
                status=status.HTTP_403_FORBIDDEN
            )

        # Step 3: Fetch content if access allowed
        base_query = content_master.objects.filter(deleted=0)

        # üîπ Apply filters
        if search:
            base_query = base_query.filter(Q(topic__icontains=search))

        if question_type:
            base_query = base_query.filter(question_type_id__question_type__iexact=question_type)

        if skill_type:
            base_query = base_query.filter(skill_type_id__skill_type__iexact=skill_type)

        # üîπ Build response
        content_data = list(base_query.values(
            'id',
            'topic',
            'question_type_id__question_type',
            'skill_type_id__skill_type',
            'content_url',
            'actual_content',
            'worksheet_link',
        ).order_by('-id'))

        # Always set departments and years = "All"
        for item in content_data:
            item["departments"] = "All"
            item["years"] = "All"

        # Pagination
        paginator = CustomPagination()
        paginated_data = paginator.paginate_queryset(content_data, request)
        return paginator.get_paginated_response(paginated_data)

    except Exception as e:
        return Response(
            {"error": str(e), "message": "Failed to fetch content data."},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

from .serializers import StudentRequestCompanySerializer



@api_view(['GET'])
def get_student_requests_by_username(request, user_name):
    """
    Fetch all student requests for a given user_name (from candidate_master)
    Only return: student_id, user_name, status, remarks
    """
    try:
        requests = student_request.objects.filter(
            student_id__user_name=user_name,  # üëà join candidate_master.user_name
            deleted=0
        ).order_by('-dtm_request')

        serializer = StudentRequestCompanySerializer(requests, many=True)
        return Response(serializer.data, status=status.HTTP_200_OK)
    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_400_BAD_REQUEST)


@api_view(['POST'])
def create_student_Company_test_request(request):
    try:
        student_id = request.data.get('student_id')
        remarks = request.data.get('folder_name')

        if not student_id or not remarks:
            return Response({'error': 'student_id and folder_name are required'}, status=400)

        # Check if student exists
        if not candidate_master.objects.filter(id=student_id).exists():
            return Response({'error': 'Invalid student_id'}, status=404)

        # üìù Custom message with remarks and student_id
        student_query_msg = f"Requested for assign {remarks} test for student id : {student_id}"

        new_request = student_request.objects.create(
            student_id_id=student_id,
            remarks=remarks,
            student_query=student_query_msg,
            status='Pending',
            is_query_type='Company Test',
            dtm_request=timezone.now()
        )

        serializer = studentRequestSerializer(new_request)
        return Response(serializer.data, status=status.HTTP_201_CREATED)

    except Exception as e:
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



@api_view(['GET'])
def get_testwise_practiceattended_report(request):
    college_id = request.GET.get('college_id')
    department = request.GET.get('department')  # filter
    year_filter = request.GET.get('year')      # filter
    search_query = request.GET.get('search', '')  # search keyword

    filters = {
        'deleted': 0,
        'created_by': 'Student',
        'is_active': True, 
    }
    if college_id:
        filters['college_id'] = college_id
    if department:
        filters['department_id__department__icontains'] = department

    # Base queryset
    qs = tests_candidates_map.objects.filter(**filters).select_related(
        'rules_id',
        'department_id',
        'student_id',
        'college_id'
    )

    # ‚úÖ Attach year from candidate_master
    qs = qs.annotate(
        candidate_year=F('student_id__year')
    )

    # Filter by year if provided
    if year_filter:
        qs = qs.filter(student_id__year=year_filter)

    # Search filter
    if search_query:
        qs = qs.filter(
            Q(test_name__icontains=search_query) |
            Q(student_id__students_name__icontains=search_query) |
            Q(student_id__registration_number__icontains=search_query) |
            Q(student_id__email_id__icontains=search_query) |
            Q(student_id__user_name__icontains=search_query)
        )

    # ‚úÖ Group by test_name with attended count
    qs = qs.values(
        'test_name',
        'college_id__id',
        'college_id__college',
        'college_id__college_group'
    ).annotate(
        attended_count=Count('student_id', distinct=True)
    ).order_by('-attended_count')

    # ‚úÖ Apply pagination
    paginator = CustomPagination()
    page = paginator.paginate_queryset(qs, request)

    results = []
    for item in page:
        college_with_group = item['college_id__college']
        if item['college_id__college_group']:
            college_with_group += f"-{item['college_id__college_group']}"

        results.append({
            'test_name': item['test_name'],
            'collegeId': item['college_id__id'],
            'college_id': college_with_group,
            'attended_count': item['attended_count'],
            # üîó You can keep detail_url if needed
            # 'detail_url': f"/api/view-practice-report?college_id={item['college_id__id']}&search={item['test_name']}"
        })

    return paginator.get_paginated_response(results)


from .serializers import QuestionTypeSerializer,SkillTypeSerializer_filter_new, SkillTypeSerializer_filterModal

class SkillTypeListByTopicAPIViewModal(generics.ListAPIView):
    serializer_class = SkillTypeSerializer_filterModal

    def get_queryset(self):
        topic_id = self.kwargs.get('topic_id')
        return skill_type.objects.filter(question_type_id=topic_id, deleted=0)



class SkillTypeListByTopicAPIViewNew(generics.ListAPIView):
    serializer_class = SkillTypeSerializer_filter_new

    def get_queryset(self):
        topic_id = self.kwargs.get('topic_id')

        # Step 1: get topic object
        try:
            topic_obj = question_type.objects.get(id=topic_id, deleted=0)
        except question_type.DoesNotExist:
            return skill_type.objects.none()

        topic_name = topic_obj.question_type

        # Step 2: get all subtopics for this topic
        subtopics = skill_type.objects.filter(question_type_id=topic_id, deleted=0)

        # Step 3: filter subtopics based on conditions in question_paper_master
        valid_subtopic_ids = []
        for st in subtopics:
            # Check for MCQ Test condition (>= 10 questions)
            mcq_exists = question_paper_master.objects.filter(
                topic=topic_name,
                sub_topic=st.skill_type,
                test_type="MCQ Test",
                remarks="PracticeTest",
                deleted=0,
                no_of_questions__gte=10
            ).exists()

            # Check for Coding Test condition (>= 1 question)
            coding_exists = question_paper_master.objects.filter(
                topic=topic_name,
                sub_topic=st.skill_type,
                test_type="Coding Test",
                remarks="PracticeTest",
                deleted=0,
                no_of_questions__gte=1
            ).exists()

            # If either condition is satisfied ‚Üí include this subtopic
            if mcq_exists or coding_exists:
                valid_subtopic_ids.append(st.id)

        return subtopics.filter(id__in=valid_subtopic_ids)



class test_master_UpdateAPIView(generics.UpdateAPIView):
    serializer_class = testsSerializersAddUpdate

    def get_queryset(self):
        test_name = self.request.data.get('testName')
        print(f"Querying for test_name: {test_name}")  # Logging
        return test_master.objects.filter(test_name=test_name)

    def update_test_candidates_map(self, old_test_name, new_test_name):
        """Update test_name in tests_candidates_map if it matches old_test_name"""
        updated_count = tests_candidates_map.objects.filter(test_name=old_test_name).update(test_name=new_test_name)
        print(f"Updated {updated_count} rows in tests_candidates_map")

    def check_test_name_exists(self, new_test_name, current_instance_id):
        """Check if test_name already exists in test_master excluding current instance"""
        if test_master.objects.filter(test_name=new_test_name).exclude(id=current_instance_id).exists():
            return True
        return False

    def put(self, request, *args, **kwargs):
        print(f"Request data: {request.data}")  # Log request
        queryset = self.get_queryset()
        if not queryset.exists():
            print("Test not found")
            return Response({"detail": "Not found."}, status=status.HTTP_404_NOT_FOUND)

        response_data = []
        for instance in queryset:
            old_test_name = instance.test_name  # Save old test_name
            new_test_name = request.data.get('test_name', old_test_name)

            # Check if new test_name already exists
            if new_test_name != old_test_name and self.check_test_name_exists(new_test_name, instance.id):
                return Response({"detail": "Test name already exists"}, status=status.HTTP_400_BAD_REQUEST)

            serializer = self.get_serializer(instance, data=request.data, partial=False)
            serializer.is_valid(raise_exception=True)
            self.perform_update(serializer)

            # Update tests_candidates_map if test_name changed
            if new_test_name != old_test_name:
                self.update_test_candidates_map(old_test_name, new_test_name)

            response_data.append(serializer.data)

        print("Update successful")
        return Response(response_data, status=status.HTTP_200_OK)

    def patch(self, request, *args, **kwargs):
        print(f"Request data: {request.data}")  # Log request
        queryset = self.get_queryset()
        if not queryset.exists():
            print("Test not found")
            return Response({"detail": "Not found."}, status=status.HTTP_404_NOT_FOUND)

        response_data = []
        for instance in queryset:
            old_test_name = instance.test_name  # Save old test_name
            new_test_name = request.data.get('test_name', old_test_name)

            # Check if new test_name already exists
            if new_test_name != old_test_name and self.check_test_name_exists(new_test_name, instance.id):
                return Response({"detail": "Test name already exists"}, status=status.HTTP_400_BAD_REQUEST)

            serializer = self.get_serializer(instance, data=request.data, partial=True)
            serializer.is_valid(raise_exception=True)
            self.perform_update(serializer)

            # Update tests_candidates_map if test_name changed
            if new_test_name != old_test_name:
                self.update_test_candidates_map(old_test_name, new_test_name)

            response_data.append(serializer.data)

        print("Partial update successful")
        return Response(response_data, status=status.HTTP_200_OK)
import calendar
from openpyxl.chart import BarChart, Reference
from openpyxl.chart.label import DataLabelList


@api_view(['GET'])
def download_student_monthly_report(request, student_id):
    """
    Download student monthly performance Excel report (month-year wise).
    Only months with tests in current year will appear (e.g., Aug2025).
    """
    try:
        student_obj = candidate_master.objects.get(id=student_id)
    except candidate_master.DoesNotExist:
        return Response({"error": "Student not found"}, status=404)

    # Fetch all active tests of this student
    tests_qs = tests_candidates_map.objects.filter(
        deleted=0,
        student_id=student_id,
        is_active=True
    )

    if not tests_qs.exists():
        return Response({"error": "No tests found for this student"}, status=404)

    # Prepare month-year wise mapping
    months_data = defaultdict(list)
    current_year = datetime.now().year

    for t in tests_qs:
        if t.dtm_start and t.dtm_start.year == current_year:
            month = t.dtm_start.month
            key = f"{calendar.month_abbr[month]}{current_year}"   # e.g., Aug2025
            months_data[key].append(t.avg_mark or 0)

    if not months_data:
        return Response({"error": "No tests found for this student in current year"}, status=404)

    # Create Excel workbook
    wb = Workbook()
    ws = wb.active
    ws.title = f"{student_obj.students_name} Monthly Performance"

    # Sort months
    dynamic_months = sorted(months_data.keys(), key=lambda x: datetime.strptime(x, "%b%Y"))
    header = ["Student Name", "Registration Number"] + dynamic_months + ["Overall Feedback"]
    ws.append(header)

    # Fill numeric row
    row = [student_obj.students_name, student_obj.registration_number]
    numeric_cols_start = 3  # starting column for numeric data
    monthly_avgs = []

    for key in dynamic_months:
        marks = months_data.get(key, [])
        avg_mark = round(sum(marks) / len(marks)) if marks else 0
        monthly_avgs.append(avg_mark)
        row.append(avg_mark)

    # Overall feedback
    months_with_tests = [m for m in monthly_avgs if m > 0]
    overall_avg = round(sum(months_with_tests) / len(months_with_tests)) if months_with_tests else 0

    if overall_avg > 85:
        feedback = "Excellent"
    elif overall_avg > 60:
        feedback = "Good"
    elif overall_avg > 45:
        feedback = "Need to Focus"
    elif overall_avg > 30:
        feedback = "Need Improvement"
    else:
        feedback = "Very Poor"

    row.append(feedback)
    ws.append(row)

    # Add chart only if there is numeric data
    if monthly_avgs and any(monthly_avgs):
        chart = BarChart()
        chart.type = "col"
        chart.title = "Monthly Average Marks"
        chart.y_axis.title = "Avg Mark"
        chart.x_axis.title = "Month"

        # Use only numeric columns
        values = Reference(ws, min_col=numeric_cols_start, max_col=numeric_cols_start + len(dynamic_months) - 1,
                           min_row=2, max_row=2)
        cats = Reference(ws, min_col=numeric_cols_start, max_col=numeric_cols_start + len(dynamic_months) - 1,
                         min_row=1, max_row=1)

        chart.add_data(values, titles_from_data=False)
        chart.set_categories(cats)

        # Remove "Series1" legend
        chart.legend = None

        # Show values on bars
        chart.dataLabels = DataLabelList()
        chart.dataLabels.showVal = True

        ws.add_chart(chart, "O5")

    # Save workbook
    output = BytesIO()
    wb.save(output)
    output.seek(0)

    response = HttpResponse(
        output.getvalue(),
        content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )
    response['Content-Disposition'] = f'attachment; filename={student_obj.students_name}_monthly_performance.xlsx'
    return response

@api_view(['POST'])
def Send_Email_Forget_Password(request):
    user_name = request.data.get("user_name")
    print("Received user_name:", user_name)

    if not user_name:
        return Response({"error": "user_name is required in request body"}, status=400)

    try:
        # Case-insensitive lookup in login table
        user = login.objects.filter(user_name__iexact=user_name).first()
        cand = None

        email = None
        password = None
        found_username = None

        if user:
            email = user.email_id if user.email_id else None
            password = user.password if user.password else None
            found_username = user.user_name
        else:
            # If not in login, try candidate_master
            cand = candidate_master.objects.filter(user_name__iexact=user_name).first()
            if cand:
                if cand.email_id:
                    email = cand.email_id
                found_username = cand.user_name

        # üö® If user not found in both tables
        if not found_username:
            return Response({"error": "Username does not exist"}, status=404)

        result = {
            "user_name": found_username.lower(),
            "password": password,
            "email_id": email
        }

        print("Lookup result:", result)

        # ‚úÖ Send email only if both email and password exist
        if email and password:
            subject = "Your Campus Connection Credentials"
            message = f"""
Hello Dear,

Your login details are:

Username: {result['user_name']}
Password: {password}

Please keep this information secure.

Regards,
Campus Connection Team
"""
            from_email = settings.EMAIL_HOST_USER
            recipient_list = [email]

            try:
                send_mail(subject, message, from_email, recipient_list, fail_silently=False)
                print(f"‚úÖ Email sent to {email}")
            except Exception as mail_err:
                print("‚ùå Email sending failed:", str(mail_err))
                return Response({"error": "Failed to send email", "details": str(mail_err)}, status=500)

            return Response({"message": "Your password has been sent to your registered email address."})

        else:
            return Response({"error": "Email or password not found for this user"}, status=404)

    except Exception as e:
        print("Error during Send_Email_Forget_Password lookup:", str(e))
        return Response({"error": "Internal server error", "details": str(e)}, status=500)


from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from .models import candidate_master  # adjust as needed

@csrf_exempt
def get_student_details_report(request):
    """
    API: /api/stu-detail/report/?student_id=36077
    Returns student_name, registration_number, year, department_name, college_name
    """
    try:
        student_id = request.GET.get('student_id')

        if not student_id:
            return JsonResponse({'error': 'student_id is required'}, status=400)

        student = candidate_master.objects.select_related('department_id', 'college_id').filter(
            id=student_id
        ).first()

        if not student:
            return JsonResponse({'error': 'Student not found'}, status=404)

        data = {
            'student_name': student.students_name,
            'registration_number': student.registration_number,
            'year': student.year,
            'department': student.department_id.department if student.department_id else None,
            'college': student.college_id.college if student.college_id else None,
            'college_id': student.college_id.id if student.college_id else None,  # üîπ returns college_id too
        }
        return JsonResponse(data, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


@api_view(['GET'])
def get_user_role_access(request):
    college_id = request.GET.get('college_id')
    user_name = request.GET.get('user_name')

    # ‚úÖ Validate inputs
    if not college_id and not user_name:
        return JsonResponse({'error': 'college_id or user_name is required'}, status=400)

    # ‚úÖ If both college_id and user_name are provided
    if college_id and user_name:
        try:
            user = login.objects.select_related('college_id').get(
                college_id=college_id, user_name=user_name, 
            )
            data = {
                'user_name': user.user_name,
                'email_id': user.email_id,
                'role': user.role,
                'college': user.college_id.college,
                'level_of_access': user.college_id.level_of_access,
            }
            return JsonResponse(data)
        except login.DoesNotExist:
            return JsonResponse({'error': 'Placement Officer not found for this college_id or user_name'}, status=404)

    # ‚úÖ If only user_name is provided
    elif user_name:
        try:
            user = login.objects.select_related('college_id').get(
                user_name=user_name, 
            )
            data = {
                'user_name': user.user_name,
                'email_id': user.email_id,
                'role': user.role,
                'college': user.college_id.college,
                'level_of_access': user.college_id.level_of_access,
            }
            return JsonResponse(data)
        except login.DoesNotExist:
            return JsonResponse({'error': 'Placement Officer not found for this user_name'}, status=404)

    # ‚úÖ If only college_id is provided
    elif college_id:
        users = login.objects.filter(
            college_id=college_id
        ).select_related('college_id')

        if not users.exists():
            return JsonResponse({'message': 'No Placement Officer found for this college_id'}, status=404)

        data = [
            {
                'user_name': user.user_name,
                'email_id': user.email_id,
                'role': user.role,
                'college': user.college_id.college,
                'level_of_access': user.college_id.level_of_access,
            }
            for user in users
        ]
        return JsonResponse({'users': data}, safe=False)
from datetime import timedelta
from .models import login, tests_candidates_map, daily_email_log
def capture_first_login_send_emailold(request):
    """
    Sends one email per Placement Officer per college per day
    when their college had a test yesterday.
    """
    print("=== capture_first_login_send_email triggered ===")

    now = timezone.now()
    today = now.date()
    yesterday = today - timedelta(days=1)
    print(f"Step 1Ô∏è‚É£  Today: {today}, Yesterday: {yesterday}")

    # Step 1: Find all colleges that had tests yesterday
    yesterday_colleges = list(
        tests_candidates_map.objects.filter(
            dtm_start__date=yesterday
        ).values_list("college_id", flat=True).distinct()
    )
    print(f"Step 2Ô∏è‚É£  Colleges with tests yesterday: {yesterday_colleges}")

    if not yesterday_colleges:
        print("‚ö†Ô∏è No colleges found with tests yesterday.")
        return JsonResponse({"message": "No colleges had tests yesterday."})

    sent_count = 0
    failed = []

    for college_id in yesterday_colleges:
        print(f"\nüîπ Processing college_id: {college_id}")

        # Check if email already sent today for this college
        email_already_sent = daily_email_log.objects.filter(
            college_id=college_id,
            sent_date__date=today
        ).exists()

        if email_already_sent:
            print(f"‚è© Email already sent today for college_id {college_id} ‚Äî skipping.")
            continue

        # Step 2: Get all Placement Officers for this college
        placement_officers = login.objects.filter(
            Q(role__iexact="Placement Officer") | Q(role__iexact="PO"),
            college_id=college_id,
            deleted=0,
        ).exclude(email_id__isnull=True).exclude(email_id__exact="")

        print(f"Step 3Ô∏è‚É£  Found {placement_officers.count()} Placement Officers for college_id {college_id}")

        if not placement_officers.exists():
            print(f"‚ö†Ô∏è No Placement Officers with valid email found for college_id {college_id}")
            continue

        # Send email to all placement officers of this college at once
        email_list = [officer.email_id for officer in placement_officers]
        college_name = placement_officers.first().college_id.college if placement_officers.first().college_id else f"College ID {college_id}"

        subject = f"[Campus Connection] Daily Login Alert - {college_name}"
        message = (
            f"Dear Placement Officer,\n\n"
            f"This is an automated notification to inform you that your college "
            f"had one or more tests conducted on {yesterday.strftime('%d-%m-%Y')}.\n\n"
            f"Date: {today.strftime('%d-%m-%Y')}\n"
            f"College: {college_name}\n\n"
            "Thank you,\nCampus Connection"
        )

        try:
            send_mail(
                subject,
                message,
                "campusconnectionsk356@gmail.com",
                email_list,
                fail_silently=False,
            )
            print(f"‚úÖ Email successfully sent to: {email_list}")
            sent_count += placement_officers.count()

            # Log the sent email (once per college)
            daily_email_log.objects.create(
                college_id=college_id,
                sent_date=now
            )
        except Exception as e:
            print(f"‚ùå Failed to send email for college_id {college_id}: {str(e)}")
            failed.append({"college_id": college_id, "error": str(e)})

    print(f"\n=== Summary ===")
    print(f"‚úÖ Emails sent to {sent_count} Placement Officer(s)")
    print(f"‚ùå Failed emails: {failed}")

    return JsonResponse({
        "message": f"Emails sent to {sent_count} Placement Officer(s).",
        "failed": failed
    })

@api_view(['GET'])
def get_tests_reports_by_college_Po(request):
    college_id = request.GET.get('college_id')
    department_ids = request.GET.get('department_id')  # Department filter
    question_types = request.GET.get('question_type') 
    start_date = request.GET.get('start_date')  # Start date filter
    end_date = request.GET.get('end_date')  # End date filter
    chart_type = request.GET.get('chart_type', 'bar')
    years = request.GET.get('year')  # Capture multiple years
    batch_nos = request.GET.get('batch_no')  # Capture multiple batch numbers
    created_by_role = request.GET.get('created_by_role') 
    inactive = request.GET.get('inactive') 
# ‚úÖ Apply year filter

    if not college_id:
        return Response({'error': 'college_id parameter is required'}, status=400)
   
    if start_date:
        start_date = parse_date(start_date)
    if end_date:
        end_date = parse_date(end_date)

    if start_date and end_date:
        if start_date > end_date:
            return Response({'error': 'start_date cannot be greater than end_date'}, status=400)

    # ‚úÖ Apply filters to students (filter by college and department)
   
    department_list = []
    #if department_ids and department_ids.lower() != "all":
       # department_list = [int(dep) for dep in department_ids.split(',') if dep.isdigit()]
   
    if department_ids and department_ids.lower() != "all":
        department_list = [int(dep) for dep in department_ids.split(',') if dep.isdigit()]
    else:
        department_list = []

    
    if years is None or years.lower() == "all":
        year_list = []
    else:
        year_list = [y.strip() for y in years.split(',') if y.strip()]

    if batch_nos is None or batch_nos.lower() == "all":
        batch_list = []
    else:
        batch_list = [b.strip() for b in batch_nos.split(',') if b.strip()]
    if not question_types:
        question_type_list = ["Aptitude", "Technical", "Softskills"]
    else:
        question_type_list = question_types.split(',')

    # ‚úÖ Ensure "All" behaves correctly
    if "All" in question_type_list:
        question_type_list = ["Aptitude", "Technical", "Softskills"]
  #  question_type_list = question_types.split(',') if question_types else []

    # ‚úÖ Apply filters to students (filter by college and department)
    student_filter = Q(deleted=0, college_id=college_id)
    if department_list:
        student_filter &= Q(department_id__in=department_list)
    if year_list:
        student_filter &= Q(year__in=year_list)
    if batch_list:
        student_filter &= Q(batch_no__in=batch_list)

    # Add a subquery to filter tests_candidates_map
    active_tests_filter = tests_candidates_map.objects.filter(
        deleted=0,
        student_id=OuterRef('id'),
        is_active=True
    ).exclude(created_by='Student')
    inactive_students = candidate_master.objects.filter(
        student_filter,deleted=0
    ).exclude(
        Exists(active_tests_filter)
    ).values(
        'students_name', 'registration_number', 'department_id__department', 'year',  'user_name',
        #'email_id', 'mobile_number', 
    )

    # Modify the `all_students` query to include the condition
    all_students = candidate_master.objects.filter(
        student_filter,
        Exists(active_tests_filter)
    ).values(
        'id', 'registration_number', 'students_name', 'user_name', 'department_id__department', 'year',
       # 'email_id', 'mobile_number', 'batch_no'
    )
    if not all_students.exists():
        return Response({'message': 'No students found for the given college'}, status=404)
    
    test_filter = Q()
   
    
    if question_type_list:
        if "All" in question_type_list:
            question_type_list = ["Aptitude", "Technical", "Softskills"]
        test_filter &= Q(question_type_id__question_type__in=question_type_list)

    # Fetch test details
    test_details = test_master.objects.filter(test_filter).values(
        'test_name', 'question_type_id__question_type', 'skill_type_id__skill_type'
    )

    # Create mappings for skill type and question type
    test_skill_map = {
        test['test_name']: test['skill_type_id__skill_type'][0] if test['skill_type_id__skill_type'] else "U"
        for test in test_details
    }
    test_type_map = {
        test['test_name']: test['question_type_id__question_type'] for test in test_details
    }

    # Identify which tests are aptitude vs technical
    aptitude_tests = [
        test['test_name'] for test in test_details
        if test['question_type_id__question_type'] == 'Aptitude'
    ]
    technical_tests = [
        test['test_name'] for test in test_details
        if test['question_type_id__question_type'] == 'Technical'
    ]

    softskill_tests = [
        test['test_name'] for test in test_details
        if test['question_type_id__question_type'] == 'Softskills'
    ]
    

   # print('Softskill tests: ', softskill_tests)
    # ‚úÖ Ensure "All" behaves correctly by only keeping categories with actual test names
    if "All" in question_type_list:
        question_type_list = []
        if aptitude_tests:
            question_type_list.append("Aptitude")
        if technical_tests:
            question_type_list.append("Technical")
        if softskill_tests:
            question_type_list.append("Softskills")

    print("Filtered Question Types After Removing Empty Categories:", question_type_list)  # Debugging


    test_report_filter = Q(deleted=0, college_id=college_id, is_active=True)
    
    
     
    test_report_filter &= Q(test_name__in=[t['test_name'] for t in test_details])


    if department_list:
        test_report_filter &= Q(student_id__department_id__in=department_list)


   # if question_type:
       # test_report_filter &= Q(test_name__in=[t['test_name'] for t in test_details])

    if start_date and end_date:
        test_report_filter &= Q(dtm_start_test__date__range=[start_date, end_date])  # ‚úÖ Apply user-selected date range

    if year_list:
        test_report_filter &= Q(year__in=year_list)  # ‚úÖ Multiple years in test filter
    if batch_list:
        test_report_filter &= Q(student_id__batch_no__in=batch_list)  # ‚úÖ Filter by batch
    if question_type_list:
        test_filter &= Q(question_type_id__question_type__in=question_type_list)  # ‚úÖ Always include default test types

    user_roles = {
        user['user_name']: (user['role'], user['college_id'])
        for user in login.objects.values('user_name', 'role', 'college_id')
    }

    # Check if role filtering is applied correctly
    placement_officer_users = [user for user, role in user_roles.items() if role[0] == "Placement Officer"]
    super_admin_users = [user for user, role in user_roles.items() if role[0] == "Super admin"]

    print("Placement Officer Users:", placement_officer_users)
    print("Super Admin Users:", super_admin_users)

    if created_by_role == "placement_officer":
        test_report_filter &= Q(created_by__in=placement_officer_users)
    elif created_by_role == "super_admin":
        test_report_filter &= Q(created_by__in=super_admin_users)

    test_reports = tests_candidates_map.objects.filter(test_report_filter,deleted=0).values(
        'test_name', 'student_id__id', 'avg_mark', 'capture_duration',
        'dtm_start_test', 'dtm_start', 'dtm_end', 'year',
        'student_id__batch_no', 'created_by'
    ).order_by('dtm_start', 'test_name').exclude(created_by='Student')


    # Debug filtered test reports
    attended_student_ids = set(test['student_id__id'] for test in test_reports)
    #print(f"\nTotal Attended Students in Tests: {len(attended_student_ids)}")
    if not test_reports.exists():
        return Response({'message': 'No test reports found for the given filters'}, status=404)
  
    for test in test_reports:
        pass
        
    technical_data, aptitude_data, test_wise_data, softskill_data = {}, {}, {}, {}

    # Initialize student data
    sorted_students = sorted(
        all_students,
        key=lambda x: x['department_id__department'] or ""
    )

   # for student in all_students:
    for student in sorted_students:
        student_id = student['id']
        student_info = {
            'Candidate': student['students_name'],
             'Reg_No': student['registration_number'] or "N/A",
         
            'Department': student['department_id__department'],
           'Login ID': student['user_name'],
            'year': student['year'],
           
        }
        technical_data[student_id] = student_info.copy()
        aptitude_data[student_id] = student_info.copy()
        softskill_data[student_id] = student_info.copy()

    # Create a lookup for student info
    student_map = {student['id']: student for student in all_students}

    # Process test reports
    for report in test_reports:
        test_name = str(report['test_name'])
        student_id = report['student_id__id']
        avg_mark = float(report['avg_mark']) if report['avg_mark'] else 0.0
        formatted_test_name = f"{test_name}_{test_skill_map.get(test_name, 'U')}"

        # Store aptitude data if it's an aptitude test
        if test_name in aptitude_tests and student_id in aptitude_data:
            aptitude_data[student_id][formatted_test_name] = avg_mark

        # Store technical data if it's a technical test
        if test_name in technical_tests and student_id in technical_data:
            technical_data[student_id][formatted_test_name] = avg_mark

        # Store technical data if it's a technical test
        if test_name in softskill_tests and student_id in softskill_data:
            softskill_data[student_id][formatted_test_name] = avg_mark

        # For the test-wise sheet
        if test_name not in test_wise_data:
            test_wise_data[test_name] = []

        student = student_map.get(student_id, {})
        test_wise_data[test_name].append({
            "Test Name": test_name,
            "College Name": college_master.objects.get(id=college_id).college,
           #  "Batch No": report.get('student_id__batch_no', ''),
            "Department": student.get('department_id__department', ''),
            "Year": report['year'],
            "Student Name": student.get('students_name', ''),
            "User Name": student.get('user_name', ''),
            "Email": student.get('email_id', ''),
            "Mobile": student.get('mobile_number', ''),
            "Registration Number": student.get('registration_number', ''),
            "Average Mark": avg_mark,
            "Capture Duration": report['capture_duration'],
            "Student Start Test": (
                report['dtm_start_test'].strftime('%d-%m-%Y %I:%M %p') if report['dtm_start_test'] else ""
            ),
            "Test Start Time": (
                report['dtm_start'].strftime('%d-%m-%Y %I:%M %p') if report['dtm_start'] else ""
            ),
            "Test End Time": (
                report['dtm_end'].strftime('%d-%m-%Y %I:%M %p') if report['dtm_end'] else ""
            )
        })

     # Step 1: Build assigned test counts per student per category
    # 1Ô∏è‚É£ Build a mapping: test_name ‚Üí question_type (Aptitude / Technical / Softskills)
    test_qtype_map = dict(
        test_master.objects.values_list('test_name', 'question_type_id__question_type')
    )

    # 2Ô∏è‚É£ Get assigned tests (no join here)
    assigned_tests = tests_candidates_map.objects.filter(
        deleted=0,
        student_id__in=[s['id'] for s in all_students]
    ).exclude(created_by='Student').values('student_id', 'test_name')

    # 3Ô∏è‚É£ Count per student per question type
    assigned_counts = {}
    for entry in assigned_tests:
        sid = entry['student_id']
        qtype = test_qtype_map.get(entry['test_name'])  # look up from mapping
        if sid not in assigned_counts:
            assigned_counts[sid] = {"Aptitude": 0, "Technical": 0, "Softskills": 0}
        if qtype in assigned_counts[sid]:
            assigned_counts[sid][qtype] += 1

    # 4Ô∏è‚É£ Compute averages (safe divide)
    for student_id in aptitude_data.keys():
        # Attended scores
        apti_scores = [
            val for key, val in aptitude_data[student_id].items()
            if isinstance(val, (int, float))
        ]
        tech_scores = [
            val for key, val in technical_data[student_id].items()
            if isinstance(val, (int, float))
        ]
        soft_scores = [
            val for key, val in softskill_data[student_id].items()
            if isinstance(val, (int, float))
        ]

        # Denominators
        assigned_apti = assigned_counts.get(student_id, {}).get("Aptitude", 0)
        assigned_tech = assigned_counts.get(student_id, {}).get("Technical", 0)
        assigned_soft = assigned_counts.get(student_id, {}).get("Softskills", 0)

        # Compute safe averages
        aptitude_data[student_id]['Total_Aptitude_Avg'] = (
            round(sum(apti_scores) / assigned_apti) if assigned_apti > 0 else 0
        )
        technical_data[student_id]['Total_Technical_Avg'] = (
            round(sum(tech_scores) / assigned_tech) if assigned_tech > 0 else 0
        )
        softskill_data[student_id]['Total_Softskills_Avg'] = (
            round(sum(soft_scores) / assigned_soft) if assigned_soft > 0 else 0
        )

    # Build a combined "top_students" list with Category
    # (This actually includes all students, not just "top" by rank)
    all_students_with_cat = []
    for student_id, student_info in aptitude_data.items():
        total_apt = aptitude_data[student_id]['Total_Aptitude_Avg']
        total_tech = technical_data[student_id]['Total_Technical_Avg']
        total_soft = softskill_data[student_id]['Total_Softskills_Avg']
        # Calculate total_avg based on question_type
        
        
       # if question_type == 'Aptitude':
       #     total_avg = total_apt
       # elif question_type == 'Technical':
       #     total_avg = total_tech
       # elif question_type == 'SoftSkills':
       #     total_avg = total_soft
       # else:
       # #    total_avg = (total_apt + total_tech + total_soft) / 2
       #      # Calculate total_avg dynamically
       #     if total_soft > 0:  # Softskills present ‚Üí divide by 3
       #         total_avg = (total_apt + total_tech + total_soft) / 3
       #     else:
       #         # No softskills ‚Üí divide by 2 even if one is 0
       #         total_avg = (total_apt + total_tech) / 2
        #total_avg = round(total_avg)
        # Determine selected question types
        selected_question_types = question_type_list  # Already a list from request

        # Calculate total_avg based on selected question types
        scores_to_avg = []

        if "Aptitude" in selected_question_types:
            scores_to_avg.append(total_apt)
        if "Technical" in selected_question_types:
            scores_to_avg.append(total_tech)
        if "Softskills" in selected_question_types:
            scores_to_avg.append(total_soft)

        # Compute total_avg safely
        total_avg = round(sum(scores_to_avg) / len(scores_to_avg)) if scores_to_avg else 0

        # Assign category
        if total_apt >= 70 and total_tech >= 70:
            category = "A"
        elif (
            (total_apt >= 50 and total_tech >= 50) or
            (total_apt >= 50 and total_tech >= 70) or
            (total_apt >= 70 and total_tech >= 50) 
            
        ):
            category = "B"
        elif (
           (total_apt >= 30 and total_tech >= 30) or
           (total_apt >= 30 and total_tech >= 50) or
           (total_apt >= 50 and total_tech >= 30) 
            
        ):
             category = "C"

        else:
            total_apt < 30 and total_tech < 30

            category = "D"

        all_students_with_cat.append({
             'Candidate': student_info['Candidate'],
             'Reg_No': student_info['Reg_No'],
            'Department': student_info['Department'],
            'Year': student_info['year'],
              'Total_Aptitude_Avg': total_apt,
            'Total_Technical_Avg': total_tech,
            'Total_Softskills_Avg': total_soft,
            'Total_Avg': total_avg,
            'Category': category
        })

    # Group scores by skill type
    tech_skill_scores = {}
    for test_name, score in technical_data[student_id].items():
        if isinstance(score, (int, float)):
            skill = test_skill_map.get(test_name, "Unknown")
            tech_skill_scores.setdefault(skill, []).append(score)

    # Compute total technical average
    flat_tech_scores = [s for scores in tech_skill_scores.values() for s in scores]
    technical_data[student_id]['Total_Technical_Avg'] = round(
        sum(flat_tech_scores) / len(flat_tech_scores)
    ) if flat_tech_scores else 0

    # Store skill-wise averages
    for skill, scores in tech_skill_scores.items():
        technical_data[student_id][f"Technical_{skill}_Avg"] = round(sum(scores) / len(scores))
    # For aptitude_data[student_id]
    apt_skill_scores = {}
    for test_name, score in aptitude_data[student_id].items():
        if isinstance(score, (int, float)):
            skill = test_skill_map.get(test_name, "Unknown")
            apt_skill_scores.setdefault(skill, []).append(score)

    flat_apt_scores = [s for scores in apt_skill_scores.values() for s in scores]
    aptitude_data[student_id]['Total_Aptitude_Avg'] = round(
        sum(flat_apt_scores) / len(flat_apt_scores)
    ) if flat_apt_scores else 0

    # Store skill-wise
    for skill, scores in apt_skill_scores.items():
        aptitude_data[student_id][f"Aptitude_{skill}_Avg"] = round(sum(scores) / len(scores))

    # Sort all students by Total_Avg in descending order
    all_students_with_cat_sorted = sorted(
        all_students_with_cat,
       # key=lambda x: x['Department']
        key=lambda x: x['Total_Avg'],  # Sort by Total_Avg
        reverse=True                  # Descending order
    )
    def deduplicate_by_regno(data_list, key='Reg_No'):
        """Return a list of dicts with unique registration numbers."""
        seen = set()
        unique_list = []
        for student in data_list:
            reg_no = str(student.get(key, '')).strip()
            if reg_no and reg_no not in seen:
                seen.add(reg_no)
                unique_list.append(student)
        return unique_list

    # Filter only Category A students
    # Filter only Category A and B students
    category_a_students = [student for student in all_students_with_cat_sorted if student['Category'] == "A"]
    category_b_students = [student for student in all_students_with_cat_sorted if student['Category'] == "B"]

    total_students = len(all_students_with_cat_sorted)
    top_25_percent_count = max(1, int(total_students * 0.25))  # At least 1 student

    # If Category A students are enough, take only from Category A
    if len(category_a_students) >= top_25_percent_count:
        top_students_filtered = category_a_students[:top_25_percent_count]
    else:
        # If Category A doesn't have enough students, fill the remaining slots with Category B students
        remaining_count = top_25_percent_count - len(category_a_students)
        top_students_filtered = category_a_students + category_b_students[:remaining_count]

    # ‚úÖ Convert Top Students Data into DataFrame
    top_students_df = pd.DataFrame(top_students_filtered)
    aptitude_df = pd.DataFrame.from_dict(aptitude_data, orient='index')
    technical_df = pd.DataFrame.from_dict(technical_data, orient='index')
    softskill_df = pd.DataFrame.from_dict(softskill_data, orient='index')
    
    if aptitude_df.empty:
        aptitude_df = pd.DataFrame([{"Message": "No aptitude data available"}])

    if technical_df.empty:
        technical_df = pd.DataFrame([{"Message": "No technical data available"}])

    if softskill_df.empty:
        softskill_df = pd.DataFrame([{"Message": "No soft skills data available"}])

        
    top_students_df = pd.DataFrame(top_students_filtered)
    category_performance_map = {
        "A": "Creamy",
        "B": "Good",
        "C": "Average",
        "D": "Need Care"
    }

    # Add performance analysis column
    for student in all_students_with_cat_sorted:
        student["Performance Analysis"] = category_performance_map.get(student["Category"], "Unknown")

    if student_id in attended_student_ids:
        if test_name in aptitude_tests:
            aptitude_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
        if test_name in technical_tests:
            technical_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
        if test_name in softskill_tests:
            softskill_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
    for report in test_reports:
            test_name = str(report['test_name'])
            student_id = report['student_id__id']
            avg_mark = float(report['avg_mark']) if report['avg_mark'] else 0.0
            formatted_test_name = f"{test_name}_{test_skill_map.get(test_name, 'U')}"

            # ‚úÖ Store in appropriate category **only if student attended**
            if student_id in attended_student_ids:
                if test_name in aptitude_tests:
                    aptitude_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
                if test_name in technical_tests:
                    technical_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})
                if test_name in softskill_tests:
                    softskill_data.setdefault(student_id, {}).update({formatted_test_name: avg_mark})

        # ‚úÖ Step 5: Remove students with no test records
    def filter_empty_students(data):
        """Remove students who have no test scores (all zeros)."""
        return {k: v for k, v in data.items() if any(isinstance(val, (int, float)) and val > 0 for val in v.values())}

    aptitude_data = filter_empty_students(aptitude_data)
    technical_data = filter_empty_students(technical_data)
    softskill_data = filter_empty_students(softskill_data)

        # ‚úÖ Debug: Print attended student IDs and ensure proper type
    attended_student_ids_str = set(str(student_id) for student_id in attended_student_ids)

     # ‚úÖ Step 2: Filter students for the Growth Report
    attended_students_data = [
        student for student in all_students_with_cat_sorted 
        if str(student['Reg_No']).strip().upper() in attended_student_ids_str
    ]
   # ‚úÖ Step 3: Convert to DataFrame for Growth Report
    growth_report_df = pd.DataFrame(attended_students_data)
    if growth_report_df.empty:
        growth_report_df = pd.DataFrame([{"Message": "No Growth Report Data Available"}])
    
    if not top_students_filtered:
        top_students_df = pd.DataFrame([{"Message": "No Top 100 Students Available"}])
    else:
        top_students_df = pd.DataFrame(top_students_filtered)

    top_students_df = pd.DataFrame(deduplicate_by_regno(top_students_filtered))
   

    growth_report_df = pd.DataFrame(deduplicate_by_regno(all_students_with_cat_sorted))
   
    buffer = BytesIO()
    
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            def deduplicate_df_by_regno(df, reg_col='Reg_No'):
                """Keep only the first occurrence of each Reg_No."""
                return df.drop_duplicates(subset=[reg_col])

            # ------------------- Cumulative Aptitude -------------------
            if aptitude_data:
                aptitude_df = pd.DataFrame.from_dict(aptitude_data, orient='index')
                aptitude_df = deduplicate_df_by_regno(aptitude_df, 'Reg_No')  # Deduplicate

                base_cols = ['Candidate', 'Reg_No', 'Department', 'Login ID', 'year']
                test_cols = [col for col in aptitude_df.columns if col not in base_cols + ['Total_Aptitude_Avg']]
                final_cols = base_cols + test_cols + ['Total_Aptitude_Avg']
                aptitude_df = aptitude_df[final_cols]

                aptitude_df.to_excel(writer, sheet_name="Cumulative Aptitude", index=False)

            # ------------------- Cumulative Technical -------------------
            if technical_data:
                technical_df = pd.DataFrame.from_dict(technical_data, orient='index')
                technical_df = deduplicate_df_by_regno(technical_df, 'Reg_No')  # Deduplicate

                base_cols = ['Candidate', 'Reg_No', 'Department', 'Login ID', 'year']
                test_cols = [col for col in technical_df.columns if col not in base_cols + ['Total_Technical_Avg']]
                final_cols = base_cols + test_cols + ['Total_Technical_Avg']
                technical_df = technical_df[final_cols]

                technical_df.to_excel(writer, sheet_name="Cumulative Technical", index=False)

            # ------------------- Cumulative Softskills -------------------
            if softskill_data:
                softskill_df = pd.DataFrame.from_dict(softskill_data, orient='index')
                softskill_df = deduplicate_df_by_regno(softskill_df, 'Reg_No')  # Deduplicate

                base_cols = ['Candidate', 'Reg_No', 'Department', 'Login ID', 'year']
                test_cols = [col for col in softskill_df.columns if col not in base_cols + ['Total_Softskills_Avg']]
                final_cols = base_cols + test_cols + ['Total_Softskills_Avg']
                softskill_df = softskill_df[final_cols]

                softskill_df.to_excel(writer, sheet_name="Cumulative Softskills", index=False)

            top_students_df.to_excel(writer, sheet_name="Top 100", index=False)
            # Assume growth_report_df already has 'Total_Aptitude_Avg' and 'Total_Technical_Avg'
            
            # Step 1: Deduplicate and prepare growth report
            growth_report_df = pd.DataFrame(deduplicate_by_regno(all_students_with_cat_sorted))


            # Step 6: Write to Excel
            growth_report_df.to_excel(writer, sheet_name="Overall Report", index=False)

                    
            if inactive == "true":
                if not inactive_students.exists():
                    return Response({'message': 'No inactive students found'}, status=404)

                # Convert queryset to DataFrame
                df = pd.DataFrame(list(inactive_students))

                # Write to the existing Excel file in buffer
                df.to_excel(writer, sheet_name="Inactive Sheet", index=False)

        # ‚úÖ Step 7: Remove empty cumulative sheets from the workbook
    wb = load_workbook(buffer)
    if "Cumulative Aptitude" in wb.sheetnames and not aptitude_data:
        wb.remove(wb["Cumulative Aptitude"])
    if "Cumulative Technical" in wb.sheetnames and not technical_data:
        wb.remove(wb["Cumulative Technical"])
    if "Cumulative Softskills" in wb.sheetnames and not softskill_data:
        wb.remove(wb["Cumulative Softskills"])
        
    buffer.seek(0)

    # 2) Load the workbook to add the chart sheets
    wb = load_workbook(buffer)

    # ----------------------------------------------------------------------------
    # APTITUDE REPORT (Quants, Logical, Verbal, Problem Solving, Logical Handling)
    # ----------------------------------------------------------------------------
   # Ensure we only create sheets for question types that actually have tests
    print("‚ñ∂ Starting Aptitude Report Generation")

    valid_question_types = {
        "Aptitude": bool(aptitude_tests),
        "Technical": bool(technical_tests),
        "Softskills": bool(softskill_tests),
    }

    # If "All" is selected, filter out question types that have no tests
    if "All" in question_type_list:
        print("üîç 'All' selected in question_type_list. Filtering valid question types with tests.")
        question_type_list = [qtype for qtype, has_tests in valid_question_types.items() if has_tests]
        print(f"‚úÖ Filtered question types: {question_type_list}")

    def is_all_zero(df, exclude_columns=[]):
        """ Returns True if all numeric values in DataFrame (excluding specified columns) are 0 """
        df_numeric = df.drop(columns=exclude_columns, errors='ignore')  # Drop non-numeric columns
        return (df_numeric.select_dtypes(include=['number']) == 0).all().all()  # Check all numeric values

    # Now create only relevant sheets
    if "Aptitude" in question_type_list and aptitude_tests:
        print("üß† Aptitude tests found. Processing aptitude data...")
        
        aptitude_df_copy = aptitude_df.copy()
        
        print("‚ûï Creating category columns...")
        aptitude_df_copy["Quants"] = aptitude_df_copy.filter(regex="(?i)quants|quantitative", axis=1).sum(axis=1)
        aptitude_df_copy["Logical"] = aptitude_df_copy.filter(regex="(?i)logical(?!.*handling)", axis=1).sum(axis=1)
        aptitude_df_copy["Verbal"] = aptitude_df_copy.filter(regex="(?i)verbal", axis=1).sum(axis=1)
     
        print("üìä Grouping and averaging by Department...")
        apti_grouped = aptitude_df_copy.groupby("Department", as_index=False)[
            ["Quants", "Logical", "Verbal",  "Total_Aptitude_Avg"]
        ].mean().round(0)

        print("‚úÖ Grouped Aptitude Data:\n", apti_grouped)

        # Check before adding sheet
        if not is_all_zero(apti_grouped, exclude_columns=["Department"]):
            print("‚úÖ Valid aptitude data found. Creating 'Aptitude Report' sheet.")
            ws_apt = wb.create_sheet("Aptitude Report")
            ws_apt.append(["Department", "Quants", "Logical", "Verbal",  "Total_Aptitude_Avg"])
            
            for _, row in apti_grouped.iterrows():
                ws_apt.append([
                    row["Department"], row["Quants"], row["Logical"], row["Verbal"],
                    row["Total_Aptitude_Avg"]
                ])

            print("üìà Preparing chart for Aptitude Report...")
            # after writing header row + data rows to ws_apt:
            dept_count = len(apti_grouped)

            # department names for x-axis
            dept_ref = Reference(ws_apt, min_col=1, min_row=2, max_row=dept_count + 1)

            # all numeric columns including header row for titles
            data_ref = Reference(ws_apt, min_col=2, max_col=4, min_row=1, max_row=dept_count + 1)

            chart_apti = get_chart(chart_type, title="Aptitude Performance", x_title="Department", y_title="Scores")
            chart_apti.add_data(data_ref, titles_from_data=True)
            chart_apti.set_categories(dept_ref)
            ws_apt.add_chart(chart_apti, "H2")

            print("‚úÖ 'Aptitude Report' sheet and chart created successfully.")
        else:
            print("‚õî Skipping Aptitude Report - All data is zero or empty.")

    else:
        print("‚ö†Ô∏è Aptitude not in question_type_list or no tests found.")


    if "Technical" in question_type_list and technical_tests:
        technical_df_copy = technical_df.copy()
        technical_df_copy["C"] = technical_df_copy.filter(regex="(?i)\\bC\\b", axis=1).sum(axis=1)
        technical_df_copy["C++"] = technical_df_copy.filter(regex="(?i)c\+\+", axis=1).sum(axis=1)
        technical_df_copy["Python"] = technical_df_copy.filter(regex="(?i)python", axis=1).sum(axis=1)
        technical_df_copy["JAVA"] = technical_df_copy.filter(regex="(?i)java", axis=1).sum(axis=1)
        technical_df_copy["All Languages"] = technical_df_copy.filter(regex="(?i)all.?languages", axis=1).sum(axis=1)

        tech_grouped = technical_df_copy.groupby("Department", as_index=False)[
            ["C", "C++", "Python", "JAVA", "All Languages", "Total_Technical_Avg"]
        ].mean().round(0)
        
        # ‚úÖ Check before adding sheet
        if not is_all_zero(tech_grouped, exclude_columns=["Department"]):
            ws_tech = wb.create_sheet("Technical Report")
            ws_tech.append(["Department", "C", "C++", "Python", "JAVA", "All Languages", "Total_Technical_Avg"])
            for _, row in tech_grouped.iterrows():
                ws_tech.append([row["Department"], row["C"], row["C++"], row["Python"], row["JAVA"], row["All Languages"], row["Total_Technical_Avg"]])
            dept_ref = Reference(ws_tech, min_col=1, min_row=2, max_row=len(tech_grouped) + 1)
            data_ref = Reference(ws_tech, min_col=2, max_col=6, min_row=1, max_row=len(tech_grouped) + 1)

            # Create chart
            chart_tech = get_chart(chart_type, title="Technical Performance", x_title="Department", y_title="Scores")
            chart_tech.add_data(data_ref, titles_from_data=True)
            chart_tech.set_categories(dept_ref)
            ws_tech.add_chart(chart_tech, "H2")
        else:
            print("Skipping Technical Report - No valid data")

    # ‚úÖ Only create "SoftSkills Report" if it has non-zero values
    if "Softskills" in question_type_list:
        if softskill_tests:  # Ensure we have soft skills tests
            softskill_df_copy = softskill_df.copy()
            softskill_df_copy["Communication"] = softskill_df_copy.filter(regex="(?i)communication", axis=1).sum(axis=1)
            softskill_df_copy["Teamwork"] = softskill_df_copy.filter(regex="(?i)teamwork", axis=1).sum(axis=1)
            softskill_df_copy["Leadership"] = softskill_df_copy.filter(regex="(?i)leadership", axis=1).sum(axis=1)

            softskill_grouped = softskill_df_copy.groupby("Department", as_index=False)[
                ["Communication", "Teamwork", "Leadership", "Total_Softskills_Avg"]
            ].mean().round(0)
            
            # ‚úÖ Check if all values are zero before creating the sheet
            if not is_all_zero(softskill_grouped, exclude_columns=["Department"]):
                ws_soft = wb.create_sheet("SoftSkills Report")
                ws_soft.append(["Department", "Communication", "Teamwork", "Leadership", "Total_Softskills_Avg"])
                for _, row in softskill_grouped.iterrows():
                    ws_soft.append([row["Department"], row["Communication"], row["Teamwork"], row["Leadership"], row["Total_Softskills_Avg"]])
                dept_ref = Reference(ws_soft, min_col=1, min_row=2, max_row=len(softskill_grouped) + 1)
                data_ref = Reference(ws_soft, min_col=2, max_col=4, min_row=1, max_row=len(softskill_grouped) + 1)

                # Create chart
                chart_soft = get_chart(chart_type, title="Soft Skills Performance", x_title="Department", y_title="Scores")
                chart_soft.add_data(data_ref, titles_from_data=True)
                chart_soft.set_categories(dept_ref)
                ws_soft.add_chart(chart_soft, "H2")
            else:
                print("Skipping SoftSkills Report - No valid data")

        # ‚úÖ Remove "Aptitude Report" if no aptitude tests exist
        if "Aptitude Report" in wb.sheetnames and not aptitude_tests:
            wb.remove(wb["Aptitude Report"])

        # ‚úÖ Remove "Technical Report" if no technical tests exist
        if "Technical Report" in wb.sheetnames and not technical_tests:
            wb.remove(wb["Technical Report"])

        # ‚úÖ Remove "Softskills Report" if no soft skills tests exist
        if "SoftSkills Report" in wb.sheetnames and not softskill_tests:
            wb.remove(wb["SoftSkills Report"])

        # --------------------------------------------------------------------------
        # CATEGORY REPORT (Department-wise count of A/B/C students)
        # --------------------------------------------------------------------------
        # all_students_with_cat has all students + assigned categories
        df_category = pd.DataFrame(all_students_with_cat)

        # Group by Department and Category to get the number of students
        group_cat = df_category.groupby(["Department", "Category"]).size().reset_index(name="Count")

        # Pivot so each department is a row, each Category is a column (A, B, C)
        cat_pivot = group_cat.pivot(index="Department", columns="Category", values="Count").fillna(0)
        print("pivot",cat_pivot)

        for col in ["A", "B", "C", "D"]:
            if col not in cat_pivot.columns:
                cat_pivot[col] = 0

        ws_cat = wb.create_sheet("Category Report")
        ws_cat.append(["Department", "A", "B", "C", "D"])

        for dept in cat_pivot.index:
            ws_cat.append([dept,
                        cat_pivot.loc[dept].get("A", 0),
                        cat_pivot.loc[dept].get("B", 0),
                        cat_pivot.loc[dept].get("C", 0),
                        cat_pivot.loc[dept].get("D", 0)])

        dept_count_cat = len(cat_pivot.index)

        chart_cat = get_chart(chart_type, title="Category Distribution by Department",
                            x_title="Department", y_title="Number of Students")

                # after writing aptitude data to ws_apt
        dept_ref = Reference(ws_apt, min_col=1, min_row=2, max_row=len(apti_grouped)+1)
        # ‚úÖ Create charts only if corresponding sheet exists
        if "Aptitude Report" in wb.sheetnames:
            ws_apt = wb["Aptitude Report"]
            dept_ref = Reference(ws_apt, min_col=1, min_row=2, max_row=len(apti_grouped)+1)
            if (chart_type or "").lower() == "pie":
                pie_data = Reference(ws_apt, min_col=5, max_col=5, min_row=2, max_row=len(apti_grouped)+1)
                pie_labels = dept_ref
                chart_apti = get_chart("pie", title="Average Aptitude per Department")
                chart_apti.add_data(pie_data, titles_from_data=False)
                chart_apti.set_categories(pie_labels)
                ws_apt.add_chart(chart_apti, "H2")
            else:
                data_ref = Reference(ws_apt, min_col=2, max_col=4, min_row=1, max_row=len(apti_grouped)+1)
                chart_apti = get_chart(chart_type, title="Aptitude Performance",
                                    x_title="Department", y_title="Scores")
                chart_apti.add_data(data_ref, titles_from_data=True)
                chart_apti.set_categories(dept_ref)
                ws_apt.add_chart(chart_apti, "H2")

        if "Technical Report" in wb.sheetnames:
            ws_tech = wb["Technical Report"]
            dept_ref = Reference(ws_tech, min_col=1, min_row=2, max_row=len(tech_grouped)+1)
            if (chart_type or "").lower() == "pie":
                pie_data = Reference(ws_tech, min_col=7, max_col=7, min_row=2, max_row=len(tech_grouped)+1)
                pie_labels = dept_ref
                chart_tech = get_chart("pie", title="Average Technical per Department")
                chart_tech.add_data(pie_data, titles_from_data=False)
                chart_tech.set_categories(pie_labels)
                ws_tech.add_chart(chart_tech, "H2")
            else:
                data_ref = Reference(ws_tech, min_col=2, max_col=6, min_row=1, max_row=len(tech_grouped)+1)
                chart_tech = get_chart(chart_type, title="Technical Performance",
                                    x_title="Department", y_title="Scores")
                chart_tech.add_data(data_ref, titles_from_data=True)
                chart_tech.set_categories(dept_ref)
                ws_tech.add_chart(chart_tech, "H2")

        if "SoftSkills Report" in wb.sheetnames:
            ws_soft = wb["SoftSkills Report"]
            dept_ref = Reference(ws_soft, min_col=1, min_row=2, max_row=len(softskill_grouped)+1)
            if (chart_type or "").lower() == "pie":
                pie_data = Reference(ws_soft, min_col=5, max_col=5, min_row=2, max_row=len(softskill_grouped)+1)
                pie_labels = dept_ref
                chart_soft = get_chart("pie", title="Average Softskills per Department")
                chart_soft.add_data(pie_data, titles_from_data=False)
                chart_soft.set_categories(pie_labels)
                ws_soft.add_chart(chart_soft, "H2")
            else:
                data_ref = Reference(ws_soft, min_col=2, max_col=4, min_row=1, max_row=len(softskill_grouped)+1)
                chart_soft = get_chart(chart_type, title="Soft Skills Performance",
                                    x_title="Department", y_title="Scores")
                chart_soft.add_data(data_ref, titles_from_data=True)
                chart_soft.set_categories(dept_ref)
                ws_soft.add_chart(chart_soft, "H2")

        if (chart_type or "").lower() == "pie":
            # total across all departments ‚Äì only D column
            pie_data = Reference(ws_cat, min_col=5, max_col=5,  # 'D' column
                                min_row=2, max_row=dept_count+1)
            pie_labels = dept_ref  # departments
            chart_cat = get_chart("pie", title="Category D per Department")
            chart_cat.add_data(pie_data, titles_from_data=False)
            chart_cat.set_categories(pie_labels)
            ws_cat.add_chart(chart_cat, "G2")

        else:
            # bar/clustered ‚Äì only include nonzero columns
            # find which category columns have at least one nonzero
            nonzero_cols = []
            for idx, cat in enumerate(["A","B","C","D"], start=2):
                values = [ws_cat.cell(row=r, column=idx).value for r in range(2, dept_count+2)]
                if any(v not in (0, None) for v in values):
                    nonzero_cols.append(idx)
            if not nonzero_cols:
                nonzero_cols = [5]  # at least D

            min_col = min(nonzero_cols)
            max_col = max(nonzero_cols)
            data_ref = Reference(ws_cat, min_col=min_col, max_col=max_col,
                                min_row=1, max_row=dept_count+1)
            chart_cat = get_chart(chart_type, title="Category Distribution by Department",
                                x_title="Department", y_title="Counts")
            chart_cat.add_data(data_ref, titles_from_data=True)
            chart_cat.set_categories(dept_ref)
            ws_cat.add_chart(chart_cat, "G2")
  
    for sheet_name in ["Cumulative Aptitude", "Cumulative Technical", "Cumulative Softskills"]:
        if sheet_name in wb.sheetnames:
            ws = wb[sheet_name]
            for col in ws.columns:
                max_length = 0
                col_letter = get_column_letter(col[0].column)  # column index to letter
                for cell in col:
                    try:
                        if cell.value:
                            max_length = max(max_length, len(str(cell.value)))
                    except:
                        pass
                adjusted_width = max_length + 5  # padding
                ws.column_dimensions[col_letter].width = adjusted_width
    try:
        college_name = college_master.objects.get(id=college_id).college
    except college_master.DoesNotExist:
        college_name = 'College'

    safe_name = slugify(college_name)
    filename = f"{safe_name}_report.xlsx"

    final_buffer = BytesIO()
    try:
        wb.save(final_buffer)
    except Exception:
        from openpyxl import Workbook
        wb = Workbook()
        ws = wb.active
        ws.title = "Error"
        ws.append(["No valid data found or workbook was not initialized."])
        wb.save(final_buffer)

    final_buffer.seek(0)

    response = HttpResponse(
    final_buffer.getvalue(),
    content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )
    response['Content-Disposition'] = f'attachment; filename="{filename}"'
    response['Access-Control-Expose-Headers'] = 'Content-Disposition'

    return response 
import tempfile
import os
from datetime import timedelta
from django.utils import timezone
from django.core.mail import EmailMessage
from django.http import JsonResponse
from django.test import RequestFactory
from django.db.models import Q

def generate_excel_for_college(college_id):
    """
    Generates the Excel report (same as get_tests_reports_by_college_Po)
    and returns the file path to attach in email.
    Works safely with both HttpResponse and DRF Response.
    """
    from django.test import RequestFactory
    import tempfile

    # Create a real Django GET request
    factory = RequestFactory()
    request = factory.get(f"/api/get_tests_reports_by_college_Po/?college_id={college_id}")

    # Call your existing report view
    response = get_tests_reports_by_college_Po(request)

    # ‚úÖ 1. Handle DRF Response objects (unrendered)
    if hasattr(response, "render"):
        try:
            response.render()
        except Exception as e:
            print(f"‚ö†Ô∏è render() failed for college {college_id}: {e}")

    # ‚úÖ 2. Extract raw content safely
    content = getattr(response, "content", None)
    if not content:
        try:
            # Some responses (like FileResponse) are iterable
            content = b"".join(response)
        except Exception as e:
            raise Exception(f"Cannot extract content for college {college_id}: {e}")

    # ‚úÖ 3. Save content into a temporary Excel file
    temp = tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx")
    temp.write(content)
    temp.flush()
    temp.close()

    return temp.name


# ‚úÖ Main function: send daily report email
def capture_first_login_send_email(request):
    """
    Sends one email per Placement Officer per college per day,
    attaching the Excel report of tests conducted yesterday.
    """
    print("=== capture_first_login_send_email triggered ===")

    now = timezone.now()
    today = now.date()
    yesterday = today - timedelta(days=1)
    print(f"Step 1Ô∏è‚É£ Today: {today}, Yesterday: {yesterday}")

    # Step 1: Find all colleges that had tests yesterday
    yesterday_colleges = list(
        tests_candidates_map.objects.filter(
            dtm_start__date=yesterday
        ).values_list("college_id", flat=True).distinct()
    )
    print(f"Step 2Ô∏è‚É£ Colleges with tests yesterday: {yesterday_colleges}")

    if not yesterday_colleges:
        print("‚ö†Ô∏è No colleges found with tests yesterday.")
        return JsonResponse({"message": "No colleges had tests yesterday."})

    sent_count = 0
    failed = []

    for college_id in yesterday_colleges:
        # Skip if already sent today
        if daily_email_log.objects.filter(college_id=college_id, sent_date__date=today).exists():
            continue

        # Find placement officers of that college
        placement_officers = login.objects.filter(
            Q(role__iexact="Placement Officer") | Q(role__iexact="PO"),
            college_id=college_id,
            deleted=0,
        ).exclude(email_id__isnull=True).exclude(email_id__exact="")

        email_list = [officer.email_id for officer in placement_officers]
        if not email_list:
            print(f"‚ö†Ô∏è No email IDs found for college {college_id}")
            continue

        # ‚úÖ Generate Excel file
        try:
            report_file_path = generate_excel_for_college(college_id)
            print(f"‚úÖ Generated report for college {college_id}: {report_file_path}")
        except Exception as e:
            print(f"‚ùå Report generation failed for college {college_id}: {e}")
            failed.append({"college_id": college_id, "error": str(e)})
            continue

        # Prepare email
        college_name = (
            placement_officers.first().college_id.college
            if placement_officers.first().college_id
            else f"College ID {college_id}"
        )

        subject = f"[Campus Connection] Daily Report - {college_name}"
        message = (
            f"Dear Placement Officer,\n\n"
            f"This is an automated notification to inform you that your college "
            f"had one or more tests conducted on {yesterday.strftime('%d-%m-%Y')}.\n\n"
            f"Date: {today.strftime('%d-%m-%Y')}\n"
            f"College: {college_name}\n\n"
            f"An Excel report is attached with this email.\n\n"
            "Thank you,\nCampus Connection"
        )

        # ‚úÖ Send email with attachment
        try:
            email = EmailMessage(
                subject,
                message,
                "campusconnectionsk356@gmail.com",  # from
                email_list,  # to
            )
            email.attach_file(report_file_path)
            email.send(fail_silently=False)
            daily_email_log.objects.create(college_id=college_id, sent_date=now)
            sent_count += 1
            print(f"üìß Email sent successfully to {email_list}")
        except Exception as e:
            print(f"‚ùå Email send failed for college {college_id}: {e}")
            failed.append({"college_id": college_id, "error": str(e)})
        finally:
            # Clean up temporary file
            if os.path.exists(report_file_path):
                os.remove(report_file_path)

    print(f"\n=== Summary ===")
    print(f"‚úÖ Emails sent to {sent_count} Placement Officer(s)")
    print(f"‚ùå Failed emails: {failed}")

    return JsonResponse({
        "message": f"Emails sent to {sent_count} Placement Officer(s).",
        "failed": failed
    })

@api_view(['POST']) 
def reassign_test_candidates_status_refresh(request):
    print("resgresfsb ")
    try:
        test_name = request.data.get('test_name')
        student_ids = request.data.get('student_ids', [])

        print(f"Received test_name: {test_name}")
        print(f"Received student_ids: {student_ids}")

        if not test_name:
            return Response({"error": "test_name is required"}, status=400)

        if not student_ids or not isinstance(student_ids, list):
            return Response({"error": "A list of student_ids is required"}, status=400)

        # Get today's date range from 6 AM to 11 PM
        today_str = timezone.localtime().strftime('%Y-%m-%d')
        dtm_start = timezone.make_aware(datetime.strptime(f"{today_str} 06:00:00", "%Y-%m-%d %H:%M:%S"))
        dtm_end = timezone.make_aware(datetime.strptime(f"{today_str} 23:00:00", "%Y-%m-%d %H:%M:%S"))

        print(f"Start Time (6 AM): {dtm_start}")
        print(f"End Time (11 PM): {dtm_end}")

        # Get existing test-candidate map records
        existing_records = tests_candidates_map.objects.filter(
            test_name=test_name, student_id__in=student_ids,deleted=0
        )

        if not existing_records.exists():
            print("No matching records found.")
            return Response({"error": "No records found for the given test_name and student_ids"}, status=404)

        # ‚ùå Delete previous answers for this test_name and student_ids
        # deleted_answers_count, _ = tests_candidates_answers.objects.filter(
        #     test_name=test_name,
        #     student_id__in=student_ids,deleted=0
        # ).delete()
        # print(f"Deleted {deleted_answers_count} answer(s) from tests_candidates_answers.")

        # ‚úÖ Update test-candidate map records
        updated_count = 0
        for record in existing_records:
            record.is_active = False
            record.status = "reassigned"
            record.is_reassigned = True
            # record.total_score = 0
            # record.avg_mark = 0
            record.assign_count = (record.assign_count or 0) + 1
            record.save()
            updated_count += 1

        print(f"Updated {updated_count} records.")
        return Response({
            "message": f"{updated_count} record(s) updated successfully",
            # "answers_deleted": deleted_answers_count
        }, status=200)

    except Exception as e:
        print(f"Error: {str(e)}")
        return Response({"error": "An internal error occurred", "details": str(e)}, status=500)



@api_view(['POST'])
def start_reassigned_exam(request):
    try:
        test_name = request.data.get('test_name', '').strip()
        student_id = request.data.get('student_id')

        print(f"üì© Received test_name: '{test_name}'")
        print(f"üì© Received student_id: {student_id}")

        # ‚úÖ Validation checks
        if not test_name:
            return Response({"error": "test_name is required"}, status=400)
        if not student_id:
            return Response({"error": "student_id is required"}, status=400)

        # ‚úÖ Find the record
        record = tests_candidates_map.objects.filter(
            test_name__iexact=test_name,  # case-insensitive
            student_id__id=student_id,
            deleted=0
        ).first()

        print(f"üîç Matching record: {record}")

        # ‚úÖ If no record found
        if not record:
            print(f"‚ùå No matching record found for test_name: '{test_name}' and student_id: {student_id}")
            return Response({
                "error": f"No record found for test_name '{test_name}' and student_id '{student_id}'"
            }, status=404)

        # ‚úÖ Update record safely
        with transaction.atomic():
            record.is_active = False
            record.is_reassigned = True
            record.status = "reassigned"

            # Increment assign_count correctly
            if record.assign_count is None:
                record.assign_count = 1
            else:
                record.assign_count += 1

            record.save()

        print(f"‚úÖ Updated record for student_id {student_id}: reassigned test '{test_name}'")
        return Response({
            "message": "Record updated successfully",
            "student_id": student_id,
            "test_name": test_name,
            "assign_count": record.assign_count
        }, status=200)

    except Exception as e:
        print(f"üî• Error in start_reassigned_exam: {str(e)}")
        return Response(
            {"error": "An internal error occurred", "details": str(e)},
            status=500
        )

@api_view(['PUT', 'POST'])
def update_movetab_test(request):
    print("----- [STEP 1] Received API Request -----")
    print("Request method:", request.method)
    print("Request data:", request.data)
    
    student_id = request.data.get('student_id')
    test_name = request.data.get('test_name')
    tab_move_count = request.data.get('tab_move_count')

    print(f"[STEP 2] Extracted Params -> student_id: {student_id} (type={type(student_id)}), test_name: '{test_name}', tab_move_count: {tab_move_count}")

    if not student_id or not test_name:
        return Response({"error": "student_id and test_name are required fields."}, status=400)

    try:
        # üîç Show what's inside DB for same test_name
        print("[STEP 3] Fetching existing rows with same test_name...")
        existing = tests_candidates_map.objects.filter(test_name=test_name)
        print(f"[STEP 3.1] Found {existing.count()} records with test_name='{test_name}'")
        for row in existing:
            print(f"   -> id={row.id}, student_id={row.student_id_id}, deleted={row.deleted}, tab_move_count={row.tab_move_count}")

        # üß† Convert student_id to int if numeric
        try:
            student_id = int(student_id)
        except:
            pass

        print("[STEP 4] Applying ORM filter now...")
        queryset = tests_candidates_map.objects.filter(
            student_id=student_id,
            test_name=test_name,
            deleted=0
        )

        updated_count = queryset.update(tab_move_count=tab_move_count)
        print(f"[STEP 6] Rows affected: {updated_count}")

        if updated_count == 0:
            return Response({"message": "No matching record found for the given student_id and test_name."}, status=404)

        print("[STEP 7] ‚úÖ tab_move_count updated successfully.")
        return Response({"message": f"tab_move_count updated successfully for {updated_count} record(s)."}, status=200)

    except Exception as e:
        print("[ERROR]", str(e))
        return Response({"error": str(e)}, status=500)



import tempfile
import subprocess
import shutil  # to check if executable exists
from django.views.decorators.csrf import csrf_exempt


@csrf_exempt
def run_node(request):
    if request.method == 'POST':
        try:
            data = json.loads(request.body)
            code = data.get('code', '')

            # ‚úÖ Create a unique temp JS file for each request
            with tempfile.NamedTemporaryFile(delete=False, suffix=".js", mode="w") as temp_file:
                temp_file.write(code)
                temp_path = temp_file.name

            # Run Node.js safely
            result = subprocess.run(
                ["node", temp_path],
                capture_output=True,
                text=True,
                timeout=10
            )

            # Clean up
            os.unlink(temp_path)

            if result.returncode == 0:
                return JsonResponse({"output": result.stdout.strip() or "No output."})
            else:
                return JsonResponse({"output": result.stderr.strip() or "Error during execution."})
        except subprocess.TimeoutExpired:
            return JsonResponse({"output": "Execution timed out."}, status=408)
        except Exception as e:
            return JsonResponse({"output": f"Error: {str(e)}"}, status=500)
    return JsonResponse({"output": "Invalid request method."}, status=405)



@csrf_exempt
def run_springboot(request):
    if request.method != 'POST':
        return JsonResponse({"output": "Invalid request method."}, status=405)

    temp_dir = None
    try:
        data = json.loads(request.body)
        code = data.get('code', '')

        # ‚úÖ Create unique temporary folder
        temp_dir = tempfile.mkdtemp()
        java_file = os.path.join(temp_dir, "Main.java")

        with open(java_file, 'w') as f:
            f.write(code)

        # ‚úÖ Compile Java
        compile_result = subprocess.run(
            ["javac", java_file],
            capture_output=True,
            text=True,
            timeout=10,
            cwd=temp_dir
        )

        if compile_result.returncode != 0:
            return JsonResponse({
                "output": compile_result.stderr.strip() or "Compilation failed."
            })

        # ‚úÖ Run compiled Java file
        run_result = subprocess.run(
            ["java", "-cp", temp_dir, "Main"],
            capture_output=True,
            text=True,
            timeout=10,
            cwd=temp_dir
        )

        if run_result.returncode == 0:
            return JsonResponse({
                "output": run_result.stdout.strip() or "No output."
            })
        else:
            return JsonResponse({
                "output": run_result.stderr.strip() or "Execution error."
            })

    except subprocess.TimeoutExpired:
        return JsonResponse({"output": "Execution timed out."}, status=408)
    except Exception as e:
        return JsonResponse({"output": f"Error: {str(e)}"}, status=500)
    finally:
        # ‚úÖ Always delete the temp folder
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)

# ----------- MATLAB COMPILER ------------


from concurrent.futures import ThreadPoolExecutor


# ‚úÖ Path to Octave (or MATLAB)
OCTAVE_PATH = r"D:\Documents\selvi folder\Yathi solution\Octave-10.3.0\mingw64\bin\octave.exe"

executor = ThreadPoolExecutor(max_workers=100)


def execute_matlab_code(code, custom_input):
    """Function to safely execute MATLAB/Octave code in background threads."""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".m", mode="w") as temp_file:
            temp_file.write(code)
            temp_path = temp_file.name

        result = subprocess.run(
            [OCTAVE_PATH, '--no-gui', '--quiet', '--eval', f"run('{temp_path}')"],
            capture_output=True,
            text=True,
            timeout=10  # Limit execution time per student
        )

        os.unlink(temp_path)  # Clean up temp file

        if result.returncode == 0:
            return {
                'status': 'SUCCESS',
                'result': result.stdout.strip() or "No output."
            }
        else:
            return {
                'status': 'FAILED',
                'message': result.stderr.strip() or "MATLAB execution error."
            }

    except subprocess.TimeoutExpired:
        return {'status': 'FAILED', 'message': 'Execution timed out.'}
    except Exception as e:
        return {'status': 'FAILED', 'message': str(e)}


@api_view(['POST'])
def run_matlab_code(request):
    """Concurrent-safe API to execute MATLAB/Octave code."""
    code = request.data.get('code', '')
    custom_input = request.data.get('inputs', '')

    if not code.strip():
        return Response({'status': 'FAILED', 'message': 'No MATLAB code provided.'}, status=400)

    if not os.path.exists(OCTAVE_PATH):
        return Response({'status': 'FAILED', 'message': 'Octave executable not found.'}, status=500)

    # ‚úÖ Run MATLAB code in background thread for concurrency
    future = executor.submit(execute_matlab_code, code, custom_input)
    result = future.result()  # Wait for this specific student's result only
    return Response(result)


CSC_PATH = r"C:\Windows\Microsoft.NET\Framework64\v4.0.30319\csc.exe"
executor = ThreadPoolExecutor(max_workers=50)  # allow 50 parallel compiles

def execute_csharp(code):
    with tempfile.TemporaryDirectory() as tmpdir:
        cs_file = os.path.join(tmpdir, "Program.cs")
        exe_file = os.path.join(tmpdir, "Program.exe")

        with open(cs_file, "w") as f:
            f.write(code)

        compile_process = subprocess.run(
            [CSC_PATH, "/out:" + exe_file, cs_file],
            capture_output=True,
            text=True,
            timeout=10
        )
        if compile_process.returncode != 0:
            return {'status': 'FAILED', 'message': compile_process.stderr.strip()}

        run_process = subprocess.run(
            [exe_file],
            capture_output=True,
            text=True,
            timeout=3
        )

        if run_process.returncode == 0:
            return {'status': 'SUCCESS', 'result': run_process.stdout.strip()}
        else:
            return {'status': 'FAILED', 'message': run_process.stderr.strip()}


@api_view(['POST'])
def run_csharp_code(request):
    code = request.data.get('code', '')

    if not code.strip():
        return Response({'status': 'FAILED', 'message': 'No C# code provided.'}, status=400)

    if not os.path.exists(CSC_PATH):
        return Response({'status': 'FAILED', 'message': 'C# compiler not found.'}, status=500)

    # Run in background thread
    future = executor.submit(execute_csharp, code)
    result = future.result()  # wait for completion
    return Response(result)



@csrf_exempt
def run_php(request):
    """
    Runs PHP or PHP+HTML code safely in a temporary directory.
    Accepts JSON body:
    {
        "code": "<?php echo 'Hello, PHP!'; ?>"
    }
    """
    if request.method != "POST":
        return JsonResponse({"output": "Invalid request method."}, status=405)

    try:
        data = json.loads(request.body)
        code = data.get("code", "").strip()

        if not code:
            return JsonResponse({"output": "No PHP code provided."}, status=400)

        with tempfile.TemporaryDirectory() as temp_dir:
            php_file = os.path.join(temp_dir, "main.php")

            # ‚úÖ Detect if code contains HTML
            contains_html = any(tag in code.lower() for tag in ["<html", "<!doctype", "<body"])

            # ‚úÖ Wrap with <?php ?> only if it's pure PHP
            if not contains_html and not code.startswith("<?php"):
                code = "<?php\n" + code + "\n?>"

            with open(php_file, "w", encoding="utf-8") as f:
                f.write(code)

            # ‚úÖ Execute PHP CLI safely
            run_result = subprocess.run(
                ["php", php_file],
                capture_output=True,
                text=True,
                timeout=10,
                cwd=temp_dir
            )

            # ‚úÖ Process result
            if run_result.returncode == 0:
                output = run_result.stdout.strip()
                # Remove any PHP tags or leftover whitespace
                output = output.replace("<?php", "").replace("?>", "").strip()

                # Prevent raw HTML injection (optional)
                # But if you *want* HTML output in iframe, keep as is
                return JsonResponse({"output": output or "No output."})
            else:
                return JsonResponse({
                    "output": run_result.stderr.strip() or "Execution error."
                }, status=400)

    except subprocess.TimeoutExpired:
        return JsonResponse({"output": "Execution timed out."}, status=408)

    except Exception as e:
        return JsonResponse({"output": f"Error: {str(e)}"}, status=500)

import json
import sqlite3
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt

@csrf_exempt
def run_mysql(request):
    """
    Execute multiple SQL statements safely using SQLite (MySQL simulator).
    Always starts with a clean, empty in-memory database.
    Shows output for all SELECT statements without any 'table exists' errors.
    """
    if request.method != "POST":
        return JsonResponse({"output": "Invalid request method."}, status=405)

    try:
        data = json.loads(request.body)
        query_script = data.get("code", "").strip()

        if not query_script:
            return JsonResponse({"output": "No SQL query provided."}, status=400)

        # ‚úÖ Always start a brand new, clean in-memory database
        conn = sqlite3.connect(":memory:")
        cur = conn.cursor()

        # ‚úÖ Split input into multiple statements
        statements = [stmt.strip() for stmt in query_script.split(";") if stmt.strip()]

        output_parts = []

        for stmt in statements:
            try:
                cur.execute(stmt)

                if stmt.lower().startswith("select"):
                    rows = cur.fetchall()
                    if cur.description:  # SELECT query
                        columns = [desc[0] for desc in cur.description]
                        table = "\n".join(
                            [", ".join(columns)] +
                            [", ".join(map(str, row)) for row in rows]
                        )
                        output_parts.append(table)
                    else:
                        output_parts.append("(no data)")
                else:
                    conn.commit()
                    output_parts.append(f"Query OK. Rows affected: {cur.rowcount}")

            except sqlite3.Error as e:
                output_parts.append(f"SQL Error: {str(e)}")

        conn.close()

        # ‚úÖ Combine results nicely
        final_output = "\n\n".join(output_parts)
        return JsonResponse({"output": final_output or "No output."})

    except Exception as e:
        return JsonResponse({"output": f"Error: {str(e)}"}, status=500)


# https://bleyer.org/icarus/ install plz
@api_view(['POST'])
def run_vlsi_code(request):
    print("=== VLSI API HIT ===")

    code = request.data.get('code', '')
    if not code.strip():
        print("Step 0: No code provided")
        return Response({'status': 'FAILED', 'message': 'No VLSI code provided.'}, status=400)

    # Locate executables
    iverilog_path = shutil.which("iverilog") or r"C:\iverilog\bin\iverilog.exe"
    vvp_path = shutil.which("vvp") or r"C:\iverilog\bin\vvp.exe"

    print(f"Step 0b: iverilog_path = {iverilog_path}")
    print(f"Step 0c: vvp_path = {vvp_path}")

    if not os.path.exists(iverilog_path):
        return Response({'status': 'FAILED', 'message': 'iverilog.exe not found'}, status=500)
    if not os.path.exists(vvp_path):
        return Response({'status': 'FAILED', 'message': 'vvp.exe not found'}, status=500)

    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            print(f"Step 1: Temporary directory = {tmpdir}")

            verilog_file = os.path.join(tmpdir, "test.v")
            output_file = os.path.join(tmpdir, "a.out")

            # Wrap paths in quotes to handle spaces
            verilog_file_quoted = f'"{verilog_file}"'
            output_file_quoted = f'"{output_file}"'

            with open(verilog_file, "w") as f:
                f.write(code)
            print(f"Step 2: Written code to file {verilog_file}")

            # Compile Verilog
            compile_cmd = f'"{iverilog_path}" -o {output_file_quoted} {verilog_file_quoted}'
            print(f"Step 3: Compile command = {compile_cmd}")
            compile_process = subprocess.run(
                compile_cmd,
                capture_output=True,
                text=True,
                shell=True,
                timeout=15
            )
            print(f"Step 3a: Compile returncode: {compile_process.returncode}")
            if compile_process.returncode != 0:
                return Response({
                    'status': 'FAILED',
                    'message': compile_process.stderr.strip() or "Verilog compilation error."
                }, status=400)

            # Run simulation
            run_cmd = f'"{vvp_path}" {output_file_quoted}'
            print(f"Step 4: Run command = {run_cmd}")
            run_process = subprocess.run(
                run_cmd,
                capture_output=True,
                text=True,
                shell=True,
                timeout=15
            )
            print(f"Step 4a: Simulation returncode: {run_process.returncode}")

            if run_process.returncode == 0:
                output = run_process.stdout.strip()

                # ‚úÖ Remove unwanted system messages (like $finish file paths)
                cleaned_lines = []
                for line in output.splitlines():
                    if "$finish" in line:
                        continue
                    if "AppData\\Local\\Temp" in line or "/tmp" in line:
                        continue
                    cleaned_lines.append(line)

                cleaned_output = "\n".join(cleaned_lines).strip()

                return Response({
                    'status': 'SUCCESS',
                    'result': cleaned_output or "Simulation completed successfully."
                })

            else:
                return Response({
                    'status': 'FAILED',
                    'message': run_process.stderr.strip() or "Simulation error."
                }, status=400)

    except subprocess.TimeoutExpired:
        return Response({'status': 'FAILED', 'message': 'Compilation or simulation timed out.'}, status=408)
    except Exception as e:
        print("Step 5: Exception occurred")
        traceback.print_exc()
        return Response({'status': 'FAILED', 'message': str(e)}, status=500)

from django.db.models import Sum
from django.db import transaction
from rest_framework.decorators import api_view
from rest_framework.response import Response
import json
from .models import tests_candidates_answers, tests_candidates_map, question_master

from rest_framework.decorators import api_view
from rest_framework.response import Response
from django.db import transaction
from django.db.models import Sum
import json

@api_view(['POST'])
def update_total_and_avg_marks(request):
    try:
        test_name = request.data.get('test_name', '').strip()
        student_id = request.data.get('student_id')

        print(f"üì• Received test_name: {test_name}")
        print(f"üì• Received student_id: {student_id}")

        if not test_name or not student_id:
            return Response({'error': 'test_name and student_id are required'}, status=400)

        # üîπ Fetch candidate answers
        answers = tests_candidates_answers.objects.filter(
            test_name=test_name,
            student_id=student_id,
            deleted=0
        )

        if not answers.exists():
            return Response({'error': 'No answers found for given test_name and student_id'}, status=404)

        # üîπ Compute total score
        total_score = answers.aggregate(total=Sum('result'))['total'] or 0
        print(f"‚úÖ Total Score from answers table: {total_score}")

        # üîπ Get candidate map entry
        map_entry = tests_candidates_map.objects.filter(
            test_name=test_name,
            student_id=student_id,
            deleted=0
        ).first()

        if not map_entry:
            return Response({'error': 'No test mapping found for given test_name and student_id'}, status=404)

        total_marks = 0

        # üî∏ CASE 1: Prefer question_ids (JSON) if available
        if map_entry.question_ids:
            raw_ids = map_entry.question_ids
            print(f"üß© Raw question_ids from DB: {raw_ids}")

            try:
                # Parse safely
                if isinstance(raw_ids, str):
                    question_ids_list = json.loads(raw_ids)
                elif isinstance(raw_ids, list):
                    question_ids_list = raw_ids
                else:
                    question_ids_list = []

                # Convert all valid items to integers
                question_ids_list = [int(x) for x in question_ids_list if str(x).isdigit()]
                print(f"‚úÖ Parsed question_ids list: {question_ids_list}")

                if question_ids_list:
                    total_marks = (
                        question_master.objects.filter(
                            id__in=question_ids_list,
                            deleted=0
                        ).aggregate(total=Sum('mark'))['total'] or 0
                    )
                    print(f"‚úÖ Total marks calculated using question_ids {question_ids_list}: {total_marks}")
                else:
                    print("‚ö†Ô∏è question_ids list empty after parsing.")

            except Exception as e:
                print(f"‚ùå Failed to parse question_ids JSON: {str(e)}")
                total_marks = 0

        # üî∏ CASE 2: Fallback to question_id (linked to question_paper_master)
        elif map_entry.question_id:
            paper_id = map_entry.question_id.id
            total_marks = (
                question_master.objects.filter(
                    question_name_id=paper_id,
                    deleted=0
                ).aggregate(total=Sum('mark'))['total'] or 0
            )
            print(f"‚úÖ Total marks using question_paper_master.id ({paper_id}): {total_marks}")

        # üßÆ Compute average mark safely
        if total_marks == 0:
            print("‚ö†Ô∏è total_marks = 0 ‚Üí avg_mark set to 0.")
            avg_mark = 0
        else:
            avg_mark = round((total_score / total_marks) * 100, 2)

        print(f"üìä Average Mark = {avg_mark}%")

        # üîê Save updates atomically
        with transaction.atomic():
            map_entry.total_score = total_score
            map_entry.avg_mark = avg_mark
            map_entry.save()

            # Optional: mark answers as updated
            answers.update(modified_by='system', dtm_modified=None)

        print("‚úÖ Total and average marks updated successfully.")
        return Response({
            'message': 'Total and average marks updated successfully',
            'test_name': test_name,
            'student_id': student_id,
            'total_score': total_score,
            'total_marks': total_marks,
            'avg_mark': avg_mark
        })

    except Exception as e:
        import traceback
        print("‚ùå Error:", traceback.format_exc())
        return Response({'error': str(e)}, status=500)

@api_view(['POST'])
def update_total_and_avg_marks_deleteanswerold(request):
    try:
        test_name = request.data.get('test_name', '').strip()
        student_id = request.data.get('student_id')

        print(f"üì• Received test_name: {test_name}")
        print(f"üì• Received student_id: {student_id}")

        if not test_name or not student_id:
            return Response({'error': 'test_name and student_id are required'}, status=400)

        # üîπ Fetch candidate answers
        answers = tests_candidates_answers.objects.filter(
            test_name=test_name,
            student_id=student_id,
            deleted=0
        )

        if not answers.exists():
            return Response({'error': 'No answers found for the given test_name and student_id'}, status=404)

        # üîπ Calculate total score
        total_score = answers.aggregate(total=Sum('result'))['total'] or 0
        print(f"‚úÖ Total Score from answers table: {total_score}")

        # üîπ Fetch test mapping entry
        map_entry = tests_candidates_map.objects.filter(
            test_name=test_name,
            student_id=student_id,
            deleted=0
        ).first()

        if not map_entry:
            return Response({'error': 'No test mapping found for the given test_name and student_id'}, status=404)

        total_marks = 0

        # üî∏ CASE 1: If question_ids JSON field is present and valid ‚Üí this takes priority
        if map_entry.question_ids:
            raw_ids = map_entry.question_ids
            print(f"üß© Raw question_ids from DB: {raw_ids}")

            try:
                # Parse safely
                if isinstance(raw_ids, str):
                    question_ids_list = json.loads(raw_ids)
                elif isinstance(raw_ids, list):
                    question_ids_list = raw_ids
                else:
                    question_ids_list = []

                question_ids_list = [int(x) for x in question_ids_list if str(x).isdigit()]
                print(f"‚úÖ Parsed question_ids list: {question_ids_list}")

                if question_ids_list:
                    total_marks = (
                        question_master.objects.filter(
                            id__in=question_ids_list,
                            deleted=0
                        ).aggregate(total=Sum('mark'))['total'] or 0
                    )
                    print(f"‚úÖ Total marks calculated using question_ids {question_ids_list}: {total_marks}")
                else:
                    print("‚ö†Ô∏è question_ids list empty after parsing.")

            except Exception as e:
                print("‚ùå Failed to parse question_ids JSON:", str(e))
                total_marks = 0

        # üî∏ CASE 2: Fallback to question_id if no valid question_ids exist
        elif map_entry.question_id:
            paper_id = map_entry.question_id.id
            total_marks = (
                question_master.objects.filter(
                    question_name_id=paper_id,
                    deleted=0
                ).aggregate(total=Sum('mark'))['total'] or 0
            )
            print(f"‚úÖ Total marks using question_paper_master.id ({paper_id}): {total_marks}")

        # üßÆ Compute average mark
        if total_marks == 0:
            print("‚ö†Ô∏è total_marks = 0 ‚Üí avg_mark set to 0.")
            avg_mark = 0
        else:
            avg_mark = round((total_score / total_marks) * 100, 2)

        print(f"üìä Average Mark = {avg_mark}%")

        # üîê Update + delete answers atomically
        with transaction.atomic():
            map_entry.total_score = total_score
            map_entry.avg_mark = avg_mark
            map_entry.save()

            deleted_count, _ = tests_candidates_answers.objects.filter(
                test_name=test_name,
                student_id=student_id
            ).delete()

            print(f"üóëÔ∏è Deleted {deleted_count} records from tests_candidates_answers")

        print("‚úÖ Total and average marks updated successfully and answers deleted.")
        return Response({
            'message': 'Total and average marks updated successfully and candidate answers deleted',
            'test_name': test_name,
            'student_id': student_id,
            'total_score': total_score,
            'total_marks': total_marks,
            'avg_mark': avg_mark,
            'deleted_answers_count': deleted_count
        })

    except Exception as e:
        import traceback
        print("‚ùå Error:", traceback.format_exc())
        return Response({'error': str(e)}, status=500)

@api_view(['POST'])
def update_total_and_avg_marks_deleteanswer(request):
    try:
        test_name = request.data.get('test_name', '').strip()
        student_id = request.data.get('student_id')

        print(f"üì• Received test_name: {test_name}")
        print(f"üì• Received student_id: {student_id}")

        if not test_name or not student_id:
            return Response({'error': 'test_name and student_id are required'}, status=400)

        # üîπ Fetch candidate answers
        answers = tests_candidates_answers.objects.filter(
            test_name=test_name,
            student_id=student_id,
            deleted=0
        )

        if not answers.exists():
            return Response({'error': 'No answers found for the given test_name and student_id'}, status=404)

        # üîπ Calculate total score
        total_score = answers.aggregate(total=Sum('result'))['total'] or 0
        print(f"‚úÖ Total Score from answers table: {total_score}")

        # üîπ Fetch test mapping entry
        map_entry = tests_candidates_map.objects.filter(
            test_name=test_name,
            student_id=student_id,
            deleted=0
        ).first()

        if not map_entry:
            return Response({'error': 'No test mapping found for the given test_name and student_id'}, status=404)

        # üîπ Fetch test details to get category
        test_entry = test_master.objects.filter(test_name=test_name).first()
        test_type_category = None
        if test_entry and test_entry.test_type_id:
            test_type_category = test_entry.test_type_id.test_type_categories

        print(f"üßæ Test Category: {test_type_category}")

        total_marks = 0

        # üî∏ CASE 1: If question_ids JSON field is present and valid ‚Üí takes priority
        if map_entry.question_ids:
            raw_ids = map_entry.question_ids
            try:
                if isinstance(raw_ids, str):
                    question_ids_list = json.loads(raw_ids)
                elif isinstance(raw_ids, list):
                    question_ids_list = raw_ids
                else:
                    question_ids_list = []

                question_ids_list = [int(x) for x in question_ids_list if str(x).isdigit()]
                if question_ids_list:
                    total_marks = (
                        question_master.objects.filter(
                            id__in=question_ids_list,
                            deleted=0
                        ).aggregate(total=Sum('mark'))['total'] or 0
                    )
                    print(f"‚úÖ Total marks calculated: {total_marks}")
            except Exception as e:
                print("‚ùå Failed to parse question_ids JSON:", str(e))
                total_marks = 0

        # üî∏ CASE 2: Fallback to question_id if no valid question_ids exist
        elif map_entry.question_id:
            paper_id = map_entry.question_id.id
            total_marks = (
                question_master.objects.filter(
                    question_name_id=paper_id,
                    deleted=0
                ).aggregate(total=Sum('mark'))['total'] or 0
            )

        # üßÆ Compute average mark
        if total_marks == 0:
            avg_mark = 0
        else:
            avg_mark = round((total_score / total_marks) * 100, 2)

        print(f"üìä Initial Average Mark = {avg_mark}% (total_score={total_score}, total_marks={total_marks})")

        # ============================================
        # üîπ Apply Special Logic Based on Test Category
        # ============================================

        if test_type_category == "Pre-Assessment":
            if avg_mark > 37:
                print(f"‚öôÔ∏è Adjusting Pre-Assessment avg_mark ({avg_mark} ‚Üí 36.99)")
                avg_mark = 36.99

        elif test_type_category == "Post-Assessment":
            capture = map_entry.capture_duration or ""
            import re

            # Extract minutes properly from "41 min 9 sec"
            min_match = re.search(r'(\d+)\s*min', capture)
            sec_match = re.search(r'(\d+)\s*sec', capture)

            minutes = int(min_match.group(1)) if min_match else 0
            seconds = int(sec_match.group(1)) if sec_match else 0

            total_seconds = minutes * 60 + seconds
            print(f"üïí Capture Duration Parsed: {minutes} min {seconds} sec ({total_seconds} seconds)")

            # Only adjust if duration > 10 min AND avg < 56
            if total_seconds > 600:  # 600 seconds = 10 minutes
                if avg_mark < 56:
                    print(f"‚öôÔ∏è Adjusting Post-Assessment avg_mark ({avg_mark} ‚Üí 56.00) due to duration > 10min")
                    avg_mark = 56.00
                else:
                    print(f"‚úÖ Duration > 10min but avg >= 56 ({avg_mark}), keeping as is")
            else:
                print(f"‚è±Ô∏è Duration ‚â§ 10min ({minutes} min) ‚Üí No adjustment")

        print(f"‚úÖ Final avg_mark = {avg_mark}% after category adjustment")

        # üîê Update + delete answers atomically
        with transaction.atomic():
            map_entry.total_score = total_score
            map_entry.avg_mark = avg_mark
            map_entry.stu_avg_mark = avg_mark
            map_entry.save()
            deleted_count = 0
            if test_type_category and test_type_category.strip().lower() in ["mock/interview", "mock", "interview"]:
                print("üõë Skipping answer deletion for Mock/Interview test type.")
            else:
                deleted_count, _ = tests_candidates_answers.objects.filter(
                    test_name=test_name,
                    student_id=student_id
                ).delete()
                print(f"üóëÔ∏è Deleted {deleted_count} answers from tests_candidates_answers")

        msg = (
            "Total and average marks updated successfully."
            + ("" if deleted_count == 0 else " Candidate answers deleted.")
        )
        print("‚úÖ Total and average marks updated successfully and answers deleted.")
        return Response({
            'message': msg,
            'test_name': test_name,
            'student_id': student_id,
            'total_score': total_score,
            'total_marks': total_marks,
            'avg_mark': avg_mark,
             'stu_avg_mark': avg_mark,
            'deleted_answers_count': deleted_count
        })

    except Exception as e:
        import traceback
        print("‚ùå Error:", traceback.format_exc())
        return Response({'error': str(e)}, status=500)

# https://nodejs.org/en/download/current plz download
@csrf_exempt
def run_jquery(request):
    """
    Executes jQuery / JS / HTML + jQuery code safely via Node.js + jsdom.
    """
    import json, tempfile, os, subprocess, traceback, re

    if request.method != "POST":
        return JsonResponse({"output": "", "error": "Invalid request method."}, status=405)

    try:
        data = json.loads(request.body)
        user_code = data.get("code", "").strip()

        if not user_code:
            return JsonResponse({"output": "", "error": "No code provided."}, status=400)

        # Detect if HTML is included
        lower = user_code.lower()
        contains_html = any(tag in lower for tag in ("<html", "<!doctype", "<body", "<div", "<span", "<script"))

        html_content = user_code if contains_html else "<!doctype html><html><body></body></html>"

        with tempfile.TemporaryDirectory() as tmpdir:
            runner_path = os.path.join(tmpdir, "run_jquery.js")

            payload = {
                "html": html_content,
                "js": user_code if not contains_html else ""
            }

            node_runner = r'''
const { JSDOM, VirtualConsole } = require("jsdom");

function extractInlineScripts(html) {
  const regex = /<script[^>]*>([\s\S]*?)<\/script>/gi;
  const scripts = [];
  let match;
  while ((match = regex.exec(html)) !== null) {
    if (match[1].trim()) scripts.push(match[1]);
  }
  return scripts;
}

async function main() {
  const payload = JSON.parse(process.argv[2] || "{}");
  const html = payload.html || "<!doctype html><html><body></body></html>";
  const userJs = payload.js || "";
  const inlineScripts = extractInlineScripts(html);

  const logs = [];
  const virtualConsole = new VirtualConsole();
  virtualConsole.on("log", (...args) => logs.push(args.join(" ")));
  virtualConsole.on("error", (...args) => logs.push("ERROR: " + args.join(" ")));

  const dom = new JSDOM(html, {
    runScripts: "dangerously",
    resources: "usable",
    virtualConsole
  });

  const window = dom.window;

  try {
    const $ = require("jquery")(window);
    window.$ = $;
    window.jQuery = $;
  } catch (e) {
    console.error("JQ_ERR: " + e.toString());
    process.exit(2);
  }

  // Wait for DOM ready
  await new Promise(resolve => {
    window.addEventListener("load", resolve);
    setTimeout(resolve, 300);
  });

  // Execute all inline <script> tags
  for (const script of inlineScripts) {
    try {
      window.eval(script);
    } catch (e) {
      console.error("SCRIPT_ERR: " + e.toString());
    }
  }

  // Execute raw JS (if no HTML was included)
  if (userJs && !inlineScripts.length) {
    try {
      window.eval(userJs);
    } catch (e) {
      console.error("EVAL_ERR: " + e.toString());
    }
  }

  // Wait for jQuery DOM manipulations to complete
  await new Promise(r => setTimeout(r, 300));

  console.log(logs.join("\\n"));
  process.exit(0);
}

main();
'''

            with open(runner_path, "w", encoding="utf-8") as f:
                f.write(node_runner)

            payload_json = json.dumps(payload)
            node_modules_path = r"E:\cc_portal_project\New folder\backend\node_modules"
            env = os.environ.copy()
            env["NODE_PATH"] = node_modules_path

            proc = subprocess.run(
                ["node", runner_path, payload_json],
                capture_output=True,
                text=True,
                timeout=10,
                cwd=tmpdir,
                env=env
            )

            def clean_text(t):
                if not t:
                    return ""
                return "\n".join([L for L in t.splitlines() if not any(w in L for w in ["DeprecationWarning", "ExperimentalWarning"])]).strip()

            stdout = clean_text(proc.stdout)
            stderr = clean_text(proc.stderr)
            plain_output = re.sub(r"<[^>]+>", "", stdout).strip()

            if proc.returncode != 0 and not plain_output:
                return JsonResponse({"output": "", "error": stderr or "Node process failed."}, status=400)

            return JsonResponse({
                "output": plain_output or "No output.",
                "error": stderr
            })

    except subprocess.TimeoutExpired:
        return JsonResponse({"output": "", "error": "Execution timed out."}, status=408)
    except Exception as e:
        traceback.print_exc()
        return JsonResponse({"output": "", "error": str(e)}, status=500)



#____________________________________________________Audi0________________________________________________#
from rest_framework.decorators import api_view, parser_classes
from rest_framework.parsers import MultiPartParser, FormParser
import pandas as pd
import re
from datetime import datetime
from django.http import JsonResponse

@api_view(['GET', 'POST'])
@parser_classes([MultiPartParser, FormParser])
def upload_communication_questions(request):
    """
    Upload communication test questions 
    Handles:
      - Excel upload (with questions inside Excel)
      - Manual upload (creates question_paper_master only)
    """

    print("üöÄ upload_communication_questions called")

    if request.method == 'GET':
        print("üìÑ GET request received ‚Äî rendering template page")
        return render(request, 'upload_communication_questions.html')

    try:
        print("üì• Extracting request data...")

        # ‚úÖ Common fields
        question_paper_name = request.data.get("question_paper_name")
        duration_of_test = request.data.get("duration_of_test")
        test_type_name = "Audio"
        test_type_category = request.data.get("test_type_categories")
        topic = request.data.get("topic")
        sub_topic = request.data.get("sub_topic")
        created_by = request.data.get("created_by", "admin")
        audio_text_from_form = request.data.get("audio_text", "")
        upload_type = request.data.get("upload_type")
        no_of_questions = request.data.get("no_of_questions", 0)
        no_of_questions = request.data.get("no_of_questions", 0)
        communication_category = request.data.get("communication_category", "")
        print("communication category : ",communication_category)



        print(f"üßæ Upload Type: {upload_type}")
        print(f"üìò Paper Name: {question_paper_name}")
        print(f"üïí Duration: {duration_of_test}")
        print(f"üß† Topic: {topic} | Sub-topic: {sub_topic}")
        print(f"üìÅ Category: {test_type_category}")
        print(f"üë§ Created By: {created_by}")
        print(f"üî¢ No. of Questions: {no_of_questions}")

        # ‚úÖ Handle Manual Upload
        if upload_type == "Manual":
            print("üìù Creating manual question paper entry in database...")
            qp = question_paper_master.objects.create(
                question_paper_name=question_paper_name,
                duration_of_test=duration_of_test,
                no_of_questions=no_of_questions,
                test_type=test_type_name,
                topic=topic,
                sub_topic=sub_topic,
                upload_type="Manual",
                created_by=created_by,
                dtm_created=datetime.now(),
                audio_text=audio_text_from_form,
                remarks=test_type_category,
                communication_category=communication_category,
                
            )

            print(f"‚úÖ Manual question paper created successfully! ID = {qp.id}")
            print("üì§ Returning response to frontend with question_paper_id")

            return JsonResponse({
                "message": "Manual Question Paper created successfully!",
                "question_paper_id": qp.id
            }, status=200)
        if upload_type == "Word":
            print("üìÑ Creating Word-based question paper master entry...")

            qp = question_paper_master.objects.create(
                question_paper_name=question_paper_name,
                duration_of_test=duration_of_test,
                no_of_questions=0,           # You will add questions later
                test_type=test_type_name,
                topic=topic,
                sub_topic=sub_topic,
                upload_type="Word",          # IMPORTANT
                created_by=created_by,
                dtm_created=datetime.now(),
                audio_text=audio_text_from_form,
                remarks=test_type_category,
                communication_category=communication_category,
            )

            print(f"‚úÖ Word Question Paper created! ID = {qp.id}")

            return JsonResponse({
                "message": "Word Question Paper created successfully!",
                "question_paper_id": qp.id
            }, status=200)
        # ‚úÖ Handle Excel Upload
        print("üì¶ Excel upload flow detected... checking file...")

        excel_file = request.FILES.get("excel_file")
        if not excel_file:
            print("‚ùå Excel file not found in request")
            return JsonResponse({"error": "Excel file is required for Excel upload"}, status=400)

        print(f"‚úÖ Excel file received: {excel_file.name}")

        # ‚úÖ Create or get test type
        print("üîç Checking or creating test_type record...")
        test_type_obj, created_tt = test_type.objects.get_or_create(
            test_type=test_type_name,
            test_type_categories=test_type_category
        )
        if created_tt:
            print(f"üÜï New test_type created: {test_type_obj}")
        else:
            print(f"‚úÖ Existing test_type found: {test_type_obj}")

        # ‚úÖ Create Question Paper entry
        print("üßæ Creating question paper entry for Excel upload...")
        qp = question_paper_master.objects.create(
            question_paper_name=question_paper_name,
            duration_of_test=duration_of_test,
            no_of_questions=0,
            test_type=test_type_name,
            topic=topic,
            sub_topic=sub_topic,
            upload_type="Excel",
            created_by=created_by,
            dtm_created=datetime.now(),
            audio_text=audio_text_from_form,
            remarks=test_type_category,
            communication_category=communication_category,
        )
        print(f"‚úÖ Question Paper created for Excel upload: ID = {qp.id}")

        # ‚úÖ Read Excel into DataFrame
        print("üìä Reading Excel into pandas DataFrame...")
        df = pd.read_excel(excel_file)
        print(f"‚úÖ Loaded {len(df)} rows from Excel")

        category = test_type_category.strip().lower()
        print(f"üî† Normalizing column headers for category: {category}")

        # ‚úÖ Header mapping: maps Excel headers ‚Üí model fields
        header_map = {
            "questions": "question_text",
            "questions**": "question_text",
            "question": "question_text",
            "optiona": "option_a",
            "option_a": "option_a",
            "optionb": "option_b",
            "option_b": "option_b",
            "optionc": "option_c",
            "option_c": "option_c",
            "optiond": "option_d",
            "option_d": "option_d",
            "optione": "option_e",
            "option_e": "option_e",
            "answer": "answer",
            "answer**": "answer",
            "mark": "mark",
            "mark**": "mark",
            "difficulty_level": "difficulty_level",
            "difficultylevel": "difficulty_level",
        }

        # ‚úÖ Normalize and rename columns
        normalized_cols = []
        for col in df.columns:
            clean_name = re.sub(r'[^a-z0-9_]', '', col.strip().lower().replace(" ", "_"))
            mapped_name = header_map.get(clean_name, clean_name)
            normalized_cols.append(mapped_name)
        df.columns = normalized_cols
        print(f"‚úÖ Normalized columns: {df.columns.tolist()}")

        # ‚úÖ Begin question creation
        print("üß© Creating questions...")
        count = 0

        # Pronunciation / AudioTyping (no options)
        if category in ["pronunciation", "audiotyping"]:
            print(f"üé§ Detected category: {category} ‚Äî creating simple Q&A type questions")
            required_cols = ["question_text", "mark", "difficulty_level"]
            for col in required_cols:
                if col not in df.columns:
                    print(f"‚ùå Missing required column: {col}")
                    return JsonResponse({"error": f"Missing column: {col}"}, status=400)

            for _, row in df.iterrows():
                q_text = str(row.get("question_text", "")).strip()
                if not q_text:
                    continue
                question_master.objects.create(
                    question_name_id=qp,
                    question_text=q_text,
                    answer=q_text,
                    mark=int(row.get("mark", "")),
                    difficulty_level=str(row.get("difficulty_level", "")).strip(),
                    created_by=created_by,
                    dtm_created=datetime.now(),
                )
                count += 1
            print(f"‚úÖ Created {count} pronunciation/audio typing questions")

        else:
            # AudioMCQ type (options + answer)
            print("üéß Detected AudioMCQ category ‚Äî creating MCQ type questions")
            required_cols = ["question_text", "answer", "mark", "difficulty_level"]
            for col in required_cols:
                if col not in df.columns:
                    print(f"‚ùå Missing required column: {col}")
                    return JsonResponse({"error": f"Missing column: {col}"}, status=400)

            for _, row in df.iterrows():
                q_text = str(row.get("question_text", "")).strip()
                if not q_text:
                    continue
                question_master.objects.create(
                    question_name_id=qp,
                    question_text=q_text,
                    option_a=row.get("option_a", ""),
                    option_b=row.get("option_b", ""),
                    option_c=row.get("option_c", ""),
                    option_d=row.get("option_d", ""),
                    option_e=row.get("option_e", ""),
                    answer=str(row.get("answer", "")),
                    mark=int(row.get("mark", "")),
                    difficulty_level=str(row.get("difficulty_level", "")).strip(),
                    dtm_created=datetime.now(),
                    created_by=created_by,
                )
                count += 1
            print(f"‚úÖ Created {count} AudioMCQ questions")

        # ‚úÖ Update question count
        print(f"üßæ Updating question count ({count}) in question_paper_master...")
        qp.no_of_questions = count
        qp.save(update_fields=["no_of_questions"])
        print("‚úÖ Question paper updated successfully")

        print("üì§ Sending success response to frontend")
        return JsonResponse({
            "message": f"‚úÖ '{question_paper_name}' uploaded successfully! ({count} questions added)"
        }, status=200)

    except Exception as e:
        print("‚ùå Exception in upload_communication_questions:", str(e))
        import traceback
        traceback.print_exc()
        return JsonResponse({"error": str(e)}, status=500)


@api_view(['GET'])
def download_communication_template(request):
    """
    Download Excel template for communication test uploads.
    """
    import pandas as pd
    from io import BytesIO
    from django.http import HttpResponse

    data = [{
        "Questions**": "What did the customer ask for?",
        "Option A": "The price of the desktop",
        "Option B": "The price of the laptop",
        "Option C": "The model number of the laptop",
        "Option D": "The delivery date of the product",
        "Answer**": "B",
        "Mark**": 1,
        "Difficulty Level": "Easy"
    }]

    df = pd.DataFrame(data)

    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='CommunicationTestTemplate')
    output.seek(0)

    response = HttpResponse(
        output,
        content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )
    response['Content-Disposition'] = 'attachment; filename="communication_test_template.xlsx"'
    return response

import pytz
@api_view(['GET'])
def active_audio_tests(request):
    username = request.query_params.get("username")
    if not username:
        return Response(
            {"status": "error", "message": "username query param is required"},
            status=400
        )

    ist = pytz.timezone("Asia/Kolkata")
    now = timezone.now().astimezone(ist)
    print(f"üïí Current datetime (IST): {now}")

    try:
        candidate = candidate_master.objects.get(user_name=username)
    except candidate_master.DoesNotExist:
        return Response({"status": "success", "tests": []})

    test_type_subquery = test_master.objects.filter(
        test_name=OuterRef('test_name')
    ).values('test_type_id__test_type')[:1]

    annotated_candidates = tests_candidates_map.objects.annotate(
        test_type_from_master=Subquery(test_type_subquery)
    ).filter(
        Q(student_id=candidate),
        Q(deleted=0),
        Q(is_active=False),
        Q(test_type_from_master='Audio'),
        Q(dtm_start__isnull=False),
        Q(dtm_end__isnull=False),
        Q(dtm_end__gt=now)
    ).select_related(
        'college_id', 'department_id', 'student_id', 'rules_id'
    ).order_by('dtm_start')

    print(f"‚úÖ Found {annotated_candidates.count()} audio tests for {username}")

    test_list = []
    for t in annotated_candidates:
        # ‚úÖ Safe timezone handling ‚Äî do not reconvert if already IST
        if timezone.is_aware(t.dtm_start):
            dtm_start_display = t.dtm_start
        else:
            dtm_start_display = ist.localize(t.dtm_start)

        if timezone.is_aware(t.dtm_end):
            dtm_end_display = t.dtm_end
        else:
            dtm_end_display = ist.localize(t.dtm_end)

        # Determine status
        if now < dtm_start_display:
            status = "Upcoming"
        elif dtm_start_display <= now <= dtm_end_display:
            status = "Active"
        else:
            status = "Expired"

        test_data = {
            "id": t.id,
            "test_name": t.test_name,
            # ‚úÖ Correct formatting ‚Äî show IST exactly as stored
            "dtm_start": dtm_start_display.strftime("%Y-%m-%d %I:%M %p"),
            "dtm_end": dtm_end_display.strftime("%Y-%m-%d %I:%M %p"),
            "duration": t.duration,
            "test_type": t.test_type_from_master,
            "user_name": t.student_id.user_name if t.student_id else None,
            "rules": t.rules_id.rule_name if t.rules_id else None,
            "instruction": t.rules_id.instruction if t.rules_id else None,
            "attempt_count": t.attempt_count,
            "duration_type": t.duration_type,
            "is_active": t.is_active,
            "status": status,
        }

        test_list.append(test_data)

    return Response({"status": "success", "tests": test_list})
@api_view(['GET'])
def get_audio_test_details(request):
    """
    Returns all question + test details for a given test_name and student user_name.
    """
    test_name = request.query_params.get("test_name")
    username = request.query_params.get("username")

    if not test_name or not username:
        return Response(
            {"status": "error", "message": "Both test_name and username are required."},
            status=400
        )

    try:
        # Step 1: Find candidate
        candidate = candidate_master.objects.get(user_name=username)
    except candidate_master.DoesNotExist:
        return Response({"status": "error", "message": "Candidate not found."}, status=404)

    # Step 2: Fetch record from tests_candidates_map
    try:
        mapping = tests_candidates_map.objects.select_related('question_id').get(
            Q(test_name=test_name),
            Q(student_id=candidate),
            Q(deleted=0)
        )
    except tests_candidates_map.DoesNotExist:
        return Response({"status": "error", "message": "Test mapping not found."}, status=404)

    # Step 3: Get related question paper
    question_paper = mapping.question_id
    question_ids = mapping.question_ids or []

    # Step 4: Get test_type_category from test_master
    test_obj = test_master.objects.filter(test_name=test_name, deleted=0).first()
    test_type_category = (
        test_obj.test_type_id.test_type_categories
        if test_obj and test_obj.test_type_id
        else None
    )

    # Step 5: Fetch questions for the paper
    questions_qs = question_master.objects.filter(
        Q(question_name_id=question_paper),
        Q(deleted=0)
    ).values(
        'id',
        'question_text',
        'option_a', 'option_b', 'option_c', 'option_d', 'option_e',
        'answer',
       
    )

    if question_ids:
        questions_qs = questions_qs.filter(id__in=question_ids)

    questions = list(questions_qs)

    # ‚úÖ Step 6: Include both `student_id` and `mapping_id` in the response
    data = {
        "status": "success",
        "mapping_id": mapping.id,            # ‚úÖ Added
        "student_id": candidate.id,          # ‚úÖ Already present
        "students_name": candidate.students_name,
        "user_name": candidate.user_name,
        "test_name": mapping.test_name,
        "question_id": mapping.question_id.id if mapping.question_id else None,
        "question_paper_name": question_paper.question_paper_name if question_paper else None,
        "question_ids": question_ids,
        "remarks": question_paper.remarks if question_paper else None,
        "duration_type": mapping.duration_type,
        "duration": mapping.duration,
        "duration_of_test": question_paper.duration_of_test if question_paper else None,
        "audio_text": question_paper.audio_text if question_paper else None,
        "test_type_categories": test_type_category,
        "questions": questions,
    }

    return Response(data, status=200)

from difflib import SequenceMatcher

@csrf_exempt
def add_or_update_result(request):
    """
    Add or update test result for a student.
    If the student's answer matches the correct answer, full marks are given.
    If partially matches (missed/spelling differences), score is scaled by similarity ratio.
    """

    print("üü¢ Received request for add_or_update_result")

    if request.method != "POST":
        print("‚ùå Invalid method used:", request.method)
        return JsonResponse({"status": "error", "message": "Only POST method allowed"}, status=400)

    try:
        # ‚úÖ Parse JSON request
        data = json.loads(request.body.decode("utf-8"))
        print("üì• Received Data:", data)

        student_id = data.get("student_id")
        test_name = data.get("test_name")
        question_id = data.get("question_id")
        user_answer = (data.get("answer") or "").strip()
        dtm_start = data.get("dtm_start")
        dtm_end = data.get("dtm_end")

        print(f"üîπ Student ID: {student_id}")
        print(f"üîπ Test Name: {test_name}")
        print(f"üîπ Question ID: {question_id}")
        print(f"üîπ User Answer: '{user_answer}'")

        if not all([student_id, test_name, question_id, user_answer]):
            print("‚ö†Ô∏è Missing required fields")
            return JsonResponse({"status": "error", "message": "Missing required fields"}, status=400)

        # ‚úÖ Get the correct question details
        try:
            question = question_master.objects.get(id=question_id, deleted=0)
            print("‚úÖ Question found:", question.question_text)
        except question_master.DoesNotExist:
            print("‚ùå Question not found for ID:", question_id)
            return JsonResponse({"status": "error", "message": "Question not found"}, status=404)

        correct_answer = (question.answer or "").strip()
        max_mark = question.mark or 0

        print(f"üîπ Correct Answer: '{correct_answer}'")
        print(f"üîπ Max Mark: {max_mark}")

        # ‚úÖ Compute similarity (using SequenceMatcher for text comparison)
        if correct_answer:
            similarity_ratio = SequenceMatcher(None, correct_answer.lower(), user_answer.lower()).ratio()
        else:
            similarity_ratio = 0

        # Convert ratio to percentage (0‚Äì100)
        similarity_percentage = int(round(similarity_ratio * 100))
        print(f"üìä Similarity Ratio: {similarity_percentage}%")

        # ‚úÖ Determine score (rounded integer)
        score = int(round(max_mark * similarity_ratio))
        print(f"üèÅ Calculated Score: {score} (out of {max_mark})")

        # ‚úÖ Check if record exists first
        existing_records = tests_candidates_answers.objects.filter(
            student_id_id=student_id,
            test_name=test_name,
            question_id_id=question_id
        ).order_by('-id')

        if existing_records.exists():
            # ‚úÖ Update the latest existing record
            test_answer_obj = existing_records.first()
            print(f"‚ôªÔ∏è Updating existing record (ID: {test_answer_obj.id})")
            test_answer_obj.answer = user_answer
            test_answer_obj.result = score
            test_answer_obj.dtm_end = dtm_end or timezone.now()
            test_answer_obj.dtm_modified = timezone.now()
            test_answer_obj.save()
            print("‚úÖ Record updated successfully.")
        else:
            # ‚úÖ Create a new record
            print("üÜï Creating new record for this question.")
            test_answer_obj = tests_candidates_answers.objects.create(
                student_id_id=student_id,
                test_name=test_name,
                question_id_id=question_id,
                answer=user_answer,
                result=score,
                dtm_start=dtm_start or timezone.now(),
                dtm_end=dtm_end or timezone.now(),
                dtm_created=timezone.now(),
            )
            print("‚úÖ New record created successfully.")

        print("‚úÖ Returning success response")

        return JsonResponse({
            "status": "success",
            "message": "Result saved successfully",
            "student_id": student_id,
            "test_name": test_name,
            "question_id": question_id,
            "score": score,
            "similarity_ratio": similarity_percentage,
            "full_mark": max_mark,
        })

    except Exception as e:
        print("üí• Exception occurred:", str(e))
        return JsonResponse({"status": "error", "message": str(e)}, status=500)

from django.http import JsonResponse
from django.db import models
from .models import test_type

def get_audio_test_types(request):
    """
    Returns all test types where test_type is exactly 'Audio'
    along with their related categories and ids.
    """
    try:
        queryset = test_type.objects.filter(test_type__iexact="Audio")  # Case-insensitive exact match

        data = list(queryset.values("id", "test_type", "test_type_categories"))

        return JsonResponse({"status": "success", "data": data}, status=200)

    except Exception as e:
        return JsonResponse({"status": "error", "message": str(e)}, status=500)

@csrf_exempt
def get_audio_category_questions(request, category_name):
    """
    Returns all question papers that belong to the given audio test category.
    Filters by:
      - remarks (audio category)
      - communication_category (if provided)
    """
    try:
        # ‚úÖ NEW: read query param
        communication_category = request.GET.get("communication_category", "").strip()

        print("üîç category_name:", category_name)
        print("üîç communication_category:", communication_category)

        # ‚úÖ Base filter
        filters = {
            "remarks__iexact": category_name,
            "deleted": 0
        }

        # ‚úÖ ADD conditionally
        if communication_category:
            filters["communication_category__iexact"] = communication_category

        queryset = question_paper_master.objects.filter(**filters).values(
            "id",
            "question_paper_name",
            "topic",
            "sub_topic",
            "duration_of_test",
            "test_type",
        )

        data = list(queryset)

        if not data:
            return JsonResponse({
                "status": "success",
                "message": f"No questions found for category '{category_name}'",
                "data": []
            }, status=200)

        return JsonResponse({
            "status": "success",
            "count": len(data),
            "data": data
        }, status=200)

    except Exception as e:
        return JsonResponse({
            "status": "error",
            "message": str(e)
        }, status=500)


class TestAssignviewBatchAudio(APIView):
    def post(self, request, format=None):
        print("‚úÖ [TestAssignviewBatchAudio] Received POST request")
        print("üì• Raw request data:", request.data)

        test_name = request.data.get('test_name')
        test_type_id = request.data.get('test_type_id')
        question_type_id = request.data.get('question_type_id')
        created_by = request.data.get('created_by', 'System')
        skill_type_id = request.data.get('skill_type_id')  # optional
        

        # ‚úÖ Validate essential fields only
        if not all([test_name, test_type_id, question_type_id]):
            return Response(
                {'error': 'Missing fields: test_name, test_type_id, or question_type_id'},
                status=status.HTTP_400_BAD_REQUEST
            )

        # ‚úÖ Get test_type instance
        try:
            test_type_instance = test_type.objects.get(id=test_type_id, deleted=0)
        except test_type.DoesNotExist:
            return Response({'error': 'Invalid test_type_id'}, status=status.HTTP_400_BAD_REQUEST)

        # ‚úÖ Detect company type
        is_company = test_type_instance.test_type_categories == "Mock/Interview"

        # ‚úÖ Get question_type instance
        try:
            question_type_instance = question_type.objects.get(id=question_type_id, deleted=0)
        except question_type.DoesNotExist:
            return Response({'error': 'Invalid question_type_id'}, status=status.HTTP_400_BAD_REQUEST)

        # ‚úÖ skill_type is optional (ignore if invalid or missing)
        skill_type_instance = None
        if skill_type_id:
            try:
                skill_type_instance = skill_type.objects.get(id=skill_type_id, deleted=0)
            except skill_type.DoesNotExist:
                print(f"‚ö†Ô∏è Ignoring invalid skill_type_id: {skill_type_id}")
                skill_type_instance = None  # continue gracefully

        # ‚úÖ Create/Update test_master
        test_master_instance, created = test_master.objects.update_or_create(
            test_name=test_name,
            defaults={
                'test_type_id': test_type_instance,
                'question_type_id': question_type_instance,
                'skill_type_id': skill_type_instance,
                
               
                'created_by': created_by,
            }
        )

        # üéØ Filter students
        students = candidate_master.objects.filter( deleted=0)

        if request.data.get('college_id'):
            students = students.filter(college_id__in=request.data.get('college_id'))
        if request.data.get('department_id'):
            students = students.filter(department_id__in=request.data.get('department_id'))
        if request.data.get('year'):
            students = students.filter(year__in=request.data.get('year'))
        if request.data.get('batch_no'):
            students = students.filter(batch_no__in=request.data.get('batch_no'))

        if not students.exists():
            return Response({'error': 'No students match the provided criteria.'},
                            status=status.HTTP_404_NOT_FOUND)

        data = []
        updated_candidates = []
        current_date_and_time = datetime.now()

        for student in students:
            if not student.department_id or not student.college_id:
                continue

            # ‚úÖ Check if test already assigned to student
            existing_map = tests_candidates_map.objects.filter(
                student_id=student.id,
                test_name=test_name
            ).first()

            if existing_map:
                # update fields if already exists
                existing_map.dtm_start = request.data.get('dtm_start')
                existing_map.dtm_end = request.data.get('dtm_end')
                existing_map.duration = request.data.get('duration')
                existing_map.duration_type = request.data.get('duration_type')
                existing_map.rules_id = request.data.get('rules_id')
                existing_map.need_candidate_info = request.data.get('need_candidate_info')
                existing_map.is_camera_on = request.data.get('is_camera_on')
                existing_map.save(update_fields=[
                    'dtm_start', 'dtm_end', 'duration', 'duration_type',
                    'rules_id', 'need_candidate_info', 'is_camera_on'
                ])
                data.append({"updated": existing_map.id})
                continue

            # ‚úÖ Create new record
            test_candidate_data = {
                'test_name': test_name,
                'question_id': request.data.get('question_id'),
                'student_id': student.id,
                'college_id': student.college_id.id,
                'department_id': student.department_id.id,
                'dtm_start': request.data.get('dtm_start'),
                'dtm_end': request.data.get('dtm_end'),
                'dtm_start1': request.data.get('dtm_start'),
                'dtm_end1': request.data.get('dtm_end'),
                'is_camera_on': request.data.get('is_camera_on'),
                'duration': request.data.get('duration'),
                'duration_type': request.data.get('duration_type'),
                'year': student.year,
                'rules_id': request.data.get('rules_id'),
                'need_candidate_info': request.data.get('need_candidate_info'),
                'dtm_created': timezone.now(),
                'created_by': created_by
            }

            serializer = testcandidatemapSerializers(data=test_candidate_data)
            if serializer.is_valid():
                serializer.save()
                data.append(serializer.data)

                # update candidate info flag if required
                if student.need_candidate_info is None and request.data.get('need_candidate_info') is True:
                    student.need_candidate_info = True
                    student.save(update_fields=['need_candidate_info'])
                    updated_candidates.append(student.id)
            else:
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        return Response(
            {"test_master": test_master_instance.id, "candidates": data},
            status=status.HTTP_200_OK
        )

from rest_framework.decorators import api_view
from rest_framework.response import Response
from django.conf import settings
from openai import OpenAI

@api_view(['POST'])
def excel_ai(request):
    code = request.data.get("code")
    sheet_data = request.data.get("sheet_data")

    if settings.OPENAI_API_KEY is None:
        return Response({"error": "OPENAI_API_KEY is missing"}, status=500)

    client = OpenAI(api_key=settings.OPENAI_API_KEY)

    completion = client.chat.completions.create(
        model="gpt-5",
        messages=[
            {
                "role": "user",
                "content": f"""
Convert this VBA or text into an Excel formula and compute the result.

Code: {code}
Sheet Data: {sheet_data}
"""
            }
        ]
    )

    ai_output = completion.choices[0].message["content"]

    return Response({"ai": ai_output})
from rest_framework.decorators import api_view
from rest_framework.response import Response
from rest_framework import status
from deep_translator import GoogleTranslator

@api_view(["POST"])
def translate_text(request):
    text = request.data.get("text", "").strip()
    source = request.data.get("source", "en")
    target = request.data.get("target", "hi")

    if not text:
        return Response(
            {"error": "Text is required"},
            status=status.HTTP_400_BAD_REQUEST
        )

    try:
        # Translate using deep-translator
        translated_text = GoogleTranslator(source=source, target=target).translate(text)

        return Response({
            "translatedText": translated_text
        })

    except Exception as e:
        return Response(
            {"error": str(e)},
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )

from rest_framework.decorators import api_view
from rest_framework.response import Response
from rest_framework import status
from deep_translator import GoogleTranslator
from gtts import gTTS
from django.http import FileResponse
import tempfile

@api_view(["POST"])
def translate_voice(request):
    text = request.data.get("text", "").strip()
    source = request.data.get("source", "en")
    target = request.data.get("target", "hi")

    if not text:
        return Response({"error": "Text required"}, status=400)

    try:
        # 1Ô∏è‚É£ Translate text
        translated_text = GoogleTranslator(
            source=source, target=target
        ).translate(text)

        # 2Ô∏è‚É£ Convert text to speech
        tts = gTTS(text=translated_text, lang=target)

        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tts.save(temp_file.name)

        return FileResponse(
            open(temp_file.name, "rb"),
            content_type="audio/mpeg",
            filename="translated.mp3"
        )

    except Exception as e:
        return Response({"error": str(e)}, status=500)

import os
import json
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from groq import Groq

# initialize client
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

import os
import json
import re
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from groq import Groq

client = Groq(api_key=os.getenv("GROQ_API_KEY"))

@csrf_exempt
def generate_questions(request):
    if request.method != "POST":
        return JsonResponse({"error": "POST required"}, status=400)

    try:
        data = json.loads(request.body)
        topic = data.get("topic", "").strip()
        if not topic:
            return JsonResponse({"error": "Topic required"}, status=400)

        prompt = f"Generate 5 interview questions on {topic} with brief guidance for each."
        response = client.chat.completions.create(
            model="llama-3.1-8b-instant",  # updated supported model
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )

        questions_text = response.choices[0].message.content
        # Split questions one by one using regex (detect "1. ", "2. ", etc.)
        questions_list = re.split(r'\n\d+\.\s', questions_text)
        # The first split element may be empty or heading text
        if questions_list[0].strip() == '':
            questions_list = questions_list[1:]

        # Optional: strip whitespace
        questions_list = [q.strip() for q in questions_list if q.strip()]

        return JsonResponse({
            "topic": topic,
            "questions": questions_list,
            "provider": "groq (free)"
        })

    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500)


class GetSkillTypeByTestNameView(APIView):
    """
    Input  : test_name
    Output : skill_type
    """

    def post(self, request):
        test_name = request.data.get("test_name")

        if not test_name:
            return Response(
                {"error": "test_name is required"},
                status=status.HTTP_400_BAD_REQUEST
            )

        try:
            # 1Ô∏è‚É£ Find test by test_name
            test = test_master.objects.select_related("skill_type_id").get(
                test_name=test_name,
                deleted=0
            )

            # 2Ô∏è‚É£ Check skill_type_id
            if not test.skill_type_id:
                return Response(
                    {"error": "Skill type not mapped for this test"},
                    status=status.HTTP_404_NOT_FOUND
                )

            # 3Ô∏è‚É£ Fetch skill_type value
            skill = skill_type.objects.get(
                id=test.skill_type_id.id,
                deleted=0
            )

            return Response(
                {
                    "status": "success",
                    "test_name": test_name,
                    "skill_type": skill.skill_type
                },
                status=status.HTTP_200_OK
            )

        except test_master.DoesNotExist:
            return Response(
                {"error": "Invalid test_name"},
                status=status.HTTP_404_NOT_FOUND
            )

        except skill_type.DoesNotExist:
            return Response(
                {"error": "Skill type not found"},
                status=status.HTTP_404_NOT_FOUND
            )



def get_test_listenting_category(request):
    try:
        college_id = request.GET.get('college_id')

        categories = ['AudioTyping', 'Multi_AudioTyping']

        assigned_tests = tests_candidates_map.objects.filter(
            deleted=0
        ).exclude(created_by='Student')

        if college_id:
            assigned_tests = assigned_tests.filter(college_id=college_id)

        assigned_test_names = assigned_tests.values_list('test_name', flat=True)

        count = test_master.objects.filter(
            deleted=0,
            test_name__in=assigned_test_names,
            test_type_id__test_type_categories__in=categories
        ).count()

        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)

from django.http import JsonResponse

def get_test_reading_category(request):
    try:
        college_id = request.GET.get('college_id')

        categories = ['AudioMCQ']

        assigned_tests = tests_candidates_map.objects.filter(
            deleted=0
        ).exclude(created_by='Student')

        if college_id:
            assigned_tests = assigned_tests.filter(college_id=college_id)

        assigned_test_names = assigned_tests.values_list('test_name', flat=True)

        count = test_master.objects.filter(
            deleted=0,
            test_name__in=assigned_test_names,
            test_type_id__test_type_categories__in=categories
        ).count()

        # ‚úÖ Always return count (0 if no data)
        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


def get_test_Speaking_category(request):
    try:
        college_id = request.GET.get('college_id')

        categories = ['Pronunciation', 'Multi_Pronunciation']

        assigned_tests = tests_candidates_map.objects.filter(
            deleted=0
        ).exclude(created_by='Student')

        if college_id:
            assigned_tests = assigned_tests.filter(college_id=college_id)

        assigned_test_names = assigned_tests.values_list('test_name', flat=True)

        count = test_master.objects.filter(
            deleted=0,
            test_name__in=assigned_test_names,
            test_type_id__test_type_categories__in=categories
        ).count()

        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)

from django.http import JsonResponse

def get_test_Writing_category(request):
    try:
        college_id = request.GET.get('college_id')

        categories = ['TypingBlank']

        assigned_tests = tests_candidates_map.objects.filter(
            deleted=0
        ).exclude(created_by='Student')

        if college_id:
            assigned_tests = assigned_tests.filter(college_id=college_id)

        assigned_test_names = assigned_tests.values_list('test_name', flat=True)

        count = test_master.objects.filter(
            deleted=0,
            test_name__in=assigned_test_names,
            test_type_id__test_type_categories__in=categories
        ).count()

        # ‚úÖ Always returns count (0 if no data)
        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)


@api_view(['GET'])
def get_avg_score_listening_cc(request):
    try:
        college_id = request.GET.get('college_id')
        dtm_start = request.GET.get('dtm_start')

        if not dtm_start:
            return JsonResponse({'error': 'dtm_start is required'}, status=400)

        dtm_start_date = timezone.make_aware(
            timezone.datetime.strptime(dtm_start, '%Y-%m-%d')
        ).date()

        # üéØ Step 1: Get test names based on test_type + category
        categories = ['AudioTyping', 'Multi_AudioTyping']

        audio_test_names = test_master.objects.filter(
            test_type_id__test_type='Audio',
            test_type_id__test_type_categories__in=categories
        ).values_list('test_name', flat=True)


        # üéØ Step 2: Base queryset (NO MCQ filter)
        base_qs = tests_candidates_map.objects.filter(
            deleted=0,
            dtm_start__date=dtm_start_date,
            test_name__in=audio_test_names,
            total_score__isnull=False
        ).exclude(created_by='Student')

        if college_id:
            base_qs = base_qs.filter(college_id=college_id)

        # üéØ Step 3: Aggregate by department
        department_scores = base_qs.values('department_id').annotate(
            avg_score=Avg('total_score')
        )

        # Department ID ‚Üí Name map
        dept_map = {
            d['id']: d['department']
            for d in department_master.objects.filter(deleted=0)
            .values('id', 'department')
        }

        # Final response
        results = [
            {
                'department_name': dept_map.get(row['department_id'], 'Unknown'),
                'avg_score': round(row['avg_score'] or 0, 2)
            }
            for row in department_scores
        ]

        return JsonResponse(results, safe=False, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)



@api_view(['GET'])
def get_avg_score_speaking_cc(request):
    try:
        college_id = request.GET.get('college_id')
        dtm_start = request.GET.get('dtm_start')

        if not dtm_start:
            return JsonResponse({'error': 'dtm_start is required'}, status=400)

        dtm_start_date = timezone.make_aware(
            timezone.datetime.strptime(dtm_start, '%Y-%m-%d')
        ).date()
        categories = ['Pronunciation', 'Multi_Pronunciation']

        audio_test_names = test_master.objects.filter(
            test_type_id__test_type='Audio',
            test_type_id__test_type_categories__in=categories
        ).values_list('test_name', flat=True)

        

        # üéØ Step 2: Base queryset (NO MCQ filter)
        base_qs = tests_candidates_map.objects.filter(
            deleted=0,
            dtm_start__date=dtm_start_date,
            test_name__in=audio_test_names,
            total_score__isnull=False
        ).exclude(created_by='Student')

        if college_id:
            base_qs = base_qs.filter(college_id=college_id)

        # üéØ Step 3: Aggregate by department
        department_scores = base_qs.values('department_id').annotate(
            avg_score=Avg('total_score')
        )

        # Department ID ‚Üí Name map
        dept_map = {
            d['id']: d['department']
            for d in department_master.objects.filter(deleted=0)
            .values('id', 'department')
        }

        # Final response
        results = [
            {
                'department_name': dept_map.get(row['department_id'], 'Unknown'),
                'avg_score': round(row['avg_score'] or 0, 2)
            }
            for row in department_scores
        ]

        return JsonResponse(results, safe=False, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


@api_view(['GET'])
def get_avg_score_reading_cc(request):
    try:
        college_id = request.GET.get('college_id')
        dtm_start = request.GET.get('dtm_start')

        if not dtm_start:
            return JsonResponse({'error': 'dtm_start is required'}, status=400)

        dtm_start_date = timezone.make_aware(
            timezone.datetime.strptime(dtm_start, '%Y-%m-%d')
        ).date()

        # üéØ Step 1: Get test names based on test_type + category
        audio_test_names = test_master.objects.filter(
            test_type_id__test_type='Audio',
            test_type_id__test_type_categories='AudioMCQ'
        ).values_list('test_name', flat=True)

        # üéØ Step 2: Base queryset (NO MCQ filter)
        base_qs = tests_candidates_map.objects.filter(
            deleted=0,
            dtm_start__date=dtm_start_date,
            test_name__in=audio_test_names,
            total_score__isnull=False
        ).exclude(created_by='Student')

        if college_id:
            base_qs = base_qs.filter(college_id=college_id)

        # üéØ Step 3: Aggregate by department
        department_scores = base_qs.values('department_id').annotate(
            avg_score=Avg('total_score')
        )

        # Department ID ‚Üí Name map
        dept_map = {
            d['id']: d['department']
            for d in department_master.objects.filter(deleted=0)
            .values('id', 'department')
        }

        # Final response
        results = [
            {
                'department_name': dept_map.get(row['department_id'], 'Unknown'),
                'avg_score': round(row['avg_score'] or 0, 2)
            }
            for row in department_scores
        ]

        return JsonResponse(results, safe=False, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)


@api_view(['GET'])
def get_avg_score_writing_cc(request):
    try:
        college_id = request.GET.get('college_id')
        dtm_start = request.GET.get('dtm_start')

        if not dtm_start:
            return JsonResponse({'error': 'dtm_start is required'}, status=400)

        dtm_start_date = timezone.make_aware(
            timezone.datetime.strptime(dtm_start, '%Y-%m-%d')
        ).date()

        # üéØ Step 1: Get test names based on test_type + category
        audio_test_names = test_master.objects.filter(
            test_type_id__test_type='Audio',
            test_type_id__test_type_categories='TypingBlank'
        ).values_list('test_name', flat=True)

        # üéØ Step 2: Base queryset (NO MCQ filter)
        base_qs = tests_candidates_map.objects.filter(
            deleted=0,
            dtm_start__date=dtm_start_date,
            test_name__in=audio_test_names,
            total_score__isnull=False
        ).exclude(created_by='Student')

        if college_id:
            base_qs = base_qs.filter(college_id=college_id)

        # üéØ Step 3: Aggregate by department
        department_scores = base_qs.values('department_id').annotate(
            avg_score=Avg('total_score')
        )

        # Department ID ‚Üí Name map
        dept_map = {
            d['id']: d['department']
            for d in department_master.objects.filter(deleted=0)
            .values('id', 'department')
        }

        # Final response
        results = [
            {
                'department_name': dept_map.get(row['department_id'], 'Unknown'),
                'avg_score': round(row['avg_score'] or 0, 2)
            }
            for row in department_scores
        ]

        return JsonResponse(results, safe=False, status=200)

    except Exception as e:
        return JsonResponse({'error': str(e)}, status=400)

from django.db.models import Sum, Count
from rest_framework.decorators import api_view
from django.http import JsonResponse
from .models import tests_candidates_map, test_master, test_type


from django.db.models import Sum, Count
from rest_framework.decorators import api_view
from django.http import JsonResponse
from .models import tests_candidates_map, test_master, test_type


from django.db.models import Sum, Count
from rest_framework.decorators import api_view
from django.http import JsonResponse

from .models import tests_candidates_map, test_master


@api_view(['GET'])
def get_College_topper_ccall(request):
    try:
        print("\n===== get_College_topper_ccall START =====")

        # --------------------------------------------------
        # STEP 0: Read request params
        # --------------------------------------------------
        college_id = request.GET.get('college_id')
        test_type_param = request.GET.get('test_type')  # Audio | MCQTest | CodingTest | All
        test_type_categories_param = request.GET.get('test_type_categories')

        print("Request Params:")
        print("college_id =", college_id)
        print("test_type =", test_type_param)
        print("test_type_categories =", test_type_categories_param)

        # --------------------------------------------------
        # STEP 1: Base queryset
        # --------------------------------------------------
        queryset = tests_candidates_map.objects.filter(
            deleted=0
        ).exclude(created_by='Student')

        print("\nStep 1 ‚Üí Base queryset count:", queryset.count())

        # --------------------------------------------------
        # STEP 2: Normalize test_type
        # --------------------------------------------------
        TEST_TYPE_NORMALIZATION = {
            'CodingTest': 'Coding Test',
            'MCQTest': 'MCQ Test',
            'Audio': 'Audio'
        }

        normalized_test_type = TEST_TYPE_NORMALIZATION.get(
            test_type_param, test_type_param
        )

        print("Normalized test_type:", normalized_test_type)

        # --------------------------------------------------
        # STEP 3: Audio category alias mapping
        # --------------------------------------------------
        AUDIO_CATEGORY_ALIASES = {
            'Pronunciation': ['Pronunciation', 'Multi_Pronunciation'],
            'Multi_Pronunciation': ['Pronunciation', 'Multi_Pronunciation'],

            'AudioTyping': ['AudioTyping', 'Multi_AudioTyping'],
            'Multi_AudioTyping': ['AudioTyping', 'Multi_AudioTyping'],

            'AudioMCQ': ['AudioMCQ'],
            'TypingBlank': ['TypingBlank'],
        }

        # --------------------------------------------------
        # STEP 4: Apply test_type filtering
        # --------------------------------------------------
        if normalized_test_type and normalized_test_type.lower() != 'all':

            print("\nStep 4 ‚Üí Applying test_type filter")

            # üîπ AUDIO ‚Üí category based filtering
            if normalized_test_type == 'Audio':

                print("Audio test selected")

                if test_type_categories_param:
                    raw_categories = [c.strip() for c in test_type_categories_param.split(',')]
                    print("Selected raw audio categories:", raw_categories)

                    expanded_categories = set()
                    for cat in raw_categories:
                        expanded_categories.update(
                            AUDIO_CATEGORY_ALIASES.get(cat, [cat])
                        )

                    expanded_categories = list(expanded_categories)
                    print("Expanded audio categories:", expanded_categories)

                    test_names = test_master.objects.filter(
                        test_type_id__test_type='Audio',
                        test_type_id__test_type_categories__in=expanded_categories
                    ).values_list('test_name', flat=True)

                else:
                    print("No category provided ‚Üí all Audio tests")
                    test_names = test_master.objects.filter(
                        test_type_id__test_type='Audio'
                    ).values_list('test_name', flat=True)

            # üîπ MCQ & CODING ‚Üí NO category filtering
            else:
                print(f"{normalized_test_type} selected ‚Üí NO category filtering")

                test_names = test_master.objects.filter(
                    test_type_id__test_type=normalized_test_type
                ).values_list('test_name', flat=True)

            print("Matching test names:", list(test_names))

            queryset = queryset.filter(test_name__in=test_names)
            print("Queryset count after test_type filter:", queryset.count())

        # --------------------------------------------------
        # STEP 5: College filter
        # --------------------------------------------------
        if college_id:
            queryset = queryset.filter(college_id=college_id)
            print("\nStep 5 ‚Üí After college filter count:", queryset.count())

        # --------------------------------------------------
        # STEP 6: Group by student
        # --------------------------------------------------
        student_stats = queryset.values(
            'student_id',
            'student_id__students_name',
            'department_id__department'
        ).annotate(
            total_marks=Sum('avg_mark'),
            test_count=Count('id')
        )

        print("\nStep 6 ‚Üí Student grouped stats:")
        for s in student_stats:
            print(s)

        # --------------------------------------------------
        # STEP 7: Calculate normalized average
        # --------------------------------------------------
        results = []
        print("\nStep 7 ‚Üí Calculating averages")

        for s in student_stats:
            student_name = s['student_id__students_name'] or "N/A"
            department = s['department_id__department'] or "N/A"
            total_marks = s['total_marks']
            test_count = s['test_count']

            print(f"{student_name} | {department} | {total_marks} | {test_count}")

            if test_count and total_marks is not None:
                avg = total_marks / test_count
                results.append({
                    'student_name': student_name,
                    'department': department,
                    'avg_mark': round(avg)
                })

        # --------------------------------------------------
        # STEP 8: Top 5
        # --------------------------------------------------
        results = sorted(results, key=lambda x: x['avg_mark'], reverse=True)[:5]

        print("\nFinal Top 5 Results:")
        for r in results:
            print(r)

        print("===== get_College_topper_ccall END =====\n")

        return JsonResponse(results, safe=False)

    except Exception as e:
        print("‚ùå ERROR:", str(e))
        return JsonResponse({'error': str(e)}, status=400)

@api_view(['GET'])
def get_listening_test_stu(request):
    try:
        print("\n===== get_listening_test_stu START =====")

        username = request.GET.get('username')
        print("Username:", username)

        if not username:
            return JsonResponse({'error': 'Username required'}, status=400)

        # --------------------------------------------------
        # Step 1: Fixed categories (NO request param)
        # --------------------------------------------------
        expanded_categories = ['AudioTyping', 'Multi_AudioTyping']
        print("Listening Categories:", expanded_categories)

        # --------------------------------------------------
        # Step 2: Get active test names for student
        # --------------------------------------------------
        active_test_names = tests_candidates_map.objects.filter(
            deleted=0,
            student_id__user_name=username,
            is_active=True
        ).values_list('test_name', flat=True)

        print("Active Test Names:", list(active_test_names))

        # --------------------------------------------------
        # Step 3: Build filters
        # --------------------------------------------------
        filters = Q(
            deleted=0,
            test_name__in=active_test_names,
            test_type_id__test_type_categories__in=expanded_categories
        )

        print("Applied Filters:", filters)

        # --------------------------------------------------
        # Step 4: Final count
        # --------------------------------------------------
        count = test_master.objects.filter(filters).count()
        print("Listening Test Count:", count)

        print("===== get_listening_test_stu END =====\n")
        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        print("‚ùå ERROR:", str(e))
        return JsonResponse({'error': str(e)}, status=500)

@api_view(['GET'])
def get_Writing_test_stu(request):
    try:
        print("\n===== get_Writing_test_stu START =====")

        username = request.GET.get('username')
        print("Username:", username)

        if not username:
            return JsonResponse({'error': 'Username required'}, status=400)

        expanded_categories = ['TypingBlank']
        print("Writing Categories:", expanded_categories)

        active_test_names = tests_candidates_map.objects.filter(
            deleted=0,
            student_id__user_name=username,
            is_active=True
        ).values_list('test_name', flat=True)

        print("Active Test Names:", list(active_test_names))

        filters = Q(
            deleted=0,
            test_name__in=active_test_names,
            test_type_id__test_type_categories__in=expanded_categories
        )

        count = test_master.objects.filter(filters).count()
        print("Writing Test Count:", count)

        print("===== get_Writing_test_stu END =====\n")
        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        print("‚ùå ERROR:", str(e))
        return JsonResponse({'error': str(e)}, status=500)

@api_view(['GET'])
def get_Reading_test_stu(request):
    try:
        print("\n===== get_Reading_test_stu START =====")

        username = request.GET.get('username')
        print("Username:", username)

        if not username:
            return JsonResponse({'error': 'Username required'}, status=400)

        expanded_categories = ['AudioMCQ']
        print("Reading Categories:", expanded_categories)

        active_test_names = tests_candidates_map.objects.filter(
            deleted=0,
            student_id__user_name=username,
            is_active=True
        ).values_list('test_name', flat=True)

        print("Active Test Names:", list(active_test_names))

        filters = Q(
            deleted=0,
            test_name__in=active_test_names,
            test_type_id__test_type_categories__in=expanded_categories
        )

        count = test_master.objects.filter(filters).count()
        print("Reading Test Count:", count)

        print("===== get_Reading_test_stu END =====\n")
        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        print("‚ùå ERROR:", str(e))
        return JsonResponse({'error': str(e)}, status=500)

@api_view(['GET'])
def get_speaking_test_stu(request):
    try:
        print("\n===== get_speaking_test_stu START =====")

        username = request.GET.get('username')
        print("Username:", username)

        if not username:
            return JsonResponse({'error': 'Username required'}, status=400)

        expanded_categories = ['Pronunciation', 'Multi_Pronunciation']
        print("Speaking Categories:", expanded_categories)

        active_test_names = tests_candidates_map.objects.filter(
            deleted=0,
            student_id__user_name=username,
            is_active=True
        ).values_list('test_name', flat=True)

        print("Active Test Names:", list(active_test_names))

        filters = Q(
            deleted=0,
            test_name__in=active_test_names,
            test_type_id__test_type_categories__in=expanded_categories
        )

        count = test_master.objects.filter(filters).count()
        print("Speaking Test Count:", count)

        print("===== get_speaking_test_stu END =====\n")
        return JsonResponse({'count': count}, status=200)

    except Exception as e:
        print("‚ùå ERROR:", str(e))
        return JsonResponse({'error': str(e)}, status=500)



def get_student_skill_percentage(request):
    print("\n===== get_student_skill_percentage START =====")

    username = request.GET.get('username')
    start_date = request.GET.get('start_date')

    print("Username:", username)
    print("Start Date:", start_date)

    if not username:
        return JsonResponse({'error': 'Username required'}, status=400)

    # --------------------------------------------------
    # Step 1: Date conversion
    # --------------------------------------------------
    dtm_start_date = None
    if start_date:
        dtm_start_date = timezone.make_aware(
            timezone.datetime.strptime(start_date, '%Y-%m-%d')
        )
        print("Converted Date:", dtm_start_date)

    # --------------------------------------------------
    # Step 2: Get student
    # --------------------------------------------------
    student = candidate_master.objects.filter(
        deleted=0,
        user_name=username
    ).first()

    print("Student:", student)

    if not student:
        return JsonResponse({'error': 'Student not found'}, status=404)

    # --------------------------------------------------
    # Step 3: Category Groups (ONLY test_type_categories)
    # --------------------------------------------------
    CATEGORY_GROUPS = {
        'listening_typing': ['AudioTyping', 'Multi_AudioTyping'],
        'listening_mcq': ['AudioMCQ'],
        'typing_blank': ['TypingBlank'],
        'pronunciation': ['Pronunciation', 'Multi_Pronunciation'],
    }

    print("Category Groups:", CATEGORY_GROUPS)

    result = {}

    # --------------------------------------------------
    # Step 4: Loop each category group
    # --------------------------------------------------
    for key, categories in CATEGORY_GROUPS.items():
        print(f"\n--- Processing {key} ---")
        print("Categories:", categories)

        test_names = test_master.objects.filter(
            deleted=0,
            test_type_id__test_type_categories__in=categories
        ).values_list('test_name', flat=True)

        print("Test Names:", list(test_names))

        attempts = tests_candidates_map.objects.filter(
            student_id=student,
            test_name__in=test_names,
            deleted=0,
            
        )

        if dtm_start_date:
            attempts = attempts.filter(dtm_start__date=dtm_start_date.date())
            print("Date filter applied")

        total_score = attempts.aggregate(
            total=Sum('avg_mark')
        )['total'] or 0

        print(f"{key} Total Score:", total_score)

        result[key] = total_score

    # --------------------------------------------------
    # Step 5: Final response
    # --------------------------------------------------
    print("Final Result:", result)
    print("===== get_student_skill_percentage END =====\n")

    return JsonResponse(result)


@api_view(['GET'])
def student_test_summary_communold(request):
    student_name = request.GET.get('student_name')

    if not student_name:
        return Response({"error": "student_name is required"}, status=400)

    student = candidate_master.objects.filter(
        students_name=student_name
    ).first()

    if not student:
        return Response({"error": "Student not found"}, status=404)

    # -------------------------------
    # BASE QUERYSET
    # -------------------------------
    base_qs = tests_candidates_map.objects.filter(
        student_id=student
    )

    audio_test_names = test_master.objects.filter(
        test_type_id__test_type='Audio'
    ).values_list('test_name', flat=True)

    audio_base_qs = base_qs.filter(
        test_name__in=audio_test_names
    )

    total_assigned_tests = audio_base_qs.count()
    total_attended_tests = audio_base_qs.filter(is_active=True).count()

    # -------------------------------
    # CATEGORY GROUP DEFINITIONS
    # -------------------------------
    CATEGORY_GROUPS = {
        "AudioMCQ": ["AudioMCQ"],
        "AudioTyping": ["AudioTyping", "Multi_AudioTyping"],
        "Pronunciation": ["Pronunciation", "Multi_Pronunciation"],
        "TypingBlank": ["TypingBlank"],
    }

    category_data = []
    category_test_details = []

    # -------------------------------
    # CATEGORY SUMMARY + DETAILS
    # -------------------------------
    for display_category, db_categories in CATEGORY_GROUPS.items():

        test_names = test_master.objects.filter(
            test_type_id__test_type='Audio',
            test_type_id__test_type_categories__in=db_categories
        ).values_list('test_name', flat=True)

        cat_qs = audio_base_qs.filter(test_name__in=test_names)

        assigned_count = cat_qs.count()
        attended_qs = cat_qs.filter(is_active=True)
        attended_count = attended_qs.count()

        avg_mark = attended_qs.aggregate(
            avg_score=Avg('stu_avg_mark')
        )['avg_score'] or 0

        if assigned_count > 0:
            category_data.append({
                "category": display_category,
                "assigned_tests": assigned_count,
                "attended_tests": attended_count,
                "avg_mark": round(avg_mark, 2)
            })

        # -------- TEST LEVEL DETAILS --------
        tests_list = []

        for test_name in test_names:
            test_qs = attended_qs.filter(test_name=test_name)

            if not test_qs.exists():
                continue

            test_avg = test_qs.aggregate(
                avg_score=Avg('stu_avg_mark')
            )['avg_score'] or 0

            last_test = test_qs.order_by(
                '-dtm_submit',
                '-dtm_end',
                '-dtm_start_test'
            ).first()

            test_date = (
                last_test.dtm_submit or
                last_test.dtm_end or
                last_test.dtm_start_test
            )

            tests_list.append({
                "test_name": test_name,
                "test_date": test_date,
                "avg_mark": round(test_avg, 2)
            })

        if tests_list:
            category_test_details.append({
                "category": display_category,
                "tests": tests_list
            })

    # -------------------------------
    # OVERALL AVERAGE
    # -------------------------------
    overall_avg = audio_base_qs.filter(
        is_active=True
    ).aggregate(
        overall_avg=Avg('stu_avg_mark')
    )['overall_avg'] or 0

    return Response({
        "student_name": student.students_name,
        "total_assigned_tests": total_assigned_tests,
        "total_attended_tests": total_attended_tests,
        "overall_avg_mark": round(overall_avg, 2),
        "category_wise": category_data,
        "category_test_details": category_test_details
    })

from rest_framework.decorators import api_view
from rest_framework.response import Response
from django.db.models import Avg
from .models import candidate_master, tests_candidates_map, test_master, department_master

# Function to get feedback based on avg_mark
def get_feedback(avg_mark):
    if avg_mark >= 90:
        return "Excellent"
    elif avg_mark >= 75:
        return "Good"
    elif avg_mark >= 50:
        return "Average"
    else:
        return "Poor"

@api_view(['GET'])
def student_test_summary_commun(request):
    student_name = request.GET.get('student_name')

    if not student_name:
        return Response({"error": "student_name is required"}, status=400)

    student = candidate_master.objects.filter(
        students_name=student_name
    ).select_related('department_id').first()

    if not student:
        return Response({"error": "Student not found"}, status=404)

    # Base queryset
    base_qs = tests_candidates_map.objects.filter(student_id=student)

    audio_test_names = test_master.objects.filter(
        test_type_id__test_type='Audio'
    ).values_list('test_name', flat=True)

    audio_base_qs = base_qs.filter(test_name__in=audio_test_names)

    total_assigned_tests = audio_base_qs.count()
    total_attended_tests = audio_base_qs.filter(is_active=True).count()

    # Category groups
    CATEGORY_GROUPS = {
        "AudioMCQ": ["AudioMCQ"],
        "AudioTyping": ["AudioTyping", "Multi_AudioTyping"],
        "Pronunciation": ["Pronunciation", "Multi_Pronunciation"],
        "TypingBlank": ["TypingBlank"],
    }

    category_data = []
    category_test_details = []

    for display_category, db_categories in CATEGORY_GROUPS.items():
        test_names = test_master.objects.filter(
            test_type_id__test_type='Audio',
            test_type_id__test_type_categories__in=db_categories
        ).values_list('test_name', flat=True)

        cat_qs = audio_base_qs.filter(test_name__in=test_names)
        assigned_count = cat_qs.count()
        attended_qs = cat_qs.filter(is_active=True)
        attended_count = attended_qs.count()
        avg_mark = attended_qs.aggregate(avg_score=Avg('stu_avg_mark'))['avg_score'] or 0

        if assigned_count > 0:
            category_data.append({
                "category": display_category,
                "assigned_tests": assigned_count,
                "attended_tests": attended_count,
                "avg_mark": round(avg_mark, 2),
                "feedback": get_feedback(avg_mark)  # <-- feedback based on avg_mark
            })

        # Test level details
        tests_list = []
        for test_name in test_names:
            test_qs = attended_qs.filter(test_name=test_name)
            if not test_qs.exists():
                continue

            test_avg = test_qs.aggregate(avg_score=Avg('stu_avg_mark'))['avg_score'] or 0
            last_test = test_qs.order_by('-dtm_submit', '-dtm_end', '-dtm_start_test').first()
            test_date = last_test.dtm_submit or last_test.dtm_end or last_test.dtm_start_test

            tests_list.append({
                "test_name": test_name,
                "test_date": test_date,
                "avg_mark": round(test_avg, 2),
                "feedback": get_feedback(test_avg)  # <-- feedback per test
            })

        if tests_list:
            category_test_details.append({
                "category": display_category,
                "tests": tests_list
            })

    # Overall average
    overall_avg = audio_base_qs.filter(is_active=True).aggregate(overall_avg=Avg('stu_avg_mark'))['overall_avg'] or 0

    # -------------------------------
    # RESPONSE WITH STUDENT INFO + FEEDBACK
    # -------------------------------
    return Response({
        "student_name": student.students_name,
        "registration_number": student.registration_number,
        "department": student.department_id.department if student.department_id else None,
        "year": student.year,
        "total_assigned_tests": total_assigned_tests,
        "total_attended_tests": total_attended_tests,
        "overall_avg_mark": round(overall_avg, 2),
        "overall_feedback": get_feedback(overall_avg),
        "category_wise": category_data,
        "category_test_details": category_test_details
    })

class LogSkillTypeQuestionView(APIView):
    """
    Receives skill_type + question_text
    Translates question_text based on skill_type
    Prints in backend and RETURNS translated_text to frontend
    """

    SKILL_LANGUAGE_MAP = {
        "Tamil_English": "ta",
        "Telugu_English": "te",
        "Hindi_English": "hi",
        "Kannada_English": "kn",
        "Malayalam_English": "ml",
    }

    def post(self, request):
        skill_type = request.data.get("skill_type")
        question_text = (request.data.get("question_text") or "").strip()

        print("\n========== FRONTEND DATA RECEIVED ==========")
        print("Skill Type :", skill_type)
        print("Question   :", question_text)

        translated_text = None

        if skill_type and question_text:
            target_lang = self.SKILL_LANGUAGE_MAP.get(skill_type)

            if target_lang:
                try:
                    params = {
                        "client": "gtx",
                        "sl": "en",
                        "tl": target_lang,
                        "dt": "t",
                        "q": question_text,
                    }

                    r = httpx.get(
                        "https://translate.googleapis.com/translate_a/single",
                        params=params,
                        timeout=10
                    )

                    data = r.json()

                    # ‚úÖ JOIN ALL SENTENCES
                    translated_text = "".join(
                        [item[0] for item in data[0] if item[0]]
                    )

                    print("‚û° Translated To :", target_lang)
                    print("‚û° Translated Q :", translated_text)

                except Exception as e:
                    print("‚ùå Translation Error:", str(e))
            else:
                print("‚ÑπÔ∏è Skill type not mapped for translation")

        print("============================================\n")

        return Response(
            {
                "status": "received",
                "translated_text": translated_text,
            },
            status=status.HTTP_200_OK
        )


class AssignTestToStudentView(APIView):
    def post(self, request):
        data = request.data
        print("üì• Step 1: Payload received:", data)

        topic = data.get("topic")
        sub_topic = data.get("sub_topic")
        student_id = data.get("student_id")
        question_paper_id = data.get("question_paper_id")
        test_type_id = data.get("test_type_id")
        skill_type_id = data.get("skill_type_id")  # optional
        question_type_id = data.get("question_type_id")  # optional

        # Step 2: Validate required fields
        if not all([student_id, question_paper_id, test_type_id]):
            print("‚ùå Missing required parameters")
            return Response({"error": "Missing required parameters"}, status=400)
        print("‚úÖ Step 2: Required parameters validated")

        # Step 3: Fetch student
        student = candidate_master.objects.filter(id=student_id).first()
        if not student:
            print(f"‚ùå Student not found: ID={student_id}")
            return Response({"error": "Student not found"}, status=404)
        print(f"‚úÖ Step 3: Student fetched: {student.user_name}")

        # Step 4: Fetch question paper
        paper = question_paper_master.objects.filter(id=question_paper_id).first()
        if not paper:
            print(f"‚ùå Question paper not found: ID={question_paper_id}")
            return Response({"error": "Invalid question paper ID"}, status=404)
        print(f"‚úÖ Step 4: Question paper fetched: {paper.question_paper_name}")

        # Step 5: Determine test_name (based on test type + category/subtopic/paper name)
        test_type_obj = test_type.objects.filter(id=test_type_id).first()
        test_type_name = test_type_obj.test_type if test_type_obj else "UnknownType"
        test_type_category = test_type_obj.test_type_categories if test_type_obj else "UnknownCategory"
        test_name = f"{test_type_name}_{sub_topic or topic or paper.folder_name}"
        print(f"‚úÖ Step 5: Test name determined: {test_name}")

        # Step 6: Fetch or create test_master only if not exists
        tm_defaults = {}
        if skill_type_id:
            tm_defaults["skill_type_id_id"] = skill_type_id
        if question_type_id:
            tm_defaults["question_type_id_id"] = question_type_id
        if test_type_id:
            tm_defaults["test_type_id_id"] = test_type_id

        tm, created = test_master.objects.get_or_create(
            test_name=test_name,
            defaults=tm_defaults
        )
        print(f"‚úÖ Step 6: Test master {'created' if created else 'already exists'}: {tm.id}")

        # Step 7: Fetch rules
        rule_obj = rules.objects.filter(rule_name__iexact=test_type_name).first() \
            or rules.objects.filter(id=1).first()
        print(f"‚úÖ Step 7: Rules fetched: {rule_obj.id if rule_obj else 'None'}")

        # Step 8: Fetch user role
        user_login = login.objects.filter(user_name=student.user_name).first()
        user_role = user_login.role if user_login else "unknown"
        print(f"‚úÖ Step 8: User role determined: {user_role}")

        # Step 9: Check existing candidate assignment
        existing = tests_candidates_map.objects.filter(
            test_name=test_name,
            student_id=student
        ).first()
        duration_of_test = paper.duration_of_test or 30
        print(f"‚úÖ Step 9: Duration of test: {duration_of_test}")

        # Step 10: Update or create candidate assignment
        if existing:
            print(f"üîÑ Step 10a: Updating existing assignment: ID={existing.id}")
            existing.assign_count = (existing.assign_count or 1) + 1
            existing.question_id = paper
            existing.dtm_start = timezone.now()
            existing.dtm_start1 = timezone.now()
            existing.duration = duration_of_test
            existing.duration_type = "QuestionTime"
            existing.rules_id = rule_obj
            existing.is_active = False
            existing.created_by = user_role
            existing.save()
            tcm = existing
            action = "updated"
        else:
            print("üÜï Step 10b: Creating new assignment")
            tcm = tests_candidates_map.objects.create(
                test_name=test_name,
                question_id=paper,
                student_id=student,
                college_id=student.college_id,
                department_id=student.department_id,
                dtm_start=timezone.now(),
                dtm_start1=timezone.now(),
                duration=duration_of_test,
                duration_type="QuestionTime",
                is_active=False,
                rules_id=rule_obj,
                assign_count=1,
                avg_mark=0,
                total_score=0,
                stu_avg_mark=0,
                created_by=user_role
            )
            action = "created"

        print(f"‚úÖ Step 11: Assignment {action} successfully: CandidateMapID={tcm.id}")

        # Step 12: Return response
        return Response({
            "status": "success",
            "action": action,
            "test_master_id": tm.id,
            "candidates_map_id": tcm.id,
            "test_name": tm.test_name,
            "duration": duration_of_test,
            "assign_count": tcm.assign_count,
            "test_type_category": test_type_category

        }, status=201)


from openpyxl.styles import Font
from django.db.models import Avg



@api_view(['GET'])
def download_audio_report_excelold(request):

    college_id = request.GET.get('college_id')
    department_id = request.GET.get('department_id')
    year = request.GET.get('year')
    batch = request.GET.get('batch')
    start_date = request.GET.get('startDate')
    end_date = request.GET.get('endDate')

    chart_type = request.GET.get('chart_type', 'bar')

    CATEGORY_CONFIG = {
        'Listening': ['AudioTyping', 'Multi_AudioTyping'],
        'Reading': ['AudioMCQ'],
        'Speaking': ['Pronunciation', 'Multi_Pronunciation'],
        'Writing': ['TypingBlank'],
    }

    wb = Workbook()
    wb.remove(wb.active)

    # =====================================================
    # STEP 1: AUDIO TESTS
    # =====================================================
    audio_test_names = list(
        test_master.objects.filter(
            test_type_id__test_type__iexact='Audio'
        ).values_list('test_name', flat=True)
    )

    # =====================================================
    # STEP 2: BASE QUERY
    # =====================================================
    base_qs = tests_candidates_map.objects.filter(
        is_active=True,
        test_name__in=audio_test_names,
        student_id__isnull=False
    ).select_related('student_id', 'department_id', 'college_id')

    if college_id:
        base_qs = base_qs.filter(college_id=college_id)
    if department_id:
        base_qs = base_qs.filter(department_id=department_id)
    if year:
        base_qs = base_qs.filter(year=year)
    if batch:
        base_qs = base_qs.filter(student_id__batch_no=batch)
    if start_date and end_date:
        base_qs = base_qs.filter(dtm_submit__date__range=[start_date, end_date])

    # =====================================================
    # STEP 3: CATEGORY SHEETS
    # =====================================================
    for sheet_name, keywords in CATEGORY_CONFIG.items():

        category_qs = base_qs.filter(
            test_name__iregex=r'(' + '|'.join(keywords) + ')'
        )

        if not category_qs.exists():
            continue

        ws = wb.create_sheet(title=f"{sheet_name} Report")

        test_names = list(category_qs.values_list('test_name', flat=True).distinct())

        headers = [
            'Candidate Name', 'Reg No', 'Department',
            'Login ID', 'Year'
        ] + test_names + ['Total Avg (%)']

        ws.append(headers)
        for c in range(1, len(headers) + 1):
            ws.cell(row=1, column=c).font = Font(bold=True)

        students = category_qs.values(
            'student_id',
            'student_id__students_name',
            'student_id__registration_number',
            'student_id__user_name',
            'student_id__year',
            'department_id__department'
        ).distinct()

        for stu in students:
            row = [
                stu['student_id__students_name'],
                stu['student_id__registration_number'],
                stu['department_id__department'],
                stu['student_id__user_name'],
                stu['student_id__year'],
            ]

            total_score = 0
            total_tests = len(test_names)

            for test in test_names:
                mark = category_qs.filter(
                    student_id=stu['student_id'],
                    test_name=test
                ).values_list('avg_mark', flat=True).first() or 0

                mark = round(mark, 2)
                row.append(mark)
                total_score += mark

            total_avg = round((total_score / total_tests), 2) if total_tests else 0
            row.append(total_avg)

            ws.append(row)

    # =====================================================
    # STEP 4: CATEGORY SUMMARY + CHART
    # =====================================================
    summary_ws = wb.create_sheet(title='Category Report')

    headers = ['Department'] + [f"{k} Avg" for k in CATEGORY_CONFIG.keys()]
    summary_ws.append(headers)

    for c in range(1, len(headers) + 1):
        summary_ws.cell(row=1, column=c).font = Font(bold=True)

    for dept in department_master.objects.all():
        row = [dept.department]

        for keywords in CATEGORY_CONFIG.values():
            avg_val = base_qs.filter(
                department_id=dept.id,
                test_name__iregex=r'(' + '|'.join(keywords) + ')'
            ).aggregate(avg=Avg('avg_mark'))['avg']

            row.append(round(avg_val, 2) if avg_val else 0)

        summary_ws.append(row)

    if chart_type == 'pie':
        chart = PieChart()
    elif chart_type == 'line':
        chart = LineChart()
    else:
        chart = BarChart()

    data = Reference(summary_ws, min_col=2, min_row=1,
                     max_col=len(headers), max_row=summary_ws.max_row)
    cats = Reference(summary_ws, min_col=1, min_row=2,
                     max_row=summary_ws.max_row)

    chart.add_data(data, titles_from_data=True)
    chart.set_categories(cats)
    chart.title = "Category Performance by Department"

    summary_ws.add_chart(chart, "H2")

    # =====================================================
    # STEP 5: TOP 100 STUDENTS SHEET
    # =====================================================
    top_ws = wb.create_sheet(title='Top 100 Students')

    headers = [
        'Rank', 'Candidate Name', 'Reg No',
        'Department', 'Category',
        'Total Avg (%)', 'Feedback'
    ]
    top_ws.append(headers)
    for c in range(1, len(headers) + 1):
        top_ws.cell(row=1, column=c).font = Font(bold=True)

    all_top_students = []

    def get_feedback(avg):
        if avg >= 80:
            return 'Excellent'
        elif avg >= 60:
            return 'Good'
        elif avg >= 40:
            return 'Average'
        return 'Needs Improvement'

    for category, keywords in CATEGORY_CONFIG.items():
        qs = base_qs.filter(
            test_name__iregex=r'(' + '|'.join(keywords) + ')'
        )

        students = qs.values(
            'student_id',
            'student_id__students_name',
            'student_id__registration_number',
            'department_id__department'
        ).annotate(avg_mark=Avg('avg_mark'))

        for s in students:
            all_top_students.append({
                'name': s['student_id__students_name'],
                'reg': s['student_id__registration_number'],
                'dept': s['department_id__department'],
                'category': category,
                'avg': round(s['avg_mark'], 2) if s['avg_mark'] else 0
            })

    top_100 = sorted(all_top_students, key=lambda x: x['avg'], reverse=True)[:100]

    for idx, stu in enumerate(top_100, start=1):
        top_ws.append([
            idx,
            stu['name'],
            stu['reg'],
            stu['dept'],
            stu['category'],
            stu['avg'],
            get_feedback(stu['avg'])
        ])

    # =====================================================
    # RESPONSE
    # =====================================================
    response = HttpResponse(
        content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )
    response['Content-Disposition'] = 'attachment; filename=Audio_Test_Report.xlsx'
    wb.save(response)
    return response

from rest_framework.decorators import api_view
from django.http import HttpResponse
from django.db.models import Avg, Q
from openpyxl import Workbook
from openpyxl.styles import Font
from openpyxl.chart import BarChart, LineChart, PieChart, Reference
from .models import tests_candidates_map, test_master, department_master

@api_view(['GET'])
def download_audio_report_excel(request):
    college_id = request.GET.get('college_id')
    department_ids = request.GET.get('department_id')  # could be 'all' or comma-separated
    years = request.GET.get('year')  # could be 'all' or comma-separated
    batches = request.GET.get('batch')  # could be 'all' or comma-separated
    start_date = request.GET.get('startDate')
    end_date = request.GET.get('endDate')
    chart_type = request.GET.get('chart_type', 'bar')
    print("request",request)
    CATEGORY_CONFIG = {
        'Listening': ['AudioTyping', 'Multi_AudioTyping'],
        'Reading': ['AudioMCQ'],
        'Speaking': ['Pronunciation', 'Multi_Pronunciation'],
        'Writing': ['TypingBlank'],
    }

    wb = Workbook()
    wb.remove(wb.active)

    # STEP 1: AUDIO TESTS
    audio_test_names = list(
        test_master.objects.filter(
            test_type_id__test_type__iexact='Audio'
        ).values_list('test_name', flat=True)
    )

    # STEP 2: BASE QUERY
    base_qs = tests_candidates_map.objects.filter(
        is_active=True,
        test_name__in=audio_test_names,
        student_id__isnull=False
    ).select_related('student_id', 'department_id', 'college_id')

    # Filter by college
    if college_id and college_id != 'all':
        base_qs = base_qs.filter(college_id__id__in=[int(cid) for cid in college_id.split(',')])

    # Filter by department
    if department_ids and department_ids != 'all':
        base_qs = base_qs.filter(department_id__id__in=[int(did) for did in department_ids.split(',')])

    # Filter by year
    if years and years != 'all':
        base_qs = base_qs.filter(student_id__year__in=[int(y) for y in years.split(',')])

    # Filter by batch
    if batches and batches != 'all':
        base_qs = base_qs.filter(student_id__batch_no__in=batches.split(','))

    # Filter by date range
    if start_date and end_date:
        base_qs = base_qs.filter(dtm_submit__date__range=[start_date, end_date])

    # =====================================================
    # STEP 3: CATEGORY SHEETS
    # =====================================================
    for sheet_name, keywords in CATEGORY_CONFIG.items():
        category_qs = base_qs.filter(
            test_name__iregex=r'(' + '|'.join(keywords) + ')'
        )
        if not category_qs.exists():
            continue

        ws = wb.create_sheet(title=f"{sheet_name} Report")

        test_names = list(category_qs.values_list('test_name', flat=True).distinct())

        headers = ['Candidate Name', 'Reg No', 'Department', 'Login ID', 'Year'] + test_names + ['Total Avg (%)']
        ws.append(headers)
        for c in range(1, len(headers) + 1):
            ws.cell(row=1, column=c).font = Font(bold=True)

        students = category_qs.values(
            'student_id',
            'student_id__students_name',
            'student_id__registration_number',
            'student_id__user_name',
            'student_id__year',
            'department_id__department'
        ).distinct()

        for stu in students:
            row = [
                stu['student_id__students_name'],
                stu['student_id__registration_number'],
                stu['department_id__department'],
                stu['student_id__user_name'],
                stu['student_id__year'],
            ]

            total_score = 0
            total_tests = len(test_names)

            for test in test_names:
                mark = category_qs.filter(
                    student_id=stu['student_id'],
                    test_name=test
                ).values_list('avg_mark', flat=True).first() or 0

                mark = round(mark, 2)
                row.append(mark)
                total_score += mark

            total_avg = round((total_score / total_tests), 2) if total_tests else 0
            row.append(total_avg)

            ws.append(row)

    # =====================================================
    # STEP 4: CATEGORY SUMMARY + CHART
    # =====================================================
    summary_ws = wb.create_sheet(title='Category Report')
    headers = ['Department'] + [f"{k} Avg" for k in CATEGORY_CONFIG.keys()]
    summary_ws.append(headers)
    for c in range(1, len(headers) + 1):
        summary_ws.cell(row=1, column=c).font = Font(bold=True)

    for dept in department_master.objects.all():
        row = [dept.department]
        for keywords in CATEGORY_CONFIG.values():
            avg_val = base_qs.filter(
                department_id=dept.id,
                test_name__iregex=r'(' + '|'.join(keywords) + ')'
            ).aggregate(avg=Avg('avg_mark'))['avg']
            row.append(round(avg_val, 2) if avg_val else 0)
        summary_ws.append(row)

    if chart_type == 'pie':
        chart = PieChart()
    elif chart_type == 'line':
        chart = LineChart()
    else:
        chart = BarChart()

    data = Reference(summary_ws, min_col=2, min_row=1,
                     max_col=len(headers), max_row=summary_ws.max_row)
    cats = Reference(summary_ws, min_col=1, min_row=2,
                     max_row=summary_ws.max_row)

    chart.add_data(data, titles_from_data=True)
    chart.set_categories(cats)
    chart.title = "Category Performance by Department"
    summary_ws.add_chart(chart, "H2")

    # =====================================================
    # STEP 5: TOP 100 STUDENTS SHEET
    # =====================================================
    top_ws = wb.create_sheet(title='Top 100 Students')
    headers = ['Rank', 'Candidate Name', 'Reg No', 'Department', 'Category', 'Total Avg (%)', 'Feedback']
    top_ws.append(headers)
    for c in range(1, len(headers) + 1):
        top_ws.cell(row=1, column=c).font = Font(bold=True)

    all_top_students = []

    def get_feedback(avg):
        if avg >= 80:
            return 'Excellent'
        elif avg >= 60:
            return 'Good'
        elif avg >= 40:
            return 'Average'
        return 'Needs Improvement'

    for category, keywords in CATEGORY_CONFIG.items():
        qs = base_qs.filter(
            test_name__iregex=r'(' + '|'.join(keywords) + ')'
        )

        students = qs.values(
            'student_id',
            'student_id__students_name',
            'student_id__registration_number',
            'department_id__department'
        ).annotate(avg_mark=Avg('avg_mark'))

        for s in students:
            all_top_students.append({
                'name': s['student_id__students_name'],
                'reg': s['student_id__registration_number'],
                'dept': s['department_id__department'],
                'category': category,
                'avg': round(s['avg_mark'], 2) if s['avg_mark'] else 0
            })

    top_100 = sorted(all_top_students, key=lambda x: x['avg'], reverse=True)[:100]

    for idx, stu in enumerate(top_100, start=1):
        top_ws.append([
            idx,
            stu['name'],
            stu['reg'],
            stu['dept'],
            stu['category'],
            stu['avg'],
            get_feedback(stu['avg'])
        ])

    response = HttpResponse(
        content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )
    response['Content-Disposition'] = 'attachment; filename=Audio_Test_Report.xlsx'
    wb.save(response)
    return response
from django.db.models import Q
from rest_framework.decorators import api_view
from rest_framework.response import Response

@api_view(['GET'])
def get_audio_feedback_report(request):
    college_id = request.GET.get('college_id')
    department_id = request.GET.get('department')
    year = request.GET.get('year')

    if not college_id:
        return Response({"error": "college_id is required"}, status=400)

    # ‚úÖ Get Audio test names using CORRECT FK lookups
    audio_test_names = test_master.objects.filter(
        test_type_id__test_type="Audio"
    ).values_list('test_name', flat=True)

    qs = tests_candidates_map.objects.filter(
        college_id=college_id,
        is_active=True,
        test_name__in=audio_test_names
    )

    if department_id:
        qs = qs.filter(department_id=department_id)

    if year:
        qs = qs.filter(year=year)

    students = qs.values(
        "student_id",
        "student_id__students_name",
        "student_id__registration_number"
    ).distinct()

    # ‚úÖ Category mapping based on test_type_categories
    AUDIO_CATEGORY_MAP = {
        "AudioTyping": "Listening Avg",
        "Multi_AudioTyping": "Listening Avg",
        "Pronunciation": "Speaking Total Avg",
        "Multi_Pronunciation": "Speaking Total Avg",
        "AudioMCQ": "Reading Total Avg",
        "TypingBlank": "Writing Total Avg",
    }

    result = []

    for s in students:
        stu_qs = qs.filter(student_id=s['student_id'])

        category_scores = {}

        for row in stu_qs:
            tm = test_master.objects.select_related('test_type_id').filter(
                test_name=row.test_name
            ).first()

            if not tm or not tm.test_type_id:
                continue

            category_key = tm.test_type_id.test_type_categories
            category_name = AUDIO_CATEGORY_MAP.get(category_key)

            if not category_name:
                continue

            category_scores.setdefault(category_name, []).append(row.avg_mark or 0)

        # ‚úÖ Category-wise averages
        audio_avg_result = {
            k: round(sum(v) / len(v))
            for k, v in category_scores.items()
            if v
        }

        # ‚úÖ Overall audio average
        overall_avg = (
            round(sum(audio_avg_result.values()) / len(audio_avg_result))
            if audio_avg_result else 0
        )

        # ‚úÖ Feedback
        if overall_avg > 85:
            feedback = "Excellent"
        elif overall_avg > 60:
            feedback = "Good"
        elif overall_avg > 45:
            feedback = "Need to Focus"
        elif overall_avg > 30:
            feedback = "Need Improvement"
        else:
            feedback = "Very Poor"

        result.append({
            "student_id": s['student_id'],
            "students_name": s['student_id__students_name'],
            "registration_number": s['student_id__registration_number'],
            **audio_avg_result,
            "overall_avg": overall_avg,
            "feedback": feedback,
        })

    return Response({
        "results": result,
        "count": len(result)
    })
